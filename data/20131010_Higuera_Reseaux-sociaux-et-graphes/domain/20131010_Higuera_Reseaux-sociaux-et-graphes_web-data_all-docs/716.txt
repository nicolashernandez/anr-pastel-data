https://www.theses.fr/2013STET4018.pdf

Détection de communautés dans les réseaux

d’information utilisant liens et attributs

Thèse présentée devant

l’Université Jean Monnet

pour obtenir le grade de

Docteur en informatique

par

David COMBE

soutenue le 15 octobre 2013 devant le jury composé de

M. Hamamache KHEDDOUCI
M. Emmanuel VIENNET
M. Pierre MARET
Mme Christine LARGERON
M. El˝od EGYED-ZSIGMOND
M. Mathias GÉRY

Professeur des Universités
Professeur des Universités
Professeur des Universités
Professeur des Universités
Maître de conférences
Maître de conférences

Rapporteur
Rapporteur
Examinateur
Directrice
Co-directeur
Co-encadrant

Année 2013

École doctorale "Sciences, Ingénierie, Santé" 488

3

Alors que les réseaux sociaux s’attachent à représenter des entités et les relations
existant entre elles, les réseaux d’information intègrent également des attributs décri-
vant ces entités ; ce qui conduit à revisiter les méthodes d’analyse et de fouille de ces
réseaux. Dans ces travaux, nous proposons des méthodes de classification des entités
du réseau d’information qui exploitent d’une part les relations entre celles-ci et d’autre
part les attributs les caractérisant. Nous nous penchons sur le cas des réseaux à vec-
teurs d’attributs, où les entités du réseau sont décrites par des vecteurs numériques.
Ainsi nous proposons des approches basées sur des techniques reconnues pour chaque
type d’information, faisant appel notamment à l’inertie pour la classification automa-
tique et à la modularité de Newman et Girvan pour la détection de communautés.
Nous évaluons nos propositions sur des réseaux issus de données bibliographiques,
faisant usage en particulier d’information textuelle. Nous évaluons également nos ap-
proches face à diverses évolutions du réseau, notamment au regard d’une détériora-
tion des informations des liens et des attributs, et nous caractérisons la robustesse de
nos méthodes à celle-ci.

While social networks use to represent entities and relationships between them,
information networks also include attributes describing these entities, leading to re-
view the analysis and mining methods for these networks. In this work, we discuss
classification of the entities in an information network. Classification operate simulta-
neously on the relationships and on the attributes characterizing the entities. We look
at the case of attributed graphs where entities are described by numerical feature vec-
tors. We propose approaches based on proven classification techniques for each type
of information, including the inertia for machine learning and Newman and Girvan’s
modularity for community detection. We evaluate our proposals on networks from
bibliographic data, using textual information. We also evaluate our methods against
various changes in the network, such as a deterioration of the relational or vector
data, mesuring the robustness of our methods to them.

Ce travail a été partiellement soutenu par la Région Rhône-Alpes (http://www.rhonealpes.fr).

Remerciements

Je remercie d’abord Christine Largeron, ma directrice, sans laquelle rien n’aurait
été possible. J’ai pu apprécier sa détermination dans les moments où j’ai eu le plus
d’incertitudes, ainsi que son ouverture d’esprit sur le plan scientifique. Je remercie en-
suite El˝od Egyed-Zsigmond, co-directeur, qui n’a jamais hésité à braver les kilomètres
entre Lyon et Saint-Etienne. Il a toujours été disponible, en face à face comme à dis-
tance, de bon conseil, et un soutien. Je remercie aussi Mathias Géry, co-encadrant,
dont les avis et conseils ont toujours fait l’objet de beaucoup d’attention de la part de
nous tous, car il ne parle jamais pour ne rien dire.

Je remercie les personnes qui m’ont fait l’honneur de prendre part au jury. Je
remercie ainsi Emmanuel Viennet, Hamamache Kedhoucci pour leur lecture attentive
du manuscrit et leurs remarques pertinentes. Enfin, je remercie Pierre Maret de bien
avoir voulu présider ce jury.

Je tiens à remercier les très nombreuses personnes avec lesquelles j’ai partagé mes
deux bureaux. D’abord Jean-Philippe, Aurélien et Fabien déjà avec moi dans les am-
phis de la Métare, mais aussi Émilie, Stéphanie, Christophe, Laurent et Frédéric, qui
m’ont accueilli, m’ont beaucoup appris, ainsi que Chahrazed, Tung, Mattias, Vladimer,
Hao, Michael, Émilie, Taygun, Nidhal, Aytaç, Stéphanie, Natacha, Adrien, Johan, Juri,
Jan-Willem et Bert-Jan. Rien que ça. J’ai apprécié la rencontre de personnes d’horizons
aussi variés pendant ce travail, dans le laboratoire mais aussi au cours des quelques
conférences auxquelles j’ai participé.

J’ajoute un grand merci pour mes professeurs de la Faculté des Sciences, Catherine,
Fabrice, Marc S., Marc B., Baptiste, François, Philippe, Thierry, car il y a certainement
un petit bout de chacun d’eux dans dans le manuscrit, ainsi qu’à ceux qui sont arrivés
un peu tard pour que je les connaisse devant un tableau noir, Leonor, Élisa, Rémi et
Amaury. Je remercie aussi Colin de la Higuera et Jean-Christophe Janodet qui ne sont
pas pour rien dans le fait que j’ai finalement réalisé ce travail. Je remercie également
tout le personnel du laboratoire Hubert Curien.

Je remercie JC, Charlotte, Nicolas B., Nicolas D. et Jordan de m’avoir changé les
idées, ma famille, qui a enduré certainement un peu de mon stress durant cette pé-
riode, et mon papa de m’avoir fait la surprise de venir à la soutenance.

Table des matières

Introduction

1 Du réseau social au réseau d’information

1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . .
1.2 Réseau social et graphe
1.2.1 Notions relatives aux graphes . . . . . . . . . . . . . . . . . . .
1.2.2 Distances dans un graphe . . . . . . . . . . . . . . . . . . . . .
1.2.3 Mesures de centralité . . . . . . . . . . . . . . . . . . . . . . . .
1.3 Réseau d’information . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.4 Réseau bibliographique
. . . . . . . . . . . . . . . . . . . . . . . . . .
1.4.1 Base de données bibliographique d’articles et/ou méta-données
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.4.2 Un exemple : la base DBLP . . . . . . . . . . . . . . . . . . . .
1.4.3 Relations de base déductibles d’une base de données bibliogra-
phique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.4.4 Construction du jeu de données des 4 sessions . . . . . . . . . .
1.5 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

associées

2 Classification automatique et détection de communautés

2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2 Classification automatique . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.1 Principes et concepts de base . . . . . . . . . . . . . . . . . . .
2.2.2 Approches méthodologiques . . . . . . . . . . . . . . . . . . . .
2.2.3 Évaluation de la qualité d’un partitionnement . . . . . . . . . .
2.3 Détection de communautés dans les graphes . . . . . . . . . . . . . . .
2.3.1 Formalisation . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.3.2 Approches méthodologiques . . . . . . . . . . . . . . . . . . . .
2.3.3 Critères d’évaluation . . . . . . . . . . . . . . . . . . . . . . . .
2.3.4 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.4 Détection de communautés dans les réseaux d’information . . . . . . .
2.4.1 Motivations . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.4.2 Formalisation du problème de détection de communautés dans
un réseau d’information . . . . . . . . . . . . . . . . . . . . . .

15

19
19
19
20
21
21
24
24

25
26

26
28
34

37
37
37
37
39
43
53
54
54
63
66
66
66

67

8

Table des matières

2.4.3 Traitement comme un problème de partitionnement dans un
graphe après intégration des valeurs des attributs . . . . . . . .
2.4.4 Traitement comme un problème de classification automatique .
2.4.5 Extension de la méthode de détection de communautés de Lou-
vain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.4.6 Modèles statistiques
. . . . . . . . . . . . . . . . . . . . . . . .
2.4.7 Évaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.5 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

68
70

71
72
73
76

3 ToTeM

79
79
3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
80
3.2 Formalisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
82
3.3 La méthode ToTeM . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
82
3.3.1 Initialisation . . . . . . . . . . . . . . . . . . . . . . . . . . . .
82
3.3.2 Phase itérative . . . . . . . . . . . . . . . . . . . . . . . . . . .
83
. . . . . . . . . . . . . . . . . . .
3.3.3 Phase de fusion des sommets
86
3.4 Optimisation du calcul de la modularité et de l’inertie . . . . . . . . . .
89
3.5 Complexité . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
89
3.6 Critères globaux de qualité . . . . . . . . . . . . . . . . . . . . . . . . .
90
3.6.1 Indice de Calinski-Harabasz . . . . . . . . . . . . . . . . . . . .
91
3.6.2 Probabilité critique . . . . . . . . . . . . . . . . . . . . . . . . .
91
3.6.3 Score différent de la modularité . . . . . . . . . . . . . . . . . .
92
3.7 Évaluation sur des réseaux artificiels . . . . . . . . . . . . . . . . . . .
93
3.7.1 Réseau de référence (R) . . . . . . . . . . . . . . . . . . . . . .
3.7.2 Dégradation de l’information relationnelle (réseaux R.1.1 et R.1.2) 96
3.7.3 Dégradation des attributs (réseaux R.2.1 et R.2.2)
98
3.7.4 Augmentation de la taille du réseau (réseaux R.3.1 et R.3.2) . . 100
3.7.5 Augmentation du nombre d’arêtes (réseaux R.4.1 et R.4.2) . . . 101
3.7.6 Conclusion sur l’évaluation après dégradation de l’information . 102
3.7.7 Dégradation simultanée de l’information relationnelle et des va-

. . . . . . .

leurs des attributs sur un réseau de taille supérieure . . . . . . 103
3.7.8 Conclusion sur l’évaluation sur des réseaux artificiels . . . . . . 106
3.8 Évaluation un réseau bibliographique . . . . . . . . . . . . . . . . . . . 106
3.8.1 Hypothèses et scénarios . . . . . . . . . . . . . . . . . . . . . . 107
3.8.2 Méthodes comparées . . . . . . . . . . . . . . . . . . . . . . . . 108
3.8.3 Résultats expérimentaux . . . . . . . . . . . . . . . . . . . . . . 111
3.8.4 Conclusion de l’expérimentation sur le jeu des quatre sessions . 115
. . 116

3.9 Évaluation sur un autre réseau de grande taille : PubMed-Diabètes

Table des matières

9

3.9.1 Présentation du jeu de données . . . . . . . . . . . . . . . . . . 116
3.9.2 Résultat sur la vérité terrain brute (en 3 classes)
. . . . . . . . 119
3.9.3 Résultats sur la vérité terrain "connexifiée" (en 2 644 classes) . 119
3.10 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121

4 Méthode 2Mod-Louvain

123
4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
4.2 Critère de modularité basée sur l’inertie . . . . . . . . . . . . . . . . . 124
4.2.1 Distance attendue . . . . . . . . . . . . . . . . . . . . . . . . . 126
4.2.2 Bornes du critère de qualité . . . . . . . . . . . . . . . . . . . . 126
4.2.3 Propriétés du critère de qualité . . . . . . . . . . . . . . . . . . 129
4.2.4 Application sur un exemple . . . . . . . . . . . . . . . . . . . . 131
4.3 Méthode 2Mod-Louvain . . . . . . . . . . . . . . . . . . . . . . . . . . 134
135

4.3.1 Synthèse des informations de distance dans la deuxième phase
4.3.2 Optimisation de l’algorithme durant la phase itérative par calcul

incrémental du gain de modularité . . . . . . . . . . . . . . . . 136
4.4 Évaluation sur des réseaux artificiels . . . . . . . . . . . . . . . . . . . 139
4.4.1 Réseau de référence (réseau R) . . . . . . . . . . . . . . . . . . 139
4.4.2 Dégradation de l’information relationnelle (réseaux R.1.1 et R.1.2)143
4.4.3 Dégradation des attributs (réseaux R.2.1 et R.2.2)
. . . . . . . 144
4.4.4 Augmentation de la taille du réseau (réseaux R.3.1 et R.3.2) . . 145
4.4.5 Augmentation du nombre d’arêtes (réseaux R.4.1 et R.4.2) . . . 147
4.4.6 Synthèse des résultats des méthodes 2Mod-Louvain, Louvain et

des K-means et conclusion . . . . . . . . . . . . . . . . . . . . . 147
4.5 Évaluation sur des réseaux réels . . . . . . . . . . . . . . . . . . . . . . 150
4.5.1 Réseau des 4 sessions
. . . . . . . . . . . . . . . . . . . . . . . 150
4.5.2 Jeu de données PubMed-Diabètes . . . . . . . . . . . . . . . . . 151
4.6 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152

5 Conclusion et perspectives

155

A Comparaison des outils d’analyse de réseaux sociaux

159
A.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159
A.2 Notations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
A.2.1 One-mode graph . . . . . . . . . . . . . . . . . . . . . . . . . . 161
A.2.2 Two-mode graph . . . . . . . . . . . . . . . . . . . . . . . . . . 161
Le premier axiome implique que chaque élément de V est affecté à une classe. Le
second que les classes ne se recouvrent pas. Le troisième que chaque classe contient
au moins un élément de V .

Dans certains cas, le second axiome n’est pas vérifiée et un élément peut appartenir
à plusieurs classes avec un certain degré d’appartenance. On parle alors de classes em-
piètantes, ou encore de partitions floues en classification automatique (Banerjee et al.,
2005; Ruspini, 1970). De même, en détection de communautés dans les graphes, on
peut accepter qu’un sommet appartienne à plusieurs communautés formant ainsi des
communautés recouvrantes (Baumes et al., 2005; Lancichinetti et al., 2009; Reichardt
et Bornholdt, 2006; Sales-Pardo et al., 2007; Wang, 2012). Dans la suite de ce travail
nous considérerons que les classes ou les communautés recherchées forment une par-
tition au sens strict du terme.

Le nombre de partitions d’un ensemble de N éléments se calcule comme le N-
ième nombre de Bell. Celui-ci peut se calculer comme une somme de nombres dits de
Stirling de seconde espèce :

N

k=1

BN =





N
k

λk

(2.1)

2.2. Classification automatique





k

j=1

=

1
k!



jN

k

j

(−1)k−j

N
k

=

ou alors par la convergence de la formule de Dobinski :

∞

k=0

kn
k!

BN =

1
e

39

(2.2)

(2.3)

Il est intéressant de faire le lien avec le monde des probabilités en soulignant
que le N-ième nombre de Bell est aussi le moment d’ordre N d’une loi de Poisson
de paramètre N. Une distribution de probabilités peut en effet être vue comme la
partition d’un ensemble.

Parmi toutes les partitions constructibles sur V , on distinguera la partition discrète
PD qui est la partition unique dans laquelle il y a autant de classes que d’éléments et
où chaque classe contient un seul élément. De même on distingue la partition grossière
PG qui est la partition unique dans laquelle tous les objets font partie de la même
classe.

Notons que la classification automatique, appelée aussi classement non supervisé,
diffère du classement supervisé. Dans ce second cas, on connaît le nombre de classes
et on dispose d’un échantillon d’éléments de la population V appelé échantillon d’ap-
prentissage, pour lesquels on connaît à la fois la représentation et la classe d’apparte-
nance. On peut alors utiliser cette information pour élaborer une procédure permet-
tant de déterminer la classe d’un élément quelconque de la population à partir de sa
représentation.

Par contre, dans le cas de la classification non supervisé qui nous intéresse, on
ne dispose pas d’un échantillon d’apprentissage et le nombre de classes est le plus
souvent inconnu. Néanmoins, certaines méthodes de classification ont besoin de cette
dernière information comme paramètre.

2.2.2 Approches méthodologiques

Deux types de résultats peuvent être produits par un algorithme de classification
automatique. Le premier est une partition, qui décrit uniquement les groupes d’élé-
ments et fournit la classe d’affectation de chacun des éléments. Le second est une
hiérarchie comprenant une suite de partitions. Dans ce cas, les différents niveaux de
partitionnement, de différentes finesses, sont imbriqués les uns dans les autres. L’inté-
rêt de cette approche est qu’elle permet de choisir plusieurs solutions en fonction du
degré de finesse voulu.

Une hiérarchie est une famille totalement ordonnée de partitions H = {P1, . . . , Pn}

40

Chapitre 2. Classification automatique et détection de communautés

telle que P1 est la partition discrète, PN est la partition grossière et pour i =
1, . . . , N − 1 on a Pi est plus fine que Pi+1 au sens de la comparaison des parti-
tions.

En fonction du résultat produit, on distingue donc parmi les méthodes de classifi-
cation non supervisées les méthodes hiérarchiques des méthodes non hiérarchiques.
Les premières peuvent être ascendantes si à partir de la partition discrète elles
aboutissent par agglomérations successives à la partition grossière ou au contraire
descendantes si elles consistent à procéder par division de la partition grossière jus-
qu’à la partition discrète. La seconde catégorie de méthodes, dites non hiérarchiques,
regroupe celles qui peuvent fournir directement une partition. Ces dernières sont
souvent itératives et leur exécution demande en général la connaissance a priori du
nombre de classes à produire.

Dans la suite nous détaillons uniquement les méthodes auxquelles nous avons eu

recours.

2.2.2.1 Classification hiérarchique

La classification hiérarchique ascendante est une méthode de classification qui
consiste, à partir de la partition discrète, à regrouper les classes les plus proches, en
utilisant une distance entre éléments (voir section 1.4.4.2) et une fonction que l’on
appelle mesure d’agrégation permettant de comparer des groupes d’éléments entre
eux.

Le principe de la classification hiérarchique ascendante est décrit dans l’algo-

rithme 1.

Algorithme 1 : Classification hiérarchique ascendante

Entrées : un ensemble d’éléments V
Sorties : un ensemble de partitions contenant de N à 1 classes
on calcule la matrice des distances entre les éléments de V ;
P ← partition discrète ;
tant que |P| ̸= 1 faire

P ← fusionner les deux classes les plus proches de P au sens de la mesure
d’agrégation ;
mettre à jour la matrice des mesures d’agrégation ;

1

2

3

4

5

Dans le cadre de la classification hiérarchique ascendante, le choix de la distance
est à la discrétion de l’utilisateur. Celle-ci dépendra de la nature de la représentation
des éléments. Dans le cas de vecteurs numériques, on utilisera souvent la distance

2.2. Classification automatique

41

euclidienne ou dans le cas de documents décrits par des sacs de mots la distance du
cosinus.

De plus la méthode requiert le choix d’un critère d’agrégation. Plusieurs critères

d’agrégation se sont imposés au fil du temps.

Le lien minimum est une mesure d’agrégation qui associe à deux classes Ck et Cl
le minimum des distances entre paires d’éléments composées d’un élément de chaque
classe. Le lien maximum associe à deux classes Ck et Cl le maximum de ces distances.
La première mesure consiste à agréger les deux classes ayant les deux éléments
les plus proches. La seconde mesure agrège les deux classes entre lesquelles les deux
éléments les plus éloignés sont les plus proches.

Smin(Ck, Cl) = minv∈Ck,v′∈Cld(v, v′)

Smax(Ck, Cl) = maxv∈Ck,v′∈Cld(v, v′)

(2.4)

(2.5)

Le lien moyen est une mesure d’agrégation qui utilise la moyenne arithmétique

des distances (Sokal et Michener, 1958) :

Smoy(Ck, Cl) =

1

|Ck| · |Cl|





v∈Ck

v∈Cl

d(v, v′)

(2.6)

La mesure de Ward est aussi connue sous le nom de construction hiérarchique du

moment d’ordre deux (Ward, 1963). Elle est définie par :

SW ard(Ck, Cl) =

mk · ml
mk + ml

· d(gCk , gCl)

(2.7)

où mk et ml sont les masses des deux classes, c’est-à-dire le nombre d’éléments qu’elles
contiennent.

Cette mesure présente l’avantage de pouvoir être interprétée en terme d’optimi-
sation d’inertie : elle conduit à maximiser l’inertie interclasses définie dans la sec-
tion 2.2.3.1.

Il n’y a pas de critère d’agrégation fondamentalement meilleur que les autres. Le
choix sera fait selon la nature des données ou des caractéristiques recherchées dans le
résultat.

On préfère souvent la classification ascendante à la classification descendante pour
une raison de complexité (Cailliez et al., 1976). En effet, pour une partition donnée, il
existe moins de possibilités différentes de choisir deux classes à fusionner (N×(N−1))
que de façons de scinder en deux l’une des classes.

42

Chapitre 2. Classification automatique et détection de communautés

2.2.2.2 Partitionnement non-hiérarchique de type nuées dynamiques

Il est possible de classifier des éléments sans se placer dans le paradigme hiérar-
chique, notamment en adoptant une approche qui produit directement une partition.
C’est le cas de la méthode des centres mobiles et de ses dérivés qui produisent des
classes non pas par agrégation ou division, mais en partant d’une séparation initiale
arbitraire des éléments en k classes, qui est ensuite raffinée.

Centres mobiles

À partir des centres (souvent appelés centroïdes) de classes, le principe des centres
mobiles consiste itérativement à affecter les individus au centre le plus proche puis à
recalculer les centres (Forgy, 1965).

L’algorithme commence par sélectionner aléatoirement k centres. Deux étapes

sont ensuite répétées jusqu’à convergence :

– l’assignation de chaque élément à la classe ayant le centre le plus proche,
– la mise à jour du centre de chacune des classes.
On cherche à minimiser l’inertie intraclasses :



C∈P



v∈C

arg min

P

mk

d (v − gC)2

(2.8)

où mk représente la masse de la classe Ck.

On note que l’on distingue parfois l’algorithme des centres mobiles dû à Forgy de
celui des K-means dû à MacQueen qui en est une variante où un seul élément est
inséré à chaque itération et les centres sont recalculés à chaque insertion.

Les centres mobiles ont pour inconvénient le fait qu’il faut connaître k, le nombre
de classes, à l’avance. De plus, l’algorithme est sensible à son initialisation, à savoir le
choix des centres, ce qui le rend de plus non déterministe.

Il existe une variante plus longue, mais donnant souvent de meilleurs résultats
de l’algorithme des K-Means intitulée les K-Means bissectifs (Steinbach et al., 2000).
Cette adaptation consiste, pour un nombre de classes à produire supérieur à 2, à
opérer récursivement la méthode des K-means, de façon à bénéficier des possibilités
du modèle hiérarchique. Une classe est alors divisée en deux à chaque opération.

X-means est une autre variante des K-means qui ne nécessite pas de connaître
à l’avance le nombre de classes à produire (Pelleg et Moore, 2000). Le principe est
d’ajouter graduellement de nouveaux centroïdes et de mesurer si leur ajout est béné-
fique pour la classification selon un critère statistique. Pour cela, deux méthodes sont
proposées. La première consiste à prendre un centre, puis à introduire un nouveau
centre dans son voisinage immédiat, et à regarder si le modèle produit est meilleur

2.2. Classification automatique

43

que le modèle précédent. Si c’est le cas, le nouveau centre est conservé. La deuxième
méthode consiste à retenir un nombre significatif (on propose alors la moitié) des
centres existants, sélectionnés selon une heuristique pour bien se prêter à un "dédou-
blement". Si le dédoublement des centres choisis a engendré une meilleure partition
que la précédente, alors elle devient la nouvelle partition de référence.

Nuées dynamiques

Les nuées dynamiques sont une variante des K-means où une classe n’est plus
représentée par un centroïde mais par un ensemble d’individus (Diday, 1971). Le but
est de mieux représenter la classe que par son seul centre, qui peut être extérieur à la
population.

Cet ensemble, appelé noyau, est choisi au hasard à l’intérieur de chaque groupe.
La distance entre un point et le centre de la classe que l’on calculait dans les K-means
est remplacée par une distance moyenne avec les points qui composent le noyau.

2.2.3 Évaluation de la qualité d’un partitionnement

Après avoir construit une partition ou un ensemble de partitions à l’aide d’une
méthode, il convient d’évaluer la qualité de ce partitionnement. Pour ce faire, on peut
faire appel à des critères internes ou externes. Les premiers permettent d’évaluer, sur-
tout relativement à d’autres, la qualité de la partition proposée. Les scores maximaux
permis par ces mesures ne sont généralement pas atteignables dans des réseaux réels.
Les seconds permettent de comparer le résultat obtenu avec un résultat attendu, dans
notre cas une partition faisant office de "vérité terrain".

Les critères internes peuvent eux-mêmes être subdivisés en critères dont l’usage
est spécifique à une distance particulière, ou à une méthode de classification spéci-
fique. C’est le cas de l’inertie interclasses, présentée dans la section 2.2.3.1. Les autres
critères, non spécifiques à une topologie des données, peuvent être utilisés pour une
distance quelconque définie entre les objets a été définie. C’est le cas des indices de
Dunn, de Davies et Bouldin, de Silhouette.

2.2.3.1 Critères d’évaluation internes

Les mesures d’inertie

Les notions d’inertie totale, intraclasses et interclasses étant largement utilisées

ensuite, nous les rappelons brièvement.

Étant donné V = {v1, . . . , vn} un ensemble fini d’éléments de R|T| formant une
partition en r classes P = {C1, . . . , Cr} de centres de gravité ou moyennes respectifs

44

Chapitre 2. Classification automatique et détection de communautés

g1, . . . , gr. On note g le centre de gravité ou moyenne de V .

L’inertie interclasses Iinter d’une partition P permet de caractériser la séparation

entre les classes de P.
Elle est définie par :

r

k=1

Iinter(P) =

mk ∥gk − g∥2

(2.9)

où gk est le centre de gravité de la classe Ck et mk est la masse qui lui est associée.

Une inertie interclasses forte traduit des classes aussi distinctes que possible. Une
inertie interclasses faible, 0 au minimum, correspond à des classes ayant la même
moyenne, égale à la moyenne de la population.

Ainsi, pour être une bonne classification, une partition doit avoir une inertie inter-

classes forte.

L’inertie intraclasses Iintra d’une partition P est la moyenne pondérée des inerties
internes à chaque classe. Elle permet de mesurer la variabilité des valeurs à l’intérieur
des classes. Alors on a :

k=1
où I(Ck) est l’inertie de la classe définie par :

r

Iintra(P) =

mk · I(Ck)

mv · d2(v, gk)



v∈Ck



v∈V

(2.10)

(2.11)

(2.12)

De même l’inertie totale associée à V est définie par :

I(V ) =

mv · d2(v, g)

D’après le théorème de Konig Huygens l’inertie totale de V est égale à la somme

de l’inertie intraclasses et de l’inertie interclasses :

I(V ) = Iintra(P) + Iinter(P)

(2.13)

Il est donc équivalent de maximiser l’inertie interclasses ou de minimiser l’inertie

intraclasses.

L’inertie interclasses (voir section 2.2.3.1) peut donner une indication sur la bonne
séparation des classes. Cependant, pour des nombres de classes différents, son utilisa-
tion ne permettra pas de comparer deux partitions. En particulier, la partition grossière
obtient toujours la plus faible inertie interclasses, égale à zéro.

2.2. Classification automatique

45

Indice de Silhouette

L’indice de Silhouette sert à caractériser la séparation des classes ainsi que le fait

que celles-ci soient compactes (Rousseeuw, 1987; Elghazel, 2007).

Pour tout élément v de l’ensemble V , Rousseeuw définit l’indice de Silhouette par :

silhouette(v) =

b(v) − a(v)

max(a(v), b(v))

(2.14)

où a(v) est la dissimilarité moyenne entre l’individu v ∈ V et tous les autres
individus de la classe c(v) à laquelle il appartient, et b(v) est le minimum des distances
de v aux éléments relevant d’une autre classe que la sienne.

L’indice de Silhouette d’une classe Ck est égal à la moyenne des indices de sil-

houette des individus qui la composent :

∀Ck ∈ P, silhouette(Ck) =



v∈Ck

silhouette(v)
|Ck|

(2.15)

De la même façon, l’indice de silhouette de la partition P est la moyenne des

indices de silhouette des classes qui la composent :

silhouette(P) =

ΣCk∈P silhouette(Ck)

|P|

(2.16)

silhouette(v) varie entre -1 et 1. Une valeur proche de 1 signifie que l’élément est
bien classé, 0 signifie que l’élément se situe entre deux classes et -1 que l’élément est
mal classé.

Pour l’indice de Silhouette, les éléments d’une bonne classe doivent avoir entre
eux une distance moyenne faible tandis que la distance moyenne doit être plus grande
entre eux et les éléments d’autres classes.

C’est un indice simple qui rend bien compte de la séparation et de la cohésion des
classes. En adaptant les mesures de dissimilarité, l’indice de Silhouette est applicable
à un large éventail de méthodes de classification.

Cependant, le calcul de l’indice de Silhouette a une complexité importante. Al-
meida et al. soulignent aussi le fait que des problèmes apparaissent lorsque l’on ma-
nipule des partitions où existent des classes singletons (Almeida et al., 2011).

Indice de Dunn

L’indice de Dunn s’attache à la caractérisation du fait que des classes soient com-
pactes et bien séparées (Dunn, 1973). C’est le rapport entre la plus petite distance
interclasses d(Ck, Cl) et la plus grande distance intraclasses d′(Ck).

46

Chapitre 2. Classification automatique et détection de communautés

Dunn(P) =

mink=1,..,r;l=1,..,r;k̸=ld(Ck, Cl)

maxk=1,..,rd′(Ck)

(2.17)

Plus la valeur de l’indice est élevée, meilleure est la classification. C’est un indice
qui n’utilise pas une mesure prédéfinie. Il peut donc être utilisé avec différents algo-
rithmes. Un inconvénient inhérent à l’indice de Dunn est qu’il dépend d’un nombre
très limité d’éléments. Pour cette raison, il est dit non robuste. Toujours pour cette
raison, il peut s’avérer difficile de comparer des partitions avec cet indice.

Indice de Davies et Bouldin

L’indice de Davies et Bouldin est proche de l’indice de Dunn mais ce sont les paires

de classes qui sont considérées (Davies et Bouldin, 1979). Il est défini par :



Ck∈P

 d′(Ck) + d′(Cl)



d(Ck, Cl)

DB(P) =

1
|P|

maxCl∈P,Cl̸=Ck

(2.18)

où d(Ck, Cl) est une distance interclasses, par exemple la distance entre les centres de
gravité, et d′(Ck) est une distance intraclasse, par exemple le diamètre intraclasse.

2.2.3.2 Critères d’évaluation externe, par rapport à une vérité terrain

Bien que l’on considère un cadre non supervisé, on peut parfois disposer d’une
partition de référence servant de vérité terrain. Cette partition peut être produite par
des experts ou par un générateur. L’évaluation du résultat d’un algorithme de classifi-
cation est effectuée vis-à-vis de cette partition faisant office de vérité terrain.

Nous notons catv la catégorie du sommet v dans la partition de la vérité terrain.
Nous verrons d’abord les solutions basées sur un appariement entre les catégories
réelles et les classes produites. Les indices que nous présenterons ensuite, plus évo-
lués, reposent sur trois approches principales. La première d’entre elles est l’approche
combinatoire initiée par Rand, tirant parti des informations dont on dispose sur les
paires d’individus. La deuxième est une approche probabiliste axée sur l’information
mutuelle et la troisième utilise la théorie de l’information, dans laquelle la notion d’en-
tropie a une place importante. Les problématiques liées à l’évaluation touchant toutes
les sciences, les travaux mentionnés ici font l’objet de publication dans des revues et
conférence aux thématiques très larges.

Tous les indices décrits ici donnent un score identique en cas de permutation des
classes à l’intérieur des partitions, car les partitions sont des ensembles non ordonnés
de classes. Hormis l’homogénéité et la complétude, qui sont des sous-indices pour la V-
mesure, ils sont également symétriques : on peut inverser l’ordre de leurs arguments.

2.2. Classification automatique

47

Taux d’éléments bien classés

Le taux d’éléments bien classés T BC(P) est le rapport entre le nombre d’éléments

bien classés et le nombre total d’éléments classés.

T BC(P) =

card({v ∈ V |catv = cv})

|V |

(2.19)

Ce taux peut être mesuré à partir de la matrice de coïncidence ou matrice de
confusion Mc dont chaque ligne correspond à une catégorie, chaque colonne à une
classe. Le terme Mc(i, j) contiendra le nombre d’éléments de la catégorie i qui ont
été affectés à la classe j. Chaque catégorie de la vérité terrain est associée à une
classe produite par la classification. La matrice n’est pas forcément carrée, l’algorithme
évalué pouvant produire un nombre de classes différent de celui de la vérité terrain.

Cette mesure a l’avantage de s’appuyer sur une réalité concrète.
Mais cette façon d’évaluer la qualité d’une classification a des inconvénients. D’abord,

cette approche soulève le "problème d’appariement" (matching problem), qui consiste
à faire correspondre des catégories réelles à des classes produites. Les éléments biens
classés dans des classes mal appariées sont systématiquement négligés dans ce critère.
De plus, si les effectifs dans les classes sont déséquilibrés, on peut obtenir de fort
taux de bien classés, uniquement en classant selon la partition grossière. Par exemple,
dans le cadre d’un partitionnement en deux classes, si on a 5 éléments dans la pre-
mière catégorie réelle et 95 dans la seconde catégorie, alors la comparaison avec une
classe produite contenant la totalité de l’effectif produira un score de 95%.

Pureté

Une autre mesure d’évaluation de la qualité d’un partitionnement est la pureté.
Pour la calculer, on cherche la catégorie réelle majoritaire Ck qui appartient à P1
l de la partition P2 produite par l’algorithme. La

dans chacune des classes produites C′
pureté est définie par :



l∈P2
C′

P uret´esimple(P1, P2) =

1
N

maxCk∈P1|Ck ∩ C′
l|

(2.20)

Une autre façon de mesurer la pureté est définie par la probabilité, étant don-
née une catégorie de P1, que deux objets tirés au hasard sans remise soient de la
même classe de P2 (Solomonoff et al., 1998; Forestier et al., 2010). Cette définition
a l’avantage de prendre en compte le fait qu’un couple d’objets, mal classés car non
majoritaires dans leur classe, aient néanmoins été classés ensemble.

La pureté est un indice très intuitif et facile à calculer à partir de la matrice de

48

Chapitre 2. Classification automatique et détection de communautés

coïncidence. Elle prend une valeur maximale égale à 1 lorsque toutes les classes de la
partition sont pures. C’est une mesure dont l’usage doit être restreint à la comparaison
de partitions ayant le même nombre de classes.

Les deux mesures précédentes sont plus faciles à utiliser dans un contexte super-

visé que dans un contexte non supervisé.

Indice de Rand

Une autre mesure de concordance entre deux partitions est l’indice de Rand. Celui-
ci est simplement le taux de paires d’éléments qui sont en accord, c’est-à-dire associés
à la fois dans P1 et P2 ou séparés à la fois dans P1 et P2.

Ainsi, on définit les quatre configurations possibles pour les paires :
– A : nombre de paires d’éléments classés ensemble à la fois dans P1 et P2
– B : nombre de paires d’éléments présents dans des classes différentes dans P1

et dans P2

– C : nombre de paires d’éléments présents dans des classes différentes dans P1

mais présents dans une même classe dans P2.

– D : nombre de paires d’éléments présents dans une même classe dans P1 mais

présents dans des classes différentes dans P2.

L’indice de Rand associé à deux partitions P1 et P2 est défini par :

Rand(P1, P2) =

A + B

A + B + C + D

(2.21)

Il varie entre 0 et 1 et prend la valeur maximale en cas de concordance des parti-

tions.

C’est un indice qui ne demande pas d’établir un appariement entre les classes
réelles et les classes prédites, car seule est prise en compte la classification commune
ou différente des paires d’éléments dans les deux partitions.

Cependant, l’indice est basé sur les paires d’objets, et non sur les objets eux-mêmes.
De plus, une simple inversion de classification pour deux éléments dans deux classes
de petites tailles sera bien moins pénalisée que si elle se produit dans des classes de
grandes tailles par exemple.

Indice de Rand ajusté

Dans la mesure où l’indice de Rand varie de façon très importante sur deux parti-
tions tirées au hasard, ce que Vinh appelle la "constant baseline property", une version
"ajustée" a été créée dont l’espérance est nulle lorsque les partitions sont sélectionnées
au hasard (Hubert et Arabie, 1985). L’indice de Rand ajusté (Adjusted Rand Index) ou

2.2. Classification automatique

49

ARI est une adaptation de l’indice de Rand conçue pour être insensible au nombre de
classes. Il a pour formule générale :

Indice ajusté =

Indice − Indice attendu

Indice maximum − Indice attendu

(2.22)

La conception de la mesure suppose l’usage de la distribution hypergéométrique,
qui fixe les chances de sortie de chacune des partitions avec un nombre de classes fixé.
L’ARI est définie par :



ARI(P1, P2) =

RI(P1, P2) − E(RI(P1, P2)||P1|,|P2|)
RI(P1, P2) − E(RI(P1, P2)||P1|,|P2|)
Ck∈P1


]/N
|Ck∩Cl|
]/N
 +
|Cl|
|Ck|
 est le nombre de façons de choisir x éléments
où |C| est la cardinalité de C et y

 − [
] − [
|Cl|


|Ck|



Cl∈P2

2 [

1

Ck,Cl∈P1×P2

|Ck|

2

2
(2.24)

|Cl|

2
Ck∈P1

2
Cl∈P2

Ck∈P1

2

2

Cl∈P2

2

=

(2.23)

2



2

x

parmi y.

Si les partitions sont identiques, le score vaut 1. L’ARI est une mesure corrigée
pour la chance : l’espérance de l’ARI de deux partitions tirées aléatoirement vaut 0.
Cependant certaines paires de partitions ont une valeur d’ARI négative. La correction
proposée ne corrige pas les problèmes de distribution présents dans l’intervalle [0, 1]
(Meil˘a, 2007).

Entropie

Plusieurs mesures importantes de l’état de l’art, reposant sur des fondements pro-
babilistes, sont définies par rapport à l’entropie de Shannon (Shannon et Weaver,
1949). Celle-ci est définie pour une variable X prenant n valeurs {x1, . . . , xn} avec
des probabilités respectives {p(x1), . . . , p(xn)} par :

H(X) =

p(xi)log

(2.25)

Pour deux variables X et Y , où p(xiyj) désigne la probabilité conjointe que X

prenne la valeur xi et Y la valeur yj, l’entropie conjointe est définie par :

n

i=1

nx

ny

i=1

j=1

 1



pxi





1

p(xi, yj)

H(X, Y ) =

p(xi, yj)log

(2.26)

C’est à partir de ces deux mesures qu’est construite l’information mutuelle.

50

Chapitre 2. Classification automatique et détection de communautés

Elle mesure la dépendance de deux variables aléatoires X et Y par :

M I(X, Y ) = H(X) + H(Y ) − H(X, Y )

(2.27)

M I(X, Y ) est d’autant plus élevée que X et Y sont liées et elle est nulle si X et Y

sont indépendantes.

Définissons P (Ck) =

|Ck|
N la probabilité qu’un objet choisi au hasard appartienne à

|Ck|



N

|Ck|
N

log

L’entropie conjointe de deux partitions P1 et P2 est donc :

Ck∈P

la classe Ck. Alors l’entropie associée à P est égale à :

P (Ck)log(P (Ck)) = − 
H(P) = − 
H(P1, P2) = − 

l)
l)logP (Ck, C′

v ∈ V |v ∈ Ck, v ∈ C′
= − 


P (Ck, C′

l∈P2
C′

Ck∈P1

Ck∈P

l

Ck∈P1

l∈P2
C′

N

v ∈ V |v ∈ Ck, v ∈ C′



(2.29)



l

N

(2.30)

log

Information mutuelle normalisée (NMI) et information mutuelle

L’information mutuelle normalisée (Normalized Mutual Information, NMI), est une

mesure dérivée de la notion d’information mutuelle (MI) (Strehl et Ghosh, 2003).

Soit l’information mutuelle définie par :





|{v ∈ V |v ∈ Ck, v ∈ Cl}|

log

Ck∈P1

l∈P2
C′

N

M I(P1, P2) =

v ∈ V |v ∈ Ck, v ∈ C′

 · N

l



|Ck| · |C′
l|

(2.28)

(2.31)

(2.32)

alors la NMI est :

N M I(P1, P2) =

H(P1)H(P2)

M I(P1, P2)

où M I est l’information mutuelle et H est la mesure d’entropie.

Vinh et al. listent des variations de cette formulation où la racine carrée est rempla-
cée par le minimum, le maximum, etc. (Vinh et al., 2010). La NMI montre cependant
un biais lorsque l’on compare des partitions avec des nombres de classes différents
(Vinh et al., 2009).

2.2. Classification automatique

51

Information mutuelle ajustée (AMI)

L’information mutuelle ajustée (Adjusted Mutual Information) est une mesure ba-

sée sur la notion d’information mutuelle (Vinh et al., 2010).

L’AMI est la version corrigée par Vinh et al. de la NMI, selon la formule de la
correction pour la chance proposée par Hubert et al. (voir formule 2.22) (Hubert et
Arabie, 1985).

AM I(P1, P2) =

M I(P1, P2) − E{M I(P1, P2)}

max{H(P1), H(P2)} − E{M I(P1, P2)}

(2.33)

où M I est l’information mutuelle, H est la mesure d’entropie et E est l’espérance
mathématique.

Deux partitions aléatoires selon la distribution hypergéométrique obtiennent alors
des scores identiques, mais cette correction peut faire perdre aux mesures certaines
propriétés.

V-mesure

La V-mesure est une mesure basée sur la notion d’entropie et les travaux de la
théorie de l’information (Rosenberg et Hirschberg, 2007). Elle est calculée à partir de
deux sous-indices, l’homogénéité et la complétude. Quelles que soient deux partitions
P1 et P2, l’homogénéité et la complétude sont liées par la relation :

homog´en´eit´e(P1, P2) = compl´etude(P2, P1)

(2.34)

Par la suite, on considérera P1 comme la partition réelle et P2 comme la partition

produite par la méthode de classification.

Homogénéité

Pour satisfaire le critère d’homogénéité, une classification doit assigner seulement
les éléments appartenant à une même catégorie à une même classe. Une communauté
est dite homogène, avec un score d’homogénéité égal à 1, si elle ne contient que des
membres issus d’une même classe. On notera que la partition discrète est totalement
homogène.

L’homogénéité est calculée comme suit :



homog´en´eit´e(P1|P2) =

1
1 − H(P1|P2)
H(P1)

si H(P1|P2) = 0
sinon

(2.35)

52

Chapitre 2. Classification automatique et détection de communautés

où H(P1) est l’entropie de P1 et H(P1|P2) est l’entropie conditionnelle de P1
sachant P2 définie par :

(2.36)

H(P1|P2) = − 

Cl∈P2



|Ck ∩ Cl|

Ck∈P1

N

log

Complétude







|Ck ∩ Cl|
Ck∈P1

|Ck ∩ Cl|

Pour satisfaire la notion de complétude, une classification doit affecter tous les
éléments appartenant à une même catégorie réelle dans une même classe prédite.
On notera que la partition grossière est totalement "complète". La complétude étant
symétrique à l’homogénéité, sa définition est analogue à celle-ci.

La V-mesure est définie comme la moyenne harmonique des indices précédents.

Dans nos expérimentations nous utilisons la formule suivante :

V M (P1, P2) = 2 · homog´en´eit´e(P1, P2) · compl´etude(P1, P2)
homog´en´eit´e(P1, P2) + compl´etude(P1, P2)

(2.37)

Rosenberg et Hirschberg exposent l’intérêt de la V-mesure sur l’exemple de la fi-
gure 2.1. La comparaison est opérée face à la F-mesure, qui est une fonction de la
précision (taux d’éléments de la catégorie dans la classe) et du rappel (taux d’élé-
ments de la catégorie correctement identifiés) (Van Rijsbergen, 1979).

FIGURE 2.1 – Le problème d’appariement (par Rosenberg et al.)

Cet exemple souligne que, dans le cas où il vaut mieux éclater des classes non

SolutionASolutionBF-Measure=0.5F-Measure=0.5V-Measure=0.14V-Measure=0.39SolutionCSolutionDF-Measure=0.6F-Measure=0.6V-Measure=0.30V-Measure=0.412.3. Détection de communautés dans les graphes

53

homogènes, quitte à créer des classes composées d’éléments isolés, alors la V-mesure
est plus pertinente que la F-mesure.

Selon Rabbany et al., le choix des critères de validité dépend grandement des jeux

de données et il doit être fait en fonction de l’application (Rabbany et al., 2012).

Les conclusions de Almeida et al., étudiant la question à partir d’un réseau de col-
laboration scientifique et d’un réseau de partage de fichiers en pair à pair, vont dans le
même sens (Almeida et al., 2011). Ils pointent le mauvais degré de précision apportée
dans la caractérisation des communautés par ces indices qui paraissent biaisés.

L’évaluation interne est elle aussi très dépendante de la notion de bonne parti-
tion que l’on retient. L’évaluation selon un critère externe parait donner lieu à moins
de débats, à condition de retenir des mesures corrigées envers les biais statistiques
provoqués par les déséquilibres dans les effectifs des classes (corrections envers la
"chance").

2.3 Détection de communautés dans les graphes

L’objectif de la détection de communautés dans les graphes, ou encore dans les ré-
seaux sociaux, est de créer une partition des sommets, en tenant compte des relations
qui existent entre les sommets dans le graphe, de telle sorte que les communautés
soient composées de sommets fortement connectés et qu’elles soient peu reliées entre
elles (Brandes et al., 2003; Newman, 2004; Schaeffer, 2007; Lancichinetti et Fortu-
nato, 2009). Parmi les principales méthodes de détection de communautés proposées
dans la littérature, on peut citer celles qui optimisent une fonction de qualité pour
évaluer la qualité d’une partition donnée, comme la modularité, la coupe ratio, la
coupe min-max ou la coupe normalisée (Kernighan et Lin, 1970; Chan et al., 1994;
Shi et Malik, 2000; Ding et al., 2001; Newman et Girvan, 2004), les techniques hié-
rarchiques comme les algorithmes de division (Flake et al., 2003), les méthodes spec-
trales (Von Luxburg, 2007) ou l’algorithme de Markov et ses extensions (Satuluri et
Parthasarathy, 2009). Ces techniques de partitionnement de graphes sont très utiles
pour détecter des composantes fortement connectées dans un graphe.

Cette section est consacrée à la détection de telles communautés qui repose donc
uniquement sur les arêtes et leur disposition dans et entre les classes. Deux sommets
classés ensemble doivent être plus liés entre eux, directement ou par l’intermédiaire
d’autres sommets, que vis-à-vis de sommets placés dans d’autres classes.

Nous présenterons les méthodes importantes du domaine en mettant l’accent sur
celles qui optimisent un critère de qualité de la partition, notamment la modularité
puisque nos propositions utilisent ce critère, en section 2.3.2. Nous évoquerons les
possibilités d’évaluation des partitions obtenues en section 2.3.3 après avoir défini

54

Chapitre 2. Classification automatique et détection de communautés

plus formellement le problème.

2.3.1 Formalisation

Soit un graphe G = (V, E). On cherche une partition P de V telle que chaque
classe C de P renferme les deux extrémités d’un grand nombre d’arêtes, tandis que
les arêtes ayant des extrémités dans deux classes différentes soient aussi rares que
possible.

Dans la réalité, une partition prise au sens de la définition donnée à la section 2.2.1
correspond d’assez loin à la transposition mathématique du terme communauté. En
effet, en général, les individus peuvent appartenir à différents groupes d’individus.
On peut ainsi être chanteurs et danseurs, étudiant et actif, ligérien et rhodanien, etc.
Un cadre souvent utilisé pour pallier à de tels cas de figure est celui des communautés
recouvrantes. Récemment, de nombreux travaux se sont intéressés à la détection de
ce type de communautés (Wang et Fleury, 2009), mais ce ne sera pas le cas dans cette
thèse.

2.3.2 Approches méthodologiques

La classification des sommets d’un graphe est un domaine plus jeune que la classi-

fication non supervisée de données vectorielles.

Comme la nature des données considérées est différente, il n’y a pas d’équivalence
d’un problème vers l’autre qui permettrait d’adapter toutes les méthodes efficaces sur
les vecteurs vers les graphes et inversement.

Fortunato propose un panorama large mais néanmoins détaillé des solutions qui y
sont apportées (Fortunato, 2009). Porter et al. proposent eux aussi une étude détaillée
(Porter et al., 2009).

Dans de nombreux travaux, la classification de sommets dans un graphe est consi-
dérée sous l’angle d’un problème d’optimisation. Une fonction associée à une partition
des sommets du graphe procure ainsi un score qui mesure la qualité de la partition.
L’un des premiers critères utilisés a été celui de la coupure minimum (Newman, 2004),
dont des extensions ont été proposées ensuite, comme le ratio cut et le normalized cut
(Chan et al., 1994; Shi et Malik, 2000). Selon ce critère, la meilleure partition en k
classes d’un graphe est celle qui est obtenue en retirant un nombre minimal d’arêtes
dans le graphe d’origine de façon à obtenir k composantes non connexes. Il ne sera
pas question ici des méthodes génériques appliquées expressément aux graphes (mé-
thodes hiérarchiques sur la distance du plus court chemin, etc.) mais plutôt de celles
liées à nos propres travaux basés notamment sur la modularité.

2.3. Détection de communautés dans les graphes

55

Nous présentons maintenant le critère de modularité QN G, critère qui est au cœur
de cette thèse tel qu’il a été défini par Newman et Girvan (Newman et Girvan, 2004).

2.3.2.1 Modularité

Comment juger quantitativement si il est plus judicieux de partitionner un graphe

d’une façon (voir figure 2.2a) ou d’une autre (voir figure 2.2b) ?

(a) Partition en 2 groupes

(b) Partition en 3 groupes

FIGURE 2.2 – Pourquoi la partition (a) est-elle la plus mauvaise ?

Pour répondre à cette question, on peut utiliser la modularité QN G, proposée par

Newman et Girvan (Newman et Girvan, 2004; Newman, 2006).

C’est une mesure qui a pour but de caractériser l’efficacité d’une partition des
sommets d’un graphe au regard de la densité des liens à l’intérieur des groupes et du
nombre de liens entre ces groupes, ainsi que vis-à-vis du degré des sommets pris en
compte.

Elle compare la proportion des arêtes du réseau qui relient des sommets issus
d’une même communauté à la proportion attendue dans un graphe équivalent dans le
sens où les sommets ont la même distribution des degrés mais où les arêtes auraient
été placées aléatoirement entre tous les sommets.

La modularité QN G se calcule comme suit :









v,v′

QN G =

1
2M

Avv′ − k(v) · k(v′)

2M

· δ(c(v), c(v′))

(2.38)

où le couple (v, v′) court sur toutes les paires de sommets de V × V (de façon à
prendre également les boucles en compte). M est la somme des valuations des arêtes,
A est la matrice d’adjacence, c(v) désigne la classe du sommet v et δ est la fonction

n15n16n17n18n19n20n21n24n25n27n28n29n30n32n33n34n35n36n37n15n16n17n18n19n20n21n24n25n27n28n29n30n32n33n34n35n36n3756

Chapitre 2. Classification automatique et détection de communautés

de Kronecker qui vaut 1 si ses arguments sont égaux et 0 sinon.

La modularité prend sa valeur entre -1 (toutes les arêtes sont intercommunau-
taires) et 1 (toutes les arêtes sont intracommunautaires). La modularité vaut 1 dans
un graphe partitionné de manière à ne pas avoir d’arête placée entre 2 sommets de
communautés différentes (mais au moins une dans une communauté). La modularité
vaut zéro pour la partition grossière. C’est aussi la valeur vers laquelle tend la modu-
larité d’une partition aléatoire. D’après Newman et al., les valeurs de modularité pour
des réseaux ayant des structures de communauté s’étalent généralement de 0,3 à 0,7.
Des valeurs supérieures sont rarement observées. Si le nombre d’arêtes intragroupes
(reliant deux arêtes du même groupe) est inférieur au nombre d’arêtes attendues dans
un graphe faisant l’objet d’une distribution aléatoire, alors la modularité QN G est né-
gative. Enfin la modularité est indéfinie sur un graphe sans aucun lien (graphe vide).
Les auteurs du concept de modularité ont envisagé d’employer différentes varia-
tions du graphe aléatoire, appelé modèle nul. Cependant, le graphe respectant la dis-
tribution des degrés s’est très vite imposé dans la littérature.

Une variante de la modularité pour les graphes orientés a été formalisée par Ni-
cosia et al. (Nicosia et al., 2009). Celle-ci repose sur l’utilisation d’une matrice d’adja-
cence non symétrique et la prise en compte du sens des connexions dans le calcul du
produit des degrés des sommets.

Si elle a eu un impact très important sur l’étude de la détection de communautés
dans les graphes, il a néanmoins été montré que la modularité a des défauts. Ainsi elle
présente une limite de résolution, qui restreint la possibilité de disposer de petites com-
munautés qui soient bien définies (Fortunato et Barthélemy, 2007). Des variantes ont
été créées pour s’affranchir de cette limite de résolution, notamment en utilisant un
paramètre permettant de choisir si on désire obtenir de petites ou de grandes classes.
Lancichinetti et Fortunato montrent que même en utilisant une extension de la mo-
dularité présentant un facteur de variation de la taille des communautés à produire,
certaines configurations ne sont pas bien résolues (Lancichinetti et Fortunato, 2011).
Gautier et al. proposent de palier à ce problème avec un facteur qui contraindrait

le nombre de classes à produire (Krings et Blondel, 2011).

Montgolfier et al. démontrent que des graphes particuliers (tores, hypercubes)
qui n’ont a priori pas de structure de communauté ont néanmoins des partitions à
modularité forte (Montgolfier et al., 2012). Keller et al. ont calculé la modularité
maximale de la partition d’une grille (torique) et celle-ci atteint 0,953 dans une grille
de 256 sommets de côté, ce qui est très élevé (Keller et Viennet, 2012). De plus, celle-
ci tend vers 1 quand la taille de la grille augmente.

Yang et al., mettent en évidence que des critères plus simples que la modularité, la
conductance (qui sera présentée dans la section 2.3.3.1) et le taux d’enrôlement dans

2.3. Détection de communautés dans les graphes

57

des triades, notamment, caractérisent souvent mieux un caractère de communauté
que la modularité (Yang et Leskovec, 2012). Cependant, la méthodologie utilisée fai-
sant appel à des perturbations de partition plutôt qu’à une optimisation, les indices
proposés posent en fait souvent des problèmes pour leur utilisation dans un cadre
d’optimisation. Par exemple, le nombre d’arêtes internes à des communautés, qui est
étudié, trouve son maximum pour la partition grossière.

Dans la méthode de Louvain, basée sur la modularité, Blondel et al. reconnaissent
le problème posé par l’exemple du "Collier de perles" (Aynaud et al., 2010; Fortunato
et Barthélemy, 2007). Une boucle de cliques reliées entre elles par des ponts formés
d’une arête, au lieu d’être identifiées comme des communautés distinctes, finissent par
se voir agglomérées entre elles. Ainsi il apparaît que les communautés sont regroupées
si leur taille est inférieure à

2M.

√

FIGURE 2.3 – Défaut de la modularité souligné par Ye et al.

Ye et al. soulèvent un défaut de l’utilisation du rapport entre le nombre d’arêtes
internes et d’arêtes externes aux communautés (Ye et al., 2012). Ainsi, dans la fi-
gure 2.3, les deux communautés suggérées ont la même contribution à la modularité
(elles ont le même nombre d’arêtes internes), bien que la communauté située à gauche
soit manifestement meilleure.

Des travaux ont porté sur la paramétrisation de la résolution. Ainsi Arenas et al.
proposent d’adjoindre une boucle sur tous les sommets, et de régler sa valuation, de
façon à créer une résistance qui va empêcher dans une certaine mesure les petites
communautés de se regrouper (Arenas et al., 2008). Reichardt et al. proposent eux
aussi une paramétrisation au sein du critère de modularité, mais qui porte elle sur le
calcul du graphe aléatoire (Reichardt et Bornholdt, 2006).

2.3.2.2 Approches heuristiques visant à optimiser un critère

La recherche d’une partition optimisant un critère particulier est le plus souvent NP
complète car le nombre de partitions possibles d’un ensemble explose avec le nombre
de ses éléments. Ainsi, les heuristiques, qui consistent en une exploration contrainte,
mais, on l’espère, plus intelligente pour ce problème particulier, ont une grande impor-
tance dans le partitionnement de graphes. L’exploration tient ainsi compte du voisi-
nage local des sommets lorsqu’il cherche à produire une nouvelle partition qui pourrait

1234567858

Chapitre 2. Classification automatique et détection de communautés

mieux satisfaire le critère à maximiser.

D’après Noack et al. (Noack et Rotta, 2009), ces méthodes peuvent être classées

en deux familles.

La première famille rassemble des algorithmes de dégrossissement, strictement
agglomératifs (Coarsening algorithms). Dans ce cas de figure, on opère uniquement
par fusions. On recherche à chaque fois une fusion sûre, car elle est définitive.

– Pas à pas. (Single-Step). Un sommet à la fois change de classe.
– Multi-pas (Multi-Step). Plusieurs sommets changent de classe au même moment

(Schuetz et Caflisch, 2007).

– Priorisation de fusions (Merge Prioritizers).

La seconde famille contient les algorithmes à raffinement. Cette fois-ci, il est pos-

sible de revenir après-coup sur une fusion.

– Complete Greedy est une solution qui cherche à chaque itération la meilleure mo-
dification d’affectation. Cette modification d’affectation concerne tous les som-
mets et toutes les classes d’affectation.

– Fast Greedy cherche successivement pour tous les sommets à les affecter dans la

meilleure classe possible (Schuetz et Caflisch, 2007; Ye et al., 2008).

– L’adaptation de Kernighan-Lin (pour la coupure minimale) adaptée par New-
man pour la modularité (Newman, 2006) vise, pour augmenter la variabilité des
partitions explorées, à ne changer l’affectation de chaque sommet qu’une seule
fois, mais il n’est plus nécessaire que le changement d’affectation provoque un
gain par rapport à l’affectation initiale.

– Le raffinement multi-niveaux. Avec les approches précédentes, la fusion de deux
sous-communautés denses moyennement connectées entre elles n’est pas pos-
sible sans effectuer plusieurs changements d’affectation qui auraient des impacts
négatifs sur la modularité. Les méthodes utilisant le raffinement multi-niveaux
construisent des résultats intermédiaires constitués par des graphes dont les
sommets constituent des agglomérations des sommets des graphes des niveaux
inférieurs. Lorsque la convergence d’un niveau est atteinte, on crée alors un
nouveau graphe à partir des communautés courantes. Le processus peut ensuite
être poursuivi sur ce nouveau graphe (Djidjev, 2008; Ye et al., 2008; Blondel
et al., 2008).

Nous allons maintenant aborder des méthodes basées sur l’optimisation de la mo-
dularité. On s’attend à ce qu’elles renvoient un résultat identique. Cependant, celles-ci
étant basées sur des heuristiques, leur efficacité en temps et en mémoire ainsi que leur
faculté à renvoyer une solution proche de l’optimale est propre à chaque méthode.

2.3. Détection de communautés dans les graphes

59

2.3.2.3 FastQ

Clauset, Newman et Moore introduisent en 2004 la méthode FastQ, pour Fast Mo-
dularity (Clauset et al., 2004). Étant entendu que tester la modularité de toutes les
partitions possibles est hors d’atteinte, FastQ utilise la modularité pour guider un pro-
cessus de recherche glouton (Brandes, 2008). Ce processus est un processus agglomé-
ratif donc ascendant, décrit dans l’algorithme 2. Tous les sommets sont initialement
placés dans des classes dont ils sont les uniques représentants. On cherche alors les
fusions successives qui produisent les meilleurs gains de modularité.

Il est fait utilisation d’une matrice dans laquelle on calcule quel est le gain de
modularité apporté par les différentes fusions possibles. Un vecteur ai contient ini-
tialement les degrés de tous les sommets et un tas h sert à faire ressortir l’incrément
maximum que l’on peut obtenir à n’importe quel moment.

Algorithme 2 : Algorithme FastQ

Entrées : Un graphe
Sorties : La hiérarchie de fusions
Calcul des valeurs initiales de ∆Qij et ai, et remplir le tas-maximum avec le
plus grand élément de chaque ligne de la matrice ∆Q;
répéter

Sélectionner le plus grand ∆Qij de h, unir les communautés
correspondantes, mettre à jour la matrice ∆Q, le tas H et ai et incrémenter
Q de ∆Qij ;

jusqu’à il ne reste plus qu’une seule communauté ;

1

2
3

4

Le temps avancé pour cette solution est de O(m· d· log(N )) où d est la profondeur

du dendogramme décrivant la structure de communauté du réseau.

D’après Blondel et al. cette méthode privilégie les grandes communautés (Blondel

et al., 2008).

La complexité de FastQ est, selon ses auteurs, de O(n3 · log(n)) dans le pire des

cas, mais de O(n · log(n)) en pratique le plus souvent.

2.3.2.4 Méthode de Wakita et Tsurumi

Wakita et al. proposent des variantes de l’algorithme de Clauset et al. qui passent
mieux à l’échelle et permettent de traiter des millions de sommets en moins d’une
heure (Wakita et Tsurumi, 2007). Pour y parvenir, ils font usage d’un tas qui sert à
mémoriser les déplacements de sommets provoquant les plus grandes augmentations
∆QN G de modularité. De plus, trois heuristiques sont comparées. Celles-ci visent à ef-
fectuer des fusions équilibrées lors du déroulement de l’algorithme. Pour cela, l’usage

60

Chapitre 2. Classification automatique et détection de communautés

FIGURE 2.4 – Partition optimisant le score de modularité sur le réseau Karate

de différentes mesures définissant ce que doit être la taille de communautés sont pro-
posées, parmi lesquelles le nombre de membres et le degré. L’auteur souligne que les
tailles des communautés formées sont soit petites, soit grandes, sans aucune commu-
nauté de taille intermédiaire.

2.3.2.5 Méthode de Louvain

La méthode de Louvain sera étudiée plus en détail dans la suite du présent do-
cument puisque notre contribution consiste à en proposer une extension adaptée aux
réseaux d’information.

La méthode de Louvain est une méthode récente proposant la classification de
sommets dans un graphe qui peut être valué (Blondel et al., 2008). Elle est appréciée
pour sa vitesse, qui la rend utilisable sur des réseaux de très grande taille (Greene
et al., 2010). La méthode de Louvain n’est pas supervisée ; le nombre de groupes à
former n’est pas demandé avant l’exécution. La méthode retourne une partition en
cherchant à optimiser le critère de modularité (voir section 2.3.2.1). Cependant, il
est important de souligner que ce n’est pas un algorithme fournissant un maximum
global, mais qu’il produit en général un optimum local.

Aynaud et al. décrivent ainsi le processus en deux étapes de la méthode présentée
dans l’algorithme 3 (Aynaud et Guillaume, 2011). La méthode de Louvain est une mé-
thode gloutonne conçue pour optimiser la modularité sur un graphe optionnellement
valué. Elle consiste en deux phases qui sont exécutées en alternance. Initialement,
chaque sommet constitue une communauté. Ensuite, durant la première phase, les

01234567891011121314151617181920212223242526272829303132332.3. Détection de communautés dans les graphes

61

Algorithme 3 : La méthode de Louvain

Entrées : Un graphe G
Sorties : Une partition P
répéter

Placer chaque sommet de G dans une unique classe;
Sauver la modularité de cette décomposition;
répéter

pour tous les sommet u de G faire

C ← communauté voisine maximisant le gain de modularité;
si le déplacement de u vers C induit un gain strictement positif alors

déplacer u de sa communauté vers C;

jusqu’à ce qu’aucun sommet ne puisse plus être déplacé ;
si le critère de qualité atteint est supérieur à sa valeur initiale alors

fin ← faux;
Afficher la décomposition trouvée;
Fusionner G en le graphe entre les classes;
fin ← vrai ;

sinon

jusqu’à fin ;

1
2
3
4
5
6
7
8

9
10
11
12
13

14
15

16

sommets sont considérés un à un (le résultat final dépend de l’ordre dans lequel les
sommets sont énumérés). Chacun d’eux est placé dans l’une des communautés voi-
sines (la sienne étant incluse), choisie car elle maximise le gain de modularité. Ce
processus est répété jusqu’à ce que plus aucun sommet ne puisse être déplacé (on
parle alors d’optimum local). Pour éventuellement se dégager de celui-ci, la phase 2
consiste à construire un nouveau graphe entre les communautés trouvées à l’issue de
la phase 1 : il y a un sommet dans le graphe pour chaque communauté et, pour deux
v,v′∈C×C′ poids(v, v′).
v,v′∈C×C poids(v, v′)2. L’algorithme exé-
cute alors les phases 1 et 2 alternativement jusqu’à ce que la modularité ne s’améliore
plus.

communautés C et C’, il y a une arête de valuation w où w =
Il y a aussi une boucle sur C de poids w =

Le pseudo-code associé au processus précédent est proposé dans l’algorithme 3.
Les auteurs ont étudié l’influence de l’ordre de l’énumération des sommets lors du
déroulement de l’algorithme (Aynaud et al., 2010). L’énumération des sommets dans
l’ordre de leurs classes d’appartenance (tous les sommets de la première communauté
puis tous les sommets de la seconde communauté, etc.) n’a amélioré ni les temps de
calcul ni la modularité de la partition finale.

C’est une méthode très rapide, y compris sur des réseaux de plusieurs millions de

62

Chapitre 2. Classification automatique et détection de communautés

sommets. Elle ne nécessite aucun paramètre, elle optimise simplement le critère de
modularité.

Les auteurs de la méthode de Louvain s’étant intéressés depuis à la classification
de réseaux en mouvement, ceux-ci soulignent l’inconvénient de cette méthode qui
réagit fortement à des modifications minimes du réseau, pouvant occasionner une
modification non seulement locale, mais aussi globale de la partition.

Comme toutes les méthodes d’optimisation de la modularité, elle hérite des incon-

vénients de cette dernière (voir section 2.3.2.1).

2.3.2.6 Travaux inspirés par la méthode de Louvain

La méthode de Louvain a inspiré de très nombreux travaux, que ce soit dans le but
de corriger certains de ses inconvénients, notamment parfois ceux de la modularité
elle-même, ou encore dans le but de l’adapter ou de l’étendre. C’est le cas des travaux
de Collingsworth ou de ceux de Seifi (Collingsworth et Menezes, 2013; Seifi, 2012).

Auto-organisation via l’utilisation de l’entropie de sommet

L’entropie de sommet est une mesure qui a pour but de quantifier le fait qu’un
sommet soit placé dans une communauté qui soit bien choisie vis-à-vis de la confi-
guration de ses voisins. Le principe de l’auto-organisation donne à chaque sommet la
possibilité de changer de communauté de façon à maximiser ce critère. La méthode
de Louvain est utilisée parallèlement à ce processus pour optimiser la position.

Collingsworth et al. proposent une méthode basée sur l’entropie de sommet (Col-
lingsworth et Menezes, 2013). Ici, on mesure l’entropie dans le cas où l’on change la
communauté d’affectation d’un sommet :

HS = − n

i=1

pilog2(pi)

k
4

e

(2.39)

où n est le nombre de communautés que le sommet peut potentiellement rejoindre, y
est le nombre de triades (sous-graphes complet comportant 3 sommets) intracommu-
nautaires formées en joignant une communauté et pi est le taux des arêtes voisines
du sommet considéré qui le relient à la communauté numéro i. Une triade est un
sous-graphe complet comportant 3 sommets.

Cœurs de communautés

Seifi propose une méthode de détection des cœurs de communautés. Ces cœurs
sont des ensembles de sommets qui sont très souvent ou toujours classés ensemble

2.3. Détection de communautés dans les graphes

63

lors de l’application de méthodes de classification non déterministes (Seifi, 2012).

Cette approche est intéressante par le fait qu’elle s’attache à produire des com-
munautés non complètes ; elle ne respecte pas la condition de complétude que l’on a
posé pour une partition, mais les résultats produits font l’objet d’une confiance très
supérieure aux autres méthodes.

2.3.3 Critères d’évaluation

2.3.3.1 Critères d’évaluation interne

La détection de communautés dans les graphes ayant été très largement traitée
sous l’angle d’un problème d’optimisation, l’éventail des critères d’évaluation interne
recouvre celui des critères d’optimisation détaillés dans la section 2.3.

D’autres critères d’évaluation de structures de communauté peuvent cependant
être mis en œuvre parmi lesquels on peut citer la couverture, la conductance, la per-
formance ou le coefficient de clustering décrits ci-après.

La couverture

La couverture est la proportion de la somme des valuations des d’arêtes intra-
communautaires par rapport aux valuations totales des arêtes de V , c’est-à-dire M
(Almeida et al., 2011) :

couverture(P) =

ψ(P)

M

(2.40)

où ψ(P) désigne la somme des valuations des arêtes intracommunautaires, c’est-à-
dire dont les deux extrémités appartiennent à la même classe :

r

k=1

1
2

ψ(P) =

Av,v′; v, v′ ∈ Ck

(2.41)

La couverture prend sa valeur entre 0 et 1. Comme c’est une mesure qui trouve
son maximum dans la partition grossière, elle ne pourra être utilisée que dans la com-
paraison de deux partitions pour lesquelles le nombre de classes est identique. C’est
la raison pour laquelle il nous faut introduire maintenant des mesures qui prennent
également en compte le nombre d’arêtes qui se trouvent sur la frontière entre deux
communautés, les arêtes interclasses.

64

Chapitre 2. Classification automatique et détection de communautés

La conductance

La conductance, également appelée métrique de la coupure normalisée, pour une
classe, mesure le taux de valuations d’arêtes qui pointent à l’extérieur de la classe, à la
classe ou à son complément, selon quel côté de la coupure la somme des valuations des
arêtes est la moins importante (Leskovec et al., 2008). En effet, ce critère a d’abord été
conçu pour évaluer la qualité d’une coupure, qui consiste en la scission des sommets
d’un graphe en deux parties. La conductance d’une classe C est donc définie par :

min

u∈C




v∈V Au,v,
v /∈C Au,v
u /∈C

u∈C


v∈V Au,v



conductance(C) =

(2.42)

À partir de cette mesure, on définit la conductance du graphe comme la plus petite

des conductances de chacune des classes :

conductance(G) = minCk∈P (conductance(Ck))

(2.43)

Ainsi, une classe avec une conductance forte est une classe qui est dense en arêtes
et faiblement liée avec les autres classes. Un graphe avec une conductance forte a
toutes ses classes denses et faiblement liées entre elles.

La performance

Par souci de simplification, nous décrivons la mesure sur un graphe non valué,

bien qu’une version valuée de celle-ci ait été définie (Brandes et al., 2007).

La performance consiste à ajouter le nombre d’arêtes internes aux communautés
au nombre d’arêtes intercommunautaires qui n’existent pas, et à diviser la somme par
le nombre total d’arêtes possibles du graphe, soit 1

2 N (N − 1) (Van Dongen, 2000).

Soit |Eintra| le nombre d’arêtes intraclasses, soit |Einter| le nombre d’arêtes inter-

classes qui n’existent pas dans le graphe :

|Einter| =





Ck∈P

Cl∈P,k>l

v, v′ /∈ E|v ∈ Ck, v′ ∈ Cl



Alors la performance est définie par :

perf ormance(C) =

|Eintra| + |Einter|

1

2 N (N − 1)

La performance prend sa valeur entre 0 et 1, une valeur élevée décrivant une classe

à la fois dense et peu liée avec d’autres classes.

Almeida et al. reprochent à cette mesure d’être mal adaptée à des grands graphes

(2.44)

(2.45)

2.3. Détection de communautés dans les graphes

65

éparses, dans lesquels le terme |Einter| dominera largement dans le score (Almeida
et al., 2011).

Coefficient de clustering

Le coefficient de clustering a été défini par Watts et Strogatz (Watts et Strogatz,
1998). Soit un sommet v, ayant deg(v) voisins. Alors au plus deg(v)(deg(v)− 1) arêtes
peuvent exister entre eux. Le coefficient de clustering CC(v) du sommet v est défini
par la proportion des arêtes qui pourraient exister mais n’existent pas dans le voisi-
nage de v, par rapport à l’ensemble des arêtes qui pourraient exister. Le coefficient de
clustering CC(G) du graphe G est défini par la moyenne des coefficients de clustering
des sommets qui le composent :



v∈V

CC(G) =

1
N

CC(v)

(2.46)

Comparaison des critères internes de qualité d’une partition des sommets

Le comparatif de Yang et al. souligne l’intérêt de la conductance mais également
la pertinence du coefficient de clustering pour mesurer la structure de communauté
(Yang et Leskovec, 2012).

Almeida propose aussi un panorama argumenté des différents critères d’optimisa-
tion que sont la modularité, l’indice de Silhouette, la couverture, la performance et la
conductance (Almeida et al., 2011). La conclusion de ces travaux est que la modula-
rité, la conductance et la couverture tendent à donner de meilleurs résultats quand
le nombre de classes est faible, tandis que la performance et l’indice de Silhouette
privilégient eux de petites communautés.

Leskovec et al. proposent une comparaison empirique de différentes méthodes de
classification des sommets d’un graphe (Leskovec et al., 2010). Ils soulignent le fait
que l’optimisation agressive d’un critère comme la conductance peut mener à des
communautés trop nombreuses, tandis qu’une optimisation approximative du critère
mène à des résultats plus intuitifs.

On pourra également consulter l’étude d’Artignan qui vise à montrer la proximité
des résultats de différents algorithmes sur ces différents critères (Artignan et Hascoët,
2011).

On conclura qu’il n’y a pas aujourd’hui de consensus sur une mesure de qualité
qui surpasserait toutes les autres. Ainsi, si on ne prend que l’indice de Silhouette et la
modularité, ces deux mesures répondent à des intuitions différentes pour lesquelles il
est difficile juger si l’une est supérieure à l’autre.

66

Chapitre 2. Classification automatique et détection de communautés

2.3.3.2 Critères externes d’évaluation

Le but du processus de classification étant de produire une partition, les critères
externes d’évaluation sont identiques à ceux décrits pour la classification de données
non supervisée.

Cependant, des extensions des mesures généralistes dédiées à des domaines d’ap-
plication existent. C’est par exemple le cas de la mesure proposée par Labatut qui
pondère l’influence de la mauvaise classification d’un sommet dans l’indice de pureté
par une notion d’importance du sommet (Labatut, 2012). La notion d’importance du
sommet est choisie de manière à refléter le fait que le sommet est au cœur de sa com-
munauté. Ainsi, un sommet mal classé pénalisera d’autant plus le critère de pureté
modifié qu’il est central à une communauté, tandis que les sommets périphériques
apporteront une pénalité plus faible.

2.3.4 Conclusion

La détection de communautés dans les graphes est une tâche qui a donné lieu à
de nombreux travaux. Si la comparaison entre les méthodes est toujours d’actualité, il
faudra cependant choisir entre différents paradigmes dans la définition d’une partition
de bonne qualité. Ainsi, la modularité de Newman et la coupure minimale, si elles
produisent des résultats différents, devront-elles être choisies selon les besoins de la
tâche à effectuer. La première montrera tout son intérêt quand le nombre de classes à
produire est inconnu. La seconde permet de produire des résultats hiérarchisés.

On peut voir qu’historiquement les heuristiques et les critères d’optimisation ont
évolué en parallèle. Les critères apparaissent comme toujours susceptibles d’être em-
ployés dans des algorithmes plus performants et les algorithmes semblent adaptables
à de nouveaux critères, bien que certaines combinaisons entre critères et algorithmes
sont apparues plus pertinentes ou plus simples à mettre en œuvre.

2.4 Détection de communautés dans les réseaux d’informa-

tion

2.4.1 Motivations

La détection de communautés dans des réseaux d’information est motivée par la
quantité plus grande de données dont il est possible de tirer parti pour obtenir une
classification de meilleure qualité, mais aussi par la complémentarité des informa-
tions. Elle est justifiée aussi par les travaux consacrés à l’homophilie (Lazarsfeld et
Merton, 1954; McPherson et al., 2001; Crandall et al., 2008; Anagnostopoulos et al.,

2.4. Détection de communautés dans les réseaux d’information

67

2008). L’homophilie exprime la tendance naturelle des individus à s’associer avec des
personnes aux caractéristiques proches.

Si la notion d’homophilie amène à penser que les liens apparaissent en priorité
entre des éléments aux attributs similaires, d’autres réseaux peuvent avoir une logique
différente que certaines méthodes de détection de communautés dans des réseaux
d’information peuvent modéliser.

Dans le cas où une source de données est incomplète, l’exploitation d’une source
complémentaire permet parfois de compenser les manques. De plus, en comparant
des résultats de classification issus de combinaisons d’informations avec des classi-
fications sans combinaison, on peut mettre en évidence des différences qui peuvent
elles-mêmes être des connaissances utiles.

En outre, la combinaison des deux informations (relationnelles et d’attributs) peut
permettre de trouver des partitions qu’il n’aurait pas été possible de produire en
ne considérant que les relations ou que les attributs. C’est ce qui nous a conduit à
construire un jeu de données dédié à la problématique de la combinaison d’informa-
tions (voir section 1.4.4).

Nous proposons une présentation des méthodes de détection de communautés
dans des réseaux d’information en quatre familles. Nous présenterons une première
famille de méthodes de classification combinée ayant pour principe de résumer les
deux types de données sous la forme d’un graphe dans la section 2.4.3. La deuxième
famille qui sera décrite dans la section 2.4.4 comporte des méthodes qui sont issues
de l’adaptation d’algorithmes de classification automatique. La troisième famille, dans
la section 2.4.5, regroupe des méthodes qui sont des extensions de méthodes de dé-
tection de communautés visant à intégrer les attributs. Enfin, dans la section 2.4.6, la
quatrième famille comporte des méthodes qui cherchent plus globalement à découvrir
le modèle statistique sous-jacent au réseaux d’information.

2.4.2 Formalisation du problème de détection de communautés dans un

réseau d’information

Soit un graphe G = (V, E) où V est l’ensemble des sommets et E est l’ensemble des

arêtes. Pour chaque sommet v ∈ V , on dispose d’un vecteur d’attributs (v1, . . . , vj, . . . v|T|)
où vj est la valeur prise par l’attribut j du sommet v.

Dans le problème de partitionnement de réseau d’information, les liens et les attri-
buts sont considérés, de telle sorte que d’une part il doit y avoir de nombreuses arêtes
entre les sommets de chaque classe et relativement peu entre elles et d’autre part,
deux sommets appartenant à la même classe sont plus proches en termes d’attributs,
que deux sommets appartenant à des classes différentes. Ainsi, les classes doivent être

68

Chapitre 2. Classification automatique et détection de communautés

bien séparées en termes de liens et différentes par rapport aux attributs et les som-
mets appartenant à un même groupe doivent être fortement connectés et homogènes
vis-à-vis des attributs.

2.4.3 Traitement comme un problème de partitionnement dans un graphe

après intégration des valeurs des attributs

La première famille d’approches opérant une combinaison de l’information rela-
tionnelle et des attributs que nous présentons passe par la création d’un nouveau
graphe dans lequel les deux types d’information sont intégrés.

2.4.3.1 Ajout dans le graphe de nouveaux sommets et d’arêtes représentant les

attributs

La construction d’un tel graphe est employée dans les méthodes SA-Cluster et Inc-
Cluster (Zhou et al., 2009, 2010). Elle consiste en l’ajout de sommets représentant les
différentes valeurs prises par chacun des attributs et aboutit à la création d’un nou-
veau graphe appelé Attribute augmented graph. Il s’agit donc d’un graphe qui contient,
en plus des informations du graphe original (le graphe structurel), des sommets repré-
sentant une valeur de chacun des attributs (que l’on désignera par sommet-attribut).
Une arête-attribut est créée entre chaque sommet-attribut et les sommets originaux
prenant la valeur que ce sommet-attribut désigne.

Par exemple, dans le jeu de données de blogs utilisé par Adamic et al. (Adamic
et Glance, 2005), chaque sommet (un blog) peut être soit libéral, soit conservateur.
Alors deux nouveaux sommets artificiels "libéral" et "conservateur" sont créés, et une
arête-attribut est créée entre chaque blog libéral et le sommet-attribut "libéral", de
même qu’entre les blogs conservateurs et le sommet-attribut correspondant.

Zhou et al. utilisent des k-médoïdes et une distance basée sur une marche aléatoire
pour la classification de ce graphe tout en envisageant d’autre méthodes de classifica-
tion réduites aux relations à cette étape. En 2010, Zhou et al. proposent une version
incrémentale de SA-Cluster, Inc-Cluster, plus efficace sur les grands graphes (Zhou
et al., 2010).

On notera que cette approche est adaptée lorsque les attributs sont des étiquettes.
Elle n’est pas utilisable dans le cas d’attributs à valeurs discrètes car il faudrait in-
troduire trop de sommets. De plus, il n’y aura plus de prise en compte du caractère
ordonné des valeurs des attributs.

Yin et al. utilisent aussi les réseaux obtenus en intégrant de nouveaux sommets
relatifs aux valeurs d’attributs qu’ils désignent sous le terme de "réseaux sociaux-
attributs" (social-attribute network, SAN) mais dans la méthode LinkRec destinée à

2.4. Détection de communautés dans les réseaux d’information

69

la prédiction de liens (Yin et al., 2010). Gong et al. utilisent aussi cette représentation
pour prédire des liens ou inférer des valeurs d’attributs, notamment en adaptant des
méthodes de Yin et al. (Gong et al., 2012).

2.4.3.2 Valuation des arêtes par la distance entre vecteurs

Une deuxième façon d’introduire les attributs dans le graphe consiste à valuer les
arêtes par une distance calculée entre les vecteurs. C’est l’approche proposée par Ne-
ville et al. (Neville et al., 2003). La valuation de chaque arête est définie comme le
nombre de valeurs d’attributs partagées par ses deux extrémités (similarité du mat-
ching coefficient). S’il n’y a pas d’arête entre deux sommets aucune valeur de matching
coefficient n’est attribuée.

Steinhaeuser et al. proposent une méthode similaire où les arêtes sont valuées
de façon à prendre en compte à la fois la similarité entre attributs et la proximité
relationnelle des sommets (Steinhaeuser et Chawla, 2008).

Nous utiliserons nous-même une méthode, T S1, reposant sur la valuation des
arêtes par les distances entre attributs qui est décrite dans (Combe et al., 2012b)
et qui sera présentée dans la section 3.8.2.3.

2.4.3.3 Combinaison de partitions

Une autre démarche consiste à fusionner diverses partitions issues de la classifica-
tion textuelle et de la classification relationnelle après la classification portant sur un
seul type de données. Les distances entre les éléments ne sont plus utilisées, seule la
classe des éléments est prise en compte pour former la partition finale. Pour désigner
cette tâche on parle souvent de combinaison de classifieurs, d’Ensemble clustering ou
de Consensus clustering (Ghaemi et al., 2009).

Les partitions, issues de la classification selon les relations et selon les vecteurs,
sont représentées par un graphe augmenté, à la manière de ce qui a été présenté dans
la section 2.4.3.1. Une solution est de créer des sommets artificiels pour représenter
les différentes classes produites par toutes les méthodes de classification, et d’attacher
avec ces sommets les sommets d’origine qui y ont été classés (Ghosh et al., 2002).
Une détection des communautés permettra ensuite de classer les sommets d’origine.
Une seconde représentation possible est celle utilisée par la méthode Hypergraph Par-
titioning Algorithm (HGPA), qui représente chaque communauté par une hyper-arête
dans un graphe où les sommets correspondent aux éléments qui ont été classés par les
différents classifieurs. Les partitions finales sont trouvées en utilisant des algorithmes
faisant appel à la coupure minimum (Strehl et Ghosh, 2003).

70

Chapitre 2. Classification automatique et détection de communautés

L’ensemble clustering montre tout son intérêt pour exploiter des algorithmes in-
stables ou lorsqu’on dispose de plusieurs partitions issues de plusieurs algorithmes
différents, mais il est limité si l’on n’a que deux partitions différentes.

2.4.4 Traitement comme un problème de classification automatique

La deuxième famille de méthodes que nous décrirons traite le problème de dé-
tection de communautés comme un problème de classification automatique. Il s’agira
alors de modifier une technique de classification afin d’intégrer une notion de distance
relationnelle.

Dans cette famille figurent notamment des extensions de l’algorithme des K-means

telles que NetScan ou JointClut.

2.4.4.1 Le problème CkC (Connected k-Center)

Ester et al. traitent la question sous l’angle du "problème CkC", des k-centres
connectés, et proposent NetScan, une version étendue de l’algorithme des K-means
qui impose une contrainte de connexité interne à chaque classe (Ester et al., 2006; Ge
et al., 2008). Sous cette condition, deux sommets d’une classe doivent être reliés par
un chemin interne à celle-ci.

Soit un nombre de centres k, une contrainte de rayon r, une norme ∥·∥ et un
graphe G = (V, E) où chaque sommet de V est associé à un vecteur de coordonnées
w de Rd. On cherche s’il existe une partition P = {V1, . . . , Vk} de V qui satisfasse les
deux conditions suivantes :

1. Les sous-graphes induits G [V1] , . . . , G [Vk] sont connectés (contrainte de connexité

interne).

2. ∀1 ≤ i ≤ k, il existe un sommet centre ci ∈ Vi, tel que ∀v ∈ Vi,||w(v)−w(ci)|| ≤ r

(contrainte de rayon maximal).

On notera que le nombre de centres k est ici fixé à l’avance, tout comme r, la dis-
tance maximale entre deux membres d’une communauté. De plus, les communautés
produites seront forcément connexes. Le problème CkC est démontré comme étant
NP-complet mais l’algorithme NetScan est une heuristique qui, d’après les expérimen-
tations menées par les auteurs, permet de résoudre efficacement le problème.

2.4.4.2 Le problème CXC (Connected X clusters)

Après l’algorithme NetScan proposé pour résoudre le problème CkC, Moser et al.
introduisent une autre solution, JointClust, ne nécessitant pas de fournir k, le nombre
de classes à retourner (Moser et al., 2007).

2.4. Détection de communautés dans les réseaux d’information

71

Au lieu de traiter le problème CkC de la détection de k communautés connexes, ils
résolvent le problème CXC. Le problème CXC consiste à trouver une partition P de G
telle que :

1. P remplit la contrainte de taille minimale, c’est-à-dire que chaque classe contient

au moins t objets, où t est un paramètre préalablement fixé.

2. P maximise le Coefficient de Silhouette Joint.

Cette approche a pour inconvénient de poser une limite basse au nombre d’objets dans
une classe.

JointClust procède en deux phases. La première permet d’identifier des classes
atomiques qui sont fusionnées dans la seconde phase, où le résultat peut être pré-
senté sous forme de dendogramme. JointClust maximise le coefficient de Silhouette
joint, introduit par les auteurs et décrit dans la section 2.4.7, qui permet de juger de
la qualité de la classification en considérant non seulement les attributs mais aussi
les relations. Un des avantages de ce critère est qu’il est indépendant du nombre de
classes. Ce même critère sera réutilisé par Wan et al. dans une méthode hiérarchique
(Wan et al., 2009).

Une autre extension des K-means est introduite par Luo et al. qui utilise non seule-
ment une distance entre les éléments par rapport aux attributs mais aussi le voisinage
de chaque élément défini également par rapport aux attributs. Mais cette méthode
pourrait cependant être appliquée en considérant un voisinage défini par rapport à
des données relationnelles (Luo et al., 2009). Après avoir choisi des sommets à forte
centralité de degrés, on opère des fusions dépendant du nombre de voisins communs
et de la proximité des attributs. L’application des K-means est opérée ensuite sur les
attributs.

Comme Netscan, cette méthode nécessite de connaître à l’avance le nombre de

classes à produire.

2.4.5 Extension de la méthode de détection de communautés de Louvain

Si des travaux de la section précédente ont consisté à étendre l’algorithme des K-
means, d’autres se sont intéressés à la méthode de Louvain. C’est le cas notamment
des travaux de Dang et al. ou Cruz-Gomez et al.

2.4.5.1 Score de modularité étendu par la similarité des attributs

Dang et al. ont étendu la modularité de Newman en ajoutant un terme pour me-
surer la similarité basée sur les attributs entre les paires de sommets relevant de la
même classe (Dang et Viennet, 2012). De cette façon, ils construisent une mesure de

72

Chapitre 2. Classification automatique et détection de communautés

modularité composite définie comme une combinaison linéaire de la modularité de
Newman et Girvan et de la similarité vis-à-vis des attributs. C’est cette mesure compo-
site qui est optimisée dans leur algorithme SAC1, déduit de Louvain. À la différence
de la méthode de Louvain, deux sommets peuvent être affectés à une même classe
même s’ils ne sont pas reliés. De plus, une des difficultés de la méthode tient au choix
du coefficient dans la combinaison linéaire.

Notons que les auteurs proposent également un autre algorithme, SAC2, qui com-
porte un pré-traitement permettant de générer un graphe des plus proches voisins
défini en fonction des liens initiaux et des attributs puis ils appliquent sur ce nouveau
graphe une méthode de détection de communautés.

2.4.5.2 Entropie de sommet

Cruz-Gomez et al. proposent aussi une méthode de détection de communautés
déduite de Louvain et basée sur l’optimisation de deux critères : la modularité pour
les relations et l’entropie pour les attributs. L’entropie de la partition est optimisée
en suivant l’approche Monte-Carlo (Cruz-Gomez et al., 2011). L’algorithme reprend
les principes de Louvain mais en optimisant successivement l’entropie et la modula-
rité afin de minimiser la première et de maximiser la seconde. De ce fait les deux
optimisations peuvent provoquer successivement des changements contradictoires.

2.4.6 Modèles statistiques

Dans cette quatrième famille, nous présentons les méthodes qui cherchent à mo-

déliser le réseau, au moyen par exemple d’une distribution.

2.4.6.1 Approximation de la loi qui régit la distribution des attributs et les liens

Xu et al. modélisent la distribution des attributs et celle des relations dans le réseau
par des loi (Dirichlet, etc.) (Xu et al., 2012). Ainsi ils sont en mesure d’évaluer la
probabilité pour deux sommets d’être classés ensemble compte tenu des liens et des
attributs.

D’autres travaux ont également été proposés par Kim et al. qui, pour leur part,
utilisent un modèle probabiliste pour capturer des affinités positives et négatives entre
les attributs de sorte que seront classés ensemble des éléments qui prennent les mêmes
valeurs pour certains attributs ou au contraire des valeurs différentes pour d’autres.
Les informations sont inscrites dans une matrice d’affinité qui traite l’interaction entre
attributs et relations (Kim et Leskovec, 2010, 2011).

2.4. Détection de communautés dans les réseaux d’information

73

2.4.6.2 Prise en compte des informations vectorielles dans le critère de modu-

larité

D’autres travaux cherchent non pas à intégrer les attributs dans un méthode de
détection de communautés existante, mais à modifier ses hypothèses sous-jacentes.
Une proposition en ce sens à été faite par Liu et al. qui proposent de modifier le
modèle nul utilisé dans le calcul de la modularité en ajoutant au degré la prise en
compte d’une similarité entre sommets (Liu et al., 2013).

Cette démarche est proche de celle qui nous a amené à proposer la modularité

basée sur l’inertie dans le chapitre 4.

2.4.7 Évaluation

Dans la littérature, on rencontre principalement deux modes d’évaluation des mé-
thodes développées en classification non supervisée de sommets dans les réseaux d’in-
formation. La première d’entre elles est l’évaluation à l’aide de critères internes. On
cherche alors à obtenir une partition la meilleure possible au sens d’un critère parti-
culier, comme la modularité.

Or face à un probléme réel, la question que l’on se pose est plutôt "La solution
que m’apporte l’algorithme est-elle de qualité, a-t-elle de bonnes propriétés ?" que "La
solution que m’apporte l’algorithme est-elle la meilleure ?" (ou l’une des meilleures, la
meilleure réponse face à un compromis temps / résultat). En particulier, la notion de
"bonne solution" varie selon le contexte d’application.

Le second mode d’évaluation est la confrontation des classes fournies par la mé-
thode à des groupes "naturels". On dira alors que l’on évalue le résultat selon un
critère externe. Le score se calcule alors en terme de précision et de rappel, ou encore
de F-mesure.

Si plusieurs mesures hybrides ont été proposées pour opérer la classification dans
des réseaux d’information, elles ne peuvent pas réellement être employées en tant
que critères d’évaluation, en tout cas si elles sont également utilisées pour construire
les classes car l’évaluation sera biaisée. Dans l’état de l’art figure cependant le critère
de Joint Silhouette Coefficient proposé par Moser et al. et qui permet de quantifier la
qualité d’une partition construite sur un réseau d’information en tenant compte des
deux types de données : attributs et relations (Moser et al., 2007). Cet indice, inspiré
de l’indice de Silhouette de Rousseeuw (Rousseeuw, 1987), est défini par :

JSC(P) =

1
|V |

bE(v) − a(v)

max{bE(v), a(v)}

(2.47)



v∈V

74

Chapitre 2. Classification automatique et détection de communautés

où a(v) est la distance entre l’élément v et le centre de sa classe et bE(v) est la distance
moyenne à toutes les autres classes connectées à la classe c(v).

Cette mesure est donc hybride. Elle est d’autant plus grande que les classes connec-
tées entre elles sont éloignées les unes des autres (bE(v)) et que la dispersion à l’inté-
rieur de chacune des classes est limitée (a(v)).

Nous proposons une synthèse des mesures d’évaluation dans la Table 2.1 qui re-
prend les critères utilisés pour la classification de vecteurs d’attributs, ceux utilisés
pour la détection de communautés dans un graphe, ainsi que les critères externes.
Ces critères sont aussi utilisables pour la détection de communautés dans un réseau
d’information.

Critères internes

Vecteurs
Indice de Silhouette (distance
euclidienne)
(Rousseeuw,
1987)
Inertie interclasses

Graphe
Indice de Silhouette (dis-
tance géodésique)

Couverture
Conductance
Modularité
Entropie de sommet (Kan-
tardzic, 2011)

Davies & Bouldin (Davis et
Leinhardt, 1967)
Dunn (Dunn, 1973)
Taux de bien classés
Pureté
Indice de Rand (Rand, 1971)
ARI (Adjusted Rand Index) (Hubert et Arabie, 1985)
AMI (Adjusted Mutual Information) (Vinh et al., 2010)
NMI (Normalized Mutual Information) (Strehl et Ghosh, 2003)
V-mesure (Rosenberg et Hirschberg, 2007)
Coefficient de Silhouette Joint (Moser et al., 2007)

Critères externes

Critères hybrides

TABLE 2.1 – Synthèse des critères d’évaluation

Génération de réseaux d’information

Confrontés au faible nombre de réseaux d’information réels exploitables pour
l’évaluation des algorithmes de détection de communautés, quelques travaux ont
porté sur leur génération. Nous commençons par un court historique sur la génération
de graphes.

2.4. Détection de communautés dans les réseaux d’information

75

Génération de graphes L’analyse des réseaux sociaux et de leurs propriétés a
provoqué le besoin de générer des réseaux soumis aux mêmes lois. Il existe plu-
sieurs modèles pour générer des réseaux sans attributs. L’un des plus anciens est celui
d’Erd˝os et Rényi (Erd˝os et Rényi, 1959). Les connexions entre les sommets y sont
équiprobables et indépendantes des autres connexions.

Le modèle du petit monde ("small world") de Watts et Strogatz intègre les éléments
de la théorie de Milgram des six degrés de séparation dans la mesure où la distance
moyenne entre deux individus est faible dans les réseaux à caractères sociaux (Watts
et Strogatz, 1998). De plus, le modèle de Watts et Strogatz amène à un clustering
coefficient, tel que défini dans la section 2.3.3.1, plus élevé que dans les deux modèles
abordés précédemment.

Barabási et Albert introduisent le principe d’attachement préférentiel (Barabási et
Albert, 1999). Dans ce modèle, chaque nouveau sommet v introduit est attaché avec
les sommets précédents selon une probabilité pv qui dépend du degré de ceux-ci :

k(v)

v′ k(v′)

pv =

(2.48)

Il est alors possible d’utiliser le principe de la sélection à la roulette (roulette wheel
selection) pour définir le sommet de rattachement.

C’est un modèle plus réaliste que les précédents, en particulier par le fait qu’il
prend en considération la loi de puissance, fréquemment observée sur les réseaux
sociaux. On parle aussi de réseaux sans échelle (scale-free networks).

Ces modèles de génération sont prévus pour construire des graphes et non des

réseaux d’information puisqu’ils ne prennent pas en compte des valeurs d’attributs.

Génération de réseaux Nous introduisons maintenant les méthodes qui ajoutent

des attributs lors de la génération du graphe.

Kim et al. proposent le modèle MAG (Multiplicative attribute graph) de génération
de réseaux d’information qui considère les sommets décrits par des attributs catégo-
riels. Dans ce modèle, une matrice permet de modéliser l’interaction entre la valeur
d’un attribut et particulier et la probabilité d’existence d’un lien entre une paire de
sommets (Kim et Leskovec, 2010).

Les mêmes auteurs proposent ensuite MAGFIT, une méthode d’estimation des pa-

ramètres de MAG (Kim et Leskovec, 2011).

Un autre modèle, introduit par Dang et al., génère aussi un réseau en fonction de
la similarité des attributs décrivant chacun des sommets. Le principe de cette méthode
est le suivant. On commence par générer quelques sommets de chaque catégorie qui
joueront le rôle de graines. Lors de l’ajout des sommets suivants, la probabilité qu’une

76

Chapitre 2. Classification automatique et détection de communautés

arête prenne place entre un nouveau sommet v et un sommet v′ existant est définie
par :


deg(v′) · s(v, v′) · scentres (cv, cv′)
v′′∈V deg(v′′) · s(v, v′′) · scentres (cv, cv′′)

pv,v′ =

(2.49)

où s(v, v′) est la similarité entre v et v′ définie par :

(2.50)
où |v − v′| donne la valeur absolue de la différence entre v et v′ et où scentres(cv, cv′)
est égal à s(gcv , gcv′ ), où gcv désigne le centre de gravité de la classe du sommet v.

|v − v′|

s(v, v′) =

1

2.5 Conclusion

Dans ce chapitre, nous avons d’abord présenté les algorithmes de classification
automatique auxquels nous avons eu recours ainsi que les critères qu’ils exploitent,
tels que l’inertie interclasses. Nous avons décrit les problèmes posés par la détermina-
tion du nombre de classes et l’évaluation de la qualité des partitions, notamment en
utilisant des critères internes comme l’indice de Silhouette, de Dunn ou de Davies et
Bouldin.

Dans un deuxième temps, nous avons décrit le critère de modularité. Bien que le
problème de l’optimisation de la modularité se soit révélé NP-complet, différentes heu-
ristiques d’optimisation du critère que nous avons rappelées permettent de proposer
une solution satisfaisante dans un temps raisonnable.

Dans un troisième temps, nous avons abordé la détection de communauté dans
des réseaux d’information. Au travers d’une typologie en quatre familles, nous avons
soulevé différents inconvénients des méthodes existantes. D’abord, les méthodes pro-
cédant par production d’un graphe résumant les deux informations peuvent se révéler
inadaptées à des données continues, ignorer certaines distances entre éléments pen-
dant la classification ou combiner les informations en reposant sur des classifications
intermédiaires sans ne plus pouvoir prendre en compte les distances entre éléments.
Les méthodes issues de la deuxième famille, reposant sur des méthodes de classifica-
tion automatique, semblent poser moins de problèmes méthodologiques mais posent
le problème de la pondération des deux informations dans la partition finale et né-
cessitent souvent des paramètres comme le nombre de classes à retourner, la taille
minimale d’une classe ou la distance maximale entre attributs de deux éléments d’une
classe.

La troisième famille, étendant la méthode de Louvain, proposent des méthodes

2.5. Conclusion

77

optimisant des critères soit locaux soit menant à des choix contradictoires. Enfin, la
quatrième et dernière famille est composée de méthodes statistiques souvent coû-
teuses en temps de calcul ou faisant des hypothèses qui pourraient ne pas se révéler
pertinentes pour tous les réseaux d’information.

L’état de l’art nous montre que la classification automatique et la classification
des sommets d’un graphe sont des domaines bien distincts qui ont chacun leurs ap-
proches et leurs critères d’optimisation. Ces domaines ont évolué parallèlement, mais
largement indépendamment.

Nous avons vu comment la modularité et l’inertie interclasses pouvaient permettre
respectivement de classer des éléments selon les relations entre eux et selon leurs
valeurs d’attributs.

Que ce soit pour la classification automatique ou la détection de communautés,
il nous semble important d’insister sur le fait que l’évaluation reste aujourd’hui com-
plexe. Le nombre de jeux de données d’évaluation de type benchmark est faible et
soulève souvent des problèmes de pertinence ou de confiance dans la manière où la
vérité terrain a été construite. Dans le cas où l’évaluation est faite par rapport à une
partition précise, on a vu que tout un éventail de mesures, des plus simples aux plus
complexes, sont disponibles. Les critères internes posent d’autres questions, qui re-
joignent celles rencontrées dans l’évaluation de la détection de communautés dans un
graphe ou de classification non supervisée. C’est la raison pour laquelle nous avons
généré nous-même un jeu de données qui sera employé dans le chapitre suivant et
avons eu recours à un générateur.

Dans le chapitre suivant, nous proposons une nouvelle méthode, ToTeM. À la dif-
férence de la méthode de Cruz-Gomez et al., ToTeM optimise un critère tenant compte
de la qualité globale de la partition par rapport aux attributs et aux relations, plutôt
que d’optimiser successivement deux critères. En ce sens elle se rapproche d’avan-
tage de la méthode SAC1 de Dang et al., mais, alors que SAC1 considère la similarité
entre les paires de sommets relevant de la même classe, ToTeM optimise une mesure
d’inertie interclasses.

CHAPITRE 3
ToTeM, une méthode de détection
de communautés utilisant
modularité et inertie

Sommaire

79
3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
80
3.2 Formalisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
82
3.3 La méthode ToTeM . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
86
3.4 Optimisation du calcul de la modularité et de l’inertie . . . . . . . .
89
3.5 Complexité . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
89
3.6 Critères globaux de qualité . . . . . . . . . . . . . . . . . . . . . . . .
3.7 Évaluation sur des réseaux artificiels . . . . . . . . . . . . . . . . . .
92
3.8 Évaluation un réseau bibliographique . . . . . . . . . . . . . . . . . . 106
3.9 Évaluation sur un autre réseau de grande taille : PubMed-Diabètes . 116
3.10 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121

3.1 Introduction

Dans le chapitre 2 nous avons d’abord vu différentes manières de classifier des
éléments décrits par des vecteurs de façon non supervisée. Nous avons ensuite décrit
différentes façons de classifier les sommets dans un graphe, puis nous avons présenté
des méthodes de détection de communautés dans des réseaux d’information combi-
nant les deux types de données relationnelles et d’attributs.

Parmi ces approches, certaines sont dédiées à la classification de sommets pour les-
quels les attributs sont discrets, comme SA-Cluster (Zhou et al., 2009). D’autres sont
des approches où la combinaison effective des données relationnelles et des données
d’attributs est effectuée tardivement dans le processus de classification, ce qui peut
apporter un déséquilibre dans la prise en compte des deux types de données (Lu et

80

Chapitre 3. ToTeM

Getoor, 2003). Certaines de ces approches font de plus usage de critères d’optimisa-
tion locaux, qui apportent peu de garanties formelles sur le résultat final, concernant
les partitions qui auront été mises de côté (Lu et Getoor, 2003; Cruz-Gomez, 2012).
Dans ce chapitre nous présentons notre première proposition, la méthode ToTeM,
conçue pour répondre à ces critiques.

La méthode a plusieurs objectifs. Elle doit tout d’abord produire des classes qui
sont denses en liens, et où les vecteurs associés aux sommets sont similaires. En com-
plément, ces classes doivent être peu liées entre elles par des arêtes, et les vecteurs as-
sociés à deux sommets de classes différentes doivent être aussi éloignés que possible.
Le contexte d’application de réseaux bibliographiques qui est le notre nécessite de
pouvoir manipuler des attributs à valeurs continues, en particulier les poids tf-idf des
termes présents dans les documents. Nous voulons aussi proposer une méthode qui
soit utilisable quelle que soit la densité des graphes et quelles que soient les moyennes
et les écarts types des attributs manipulés. L’influence des deux sources d’information
doit être équilibrée. De plus, cette méthode doit permettre de classifier les sommets
sans effectuer une fusion prématurée des deux types d’informations, comme préco-
nisé en conclusion du chapitre précédent. Enfin, nous basons notre méthode sur deux
critères reconnus qui n’ont à notre connaissance jamais été rapprochés : l’inertie et la
modularité.

Alors que la méthode de Louvain ne classifie les sommets que sur la base des rela-
tions, ToTeM prend également en compte les attributs continus durant la classification,
tout en proposant une simplification des calculs relatifs à ces attributs, à la manière
de ce que Newman a initié et Blondel a étendu pour le critère de modularité.

Après avoir formalisé le problème dans la section suivante, la méthode ToTeM sera
décrite dans la section 3.3. Les optimisations implantées dans la méthode seront dé-
veloppées dans la section 3.4. La complexité de la méthode sera analysée dans la sec-
tion 3.5. Les différents critères globaux de qualité que nous envisageons sont décrits
dans la section 3.6. Nous évaluerons les performances de ToTeM sur des réseaux arti-
ficiels dans la section 3.7 puis sur des réseaux d’information d’origine bibliographique
dans la section 3.8 et dans la section 3.9. Nous conclurons dans la section 3.10.

3.2 Formalisation

Étant donné un graphe G = (V, E) où V est l’ensemble des sommets et E ⊂ V × V
est l’ensemble des arêtes éventuellement valuées. Dans la suite, on notera A la matrice
d’adjacence de G telle que Avv′ indique la valuation de l’arête entre v et v′ si elle existe

et vaut 0 sinon. Le degré du sommet v, noté k(v), est égal à

v′∈V Avv′.

On considère les sommets de l’ensemble V comme des éléments d’un espace vec-

3.2. Formalisation

81

toriel à |T| dimensions. Chaque élément v de V est associé à un vecteur d’attributs ⃗v,
que par souci de simplification des notations nous noterons simplement v :

v = (v1, . . . , v|T|)

(3.1)

De plus, chaque sommet est associé à une masse mv. Dans le graphe initial, la

masse de chaque sommet est égale à 1.

Nous nous limiterons au cas où le processus de détection de communautés consiste
à partitionner l’ensemble V des sommets en r classes distinctes P = {C1, . . . , Cr} où
r est a priori inconnu. Les classes à produire réalisent une partition de V : elles ne se
recouvrent pas et chaque classe comporte au moins un élément, selon les définitions
proposées dans la section 2.2.1.

– 

k∈{1,...,r} Ck = V

– Ck ∩ Cl = ∅, ∀ 1 ≤ k < l ≤ r
– Ck ̸= ∅, ∀k ∈ {1, . . . , r}
Enfin, on note cv la classe d’appartenance du sommet v dans la partition P.

Dans certains algorithmes de détection de communautés, comme par exemple ce-
lui de Newman et al. basé sur l’intermédiarité, les classes recherchées doivent être
connexes (Newman et Girvan, 2004). On dit qu’une classe C est connexe au sein du
graphe G si entre toute paire de sommets de cette classe on peut trouver un chemin
composé de sommets de cette même classe.

∀(v, v′) ∈ C × C ∃v1, v2, . . . , vn ∈ C | (v, v1) ∈ E, (v1, v2) ∈ E,
. . . , (vn−1, vn) ∈ E, (vn, v′) ∈ E

(3.2)

Nous adoptons le principe selon lequel les communautés à découvrir sont sinon
toujours connexes, le plus souvent proche de la connexité, et que ceci est utile dans
leur construction. C’est une hypothèse forte dans le sens où elle empêchera de rassem-
bler des individus identiques mais isolés parce qu’ils ne sont pas les extrémités d’un
chemin d’individus appartenant à la même classe. Une telle restriction à des commu-
nautés connexes est présente dans les travaux d’Ester et al. (Ester et al., 2006) alors
qu’elle ne l’est pas dans ceux de Dang et al. (Dang et Viennet, 2012).

Nous verrons néanmoins dans la section 3.6.3 que l’on ne garantira pas strictement

la connexité des classes.

82

Chapitre 3. ToTeM

3.3 La méthode ToTeM

La méthode ToTeM vise à construire une partition des sommets du réseau en consi-

dérant à la fois les relations qui existent entre les sommets et leurs attributs.

Notre proposition est une extension d’une méthode de partitionnement de graphe
qui a provoqué un intérêt fort dans la communauté de l’analyse des réseaux sociaux :
la méthode dite de Louvain (Blondel et al., 2008). La méthode de Louvain a pour
avantages sa vitesse, sa simplicité et le fait qu’elle repose à la fois sur un critère (la
modularité) lui-même très étudié et sur un principe intuitif comme exposé dans la
section 2.3.2.5. ToTeM conserve la même logique exploratoire mais repose sur l’utili-
sation d’un critère de qualité hybride. Ce critère permet de classer les sommets en se
souciant à la fois de la qualité des classes d’un point de vue relationnel mais également
du point de vue des attributs.

La méthode fait appel aux notions de modularité et d’inertie interclasses, notions
importantes dans l’état de l’art, respectivement en détection de communautés dans les
graphes (voir section 2.3.2.2) et en apprentissage non supervisé (voir section 2.2.3.1).

Un exemple de critère que la méthode pourra optimiser est le suivant :

CG1 =

Iinter(P)

I(V )

· QN G(P)

(3.3)

où Iinter(P) est l’inertie interclasses associée à la partition P.

ToTeM comprend deux phases principales. La phase itérative consiste à optimiser
un critère de qualité jusqu’à convergence vers un optimum local tandis que la seconde
a pour but de synthétiser les données du réseau d’information dans le but d’échapper
à des optima locaux. Les différentes étapes de cette méthode, décrites ci-après, seront
présentées sur un exemple décrivant un réseau d’information à 9 sommets caractérisés
chacun par une valeur réelle indiquée entre crochets sur le sommet à la figure 3.1.

3.3.1 Initialisation

Initialement, chaque sommet est affecté à une classe qui lui est propre et il est
décrit par un vecteur à valeurs réelles. L’algorithme démarre donc avec la partition
discrète.

3.3.2 Phase itérative

Après l’initialisation arrive la phase itérative. Celle-ci consiste pour chaque sommet
à mesurer l’amélioration du critère global obtenue en le plaçant dans la classe d’un
de ses sommets voisins. Si il y a une amélioration effective du critère, le sommet

3.3. La méthode ToTeM

83

FIGURE 3.1 – Réseau d’information d’illutration

est affecté à la classe pour laquelle cette amélioration est la plus grande. Si aucune
amélioration n’est possible, le sommet reste dans sa classe initiale. Le critère global est
basé à la fois sur la modularité et sur l’inertie interclasses. On itère ainsi sur l’ensemble
des sommets jusqu’à ce qu’aucun déplacement ne soit plus observé sur une itération
entière.

Dans l’exemple illustratif, la phase itérative consistera ainsi à prendre un premier
sommet, dans la figure 3.2 par exemple le sommet d’attribut 11, et à calculer la va-
leur du critère global lorsque ce sommet est placé avec le sommet d’attribut 2 ou 9
ou 22. Si le critère a une valeur supérieure quand le sommet d’attribut 11 est placé
avec le sommet d’attribut 9, alors on place ces deux sommets dans une communauté
conjointe. Si le sommet d’attribut 11 avait eu une valeur de critère supérieure en étant
placé seul, alors il serait resté dans sa propre classe. Un exemple d’état du réseau à la
fin de cette phase est donné par la figure 3.3

3.3.3 Phase de fusion des sommets

Lors de cette seconde étape, qui est exécutée lorsque plus aucun sommet ne peut
être déplacé en provoquant un gain, on construit un nouveau graphe en fusionnant
tous les sommets d’une classe en un nouveau sommet. Les sommets ainsi associés le
seront alors définitivement. La fusion concerne d’une part les données relationnelles et
d’autre part les données d’attributs et elle est détaillée dans les sous-sections suivantes.

[1][2][9][11][28][30][22][24][23]84

Chapitre 3. ToTeM

FIGURE 3.2 – Phase itérative

FIGURE 3.3 – Partition obtenue à la fin de la phase itérative

[1][2][9][11][28][30][22][24][23]???Contour de communauté[1][2][9][11][28][30][22][24][23]C1C2C4C33.3. La méthode ToTeM

85

3.3.3.1 Synthèse des informations relationnelles

L’opération de synthèse des informations du graphe consiste, à l’instar de ce qui
est opéré dans la méthode de Louvain, à fusionner les sommets affectés à une même
classe de façon à n’en faire qu’un seul sommet. Ainsi, à partir de la partition P′ =
(C1, . . . , Cr) obtenue à l’issue de la phase d’optimisation, un nouveau graphe G′ =
(V ′, E′) est crée. Ce graphe comporte autant de sommets qu’il y a de classes dans
P′ et chaque sommet v′
l de V ′ incarne une classe Cl de P′. La valuation de l’arête
éventuellement présente entre les sommets v′
z de V ′ est égale à la somme des
valuations des arêtes présentes entre des sommets de G appartenant aux classes Cy et
Cz de P′.

y et v′

Soit τ la fonction qui indique, pour un sommet v de V , par quel sommet v′ de
V ′ il est représenté, alors la valuation associée à une arête est calculée de la façon
suivante :

Ava,vb · δ(τ (va), v′

y) · δ(τ (vb), v′
z)

(3.4)



A′

v′
y,v′

z =

(va,vb)∈V ×V

où A est la matrice d’adjacence de G, A′ est la matrice d’adjacence de G′ et δ est la
fonction de Kronecker.

Il est à souligner que ceci est aussi applicable aux arêtes internes aux classes de

P ; celles-ci deviennent des boucles dans G′.

Cette opération est illustrée par la figure 3.4 où une boucle est créée sur les som-
mets représentant les communautés C1, C2 et C3, car ces dernières contenaient cha-
cune une arête interne. La communauté C4 contenant deux arêtes internes, deux
boucles sont créées sur le sommet correspondant. Chaque nouveau sommet est lié
aux sommets voisins de la même façon que la communauté qu’il représente était liée
aux autres communautés.

3.3.3.2 Synthèse des informations des attributs

Après avoir opéré la fusion des éléments d’un point de vue relationnel, comme
exposé dans la section précédente, il est nécessaire de transférer les informations
relatives aux attributs sur le nouveau graphe G′.

Pour cela, on affecte les masses mCl des classes d’origine aux sommets correspon-
dants dans G′. De plus, le centre de gravité de la classe Cl devient le vecteur d’attributs
du sommet v′
l de V ′ résultant de
la classe Cl de P′ on a :

l de V ′ correspondant à Cl. Ainsi, pour tout sommet v′

86

Chapitre 3. ToTeM

FIGURE 3.4 – Fin de la phase de fusion des sommets

l

= mCl

mv′
v′
l = gCl

(3.5)

(3.6)

Sur la figure 3.4, on constate que dans le graphe des communautés G′ image du
graphe G les sommets sont associés aux masses et aux centres de gravité qui caracté-
risaient chaque communauté de la partition des sommets de G.

La méthode ToTeM est détaillée dans l’algorithme 4.

3.4 Optimisation du calcul de la modularité et de l’inertie

De même que dans l’algorithme de Louvain, le calcul de la modularité peut être
optimisé en tenant compte uniquement des changements induits localement par le
déplacement d’un sommet. Nous montrons dans cette section qu’il en va de même
pour l’inertie interclasses.

D’après Blondel et al., le gain de modularité induit par le déplacement d’un som-

met isolé u vers une classe B est égal à (Blondel et al., 2008) :





2





∆Q =

in +2ku,in

−

2M

tot +k(u)
2M

−

−

in
2M

tot
2M

arêtes du graphe,
dans la classe B,

où k(u) et le degré valué du sommet u, M est la somme des valuations de toutes les
in est la somme des poids des arêtes ayant leurs deux extrémités
tot est la somme des poids des arêtes adjacentes aux sommets de

2 −

 k(u)

2

2M

(3.7)

mC=3C=23MC=2C=29MC=2C=1,5mC=2C=10C1C2C3C411224433gggg3.4. Optimisation du calcul de la modularité et de l’inertie

87

Algorithme 4 : ToTeM

Entrées : Réseau d’information G
Sorties : Partition P
répéter

fin ← faux;
P ← partition discrète des sommets de V ;
CG_antérieur ← valeur du critère global de la partition P;
répéter

pour chaque sommet u de G faire

B ← communauté voisine maximisant le gain du critère de qualité;
si le placement de u dans B induit un gain strictement positif alors

Mettre à jour la partition P suite au transfert de u dans B

jusqu’à ce qu’aucun sommet ne puisse plus être déplacé ;
si le critère de qualité global de P est supérieur à CG_antérieur alors

sinon

Fusionner G en un réseau d’information entre les classes;
fin ← vrai ;

jusqu’à fin ;
P ← P partition des sommets de V

1
2
3
4
5
6
7
8
9

10
11
12
13
14

15
16

B, ku,in est la somme des poids des arêtes reliant u aux sommets de B (Blondel et al.,
2008).

De même, dans ToTeM, l’efficience de l’algorithme peut être améliorée en remar-
quant que la variation d’inertie interclasses induite par le déplacement d’un sommet
de sa classe vers celle de l’un de ses voisins peut se calculer avec uniquement une
information locale. Ainsi, comme pour la modularité, il est possible de calculer le gain
de inertie interclasses induite par le déplacement d’un sommet u d’une classe A vers
une classe B.

Considérons deux partitions P et P′ telles que : P = (A, B, C1, . . . , Cr) et

P′ = (A \ {u} , B ∪ {u} , C1, . . . , Cr).

Par la suite, A \ {u} désigne la classe A privée du sommet u et B ∪ {u} la classe B

augmentée du sommet u.

L’inertie interclasses Iinter(P) associée à la partition P est égale à :

Iinter(P) = mA ∥gA − g∥2 + mB ∥gB − g∥2 +

ml ∥gl − g∥2

(3.8)

où gA est le centre de gravité de A, gB est le centre de gravité de B, mA est le poids

l=1,...,r



88

Chapitre 3. ToTeM

de A et mB est le poids de B.

L’inertie interclasses de la partition P′ obtenue en retirant u de sa classe A et en

l’affectant à la classe B vaut :

Iinter(P′) = mA\{u}

gA\{u} − g

2

+ mB∪{u}

gB∪{u} − g

2

+



l=1,...,r

ml ∥gl − g∥2

(3.9)

La variation d’inertie interclasses induite par le déplacement du sommet u de la

classe A vers la classe B est donnée par :

∆Iinter =Iinter(P′) − Iinter(P)

=mA\u ·gA\{u} − g
2
+ mB∪u ·gB∪{u} − g
− mA · ∥gA − g∥2 − mB · ∥gB − g∥2 −
2
=(mA − mu) ·gA\{u} − g


+ (mB + mu) ·gB∪{u} − g

ml ∥gl − g∥2

2

2

+

ml ∥gl − g∥2

− mA · ∥gA − g∥2 − mB · ∥gB − g∥2

(3.10)

(3.11)

(3.12)

gA\{u} et gB∪{u} sont eux aussi calculés facilement en considérant le sommet u et

les classes A et B ainsi que leurs centres de gravités gA, gB :



gA\{u} =

1

mA\{u}

=

gB∪{u} =

mA − mu

1

1

mB + mu

mvv

v∈A\{u}
(mA · gA − mu · u)
(mB · gB + mu · u)

(3.13)

(3.14)

(3.15)

On notera qu’à la suite du déplacement, la classe A peut se retrouver vide et donc

disparaître. Sa contribution à l’inertie interclasses devient alors nulle.

Les valeurs des masses associés aux classes peuvent aussi être recalculées à l’aide

de l’information locale :

mA\{u} = mA − mu
mB∪{u} = mB + mu

(3.16)
(3.17)

3.5. Complexité

3.5 Complexité

89

Brandes et al. ont prouvé que l’optimisation de la modularité était un problème NP-
complet (Brandes et al., 2007). Les auteurs de la méthode de Louvain reconnaissent
à celle-ci une complexité théorique en O(|E|3) dans le pire des cas. Cependant, dans
la pratique, les temps d’exécution sont plutôt ceux d’un processus en temps linéaire
(Aynaud et al., 2010; Seifi, 2012). Ceci s’explique par la convergence très rapide du
critère de modularité, qui ne rencontre pas de cas aussi défavorable que l’algorithme
peut le laisser supposer.

Si pour la méthode de Louvain le déplacement d’un sommet d’une classe à l’autre
est une opération élémentaire, cette opération devient linéaire avec la prise en compte
des attributs (O(|T|)). On a vu dans la section 3.3.3.2 que la synthèse des informations
des attributs lors de la phase 2 était elle immédiate. La vitesse de calcul est aussi
affectée par les calculs liés au calcul du critère global, qui pour le critère CG2 que
nous préconisons et qui sera décrit ultérieurement, ont une complexité élémentaire,
donc sans incidence sur la complexité théorique. On a donc une complexité, pour un
déplacement et dans le pire des cas, de O(|T |). Ceci nous amène à une complexité
dans le cas le plus défavorable en O(|T|×|E|3). Comme pour la méthode de Louvain,
ceci doit être pris en compte comme une borne théorique qui n’est pas rencontrée dans
la pratique. Une amélioration possible est la mise en mémoire des valeurs de critères
déjà calculées, car l’heuristique d’exploration calcule la qualité de certaines partitions
de multiples fois, surtout à la fin de la phase itérative. Cependant ceci nécessite la mise
en place de structures de stockage adéquates permettant de reconnaître des partitions,
ou des classes, qui ont déjà été rencontrées.

3.6 Critères globaux de qualité

Si l’utilisation de la modularité, couplée à l’heuristique de la méthode de Louvain,
est efficace pour détecter les communautés structurelles dans les graphes, le critère
que nous devons utiliser doit aussi séparer les sommets quand leurs valeurs d’attributs
divergent.

Ce critère de qualité globale intervenant dans ToTeM doit donc être une fonction
d’une mesure de la qualité de la partition par rapport aux relations et d’une mesure de
sa qualité par rapport aux attributs. La modularité QN G (définie par l’équation 2.38)
peut être utilisée comme mesure de la qualité par rapport aux relations. Pour ce qui
est de la qualité par rapport aux attributs, une première solution envisageable peut
consister à prendre le taux d’inertie interclasses. Ce qui conduit à une première mesure
de qualité globale définie par :

90

Chapitre 3. ToTeM

CG1 =

Iinter(P)

I(V )

· QN G(P)

(3.18)

où Iinter(P) désigne l’inertie interclasses de P et I(V ) désigne l’inertie de V .
On justifie un tel critère par le besoin de créer des classes aussi distinctes que pos-
sible du point de vue des attributs (donc avec une inertie interclasses forte). Comme
l’inertie interclasses est bornée par l’inertie totale et que la modularité est elle même
bornée par la valeur 1, cet indice est lui aussi borné par 1. Cependant, l’inconvénient
de ce critère global est que l’inertie interclasses n’est pas conçue pour comparer des
partitions ayant un nombre de classes différent. En effet, le taux d’inertie interclasses
varie structurellement avec le nombre de classes de la partition de sorte qu’il est maxi-
mum pour la partition discrète. Une solution simple visant à palier ce biais structurel
consiste à tenir compte du nombre de classes de la partition pour définir un critère
global. Ceci nous mène à la définition d’un deuxième critère :

Iinter(P)
|P| · I(V )

· QN G(P)

CG2 =

(3.19)
où |P| désigne le nombre de classes de P. Contrairement au précédent, ce critère
donne un avantage aux partitions à faible nombre de classes, celles que l’inertie inter-
classes a en pratique une forte tendance à pénaliser. Une autre alternative pour palier
le biais structurel consiste à avoir recours à des indices conçus dans le but d’optimiser
le nombre de classes dans le cas du partitionnement de données vectorielles, comme
par exemple l’indice de Calinski-Harabasz.

3.6.1 Indice de Calinski-Harabasz

Ainsi l’indice de Calinski-Harabasz CH peut-il être introduit au sein du critère
global à la place de l’inertie interclasses (Calinski et Harabasz, 1974). Il est défini
par :

CH(P) =

Iinter(P)/(|P| − 1)
Iintra(P)/(|V | − |P|)

(3.20)

où Iintra est l’inertie intraclasses. Ce critère permet de comparer deux partitions quelque
soit leurs nombres de classes, tandis que l’inertie interclasses ne permet que de compa-
rer des partitions avec un même nombre de classes. On peut également avoir recours
à d’autres indices de validation internes de détection de communauté comme l’indice
de Dunn ou de Davies-Bouldin (voir section 2.3.3.1) (Davies et Bouldin, 1979; Duda
et Hart, 1973; Baker et Hubert, 1975; Milligan et Cooper, 1985).

3.6. Critères globaux de qualité

91

3.6.2 Probabilité critique

Une autre solution pour comparer deux partitions P et P′ consiste à faire appel à
des tests statistiques. En effet, sous l’hypothèse nulle selon laquelle les éléments sont
répartis aléatoirement au sein de la partition P, la statistique F (P) définie par :

FP =

Iinter/(|P| − 1)

(I(V ) − Iinter)/(|V | − |P|))

(3.21)

suit une loi de Fisher-Snedecor F (|P|− 1,|V |−|P|) à (|P|− 1,|V |−|P|) degrés de
liberté.

On peut donc calculer la probabilité critique P C associée :
P C = P (F (|P| − 1,|V | − |P|) > FP )

(3.22)

De même, la statistique F (P′) peut être déterminée sur la partition P′ et on peut en
déduire P C′ :

P C′ = P (F (P′ − 1,|V | −P′) > FP′)

(3.23)
La comparaison des probabilités critiques associées à P et à P′ conduira à préfé-

rer la partition pour laquelle cette probabilité est la plus faible.

De la même façon que dans le contexte de la classification automatique les mesures
d’agrégation et de proximité sont difficiles à choisir, les critères globaux pour la clas-
sification des sommets d’un réseau d’information ne font pas l’objet d’un consensus.
Leur choix dépend de la sémantique des informations, de la dominance éventuelle des
attributs sur les relations ou inversement, ainsi que des problématiques de contrôle
de la taille des classes produites les unes par rapport aux autres.

3.6.3 Remarque sur l’utilisation de Louvain pour l’optimisation d’un score

différent de la modularité

L’heuristique de Louvain a inspiré de nombreux travaux. Certains, dont notre pro-
position, modifient le critère à optimiser. Au cours de l’heuristique, les fusions de
communautés ne sont opérées qu’entre communautés reliées au moins par une arête.
Il est nécessaire de garder à l’esprit que si l’optimisation de la modularité donne des
communautés finales connexes, l’optimisation d’un autre critère ne garantit pas un tel
résultat. Cette mise au point est faite par exemple par Martelot et Hankin (Le Mar-
telot et Hankin, 2013). Utilisant divers critères dans leur tâche de détection de com-
munautés relationnelles, ils suggèrent, lorsqu’un changement d’affectation de sommet
a été jugé préférable, de vérifier auparavant si celui-ci casse une communauté exis-
tante. En effet, si le sommet à transférer était le seul pont entre deux sous-ensembles

92

Chapitre 3. ToTeM

de sommets de la communauté, alors cette dernière se retrouvera scindée. Les deux
sous-groupes de sommets conserveront malgré tout une information enregistrée les
affectant dans la même communauté mais cette dernière ne sera pas connexe.

Martelot et Hankin préfèrent ne pas opérer le changement d’affectation si le cas
se présente. La technique de vérification utilise un parcours en largeur, au sein de la
communauté, afin de savoir si tous les sommets sont atteignables depuis un point de
la communauté, malgré le changement d’affectation. Ils expliquent que la modularité
offre une garantie contre ce phénomène. Mais, en toute généralité, les critères ne
fournissent pas cette garantie structurelle.

Pour notre part, nous préférons ne pas garantir la connexité des classes par souci
d’efficience. Il appartiendra à l’utilisateur de modifier l’algorithme de ToTeM en sui-
vant la démarche de Martelot et Hankin pour assurer cette connexité si elle est néces-
saire.

Un autre point à soulever concernant le choix du critère à optimiser concerne sa
cohérence face à la fusion des sommets dans la seconde phase. Afin que l’exploration
des partitions soit cohérente, et surtout respecter l’unicité du score pour une partition
donnée, le critère doit respecter l’égalité entre les scores de la partition des deux
graphes entre le début et la fin de la phase de fusion. L’utilisation des masses garantit
ce comportement dans notre usage de l’inertie interclasses.

3.7 Évaluation sur des réseaux artificiels

Afin d’étudier le comportement de l’algorithme face à des méthodes prenant en
compte uniquement les attributs ou les relations, nous avons généré automatiquement
des graphes. À partir d’un graphe de référence pour lequel les partitionnements basés
sur les attributs ou les relations sont très proches, nous avons dégradé tantôt les at-
tributs, tantôt les relations. Notre objectif est d’évaluer l’impact de cette dégradation.
Nous avons appliqué les trois algorithmes que sont les K-means, pour un partitionne-
ment sur les attributs, Louvain, pour un partitionnement selon les arêtes et ToTeM,
notre méthode hybride, pour les réseaux d’information.

L’implémentation de la méthode de Louvain que nous utilisons est celle de Tho-
mas Aynaud réalisée en langage Python, proposée en 2009 1 qui prend en compte la
valuation des arêtes pour la détection des communautés. On précise que le critère qui
est utilisé pour ToTeM est :

CG2(P) =

Iinter(P) × QN G

|P| × I(V )

(3.24)

1. http://perso.crans.org/aynaud/communities/

3.7. Évaluation sur des réseaux artificiels

93

Dans la suite, nous modifions plusieurs paramètres : le nombre de sommets, la
densité du graphe, la pertinence du placement des arêtes au regard de la catégorie
d’origine des sommets ainsi que l’écart-type des distributions des attributs à l’intérieur
des classes. La "détérioration" des attributs consiste à rendre les valeurs de différents
sommets de moins en moins caractéristiques d’une classe particulière. La détérioration
des relations changera des arêtes intraclasses en arêtes interclasses. Selon notre hypo-
thèse, la méthode ToTeM préservera la partition d’origine au-delà de ce que pourront
faire la méthode de Louvain ou les K-means, lors de l’application des dégradations du
réseau.

Pour notre étude, nous partirons d’un graphe dont le découpage en partitions par
une méthode aussi bien basée sur les relations que sur les attributs donne de bons
résultats avec peu d’ambiguïté. Nous créons un graphe de départ ayant trois classes
composées de 33 sommets chacune. À partir de ce réseau de référence noté R dans la
suite, nous avons construit les familles de réseaux :

– R.1.x dans lesquels l’information relationnelle est dégradée par rapport à R,
– R.2.x dans lesquels les valeurs des attributs sont moins représentatives de chaque

classe,

– R.3.x qui comportent plus de sommets que R,
– R.4.x qui comportent plus d’arêtes que R.

Nous comparons pour chaque graphe ainsi généré les partitions données par ToTeM,
la méthode de Louvain et les K-means.

L’évaluation sera faite sur le nombre de classes trouvées, le taux de sommets bien
classés (TBC), l’information mutuelle normalisée (NMI), la modularité (QN G), l’iner-
tie interclasses (Iinter) et deux indices de silhouette utilisant pour le premier la dis-
tance géodésique (silhouette-Liens) et pour le second la distance entre les vecteurs
associés à deux sommets (silhouette-Attributs) (voir section 2.2.3.1). Ces indices, sur
critères internes et externes, nous permettront de savoir si la partition retournée est
bien proche de la vérité terrain (TBC, NMI) et si elle a des classes compactes du
point de vue des liens comme des attributs (QN G, Iinter, silhouette-Liens et silhouette-
Attributs).

Les résultats obtenus sur le réseau de référence et ses caractéristiques sont décrits

dans la prochaine section, les suivantes sont consacrées aux autres réseaux.

3.7.1 Réseau de référence (R)

On génère, à l’aide du modèle proposé par Dang (Dang, 2012) et décrit dans la

section 2.4.7, un réseau de référence R.

Pour construire ce graphe de référence, nous introduisons 99 sommets uniformé-

94

Chapitre 3. ToTeM

ment répartis entre 3 catégories. Chaque sommet est décrit par une valeur d’attribut
réelle qui suit une loi normale d’écart-type 7, centrée autour d’une valeur propre à sa
classe d’origine. Ainsi la première classe a un centre µ1 = 10, la deuxième un centre
µ2 = 40 et la troisième un centre µ3 = 70. La classe d’origine du sommet sert de vérité
terrain pour l’évaluation. Enfin, durant la génération du graphe de référence, nous
avons choisi que le processus de génération des arêtes crée au maximum deux arêtes
à chaque fois qu’un nouveau sommet est introduit.

Ce réseau de référence R comporte donc 99 sommets et 168 arêtes. Le graphe de
référence R est représenté dans la figure 3.6 et la distribution des valeurs des attributs
attachés aux sommets de chaque classe dans la figure 3.5.

FIGURE 3.5 – Distribution des attributs des sommets du réseau R (écart-type de 7)

La table 3.1 montre la répartition des arêtes entre les classes dans ce graphe R.
L’évaluation de la méthode ToTeM sera effectuée sur le graphe de référence R et
les résultats seront comparés à ceux produits par la méthode de Louvain et par les
K-means en fixant le paramètre à 3.

Catégorie 1 Catégorie 2 Catégorie 3

Catégorie 1
Catégorie 2
Catégorie 3

55
2
1

53
7

50

TABLE 3.1 – Répartition des extrémités des liens du graphe de référence R

Résultats sur le réseau de référence

Les résultats de l’application des trois méthodes sont présentés dans la table 3.2.

02468101214--------1001020304050607080Nombre de sommetsValeurs d'attributs3.7. Évaluation sur des réseaux artificiels

95

FIGURE 3.6 – Catégories de la vérité terrain du jeu de données synthétique de réfé-
rence

On constate que ToTeM surpasse la méthode de Louvain, mais ne fait pas mieux
que les K-means qui parviennent à un très bon résultat en terme de taux de bien
classés. ToTeM suit de près les K-means, pour lesquels le nombre de classes est fixé par
avance. La méthode de Louvain provoque néanmoins la scission de l’une des classes.
Sur ce jeu, les taux de biens classés sont élevés pour les 3 méthodes.

96

Chapitre 3. ToTeM

Nombre de classes
Taux de bien classés
NMI
QN G
Iinter
silhouette-Liens
silhouette-Attributs

ToTeM Louvain K-means
3
0,970
0,91
0,60
659
0,46
0,80

4
0,838
0,78
0,62
651
0,48
0,78

3
0,960
0,86
0,61
658
0,47
0,80

TABLE 3.2 – Résultats sur le réseau R

3.7.2 Dégradation de l’information relationnelle (réseaux R.1.1 et R.1.2)

On veut d’abord savoir si la méthode parvient à maintenir ses résultats dans la
situation où l’information relationnelle est dégradée. Un nombre important d’arêtes
intraclasses aide à la fois la méthode de Louvain et ToTeM à retrouver les communau-
tés. On veut réduire le nombre d’arêtes intraclasses et introduire à la place des arêtes
interclasses, qui compliquent la tâche de classification.

Pour ce faire, on introduit l’algorithme 5 dans lequel un paramètre détermine la

proportion d’arêtes intraclasses à remplacer par une arête interclasses.

Algorithme 5 : Algorithme de dégradation de l’information relationnelle

Entrées : le graphe G, la proportion d’arêtes intraclasses à transformer en

arêtes interclasses ratioarˆetes

Sorties : le graphe G modifié avec une information relationnelle dégradée
on fait la liste des arêtes intraclasses (celles dont les deux extrémités sont de la
même classe de la partition vérité terrain);
pour tous les i de 0 à ratioarˆetes × nb_arˆetes faire

on choisi une arête de la liste;
on choisi une de ses extrémités;
on choisi un sommet v′ au hasard dans le graphe tel qu’il n’est pas issu de la
même classe ;
on remplace le sommet incident de l’extrémité choisie par v′;

1

2

3

4

5

6

On propose de mesurer les résultats sur les graphes R.1.1 et R.1.2, dégradés res-

pectivement avec des valeurs du paramètre de 0,25 et 0,5.

On ne retient la dégradation appliquée au graphe de référence que si le nouveau
graphe est connexe. La répartition des liens entre les classes, pour un facteur de dé-
gradation de 0,25, est présentée dans le tableau 3.3. Les résultats sont présentés dans
le tableau 3.4.

3.7. Évaluation sur des réseaux artificiels

97

Catégorie 1 Catégorie 2 Catégorie 3

Catégorie 1
Catégorie 2
Catégorie 3

43
12
18

39
18

35

TABLE 3.3 – Répartition des extrémités des liens du graphe R.1.1

Nombre de classes
Taux de bien classés
NMI
QN G
Iinter
silhouette-Liens
silhouette-Attributs

ToTeM Louvain K-means
3
0,97
0,91
0,60
659
0,47
0,80

9
0,24
0,22
0,54
175
0,40
0,22

30
0,18
0,49
0,40
654
0,67
0,78

TABLE 3.4 – Résultats sur le graphe R.1.1

La répartition des liens entre les classes pour un facteur de dégradation de 0,5 est

présentée dans le tableau 3.5. Les résultats sont présentés dans le tableau 3.6.

Catégorie 1 Catégorie 2 Catégorie 3

Catégorie 1
Catégorie 2
Catégorie 3

30
28
25

24
32

24

TABLE 3.5 – Répartition des extrémités des liens du graphe R.1.2

La dégradation de l’information relationnelle provoque une augmentation du nombre

de classes retournées par ToTeM. La NMI de ToTeM se montre néanmoins sensible-
ment supérieure à celle de la méthode de Louvain pour les deux valeurs de para-
mètres testées. Cela traduit le fait que les classes trouvées par ToTeM recoupent mieux
la partition de la vérité terrain que les classes produites par la méthode de Louvain
notamment lorsque la dégradation est forte.

98

Chapitre 3. ToTeM

Nombre de classes
Taux de bien classés
NMI
QN G
Iinter
silhouette-Liens
silhouette-Attributs

ToTeM Louvain K-means
3
0,970
0,91
0,60
659
0,46
0,80

10
0,141
0,12
0,52
169
0,41
0,20

36
0,141
0,38
0,42
544
0,64
0,62

TABLE 3.6 – Résultats sur le graphe R.1.2

3.7.3 Dégradation des attributs (réseaux R.2.1 et R.2.2)

On teste ensuite la robustesse de la méthode sur des réseaux d’information où
les vecteurs d’attributs sont moins caractéristiques des classes de la vérité terrain.
Pour cela, on se propose d’augmenter l’écart-type des attributs générés pour chacun
des sommets. Le but est d’obtenir des distributions des valeurs d’attributs qui se che-
vauchent de plus en plus. Nous avons évalué les conséquences d’une augmentation
de l’écart-type à des valeurs de 10 et 12 correspondant respectivement aux réseaux
d’information notés R.2.1 et R.2.2. Les figures 3.7 et 3.8 présentent respectivement
les distributions des attributs par classe pour ces réseaux.

FIGURE 3.7 – Distribution des attributs par classe sur R.2.1 (écart-type de 10)

Pour un écart-type de 10, les résultats sont à consulter dans le tableau 3.7 et le taux
de biens classés s’élève à 95% tandis que pour un écart-type de 12, ils sont présentés
dans le tableau 3.8 et le taux de biens classés s’élève à 19% avec la méthode ToTeM.
On remarque que les résultats restent bons pour un écart-type de 10 et que ToTeM

Nombre de sommetsValeurs d'attributs-2004020608024683.7. Évaluation sur des réseaux artificiels

99

Nombre de classes
Taux de bien classés
NMI
QN G
Iinter
silhouette-Liens
silhouette-Attributs

ToTeM Louvain K-means
3
0,919
0,75
0,56
712
0,44
0,76

4
0,838
0,78
0,62
690
0,48
0,71

3
0,949
0,82
0,61
703
0,46
0,74

TABLE 3.7 – Résultats sur le graphe R.2.1

FIGURE 3.8 – Distribution des attributs par classe sur le réseau R.2.2 (écart-type de
12)

supporte mieux la dégradation d’information que les K-means d’après la NMI. Avec un
écart-type de 12, les résultats de ToTeM sont très dégradés. Ceci est une conséquence
du grand nombre de classes produites (26). Ceci affecte directement le taux de biens
classés et, dans une moindre mesure, les autres critères tels que la NMI qui reste
néanmoins proche de celle de la partition fournie par les K-means pour laquelle le
nombre de classes attendues a été donné par l’utilisateur.

Nombre de sommetsValeurs d'attributs-200402060802468100

Chapitre 3. ToTeM

Nombre de classes
Taux de bien classés
NMI
QN G
Iinter
silhouette-Liens
silhouette-Attributs

ToTeM Louvain K-means
3
0,828
0,59
0,43
759
0,35
0,74

4
0,838
0,78
0,62
718
0,48
0,67

26
0,192
0,57
0,45
820
0,69
0,81

TABLE 3.8 – Résultats sur le graphe R.2.2

3.7.4 Augmentation de la taille du réseau (réseaux R.3.1 et R.3.2)

On cherche à déterminer l’influence du nombre de sommets sur les résultats de
la classification. On propose d’ajouter des sommets dans le graphe de référence et de
mesurer les résultats sur de nouveaux graphes de 999 et 5 001 sommets.

Pour un réseau R.3.1 à 999 sommets, la répartition des liens entre les classes est
présentée dans le tableau 3.9. Les résultats sont présentés dans le tableau 3.10. Le
taux de bien classés est de 96,2% pour ToTeM.

Catégorie 1 Catégorie 2 Catégorie 3

Catégorie 1
Catégorie 2
Catégorie 3

599
36
5

573
56

570

TABLE 3.9 – Répartition des extrémités des liens du graphe R.3.1

Nombre de classes
Taux de bien classés
NMI
QN G
Iinter
silhouette-Liens
silhouette-Attributs

ToTeM Louvain K-means
3
0,972
0,88
0,62
608
0,30
0,81

12
0,502
0,60
0,68
601
0,32
0,80

3
0,962
0,85
0,63
604
0,30
0,80

TABLE 3.10 – Résultats sur le graphe R.3.1

Pour un réseau R.3.2 à 5001 sommets, la répartition des liens entre les classes est
présentée dans le tableau 3.11. Les résultats sont présentés dans le tableau 3.12. Le
taux de bien classés est de 0,45%. Si ToTeM se comporte bien pour une petite aug-
mentation du nombre de sommets, une augmentation plus forte provoque la multipli-

3.7. Évaluation sur des réseaux artificiels

101

cation des classes trouvées par ToTeM, et une dégradation importante des résultats.
Le nombre de classes découvertes par la méthode de Louvain reste, lui, raisonnable.
Les K-means ne sont pas affecté par cette transformation du réseau.

Catégorie 1 Catégorie 2 Catégorie 3

Catégorie 1
Catégorie 2
Catégorie 3

3033
214
25

2934
244

2990

TABLE 3.11 – Répartition des extrémités des liens du graphe R.3.2

Nombre de classes
Taux de bien classés
NMI
QN G
Iinter
silhouette-Liens
silhouette-Attributs

ToTeM Louvain K-means
3
0,976
0,89
0,63
598
0,24
0,81

10
0,400
0,58
0,70
588
0,24
0,81

1518
0,005
0,38
0,38
640
0,79
0,97

TABLE 3.12 – Résultats sur le graphe R.3.2

3.7.5 Augmentation du nombre d’arêtes (réseaux R.4.1 et R.4.2)

On cherche ici à déterminer si la densité des arêtes dans le graphe a une influence
sur le résultat. Pour cela, on augmente le nombre d’arêtes ajoutées dans le graphe
lors de l’introduction de chaque nouveau sommet, à l’image de ce qui se fait dans le
modèle d’Albert et Barabási (Albert et Barabási, 2002).

Le jeu de référence R utilise une valeur de 2 arêtes par sommet introduit. On

propose de tester les résultats avec des valeurs de 5 et 10 arêtes.

On considère le réseau R.4.1 où 5 arêtes au maximum sont introduites à chaque
insertion d’un sommet dans le réseau. La répartition des liens entre les classes est
présentée dans le tableau 3.13 et les résultats dans le tableau 3.14.

Catégorie 1 Catégorie 2 Catégorie 3

Catégorie 1
Catégorie 2
Catégorie 3

95
20
2

92
16

90

TABLE 3.13 – Répartition des extrémités des liens du graphe R.4.1

102

Chapitre 3. ToTeM

Nombre de classes
Taux de bien classés
NMI
QN G
Iinter
silhouette-Liens
silhouette-Attributs

ToTeM Louvain K-means
3
0,970
0,91
0,60
659
0,46
0,80

3
0,960
0,85
0,56
581
0,38
0,79

3
0,949
0,81
0,57
581
0,39
0,79

TABLE 3.14 – Résultats sur le graphe R.4.1

Pour le graphe le plus dense R.4.2 où un maximum de 10 arêtes sont introduites
pour chaque ajout d’un sommet dans le réseau, la répartition des liens entre les classes
est présentée dans le tableau 3.15. Les résultats sont présentés dans le tableau 3.16.

Catégorie 1 Catégorie 2 Catégorie 3

Catégorie 1
Catégorie 2
Catégorie 3

147
30
4

142
27

158

TABLE 3.15 – Répartition des extrémités des liens du graphe R.4.2

Nombre de classes
Taux de bien classés
NMI
QN G
Iinter
silhouette-Liens
silhouette-Attributs

ToTeM Louvain K-means
3
0,969
0,91
0,60
659
0,46
0,80

3
0,969
0,88
0,55
586
0,39
0,80

3
0,979
0,92
0,55
587
0,39
0,81

TABLE 3.16 – Résultats sur le graphe R.4.2

On remarque que l’augmentation du nombre d’arêtes par sommet a plutôt un effet
positif sur les résultats de ToTeM, en particulier au niveau de la NMI. Si les K-means ne
sont pas affectés par cette modification, on ne s’étonne pas du fait que la méthode de
Louvain bénéficie elle aussi d’une amélioration lors de la détection des communautés.

3.7.6 Conclusion sur l’évaluation après dégradation de l’information

Les résultats en fonction de la NMI sont récapitulés dans le tableau 3.17. On pré-
cise que les valeurs entre parenthèses indiquent les scores qui n’ont pas été affectés

3.7. Évaluation sur des réseaux artificiels

103

par la dégradation appliquée. Les valeurs en gras indiquent, parmi les méthodes af-
fectées, laquelle a obtenu le meilleur score de NMI. Les résultats en terme de taux de
bien classés ne sont en effet pas raisonnablement calculables dans toutes les configu-
rations.

ToTeM

Louvain

K-means

0,49
0,38

0,82
0,57

0,78

0,22
0,12

Graphe de référence
R
0,91
Dégradation de l’information relationnelle
(0,91)
R.1.1
R.1.2
(0,91)
Dégradation des attributs
R.2.1
R.2.2
Augmentation de la taille du réseau
R.3.1
R.3.2
Augmentation du nombre d’arêtes
R.4.1
R.4.2

(0,78)
(0,78)

(0,91)
(0,91)

0,75
0,59

0,88
0,89

0,85
0,38

0,81
0,92

0,86

0,60
0,58

0,85
0,88

TABLE 3.17 – Bilan de l’expérimentation, selon le score de NMI entre la partition
terrain et la partition réelle)

ToTeM se comporte bien face à une augmentation importante de la densité des
liens. De plus, on constate que ToTeM montre une forte robustesse par rapport à Lou-
vain face à la dégradation de l’information relationnelle et par rapport aux K-means
face à une dégradation raisonnable de l’information apportée par les attributs. Ceci
démontre l’intérêt de la combinaison des deux informations. Par contre, l’augmen-
tation de la taille du graphe provoque une augmentation très rapide du nombre de
classes produites, et une forte dégradation des résultats.

3.7.7 Dégradation simultanée de l’information relationnelle et des va-

leurs des attributs sur un réseau de taille supérieure

On veut tester la performance de la méthode ToTeM dans le cas où on dégrade à la
fois les relations et les valeurs des attributs. Pour cela on utilise un nouveau graphe de
référence. Les attributs restent centrés sur µ1 = 10, µ2 = 40 et µ3 = 70. Les jeux sont
générés de façon à comporter chacun 3 classes de 999 sommets. Le nombre de liens
par lesquels un sommet est attaché à des sommets introduits précédemment est cette
fois-ci au maximum de 4, afin de ne pas affecter la densité de façon trop significative

104

Chapitre 3. ToTeM

par rapport aux expérimentations sur le réseau R. Il s’agit donc d’un graphe à la fois
plus grand et plus dense que celui utilisé dans la section 3.7.1.

Les attributs sont dégradés selon les modalités de l’algorithme 5 en considérant
des valeurs d’écart-type σ variant de 7 à 50. Le taux d’arêtes dégradées variera de 0 à
0,3. Les résultats sont présentés dans le tableau 3.18.

σ

NMI

ToTeM
Nb de
classes

Bien NMI

classés

Louvain
Nb de
classes

Bien NMI

classés

K-means
Nb de
classes

Bien
classés

Ratio d’arêtes
dégradées
0

0,1

0,2

0,3

7
10
20
30
50

7
10
20
30
50

7
10
20
30
50

7
10
20
30
50

0,89
0,92
0,84
0,70
0,47

0,82
0,87
0,60
0,40
0,22

0,74
0,82
0,52
0,27
0,18

0,78
0,74
0,49
0,27
0,12

3
3
3
5
4

3
3
3
5
8

3
5
3
4
8

3
3
3
3
10

0,97
0,98
0,96
0,89
0,79

0,94
0,97
0,87
0,52
0,42

0,92
0,96
0,83
0,68
0,60

0,94
0,93
0,80
0,66
0,54

0,76
0,76
0,76
0,76
0,76

0,60
0,60
0,60
0,60
0,60

0,33
0,33
0,33
0,33
0,33

0,15
0,15
0,15
0,15
0,15

5
5
5
5
5

6
6
6
6
6

8
8
8
8
8

14
14
14
14
14

0,85
0,85
0,85
0,85
0,85

0,63
0,63
0,63
0,63
0,63

0,42
0,42
0,42
0,42
0,42

0,16
0,16
0,16
0,16
0,16

0,90
0,73
0,34
0,19
0,09

0,90
0,73
0,34
0,19
0,09

0,90
0,73
0,34
0,19
0,09

0,90
0,73
0,34
0,19
0,09

(3)
(3)
(3)
(3)
(3)

(3)
(3)
(3)
(3)
(3)

(3)
(3)
(3)
(3)
(3)

(3)
(3)
(3)
(3)
(3)

0,98
0,92
0,69
0,57
0,47

0,98
0,92
0,69
0,57
0,47

0,98
0,92
0,69
0,57
0,47

0,98
0,92
0,69
0,57
0,47

TABLE 3.18 – Dégradation simultanée des relations et des attributs

3
7

.

.

É
v
a
l
u
a
t
i
o
n
s
u
r
d
e
s

r
é
s
e
a
u
x

a
r
t
i
fi
c
i
e
l
s

1
0
5

106

Chapitre 3. ToTeM

On voit que tant que la dégradation appliquée sur les attributs est faible, l’applica-
tion des K-means en trois classes est la plus efficace (écart-type à 7), mais nécessite de
connaître le nombre de classes. On constate aussi que pour une dégradation moyenne
des valeurs d’attributs (σ = 10 ou σ = 20), les K-means et la méthode de Louvain
sont dépassés par ToTeM en terme de NMI. En cas de forte dégradation des attributs,
la méthode de Louvain parvient évidemment à reprendre la tête car elle n’est pas af-
fectée par la baisse de qualité des attributs. Par ailleurs, lorsque le nombre de liens
dégradés est important, ToTeM va rester plus longtemps compétitif face à Louvain. De
plus, le nombre de classes découvertes par ToTeM est généralement plus faible que
celui des classes découvertes par Louvain, notamment en cas de forte dégradation des
liens (ratio = 0,3).

3.7.8 Conclusion sur l’évaluation sur des réseaux artificiels

Nous avons présenté des expérimentations testant l’apport effectif de ToTeM dans

des contextes de classification de réseaux d’information.

La première expérimentation a montré que la méthode était robuste face à une
dégradation de l’information relationnelle. En revanche, avec l’augmentation de la
taille du graphe, on a vu que le nombre de classes produites par ToTeM a tendance
à augmenter. La méthode de Louvain est également touchée par ce phénomène. On
rappelle que dans le comparatif, la méthode des K-means a bénéficié de la connais-
sance du nombre de classes à produire, alors que ce n’était pas le cas pour la méthode
de Louvain et ToTeM.

La deuxième expérimentation a montré que lorsque le réseau est dégradé dans
une mesure raisonnable à la fois au niveau des arêtes et au niveau des attributs des
sommets, notre méthode donne de bons résultats qui confirment tout l’intérêt de la
prise en compte simultanée des deux informations. On constate également dans cette
seconde expérimentation menée sur un graphe plus dense que précédemment que le
nombre des communautés retournées parvient cette fois à être plus faible qu’avec la
méthode de Louvain.

Ces expérimentations effectuées sur des réseaux artificiels montrent que ToTeM
apporte un bénéfice dans la classification combinée de réseaux d’information, mais le
problème du passage à l’échelle reste posé.

3.8 Évaluation de ToTeM sur le jeu des 4 sessions

Dans cette section, nous évaluons la méthode ToTeM sur un réseau bibliogra-
phique. Cette évaluation sera effectuée sur le jeu de données des 4 sessions construit

3.8. Évaluation un réseau bibliographique

107

par nos soins dans le but de mesurer l’apport de la prise en compte de la combinai-
son des sources de données (Combe et al., 2012a,b). Ce jeu est est décrit dans la
section 1.4.4. Rappelons que ce réseau comporte 99 auteurs et 2 623 relations de
coparticipation à des conférences.

3.8.1 Hypothèses et scénarios

L’évaluation sur le jeu de données des sessions cherche à étudier le comportement

des algorithmes par rapport à trois scénarios :

– Quelle est la thématique d’un auteur ?
– Dans quelle conférence a-t-il publié ?
– Dans quelle session a-t-il publié ?
On suppose que selon le scénario choisi, la solution pourra être plus ou moins
facilement trouvée selon que l’on exploite l’information textuelle, relationnelle ou les
deux.

Nous définissons ci-dessous les différents scénarios de classification. Nous considé-
rons quatre sous-ensembles A (Bioinformatique), B (Robotique-SAC), C (Robotique-
IJCAI) et D (Contraintes), rassemblant les auteurs publiant dans les quatre sessions
considérées (voir tableau 3.19).

Session et conférence de rattachement Effectif
A Bioinformatique (SAC)
24
16
B Robotique (SAC)
38
C Robotique (IJCAI)
D Contraintes (IJCAI)
21
99
Effectif du jeu de données

TABLE 3.19 – Effectif de chaque session

– Scénario 1 : Identification du domaine de recherche : 3 catégories (PT )

L’hypothèse qui fonde cette première expérience est que l’information textuelle
devrait permettre de retrouver les trois domaines de recherche : robotique, bio-
informatique et programmation par contraintes ; ceci revient à prendre comme
vérité terrain la partition en trois groupes contenant les auteurs rattachés à
chaque thématique de recherche : PT = {A, B ∪ C, D}.

– Scénario 2 : Identification de la conférence : 2 catégories (PS)

La prise en compte des données relationnelles seules devrait permettre d’iden-
tifier deux groupes correspondant aux auteurs qui participent à chaque confé-
rence et qui correspondent à la vérité terrain de la partition PS = {A∪B, C∪D}.

108

Chapitre 3. ToTeM

– Scénario 3 : identification de la session : 4 catégories (PT S)

Enfin, si nous voulons identifier les auteurs rattachés à chaque session, les in-
formations textuelles et relationnelles doivent alors être utilisées. Dans ce cas,
la partition associée à la vérité terrain est PT S = {A, B, C, D}.

Afin d’évaluer les algorithmes, nous serons donc en mesure pour chaque scénario
de comparer le résultat produit à la partition attendue (PS, PT ou PT S) et de calculer
un pourcentage de bien classés. De plus, les affectations des auteurs sont présentées
sous la forme de matrices de coïncidences. Ces matrices permettent à la fois de savoir
quelles sont les classes réelles qui sont les plus difficiles à retrouver, mais également
quelle est la répartition des auteurs des différentes sessions dans les partitions inférées
par la méthode.

Afin de comparer ToTeM à des méthodes exploitant à la fois des données rela-
tionnelles et d’attributs, nous considérons trois méthodes de référence à confronter à
notre algorithme. Ces méthodes, dénommées T S1, T S2 et T S3, sont décrites ci-après.

3.8.2 Méthodes comparées

Les méthodes dont les résultats, selon les différentes hypothèses, ont été comparés
sont décrites dans cette section. Deux méthodes de référence mesurent les résultats
obtenus en ne prenant en compte qu’un seul type de données. De plus, trois mé-
thodes de détection de communautés dans des réseaux d’information T S1, T S2 et
T S3, simples à mettre en œuvre, sont considérées dans notre expérimentation. Ces
méthodes ont été introduites dans (Combe et al., 2012b).

3.8.2.1 Méthode relationnelle de référence : S

La méthode Louvain, de Blondel et al. qui exploite seulement les données structu-
relles (le graphe G = (V, E)) sera utilisé comme méthode relationnelle de référence
(Blondel et al., 2008). Elle sera appliquée sur le graphe des auteurs muni de la relation
de coparticipation à des conférences. Elle sera notée S dans les sections suivantes.

3.8.2.2 Méthode textuelle de référence : T

La classification en fonction des attributs textuels ne prend en compte que les
documents {di,∀vi ∈ V }. Elle a été réalisée avec la distance euclidienne ainsi qu’avec
la distance du cosinus calculée sur la description tf-idf, et avec la méthode des K-means
bissectif, puis avec la distance du cosinus et l’algorithme du lien moyen. Comme le
lien moyen donne de meilleurs résultats, c’est la seule méthode qui sera présentée ici
comme référence pour nos expérimentations.

3.8. Évaluation un réseau bibliographique

109

3.8.2.3 T S1 : Détection de communautés relationnelles sur le graphe valué à

l’aide de distances entre attributs

Cette première méthode combinante notée T S1 s’apparente à celle décrite par
Steinhaeuser (Steinhaeuser et Chawla, 2008). Les attributs sont utilisés pour obte-
nir un graphe valué. Nous définissons une distance portant sur les attributs disT , par
exemple la distance euclidienne ou la dissimilarité du cosinus, bien adaptée aux at-
tributs textuels. Nous avons retenu la distance du cosinus appliquée sur les vecteurs
tf-idf. La valeur disT (v, v′) est associée à chaque arête (v, v′) de E. Puis, une méthode
de détection de communautés dans un graphe, compatible avec les graphes valués, est
utilisée pour partitionner l’ensemble des sommets V , par exemple un algorithme qui
optimise une fonction de qualité comme l’algorithme de Kernighan-Lin ou ceux basés
sur la modularité (Kernighan et Lin, 1970). Dans les expérimentations, nous utilisons
la méthode de Louvain sur le graphe valué. La figure 3.9 montre le déroulement de
cette méthode.

FIGURE 3.9 – Déroulement de la méthode T S1

Ce traitement a pour avantage de permettre de limiter le calcul des distances aux

paires de sommets reliées par les arêtes.

Cependant, un inconvénient de cette méthode est qu’il n’y a pas de prise en compte
des distances par rapport aux attributs entre des sommets qui ne sont pas directement
reliés dans le graphe.

Graphe valuépar la distance textuelleAlgorithme de détection de communautés sur graphe valuéRéseau d’informationMatrice de distance textuelle (cosinus)110

Chapitre 3. ToTeM

3.8.2.4 T S2 : Classification automatique basée sur la matrice des distances géo-

désiques déduites du graphe valué à partir des attributs

Dans cette méthode, dite T S2, les informations relationnelles sont utilisées pour
définir une mesure de dissimilarité disS(v, v′) entre chaque paire de sommets (v, v′)
dans le graphe. Dans la pratique, la longueur du plus court chemin entre v et v′
peut être utilisée comme disS(v, v′), où le chemin le plus court entre v et v′ est le
chemin qui comporte le plus petit nombre d’arêtes. Dans le cas où les arêtes sont
valuées, la longueur du chemin entre v et v′ est la somme des valuations des arêtes du
chemin et le plus court chemin entre deux sommets est celui pour lequel cette somme
est minimale. Les longueurs des chemins minimaux définissent des dissimilarités et
toute technique d’apprentissage non supervisée peut être appliquée sur la matrice de
dissimilarités ainsi obtenue. La figure 3.10 montre le déroulement de cette méthode.
Dans nos expérimentations, nous avons utilisé la distance géodésique sur le graphe
valué où à chaque arête on associe la distance du cosinus définie sur les attributs tex-
tuels (tf-idf) relatifs aux sommets de cette arête. On applique ensuite la classification
hiérarchique avec plusieurs critères d’agrégation (les liens simple, moyen, complet,
des centres de gravité) sans constater de différence dans le résultat de la classifica-
tion.

FIGURE 3.10 – Déroulement de la méthode T S2

Graphe valuépar la distance textuelleMatrice de distance du pluscourt cheminMatrice de distance textuelle (cosinus)Réseau d’informationClassification automatique3.8. Évaluation un réseau bibliographique

111

Une limite de la méthode T S2 est que, comme précédemment, il n’y a pas de
prise en compte des distances textuelles directes entre des sommets qui ne sont pas
directement reliés dans le graphe.

3.8.2.5 T S3 : Combinaison linéaire de distances

Dans la troisième méthode, T S3, une dissimilarité globale disT S(v, v′) entre deux
sommets v et v′ est définie comme une combinaison linéaire de deux mesures de
dissimilarité correspondant respectivement à chaque type d’information :

disT S(v, v′) = α disT (v, v′) + (1 − α) disS(v, v′)

(3.25)
où disT (di, dj) est une dissimilarité définie sur les attributs, disS(v, v′) est définie
directement à partir du graphe et α est un paramètre compris entre 0 et 1.

Comme précédemment, la longueur d’un plus court chemin entre v et v′ peut être
utilisée pour disS(v, v′), et la distance euclidienne ou la distance du cosinus calcu-
lées sur les attributs pour disT (dv, dv′). Ensuite, la partition peut être construite soit
avec un algorithme de partitionnement de graphe appliqué sur le graphe étendu et
valué par la dissimilarité globale, soit par une technique non supervisée d’apprentis-
sage utilisant la dissimilarité globale. La figure 3.11 montre le déroulement de cette
méthode.

Ce scénario repose sur l’hypothèse que les deux dissimilarités se complètent ou se

renforcent.

La combinaison linéaire est très facile à mettre en œuvre. Elle est facilement gé-
néralisable à un plus grand nombre de matrices et donc de distances. Cependant, un
inconvénient de cette approche est qu’il n’est pas aisé de choisir la valeur du coefficient
α.

Dans nos expérimentations, nous avons utilisé la distance du cosinus entre les
vecteurs d’attributs représentés selon le modèle tf-idf et la distance géodésique sur
le graphe non valué pour exploiter l’information des relations, puis la classification
hiérarchique avec le critère d’agrégation du lien moyen.

3.8.3 Résultats expérimentaux

3.8.3.1 Identification du domaine de recherche (scénario 1)

Nous avons supposé que pour déterminer le domaine de recherche, seule l’infor-
mation textuelle était utile. Cette section décrit donc les résultats obtenus à l’aide de
la méthode textuelle de référence T .

112

Chapitre 3. ToTeM

FIGURE 3.11 – Déroulement de la méthode T S3

Matrice de distance entre les sommetsGraphe valuépar la distance textuelleMatrice de distance textuelle (cosinus)Calcul des plus courts cheminsCombinaisonMatrice de distances combinéesClassification automatique ou détection de communautés sur le graphe valué par la distance globale 1-αlinéaireα3.8. Évaluation un réseau bibliographique

113

Le tableau 3.20 présente les résultats pour la partition en trois classes. Dans les
matrices de coincidences, les nombres en gras correspondent aux effectifs de sommets
qui sont utilisés pour calculer le taux de sommets bien classés. Ici le taux de bien
classés est de 87% ( (11+16+38+21)

· 100).

99

Classe prédite →
Session réelle ↓
A - SAC Bioinformatique
B - SAC Robotique
C - IJCAI Robotique
D - IJCAI Contraintes
Total

Classe 1 Classe 2 Classe 3 Total

11

11

21
21

13
16
38

67

24
16
38
21
99

TABLE 3.20 – Résultat de la méthode T en 3 classes

Le tableau 3.21 présente ensuite les résultats de la méthode T pour la partition
en quatre classes. Le taux d’auteurs bien classés est de 69%. C’est ce taux que l’on
gardera pour la méthode textuelle de référence lorsque l’objectif sera de déterminer
la session de chaque auteur, pour la comparaison avec les méthodes de combinaison.

1

Classe prédite →
Session réelle ↓
A - SAC Bioinformatique 11
B - SAC Robotique
C - IJCAI Robotique
D - IJCAI Contraintes
Total

11

2

3

4 Total

13
2 14
4 34

6

61

21
21

24
16
38
21
99

TABLE 3.21 – Résultat de la méthode T en 4 classes

3.8.3.2 Identification de la conférence (scénario 2)

Notre hypothèse était que les données relationnelles permettaient d’identifier la

conférence à laquelle les auteurs ont participé.

Cette section décrit les résultats obtenus à l’aide de la méthode relationnelle de
référence (S) à savoir la méthode de Louvain sur le graphe non valué de la relation
de coparticipation à des conférences.

L’algorithme donne sans surprise une partition en 2 classes et un taux de bien clas-
sés de 100% pour le scénario de reconnaissance des conférences. Celle-ci est consul-
table dans le tableau 3.22.

114

Chapitre 3. ToTeM

Communauté prédite → Classe 1 Classe 2 Total
Session réelle ↓
A - SAC Bioinformatique
B - SAC Robotique
C - IJCAI Robotique
D - IJCAI Contraintes
Total

24
16
38
21
99

38
11
59

24
16

40

TABLE 3.22 – Résultats de la méthode relationnelle de référence

Il n’est pas possible de contraindre la méthode de Louvain à fournir 4 classes sur ce
problème. Par conséquent le taux de bien classés pour la reconnaissance des sessions
n’est que de 63%.

3.8.3.3 Identification de la session (scénario 3)

Notre hypothèse est que pour identifier la session d’un auteur les informations
relationnelles et textuelles sont nécessaires. Nous allons le vérifier en comparant les
résultats produits par les méthodes exploitant les deux types de données (ToTeM, T S1,
T S2, T S3) aux méthodes textuelle et relationnelle de référence T et S. De plus, nous
pourrons évaluer la performance de ToTeM par rapport aux autres approches.

Le tableau 3.23 résume les résultats obtenus avec les différentes méthodes. De
plus, les matrices de coïncidence sont présentées dans la table 3.24. Le taux de bien
classés s’élève à 63% pour la méthode ToTeM comme pour Louvain.

On constate que T S1 a fourni une classe supplémentaire. Malgré cela, c’est la
méthode qui donne le meilleur résultat en terme de taux de bien classés. La méthode
T S2 obtient aussi un bon résultat. La méthode T S3 voit son résultat moins marqué
vis-à-vis des deux conférences, elle identifie cependant parfaitement une catégorie.

On notera entre autres que la méthode de Louvain ne permet pas de déterminer
le nombre de communautés à obtenir dans le cas du scénario 3 visant à identifier les
sessions.

En effet ces méthodes trouvent bien les classes détectables par les relations, mais
passent à côté de l’information détectable par la prise en compte du texte. Ceci s’ex-
plique par le fait que l’information relationnelle est très forte dans le sens où la relation
de coparticipation à une même conférence produit un réseau très dense sur lequel les
méthodes de détection de communautés sont très stables. Pour que la prise en compte
de l’information des attributs soit profitable, il faudrait que l’information contenue
dans les vecteurs textuels soit elle aussi très marquée et qu’elle discrimine fortement
les auteurs.

3.8. Évaluation un réseau bibliographique

115

Précision vis-à-vis de :
PT
87%

PS
-

PT S
69%
63%
76%
73%

47-69%

63%

Modèle

T

S

T S1
T S2
T S3
ToTeM

-
-
-
-
-

100%

-
-
-
-

TABLE 3.23 – Synthèse des résultats : modèles T , S, T S1, T S2, T S3 et ToTeM

3.8.4 Conclusion de l’expérimentation sur le jeu des quatre sessions

Tels que ceux-ci ont été présentés dans les sections précédentes, nous obtenons des
résultats très différents selon la méthode employée pour la détection de communautés
dans le réseau d’attributs, mais également selon le scénario et la partition de référence
considérée.

Les attributs textuels permettent assez bien de retrouver les thèmes de recherche
et les données structurelles de co-participation permettent de retrouver quasiment
parfaitement les conférences.

Les articles publiés dans les différentes thématiques sont décrits par des vecteurs
contenant principalement des termes distincts. Grâce à cela, une méthodologie basée
sur l’usage du tf-idf et de la distance du cosinus fonctionne bien. Des méthodes diffé-
rentes de génération des vecteurs du réseau peuvent donner des résultats différents.
Le choix des mots vides peut à lui seul se révéler important.

Quand il est question de manipuler les données structurelles, nous avons utilisé
l’information de co-participation pour construire le graphe. D’autres relations, telles
que la co-écriture ou la citation pourraient être utilisées à ce stade.

Certaines communautés ne peuvent être déterminées qu’en associant l’informa-
tion relationnelle et l’information textuelle. Dans notre cas, ces communautés sont
les quatre sessions sélectionnées. Dans le but de retrouver cette partition, nous avons
combiné ces deux informations, en proposant trois méthodes de combinaison diffé-
rentes qui sont comparées à ToTeM. Les résultats montrent que, dans notre cas, la
combinaison linéaire n’est pas en mesure d’améliorer les résultats. De plus, elle néces-
site un paramètre de pondération relative des deux critères.

Les méthodes T S1 et T S2 donnent de meilleurs résultats que celle utilisant la

combinaison linéaire des deux distances textuelle et relationnelle.

Quelque soit l’application et le jeu de données, la combinaison de deux types de

116

Chapitre 3. ToTeM

Communauté prédite →
Session réelle ↓
A SAC’09 - Bioinformatique
B SAC’09 - Robotique
C IJCAI’09 - Robotique
D IJCAI’09 - Contraintes
Total

1

2

3

4 5

13
11

24

11

5

11 5

38
6
44

15
15

Com. préd. → 1
Session ↓
A
B
C
D
Total

4

2

3

4

24
4 11

35

1
1 37
7 14
51
9

(a) T S1

(b) T S2

1

Communauté prédite →
Session réelle ↓
A SAC’09 - Bioinformatique 11
B SAC’09 - Robotique
C IJCAI’09 - Robotique
D IJCAI’09 - Contraintes
Total

11

(c) T S3

2

3

4

13
2 14
4 34

6

61

21
21

Communauté préd. → 1
Session réelle ↓
A
B
C
D
Total

38
21
59

2

24
16

40

(d) T oT eM

TABLE 3.24 – Matrices de coïncidence pour les quatre méthodes de combinaison com-
parées

données nécessite de s’appuyer sur la donnée la plus robuste dans le but de ne pas
amplifier les défauts.

Nous avons également montré que de bons résultats de classification peuvent être
obtenus en utilisant des méthodes simples à mettre en œuvre, du moment que le
scénario est adapté aux données et que les caractéristiques décrivant ce qu’est une
bonne communauté soient bien déterminées. Malheureusement, ce dernier point est
souvent le plus difficile.

3.9 Évaluation sur un autre réseau de grande taille : PubMed-

Diabètes

Cette fois-ci nous évaluons notre proposition sur un second jeu de données, PubMed-

Diabètes, issu d’une base de données bibliographiques médicales.

3.9.1 Présentation du jeu de données

Le jeu de données Pubmed-Diabètes comprend 19 717 publications scientifiques
traitant du diabète (Sen et al., 2008). Celles-ci sont classées en trois catégories (1)
"Diabetes Mellitus, Experimental", (2) "Diabetes Mellitus Type 1", (3) "Diabetes Melli-

3.9. Évaluation sur un autre réseau de grande taille : PubMed-Diabètes

117

rat common use examin pathogenesi retinopathi mous studi anim model metabol abnorm contribut
develop investig mice 2 month compar obtain method induc 6 inject experiment normal diet 30 hyper-
glycemia level lipid oxid activ protein kinas c measur result increas retin stress 3 similar observ conclus
play import role present p m r muscl control chang dure lower higher mass correl decreas determin
concentr stimul period caus mark group evid fast type signific differ ratio suggest degre occur vivo res-
pect dysfunct region high appear sever affect cardiovascular complic primari death patient clinic suscept

v,v′∈B

v,v′∈A\{u}

C̸=A,B

v,v′∈C

1

1

1

1

2N · I(V )

2N · I(V )

1

2N · I(V )

1

N · I(V )

2N · I(V )

2N · I(V )

+

+

+

+

+

+






− Dvv′

 I(V, v) · I(V, v′)

2N · I(V )

− Dvv′



− Dvv′

− Duv

− Dvv′

 I(V, v) · I(V, v′)

2N · I(V )

− Dvv′

137

(4.59)

(4.60)





La modularité de la partition P′ vaut quant à elle :



Qinertie(P′) =

=

1

2N · I(V )

C∈P
1

2N · I(V )

v,v′∈C

2N · I(V )

 I(V, v) · I(V, v′)

 I(V, v) · I(V, v′)

 I(V, v) · I(V, v′)



2N · I(V )

2N · I(V )



v,v′∈B∪u

v,v′∈A\u

C̸=A\{u},B∪{u}

v,v′∈C

− Dvv′



− Dvv′


 I(V, v) · I(V, v′)

− Dvv′

2N · I(V )

+

+

1

1

2N · I(V )

2N · I(V )



(4.61)



− Dvv′

(4.62)

138

=

1

2N · I(V )




− Dvv′

− Dvv′



v,v′∈A\u

2N · I(V )

 I(V, v) · I(V, v′)
 I(V, v) · I(V, v′)




 I(V, u)2
 I(V, u) · I(V, v)




2N · I(V )

2N · I(V )

2N · I(V )

− D(u, u)

v,v′∈B

v∈B

C̸=A\{u},B∪{u}

v,v′∈C

+

+

+

+

1

1

2N · I(V )

2N · I(V )

1

N · I(V )

1

2N · I(V )

Chapitre 4. Méthode 2Mod-Louvain

− Duv

 I(V, v) · I(V, v′)

2N · I(V )



− Dvv′

(4.63)

Le gain de modularité lors du passage de P à P′ a donc pour valeur :

∆Qinertie =Qinertie(P′) − Qinertie(P)



(4.64)

=

1

2N · I(V )

v,v′∈A\{u}

− Dvv′

− Dvv′

v∈B

2N



v,v′∈B

− Duv

− Duu

2N · I(V )

2N · I(V )

2N · I(V )

 I(V, v) · I(V, v′)

 I(V, u) · I(V, v)

 I(V, v) · I(V, v′)

 I(V, u)2



 I(V, v) · I(V, v′)

 I(V, v) · I(V, v′)

 I(V, u)2

 I(V, u) · I(V, v)


C̸=A\{u},B∪{u}

2N · I(V )

2N · I(V )

2N · I(V )

v,v′∈A\{u}

− Duu

v,v′∈B

v,v′∈C



− Duv

2N · I(V )

v∈B

− Dvv′





+

+

+

+

−

+

+

+

1

1

1

1

1

1

N · I(V )

2N · I(V )

2N · I(V )

2N · I(V )



1

2N · I(V )

2N · I(V )

2N · I(V )

1

N · I(V )



− Dvv′

 I(V, v) · I(V, v′)


2N · I(V )

− Dvv′

4.4. Évaluation sur des réseaux artificiels

1

+

2N · I(V )



v∈B

=

1

N · I(V )
−
1

N · I(V )



C̸=A\{u},B∪{u}


 I(V, u) · I(V, v)


 I(V, u) · I(V, v)

2N · I(V )

− Duv

v,v′∈C

2N · I(V )

v∈A\{u}

 I(V, v) · I(V, v′)


2N · I(V )



− Duv



139

(4.65)

− Dvv′

(4.66)

De plus, on peut remarquer que la variation de modularité induit par la suppres-
sion de u de sa classe d’origine sera la même quelque soit sa classe d’affectation.
Par conséquent le calcul de variation de modularité peut être effectué en considérant
uniquement la différence induite par l’insertion de u dans sa nouvelle communauté
d’affectation, décrite par le premier terme de l’équation 4.66.

Ces calculs nous permettent de montrer que notre critère bénéficie lui aussi de
la possibilité d’être calculé de façon incrémentale. Le gain de modularité basée sur
l’inertie repose uniquement sur des informations locales relatives au sommet déplacé
et à sa distance avec les autres sommets.

4.4 Évaluation de la méthode 2Mod-Louvain sur des réseaux

artificiels

On propose, comme on l’a fait pour ToTeM dans la section 3.7, d’évaluer la mé-
thode 2Mod-Louvain qui optimise le critère global QQ+ basé à la fois sur la modularité
de Newman et Girvan et la modularité par rapport à l’inertie. Dans un premier temps,
nous étudions la robustesse de la méthode sur des réseaux artificiels vis-à-vis d’une
dégradation de la structure de communautés définie par rapport aux relations, ou des
classes définies par rapport aux attributs, ou encore d’une augmentation de la taille
du réseau d’information ou d’une variation de la densité des liens.

L’évaluation sera faite selon une vérité externe en fonction des critères de NMI,
d’ARI, d’AMI, de nombre de classes et, quand c’est possible, de taux de bien classés
qui ont été définis dans la section 2.2.3.2. On notera que les évolutions du réseau ont
été opérées ici indépendament de celles évoquées dans le chapitre précédent, ce qui
explique des résultats différents pour les méthodes de Louvain et des K-means.

4.4.1 Réseau de référence (réseau R)

On utilise, de même que dans la section 3.7.1 dédiée à l’évaluation de la mé-
thode ToTeM, un réseau de référence R qui comporte 3 classes composées chacune de

140

Chapitre 4. Méthode 2Mod-Louvain

Classe 1 Classe 2 Classe 3

Classe 1
Classe 2
Classe 3

55
2
1

53
7

50

TABLE 4.6 – Répartition des extrémités des liens du graphe R

FIGURE 4.2 – Distribution des valeurs de l’attribut des sommets de R par classe

33 sommets. Chaque sommet est décrit par une valeur réelle. Nous considérons les
mêmes paramètres de génération de ce réseau. Les attributs suivent une loi normale
d’écart-type 7, centrée autour d’une valeur propre à sa classe d’origine. Ainsi la pre-
mière classe a un centre de 10, la deuxième un centre de 40 et la troisième un centre
de 70. La classe d’origine du sommet sert de vérité terrain pour l’évaluation. Enfin,
durant la génération du réseau de référence, nous avons fait en sorte que le calcul
précédent de génération des arêtes crée au maximum deux arêtes à chaque fois qu’un
nouveau sommet est introduit.

Le réseau R, qui servira de référence, est représenté dans la figure 4.3a.

Il comporte 99 sommets et 168 arêtes. La table 4.6 montre la répartition des arêtes

entre les classes dans le graphe R.

La distribution des valeurs de l’attribut attaché aux sommets de chaque classe est
présentée dans la figure 4.2. La figure 4.3a illustre le graphe, issu du modèle, qui nous
servira de référence.

02468101214--------1001020304050607080Nombre de sommetsValeurs d'attributs4.4. Évaluation sur des réseaux artificiels

141

(a) Classes de la vérité terrain

(b) Application de 2Mod-Louvain

(c) Application de

la méthode de Louvain

(d) Application des K-means

FIGURE 4.3 – Partitions du

réseau de reéférence R

142

Chapitre 4. Méthode 2Mod-Louvain

Application de la méthode de Louvain

La visualisation du résultat de l’application de la méthode de Louvain sur le réseau
de référence est présentée dans la figure 4.3c. La matrice de coïncidence associée est
présentée dans le tableau 4.7.

Classes prédites → Classe 1 Classe 2 Classe 3 Classe 4
Classes réelles ↓
Classe 1
Classe 2
Classe 3

1
30

2
21

1
12

32

TABLE 4.7 – Matrice de coïncidence associée à l’application de la méthode de Louvain
qui produit 4 classes sur le réseau de référence R

Le taux de sommets bien classé s’élève à 84%. Le score de NMI est de 0,78.
La méthode de Louvain considère uniquement les données relationnelles. On constate

que les classes réelles sont bien identifiées, mais la troisième est scindée en deux. 21
sommets sont affectés à l’une des classes prédites et 12 à une autre.

Application des K-means

Les résultats des K-means sur le réseau de référence sont présentés dans le ta-

bleau 4.8 et illustrés par la figure 4.3d.

Classes prédites → Classe 1 Classe 2 Classe 3
Classes réelles ↓
Classe 1
Classe 2
Classe 3

2
31

2
33

31

TABLE 4.8 – Matrice de coïncidence du réseau de référence R.1.1 issue de l’application
des K-means

Le taux de bien classés est de 96%. La NMI est de 0,86. On constate que les K-
means obtiennent donc sur cette tâche un bon résultat mais rappelons que cet algo-
rithme nécessite un paramétrage correspondant au nombre de classes à produire.

Application de 2Mod-Louvain

Les résultats de 2Mod-Louvain sur le réseau de référence sont présentés dans le

tableau 4.9 et illustrés par la figure 4.3b.

4.4. Évaluation sur des réseaux artificiels

143

Classes prédites → Classe 1 Classe 2 Classe 3
Classes réelles ↓
Classe 1
Classe 2
Classe 3

2
33

33

31

TABLE 4.9 – Matrice de coïncidence du réseau de référence R issue de l’application de
2Mod-Louvain

Le taux de bien classés s’élève à 98%. La NMI est de 0,93. On constate que sur
ce jeu posant a priori peu de difficultés, la combinaison des informations est déjà
bénéfique puisqu’elle permet en particulier de corriger la scission d’une classe par la
méthode de Louvain.

4.4.2 Dégradation de l’information relationnelle (réseaux R.1.1 et R.1.2)

Un nombre important d’arêtes intraclasses aide à la fois la méthode de Louvain
et 2Mod-Louvain à trouver les communautés de la vérité terrain. On veut savoir si la
méthode parvient à maintenir ses résultats dans la situation où l’information relation-
nelle est dégradée. Pour cela, on réduit le nombre d’arêtes intraclasses et on introduit
à la place des arêtes interclasses.

On réutilise l’algorithme de dégradation de l’information relationnelle présenté
dans le chapitre précédent. On introduit un paramètre qui détermine la proportion
d’arêtes intraclasses à remplacer par une arête interclasses.

Pour le graphe dégradé à 25%, la matrice de coïncidence est présentée dans le

tableau 4.10. Le taux de bien classés est de 78%. La NMI s’élève à 0,60.

Classes prédites → Classe 1 Classe 2 Classe 3 Classe 4 Classe 5
Classes réelles ↓
Classe 1
Classe 2
Classe 3

33
3
1

18
1

3
26

9
3

2

TABLE 4.10 – Matrice de coïncidence du graphe R.1.1 dégradé à 25%

Pour le réseau R.1.2 dégradé à 50%, la matrice de coïncidence est présentée dans

le tableau 4.11. Le taux de bien classés s’élève à 63%. La NMI s’élève à 0,35.

144

Chapitre 4. Méthode 2Mod-Louvain

Classes prédites → Classe 1 Classe 2 Classe 3 Classe 4 Classe 5 Classe 6
Classes réelles ↓
Classe 1
Classe 2
Classe 3

1
10
4

29
6
1

6
23

6
2

1
2
2

2
3
1

TABLE 4.11 – Matrice de coïncidence du graphe R.1.2

On constate que 2Mod-Louvain souffre de la dégradation de l’information rela-
tionnelle et produit alors des classes plus nombreuses et moins pertinentes. Elle est
cependant moins pénalisée que la méthode de Louvain, qui atteint elle 31% de bien
classés.

4.4.3 Dégradation des attributs (réseaux R.2.1 et R.2.2)

On teste ensuite la robustesse de la méthode envers des réseaux d’information où
l’attribut est moins caractéristique de chacune des classes de la vérité terrain. Pour
cela, on propose d’augmenter l’écart-type de l’attribut en le fixant à 10 alors qu’il va-
lait 7 dans le réseau de référence. Le but est d’obtenir des distributions des différentes
classes qui se chevauchent de plus en plus du point de vue des attributs. Ainsi on
considère que les attributs descriptifs des sommets des 3 classes suivent respective-
ment des lois normales de paramètres (10, 10), (40, 10), (70, 10) pour le graphe
R.2.1 puis (10, 12), (40, 12), (70, 12) pour le graphe R.2.2.

La matrice de coïncidence issue de l’application de 2Mod-Louvain est présentée

dans le tableau 4.12. Le taux de bien classés est de 96%. La NMI s’élève à 0,89.

Classes prédites → Classe 1 Classe 2 Classe 3
Classes réelles ↓
Classes 1
Classes 2
Classes 3

4
33

29

33

TABLE 4.12 – Matrice de coïncidence du graphe R.2.1 avec des écarts-types de 10

Pour le réseau d’information où les attributs ont été remplacés par des attributs
dégradés d’écart-type 12, la matrice de coïncidence issue de l’application de 2Mod-
Louvain est présentée dans le tableau 4.13. Le taux de bien classés est de 98%. La
NMI s’élève à 0,93.

4.4. Évaluation sur des réseaux artificiels

145

Classes prédites → Classe 1 Classe 2 Classe 3
Classes réelles ↓
Classes 1
Classes 2
Classes 3

2
33

33

31

TABLE 4.13 – Matrice de coïncidence du graphe R.2.2 avec des écarts-types de 12

On constate que la classification est peu modifiée par l’étalement des distributions
des valeurs d’attributs. Avec des taux de réussite de 88% pour le réseau R.2.1 et de
90% pour le réseau R.2.2, les K-means ont subi une dégradation de leurs résultats.
La prise en compte de l’information relationnelle a permis de limiter la dégradation
subie par le résultat de notre méthode.

4.4.4 Augmentation de la taille du réseau (réseaux R.3.1 et R.3.2)

On cherche ensuite à déterminer l’influence du nombre de sommets sur les résul-
tats de la classification. On propose d’ajouter des sommets dans le réseau de référence
et de mesurer les résultats sur de nouveaux réseaux comportant 999 et 9 999 som-
mets.

Pour le réseau à 999 sommets répartis en 3 classes de 333 sommets, la matrice de
coïncidence issue de l’application de 2Mod-Louvain est présentée dans le tableau 4.14.
Le taux de bien classés est de 84%. La NMI s’élève à 0,80.

Classes prédites → Classe 1 Classe 2 Classe 3 Classe 4
Classes réelles ↓
Classes 1
Classes 2
Classes 3

1
183
7

330
9

11
326

2
130

TABLE 4.14 – Matrice de coïncidence du réseau R.3.1 à 999 sommets

Pour le graphe à 9 999 sommets répartis en 3 classes de 3 333 sommets, la ma-
trice de coïncidence issue de l’application de 2Mod-Louvain est présentée dans le
tableau 4.15. Le taux de bien classés est de 85,46%. La NMI s’élève à 0,77.

146

Chapitre 4. Méthode 2Mod-Louvain

Classes prédites → Classe 1 Classe 2 Classe 3 Classe 4
Classes réelles ↓
Classes 1
Classes 2
Classes 3

50
1 977
12

75
3 291

3 278
251
2

5
1 030
28

TABLE 4.15 – Matrice de coïncidence du graphe R.3.2 à 9 999 sommets

Dans la mesure où il est difficile de produire des résultats en termes de nombres
de biens classés quand le nombre de classes produites ou réelles devient important,
nous comparerons les partitions produites par 2Mod-Louvain à ceux produits par la
méthode de Louvain et les K-means par l’indice de NMI. La méthode de Louvain pro-
duit, pour les réseaux de 999 et 9 999 sommets, des partitions de NMI s’élevant à
0,60. Au passage, les nombres de classes grandissent pour s’élever à 10 et 13. Les
K-means produisent des résultats de 0,88 et 0,89. Cela montre que le résultat des K-
means ne diminue pas lorsque la taille du réseau augmente. Ceci est normal dans la
mesure où la proportion des éléments qui se chevauchent demeure identique dans les
3 distributions malgré l’évolution de la taille du réseau.

On constate que l’augmentation de la taille du graphe a un impact limité sur les
résultats de 2Mod-Louvain qui restent très satisfaisants. Le nombre de classes pro-
duites est contenu par rapport au résultat donné par la méthode de Louvain. Cette
dernière apparaît elle comme ayant plus de mal à trouver la structure communautaire
à mesure que le réseau grandit.

L’augmentation de la taille du graphe nous permet également d’étudier l’évolution
des temps de traitement des différentes méthodes. Sur le réseau de référence, la mé-
thode de Louvain et les K-means ont des temps d’exécution très rapides, inférieurs à la
seconde. 2Mod-Louvain dure lui une dizaine de secondes. Sur le réseau de 999 som-
mets, 2Mod-Louvain prend 12 minutes. Sur le réseau de 9 999 sommets, les temps
d’exécution des K-means restent quasi instantanés, la méthode de Louvain perd moins
de 20 secondes et 2Mod-Louvain environ 3 heures. Ces temps d’exécution montrent
les limites de 2Mod-Louvain pour ce qui est de la classification dans de grands réseaux
d’information. Pour diminuer ces temps de calcul, il peut être envisagé de mémoriser
les valeurs de critères pour les partitions, qui sont susceptibles d’être recalculées pen-
dant le déroulement de l’algorithme. Dans tous les cas, une approche ne nécessitant
pas de considérer la distance d’un sommet avec tous les autres lors d’un déplacement
serait un réel apport pour manipuler des réseaux de plus grandes tailles ou faisant
l’objet de plus d’attributs.

4.4. Évaluation sur des réseaux artificiels

147

4.4.5 Augmentation du nombre d’arêtes (réseaux R.4.1 et R.4.2)

On cherche ici à déterminer si la densité d’arêtes dans le réseau a une influence
sur le résultat. Le réseau R utilise une valeur de 2 arêtes par sommet introduit (les
résultats sont présentés à la section 4.4.1). On propose de tester les résultats avec des
valeurs de 5 et 10 arêtes.

Pour le réseau R.4.1 à 5 arêtes par sommet, la matrice de coïncidence issue de
l’application de 2Mod-Louvain est présentée dans le tableau 4.16. Le taux de bien
classés s’élève à 94%. La NMI s’élève à 0,82.

Classes prédites → Classe 1 Classe 2 Classe 3
Classes réelles ↓
Classe 1
Classe 2
Classe 3

33
4

2
33

27

TABLE 4.16 – Matrice de coïncidence du graphe R.4.1

Pour le graphe à 10 arêtes par sommet, la matrice de coïncidence issue de l’appli-
cation de 2Mod-Louvain est présentée dans le tableau 4.17. Le taux de bien classés
est de 98%. La NMI est de 0,92.

Classes prédites → Classe 1 Classe 2 Classe 3
Classes réelles ↓
Classe 1
Classe 2
Classe 3

33
1

1
33

31

TABLE 4.17 – Matrice de coïncidence du graphe R.4.2

On constate que l’augmentation de la densité ne modifie pas les résultats de fa-
çon significative, qui demeurent élevés. Avec des taux de bien classés de 96 et 97%
respectivement sur R.4.1 et R.4.2, la méthode de Louvain trouve ses scores améliorés
par l’augmentation de la densité du réseau.

4.4.6 Synthèse des résultats des méthodes 2Mod-Louvain, Louvain et

des K-means et conclusion

On récapitule les résultats en matière de taux de bien classés (tableau 4.18a) et

de NMI (tableau 4.18b).

La méthode proposée réussit à apporter de la robustesse à la méthode de Louvain
face à la dégradation de l’information relationnelle. Dans le cas où la taille du ré-

148

Chapitre 4. Méthode 2Mod-Louvain

seau augmente, la méthode proposée permet de parer à la multiplication des classes
qui survient alors avec la méthode de Louvain (4 classes contre 10). Les K-means
conservent de bons résultats dans le cas où la taille du réseau évolue, car l’informa-
tion des attributs demeure de bonne qualité. De plus contrairement aux deux autres
méthodes, le nombre de classes étant donné, la multiplication des classes n’est pas un
risque pour les K-means.

4.4. Évaluation sur des réseaux artificiels

149

2Mod-Louvain

K-means
TBC (%) Nb de classes TBC (%) Nb de classes TBC (%)
Graphe de référence

Louvain

R

R.1.1
R.1.2

R.2.1
R.2.2

R.3.1
R.3.2

R.4.1
R.4.2

98

3

84

Dégradation de l’information relationnelle

78
63

5
6

40
31

Étalement des distributions

96
98

3
3

(84)*
(84)*

Taille du réseau d’information

84
85,46
Densité
94
98

4
4

3
3

50
†

96
97

4

8
8

4
4

10
13

3
3

96

(96)*
(97)*

88
90

97
†

(96)*
(97)*

* La dégradation de l’information relationnelle et le changement de densité n’influençant pas les

résultats des K-means, et la dégradation de l’information des attributs n’influençant pas les résultats de

la méthode de Louvain, ces résultats ne sont pas pris en compte dans la comparaison.

† Le calcul du taux de bien classés est impraticable compte tenu du nombre élevé de classes produites.

NMI

R

R.1.1
R.1.2

R.2.1
R.2.2

R.3.1
R.3.2

R.4.1
R.4.2

(a) Évaluation selon le taux de bien classés

2Mod-Louvain Louvain
Graphe de référence

K-means

0,93

0,86
Dégradation de l’information relationnelle
(0,86)
(0,91)

0,60
0,35

0,78

0,31
0,13

Étalement des distributions

0,89
0,93

0,78
0,78

Taille du réseau d’information

Densité

0,80
0,77

0,82
0,91

0,60
0,60

0,85
0,88

(b) Évaluation selon la NMI

0,69
0,69

0,88
0,89

(0,86)
(0,89)

TABLE 4.18 – Bilan de l’expérimentation sur des réseaux artificiels

150

Chapitre 4. Méthode 2Mod-Louvain

4.5 Évaluation sur des réseaux réels

Nous complétons les résultats expérimentaux précédents par une étude sur des
graphes réels. On propose d’évaluer la méthode 2Mod-Louvain sur le réseau des 4
sessions. Ensuite, nous l’évaluerons pour la classification d’articles issus du réseau de
données bibliographiques PubMed-Diabetes.

4.5.1 Réseau des 4 sessions

On utilise ici le jeu de données dont la construction a été décrite dans la sec-
tion 1.4.4. On rappelle que ce réseau d’information comporte 99 auteurs et 2 623
relations de coparticipation à des conférences.

On applique 2Mod-Louvain sur le réseau d’information des 4 sessions. Comme
le montre le tableau 4.19, 2Mod-Louvain trouve à trois sommets près le découpage
selon les deux conférences, ce qui était déjà le cas pour la méthode ToTeM. Selon
l’évaluation envers les quatres sessions, le taux de bien classés s’élève à 63%.

Classes prédites →
Classes réelles ↓
A - SAC Bioinformatique
B - SAC Robotique
C - IJCAI Robotique
D - IJCAI Contraintes
Total

Classe 1 Classe 2 Classe 3 Total

24
16
1
1
42

37
19
56

24
16
38
21
99

1
1

TABLE 4.19 – Résultat de l’application de 2Mod-Louvain sur le réseau des 4 sessions

Les résultats issus de l’application de la méthode de Louvain sont présentés dans
le tableau 4.20, où le taux de bien classés s’élève à 63%. On peut voir que les deux
conférences sont identifiées, mais pas les sessions. Ce résultat est à comparer avec les
résultats de la méthode de Louvain et des K-means présentés dans la section 3.8.3.3
qui sont respectivement de 63% et 41%. Le bilan de cette expérimentation est que la
composante textuelle incarnée par les vecteurs tf-idf n’a pas une influence suffisante
pour permettre à 2Mod-Louvain de différencier les résultats de ceux de la méthode
de Louvain appliquée seule. La méthode atteint cependant le meilleur des résultats
procurés par chacune des deux modalités isolées.

4.5. Évaluation sur des réseaux réels

151

Session prédite →
Session réelle ↓
A - SAC Bioinformatique
B - SAC Robotique
C - IJCAI Robotique
D - IJCAI Contraintes
Total

Classe 1 Classe 2 Total

24
16
1
1
42

24
16
38
21
99

37
20
57

TABLE 4.20 – Résultat de l’application de Louvain sur le réseau des 4 sessions

En conclusion, ce réseau a une information relationnelle trop proéminente pour

que les valeurs des attributs soient exploitées avantageusement.

4.5.2 Jeu de données PubMed-Diabètes

Nous considérons le jeu de données PubMed-Diabètes qui a été présenté dans la
section 3.9.1 (Sen et al., 2008). Nous rappelons qu’il comprend 19 717 publications
scientifiques traitant du diabète, qui sont réparties en trois catégories. L’index associé
comporte 500 termes.

D’abord, pour la méthode des K-means, le taux de bien classés est de 60%. C’est
un taux élevé, mais qui doit être analysé au regard des 3 classes qui ont été imposées.
Quant à la méthode de Louvain, celle-ci produit un nombre de classes élevé (36)

et un taux de bien classés de 25%.

Les résultats complets sont présentés dans le tableau 4.21.

2Mod-Louvain Louvain K-means

Vérité terrain non connexifiée (3 catégories réelles)
NMI
ARI
AMI
V-Mesure
Homogénéité
Complétude
Taux de bien classés
Nombre de classes

0,23
0,11
0,13
0,20
0,1348
0,39
0,25
36

0,24
0,09
0,13
0,21
0,14
0,43
0,22
64

0,18
0,15
0,17
0,18
0,18
0,17
0,60
(3)

TABLE 4.21 – Résultat de l’évaluation de 2Mod-Louvain et des méthodes de référence
sur PubMed-Diabètes

Le bilan de cette expérimentation est que notre proposition donne les meilleurs
résultats pour plusieurs critères et procure toujours un résultat bien placé face aux
méthodes de référence. Il est difficile d’interpréter les résultats au regard du nombre

152

Chapitre 4. Méthode 2Mod-Louvain

de bien classés ; les nombres de classes sont variables et la partition en 3 classes est
ainsi très favorisée.

2Mod-Louvain produit plus de classes (64), mais celles-ci sont mesurées comme
s’appariant mieux à la vérité terrain du point de vue des critères perfectionnés de NMI
et de V-mesure.

En effet, une des difficultés rencontrées par notre méthode et celle de Louvain est
qu’elle favorise les communautés connexes. Or dans ce jeu de données les classes de la
vérité terrain ne sont pas connexes. L’évaluation face à la vérité terrain "connexifiée"
consiste à faire subir un traitement préalable à la vérité terrain. Ainsi s’il n’existe pas
de chemin entre deux sommets d’une même classe ne passant que par des sommets
de cette même classe, alors il y a séparation de la classe en deux nouvelles classes
connexes. Vis-à-vis de la vérité terrain où les classes ont subi ce traitement pour de-
venir connexes (voir section 3.2), le taux de bien classé n’est plus calculable en temps
raisonnable en raison de la hausse du nombre de classes réelles, mais les autres indi-
cateurs confirment l’amélioration des résultats produits par les méthodes basées sur
la modularité et au contraire une dégradation de ceux fournis par les K-means.

2Mod-Louvain Louvain K-means

Vérité terrain connexifiée (2 644 catégories réelles)
NMI
ARI
AMI
V-Mesure
Homogénéité
Complétude
Nombre de classes

0,36
0,15
0,21
0,35
0,32
0,40
36

0,37
0,12
0,21
0,37
0,32
0,43
64

0,18
0,11
0,06
0,16
0,28
0,11
(3)

TABLE 4.22 – Résultat de l’évaluation de 2Mod-Louvain et des méthodes de référence
sur PubMed-Diabètes, après connexification des classes

Une visualisation du réseau coloré selon les communautés formées est présentée
par la figure 4.4. On voit que malgré le nombre élevé de communautés découvertes,
un petit nombre s’étendent assez largement sur le réseau. En effet, 7 des 64 classes
contiennent 50% des sommets du réseau.

4.6 Conclusion

Dans ce chapitre, nous avons défini la modularité basée sur l’inertie, un indice
de mesure de la qualité d’une partition d’éléments décrits dans un espace vectoriel.
Cet indice se veut un pendant de la modularité de Newman et Girvan, adapté au

4.6. Conclusion

153

FIGURE 4.4 – 2Mod-Louvain appliqué à PubMed

154

Chapitre 4. Méthode 2Mod-Louvain

contexte de la classification non supervisée. Il permet de produire une classification
ne nécessitant pas comme paramètre le nombre de classes à produire. Pour cela, il
compare le carré de la distance entre deux points à sa valeur attendue compte tenu
des valeurs d’inertie de chacun des deux points. Nous avons montré que notre critère
comportait une normalisation intrinsèque et qu’il apportait certaines des propriétés
de la modularité de Newman et Girvan au domaine de la classification de vecteurs.

Nous avons proposé 2Mod-Louvain, une méthode utilisant notre critère de modu-
larité basée sur l’inertie conjointement à la modularité de Newman et Girvan pour
détecter des communautés dans des réseaux d’information artificiels et réels. Nous
avons testé la robustesse de notre proposition face à diverses modifications que peut
subir un réseau d’information. 2Mod-Louvain a ainsi montré de bons résultats sur des
réseaux ayant subit une dégradation des relations, des attributs, une augmentation
de la densité des relations et de la taille du réseau. Alors que la méthode de Louvain
produit un nombre de classes plus important lorsque le réseau d’information grandit,
notre combinaison des deux informations relationnelles et des attributs s’est avérée
plus robuste. Sur les réseaux réels, bien que l’ARI, plus sensible au nombre de classes,
soit plus sévère, l’évaluation a montré que notre proposition fournissait de bons résul-
tats selon les critères de NMI ou de V-mesure, sur des réseaux où la dégradation des
liens ou des attributs ne permettait plus d’obtenir des taux de bien classés satisfaisants
avec la méthode de Louvain ou avec les K-means.

Ce qui semble être la plus grande faiblesse du critère de modularité basée sur
l’inertie est sa complexité. Si la modularité de Newman et Girvan tire parti des ma-
trices d’adjacence creuses, les matrices de distance ne le sont jamais. Une étude des
améliorations algorithmiques possibles est nécessaire afin de pouvoir proposer une
méthode pouvant traiter des réseaux de tailles supérieures à 10 000 sommets. De
plus, nous nous attendons à ce que notre critère soit affecté, comme la modularité de
Newman et Girvan, par une limite de résolution. Il serait judicieux de poursuivre ce
travail par l’étude des conséquences que cette limite apporte sur la classification de
vecteurs numériques.

Ainsi, les perspectives que nous jugeons intéressantes concernent-elles l’étude du
critère proposé dans un cadre faisant uniquement intervenir des vecteurs numériques,
notamment pour étudier la sensibilité à la limite de résolution. De plus, un cadre plus
formel pour considérer simultanément les relations et chacun des attributs pourrait
permettre de combiner ces informations de façon plus pertinente. Ainsi la conception
d’un réseau d’information aléatoire et d’une modularité associée unifiant les deux
paradigmes incarnés par les relations et les attributs semble également être une voie
digne d’intérêt.

CHAPITRE 5
Conclusion et perspectives

Dans cette thèse, nous avons étudié le problème de la détection de communau-
tés dans des réseaux d’information, c’est à dire des graphes dont les sommets sont
munis d’un vecteur d’attributs numériques. L’objectif était de permettre la détection
de communautés dans ces réseaux, en tirant parti le mieux possible des informations
relationnelles et vectorielles.

Nous nous sommes placés dans le contexte difficile de l’apprentissage non super-
visé. Nous ne disposons ainsi que du réseau d’information et devons retourner, sans
rien connaître ni du processus de génération des données ni de l’attente de l’utilisa-
teur, la meilleure partition possible.

Nous avons abordé le problème en produisant des états de l’art distincts sur la clas-
sification automatique puis la détection de communautés. De cette façon nous avons
pu étudier les approches pratiques pour les deux types de classification. Nous avons
ensuite abordé les techniques existantes en matière de combinaison des informations
relationnelles et d’attributs. Cette démarche nous a permis de mieux comprendre les
limites des approches existantes de détection de communautés dans des réseaux d’in-
formation.

Une des premières barrières qui nous est apparue est le problème de la normali-
sation des critères employés sur les liens et les attributs. C’est la raison pour laquelle
notre première méthode ToTeM a fait l’objet de plusieurs suggestions de critères glo-
baux. Une deuxième difficulté tient à la pondération des deux informations, dont l’une
peut être plus pertinente que l’autre, ou plus nuancée par exemple. C’est un problème
qui n’est pas souvent soulevé, mais qui apparaît très vite lorsque l’on se penche sur la
classification non supervisée de données hétérogènes.

La première méthode que nous avons introduite, ToTeM, montre que l’optimisa-
tion de l’inertie interclasses combinée à la modularité de Newman et Girvan, s’intègre
bien dans l’heuristique multi-échelle de la méthode de Louvain. Comme pour la mo-
dularité de Newman et Girvan, on peut calculer de manière incrémentale un gain (ou
une perte) d’inertie induite par le changement d’affectation d’un sommet. Un autre
point au moins aussi intéressant est que nous avons étendu le principe de change-
ment d’échelle pour l’appliquer aux attributs. En effet, en tenant compte des masses
associées initialement à chaque sommet, l’inertie interclasses garde sa cohérence lors

156

Chapitre 5. Conclusion et perspectives

de la phase de fusion des sommets. Cette propriété étant également présente dans
le critère de modularité de Newman et Girvan, elle nous assure que l’utilisation d’un
critère global s’appuyant uniquement sur ces deux mesures ne varie pas lors d’un
changement d’échelle, tel que dans la phase de fusion de Louvain. Cela fait de l’iner-
tie interclasses un critère ayant de très bonnes propriétés pour la classification, même
adapté à une heuristique, celle de la méthode de Louvain, initialement introduite pour
la détection de communautés dans les graphes.

Cependant, malgré ses bonnes propriétés mathématiques, le critère d’inertie inter-
classes a comme défaut le fait que le changement d’affectation d’un élément entraîne
des calculs faisant intervenir tous les sommets de son ancienne et de sa nouvelle
classe. De ce fait les traitements sont plus lourds que pour la modularité de Newman
et Girvan, pour laquelle seuls les degrés avec les sommets voisins sont considérés.

Nous avons exposé plusieurs critères globaux d’optimisation qui peuvent être uti-
lisés dans le cadre de notre méthode. Tous sont dépendants de l’inertie interclasses et
de la modularité de Newman et Girvan, et certains font usage du nombre de classes
produites. Nous avons ensuite comparé ToTeM à des méthodes de référence sur des
graphes réels et artificiels. Nous avons montré sur un jeu de données spécifiquement
conçu que la prise en compte des deux informations permettait de trouver des parti-
tions qui ne l’auraient pas été avec des méthodes n’utilisant qu’un seul type de don-
nées. L’évaluation sur des graphes artificiels produits par des générateurs nous a de
plus permis de connaître les points forts et les faiblesses de ToTeM au regard des
caractéristiques des réseaux.

De manière à répondre à ces faiblesses et à certains problèmes de normalisation du
critère d’inertie interclasses, nous avons proposé une deuxième méthode de détection
de communautés dans des réseaux d’information dénommée 2Mod-Louvain. Elle tire
parti d’un nouveau critère que nous avons introduit, que nous appelons la modularité
basée sur l’inertie. C’est un critère pour la classification automatique non supervisée,
qui agit indépendamment du nombre de classes de la partition évaluée. Nous avons
montré que ce critère gardait une valeur constante face à une transformation linéaire
des données. Prenant sa valeur entre -1 et 1, il est d’autant plus grand que la parti-
tion testée est bonne. Bien que ce critère soit inspiré de la modularité de Newman
et Girvan, il ne repose pas sur les concepts de degrés et de distribution des arêtes,
inexistants en classification automatique. Il utilise des notions d’inertie par rapport à
un point et d’inertie totale. Le modèle nul, qui désigne dans la modularité classique la
valuation attendue entre deux sommets en fonction de leurs degrés, est remplacé par
le carré de la distance attendue, qui se calcule d’une façon très similaire.

L’exploitation en parallèle des deux critères de modularité nous permet de jeter un
regard nouveau sur le problème de la détection de communautés combinant les deux

157

informations.

Pour donner une égale importance aux deux types d’information, nous avons
conçu notre algorithme 2Mod-Louvain autour d’un critère global défini comme la
somme des deux critères de modularité. Nous avons donc proposé une réponse à
la problématique de détection de communautés dans un réseau d’information par une
adaptation de la méthode de Louvain opérant à la fois sur les données relationnelles
et d’attributs.

Nous avons conduit des expérimentations sur des jeux de données réels et artifi-

ciels qui ont confirmé l’intérêt de l’approche.

Néanmoins, nous pensons que des progrès restent à faire du point de vue de la vi-
tesse de la méthode. En effet, celle-ci nécessite de disposer de la matrice des distances
entre les objets, qui se calcule en O(N 2). En outre, si la méthode de Louvain profite
de matrices d’adjacence souvent creuses en ce qui concerne les graphes, nous sommes
en revanche pénalisés quand il est question d’opérer sur les attributs et leur matrice
de distance. Nous pensons qu’il est possible de concevoir une heuristique qui soit plus
adaptée que celle de la méthode de Louvain à l’optimisation de la modularité basée
sur l’inertie.

Sur un plan plus général, nous désirons trouver de nouvelles applications pour
la modularité basée sur l’inertie, dans les domaines de la classification. Enfin, nous
espérons que la proposition de ce critère permettra de mieux rapprocher les domaines
de la classification automatique et de la détection de communautés.

ANNEXE A
Comparaison des outils d’analyse
de réseaux sociaux

Cette annexe reprend un rapport technique que nous avons réalisé en début de
thèse sur des outils adaptés à notre problématique. Elle présente une étude compa-
rative de logiciels et de bibliothèques de développement fournissant des méthodes
d’analyse de réseaux qui a fait l’objet d’une communication dans la conférence WIVE
- ProVE 2010 (Combe et al., 2010).

A.1 Introduction

The explosion of Web 2.0 (blogs, wikis, content sharing sites, social networks, etc.)
opens up new perspectives for sharing and managing information. In this context,
among several emerging research fields related to "Web Intelligence", one of the most
exciting are the applications specialized in the handling of the social dimension of the
Web. In particular, building and managing communities require the development of a
new generation of tools integrating social network mining and modeling features.

Several decades ago, the first studies on Social Network Analysis (SNA) were car-
ried out by researchers in Social Sciences who wanted to understand the behavior of
human networks (Wasserman et Faust, 1994a; Scott, 2000). Several indicators were
proposed to characterize the actors as well as the network itself. One of them, for
example, is the centrality, which can be viewed as a characterization of some kind of
power within social networks, and thus can be used in viral marketing to discover the
early adopters or the people whose activity is likely to spread information to many
other people very quickly.

Nowadays, the wide use of Internet around the world allows a lot of people to
connect. Facebook currently claims over 500 million active users 1 and according to
Datamonitor they will be around one billion in 2012. As pointed out by the Gartner
study, this very important development of the networks gives rise to a growing need

1. Facebook Factsheet page http://www.facebook.com/

press/info.php?statistics

160

Annexe A. Comparaison des outils d’analyse de réseaux sociaux

for social network mining and social network analysis methods (Gartner, 2008). SNA
