https://cedric.cnam.fr/fichiers/art_3290.pdf

 

 

ÉCOLE DOCTORALE INFORMATIQUE, TÉLÉCOMMUNICATION ET 

ÉLECTRONIQUE (PARIS) 

ÉQUIPES ISID/VERTIGO – LABORATOIRE CEDRIC 

 

THÈSE  présentée par : 

Mohamed Ryadh DAHIMENE 

soutenue le : 8 Décembre 2014 

 

 

 

pour obtenir le grade de : Docteur du Conservatoire National des Arts et Métiers 

Discipline/ Spécialité : Informatique 

 

 

Filtrage et Recommandation sur les Réseaux 

Sociaux 

 

THÈSE dirigée par : 

M. DU MOUZA Cédric 
Mme. CONSTANTIN Camelia 

MCF-HDR, CNAM 
MCF, UPMC 

 
RAPPORTEURS : 

M. DEFUDE Bruno 
Mme. VOISARD Agnès 
 
 

JURY : 

Professeur, TELECOM SudParis 
Professeur, Freie Universität Berlin 

M. DEFUDE Bruno 
Mme. VOISARD Agnès 
M. CAUTIS Bogdan 
Mme. COMYN-WATTIAU Isabelle  Professeur, CNAM 
M. VODISLAV Dan 
M. DU MOUZA Cédric 
Mme. CONSTANTIN Camelia 

Professeur, TELECOM SudParis 
Professeur, Freie Universität Berlin 
Professeur, Université Paris-Sud 

Professeur, Université de Cergy-Pontoise 
MCF-HDR, CNAM 
MCF, UPMC 

 

 

 

Conservatoire National des Arts et Métiers

École Doctorale Informatique, Télécommunication et Électronique (Paris)

Laboratoire CEDRIC – Équipes ISID/VERTIGO

THÈSE
présentée par

Mohamed Ryadh Dahimene

Docteur du Conservatoire National des Arts et Métiers

pour obtenir le grade de

Discipline/Spécialité : Informatique

Filtrage et Recommandation sur

les Réseaux Sociaux

Devant le jury composé de :

Monsieur
Madame
Monsieur
Madame
Monsieur
Monsieur
Madame

Bruno Defude
Agnès Voisard
Bogdan Cautis
Isabelle Comyn-Wattiau
Dan Vodislav
Cédric Du Mouza
Camelia Constantin

Rapporteurs

Examinateurs

Directeur de thèse
Encadrante de thèse

Paris, le 8 Décembre 2014

Je dédie ce travail à la mémoire de trois hommes,
à mon grand-père Rachid Benhaddad
à Karim Benabadji
et à Michel Scholl

i

ii

Remerciements

Je tiens d’abord à remercier Michel Scholl 1 de m’avoir accepté en thèse

un beau jour de Mai 2010 et d’avoir mis ce travail sur les rails.

Aussi, je remercie profondément Cédric et Camelia de m’avoir accompa-
gné durant cette aventure en guidant mes pas, en m’accordant leur conﬁance
et en orientant notre collaboration durant ces années. Sans leur implication,
ce travail n’aurait pas vu le jour.

Ma gratitude s’adresse également à Monsieur Bruno DEFUDE ainsi qu’à
Madame Agnès VOISARD pour avoir accepté de rapporter cette thèse.
Je remercie aussi Monsieur Bogdan CAUTIS, Madame Isabelle COMYN-
WATTIAU et Monsieur Dan VODISLAV de bien vouloir participer à mon
jury.

J’adresse mes remerciements aussi à tous les membres des équipes ISID
et VERTIGO qui m’ont accueilli et avec qui j’ai eu le plaisir d’échanger
pendant ma thèse sans oublier aussi les membres du LIP6. Merci à Bernd
AMANN, Jacky AKOKA, Michel CRUCIANU, Hammou FADILI, Marin
FERECATU, Fayçal HAMDI, Nadira LAMMARI, Elisabeth METAIS, Ni-
colas PRAT, Christophe PICOULEAU, Philippe RIGAUX, Samira SI-SAID
CHERIFI et Nicolas TRAVERS.

Je remercie aussi très chaleureusement mes collègues du CNAM mais
aussi d’ailleurs pour avoir été là pendant ces années. Merci à Amina, Andrés,
Anh, Damien, Feten, Houda, Lydia, Nabil, Nelly, Pascal, Quentin, Rodney,
Sarah et enﬁn Zeinab pour son aide et ses conseils.

Les mots ne suﬃsent pas pour remercier mes parents, ma sœur, ma
1. http ://cedric.cnam.fr/∼scholl/hommage

iii

grand-mère et toute ma famille pour leur soutien et pour avoir toujours cru
en moi. Ce travail est aussi le fruit de leur patience. Merci.

Enﬁn, merci aussi à Darine et un clin d’œil particulier aux amis Ah-
med, Chakib, Chemsou, Elkindi, Mebarek, Malek et Salim et aux “Saint-
Jacquois” : Clau, Gabi, Lee, Manu, Vic et Paul.

iv

Résumé

Ces dernières années, le contenu disponible sur le Web a augmenté de
manière considérable dans ce qu’on appelle communément le Web social.
Pour l’utilisateur moyen, il devient de plus en plus diﬃcile de recevoir du
contenu de qualité sans se voir rapidement submergé par le ﬂot incessant
de publications. Pour les fournisseurs de service, le passage à l’échelle reste
problématique. L’objectif de cette thèse est d’aboutir à une meilleure ex-
périence utilisateur à travers la mise en place de systèmes de ﬁltrage et de
recommandation. Le ﬁltrage consiste à oﬀrir la possibilité à un utilisateur
de ne recevoir qu’un sous ensemble des publications des comptes auxquels
il est abonné. Tandis que la recommandation permet la découverte d’infor-
mation à travers la suggestion de comptes à suivre sur des sujets donnés.
Nous avons élaboré MicroFilter un système de ﬁltrage passant à l’échelle
capable de gérer des ﬂux issus du Web ainsi que RecLand, un système de
recommandation qui tire parti de la topologie du réseau ainsi que du contenu
aﬁn de générer des recommandations pertinentes.

Mots-clés : Réseaux Sociaux, Filtrage, Recommandation, Indexation, Micro-
blogging

v

vi

Abstract

In the last years, the amount of available data on the social Web has ex-
ploded. For the average user, it became hard to ﬁnd quality content without
being overwhelmed with publications. For service providers, the scalability of
such services became a challenging task. The aim of this thesis is to achieve
a better user experience by oﬀering the ﬁltering and recommendation fea-
tures. Filtering consists to provide for a given user, the ability of receiving
only a subset of the publications from the direct network. Where recommen-
dation allows content discovery by suggesting relevant content producers on
given topics. We developed MicroFilter, a scalable ﬁltering system able
to handle Web-like data ﬂows and RecLand, a recommender system that
takes advantage of the network topology as well as the content in order to
provide relevant recommendations.

Keywords : Social Networks, Filtering, Recommendation, Indexing, Micro-
Blogging

vii

viii

Table des matières

1 Introduction

1.1 Contexte . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2 Notre Problématique . . . . . . . . . . . . . . . . . . . . . . .
1.3 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.4 Organisation de la thèse . . . . . . . . . . . . . . . . . . . . .

2 État de l’art

2.3 Le Filtrage

2.3.1
2.3.2
2.3.3

2.1
2.2 Un Web Social

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.1 Caractérisation du phénomène
. . . . . . . . . . . . .
2.2.2 Comportement des utilisateurs . . . . . . . . . . . . .
2.2.3 La détection d’événements . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
Stratégies de ﬁltrage . . . . . . . . . . . . . . . . . . .
Indexation . . . . . . . . . . . . . . . . . . . . . . . .
Systèmes de publication/souscription . . . . . . . . . .
2.4 Les systèmes de recommandation . . . . . . . . . . . . . . . .
2.4.1 Déﬁnition . . . . . . . . . . . . . . . . . . . . . . . . .
2.4.2 Les systèmes basés sur le contenu . . . . . . . . . . . .
2.4.3 Le ﬁltrage collaboratif
. . . . . . . . . . . . . . . . . .
2.4.4 Les systèmes hybrides . . . . . . . . . . . . . . . . . .
2.4.5 Recommandations sociales . . . . . . . . . . . . . . . .
2.5 Mesures sur les graphes sociaux . . . . . . . . . . . . . . . . .
2.6 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3 Données issues des réseaux sociaux

3.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2 Le Micro-Blogging . . . . . . . . . . . . . . . . . . . . . . . .
3.3 Modèle de données . . . . . . . . . . . . . . . . . . . . . . . .

ix

1
1
6
6
8

11
11
12
13
17
18
19
19
20
21
21
21
22
23
24
25
27
29

31
31
32
33

TABLE DES MATIÈRES

3.3.1 Exemple de graphe social
. . . . . . . . . . . . . . . .
3.3.2 Le système de micro-blogging . . . . . . . . . . . . . .
3.3.3 Les ﬁltres . . . . . . . . . . . . . . . . . . . . . . . . .
3.3.4 La notiﬁcation . . . . . . . . . . . . . . . . . . . . . .
3.4 L’acquisition de données . . . . . . . . . . . . . . . . . . . . .
3.4.1 Le crawling, approche et limitations
. . . . . . . . . .
3.4.2 Constitution du jeu de données . . . . . . . . . . . . .
3.5 Jeu de données pour le Filtrage . . . . . . . . . . . . . . . . .
3.6 Jeu de données pour la recommandation . . . . . . . . . . . .
3.7 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4 Filtrage et indexation

4.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.2 L’indexation des ﬁltres . . . . . . . . . . . . . . . . . . . . . .
4.3 Structures et modèle analytique . . . . . . . . . . . . . . . . .
4.3.1 Le PFT-index . . . . . . . . . . . . . . . . . . . . . . .
4.3.2 Le PTF-index . . . . . . . . . . . . . . . . . . . . . . .
4.3.3 Le TPF-index . . . . . . . . . . . . . . . . . . . . . . .
4.4 Expérimentations . . . . . . . . . . . . . . . . . . . . . . . . .
4.4.1 Espace mémoire
. . . . . . . . . . . . . . . . . . . . .
4.4.2 Temps d’indexation . . . . . . . . . . . . . . . . . . .
4.4.3 Temps de recherche (matching) . . . . . . . . . . . . .
4.4.4 Eﬃcacité du ﬁltrage . . . . . . . . . . . . . . . . . . .
4.5 L’évolution du graphe social . . . . . . . . . . . . . . . . . . .
4.6 Une structure hybride . . . . . . . . . . . . . . . . . . . . . .
4.6.1 Occupation mémoire de la structure hybride . . . . . .
4.6.2 Temps de matching pour la structure hybride . . . . .
4.7 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5 Recommandation de comptes

5.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.2 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.3 Recommandation . . . . . . . . . . . . . . . . . . . . . . . . .
5.3.1 Le score de recommandation . . . . . . . . . . . . . .
. . . . . . . . . .
5.3.2 La convergence du calcul des scores
5.4 Une estimation eﬃcace des recommandations . . . . . . . . .
5.4.1 Vue d’ensemble de l’approche basée sur les landmarks
5.4.2 Pré-traitement
. . . . . . . . . . . . . . . . . . . . . .
5.4.3 Approximation rapide des recommandations . . . . . .
5.5 Expérimentations . . . . . . . . . . . . . . . . . . . . . . . . .

34
34
35
35
36
36
39
40
40
44

47
47
48
50
50
51
53
55
56
58
59
61
62
63
65
65
68

69
69
70
70
73
77
79
79
81
83
86

x

TABLE DES MATIÈRES

5.5.1
Implantation . . . . . . . . . . . . . . . . . . . . . . .
5.5.2 Qualité des recommandations . . . . . . . . . . . . . .
5.5.3 Validation par les utilisateurs . . . . . . . . . . . . . .
5.5.4 Approximation du calcul de recommandations . . . . .
5.6 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . .

86
87
91
93
97

6 Conclusion

99
6.1 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . .
99
6.2 Perspectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101

A Captures d’écran de MicroFilter

B Captures d’écran de RecLand

105

107

xi

TABLE DES MATIÈRES

xii

Table des ﬁgures

1.1 Nombre d’utilisateurs actifs sur Facebook et Twitter entre
2010 et le second trimestre 2014 . . . . . . . . . . . . . . . . .
1.2 Architecture centralisée de Twitter . . . . . . . . . . . . . . .
1.3 L’illustration sur la page d’accueil de Twitter.com lors des
interruptions de service (connue sous le nom de Twitter
Fail Whale) . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . .

3.1 Un graphe social étiqueté (LSG)
36
3.2 Visualisation d’un extrait du graphe social obtenu par crawling 38
42
3.3 Twitter400k Degré entrant/sortant . . . . . . . . . . . . . . .
43
3.4 Visualisation d’un graphe social de 10.000 nœuds . . . . . . .
3.5 Distribution des arcs par topic
. . . . . . . . . . . . . . . . .
44

3
4

5

4.1 Le PFT-index . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.2 Le PTF-index . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3 Le TPF-index . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.4 Espace mémoire / τ
. . . . . . . . . . . . . . . . . . . . . . .
4.5 Espace mémoire / N . . . . . . . . . . . . . . . . . . . . . . .
4.6 Temps de matching / τ
. . . . . . . . . . . . . . . . . . . . .
4.7 Temps de matching / N . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . .
4.8 Utilisateurs suivant leur nombre de followers
4.9 Utilisateurs suivant leur nombre moyens de tweets
. . . . . .
4.10 Espace mémoire occupé par rapport à N et au seuil choisi . .
4.11 Temps de matching pour la structure hybride par rapport au
seuil popularité . . . . . . . . . . . . . . . . . . . . . . . . . .

5.1 Exemple de LSG dans un contexte de recommandation . . . .
5.2 Exemple de recommandation par landmarks . . . . . . . . . .
5.3 Rappel à N . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.4 Précision VS rappel
. . . . . . . . . . . . . . . . . . . . . . .

50
52
54
57
57
60
61
64
64
65

66

72
80
88
89

xiii

TABLE DES FIGURES

90
91

92

5.5 Rappel suivant la stratégie de suppression d’arêtes . . . . . .
5.6 Rappel suivant la popularité des topics . . . . . . . . . . . . .
5.7 Extrait de l’interface du système d’évaluation pour le topic
Technology . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.8 Scores de pertinence obtenus par la validation par les utilisa-
teurs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

92
A.1 MicroFilter : Vue d’ensemble . . . . . . . . . . . . . . . . . 105
A.2 MicroFilter : Sélection d’un compte . . . . . . . . . . . . . 106
A.3 MicroFilter : Paramètres . . . . . . . . . . . . . . . . . . . 106
A.4 MicroFilter : Flux . . . . . . . . . . . . . . . . . . . . . . . 106
B.1 RecLand : Vue d’ensemble . . . . . . . . . . . . . . . . . . . 107
B.2 RecLand : Sélection d’un compte . . . . . . . . . . . . . . . 108
B.3 RecLand : Paramètres
. . . . . . . . . . . . . . . . . . . . . 108
B.4 RecLand : Aﬃchage des résultats . . . . . . . . . . . . . . . 109
B.5 RecLand : Top-k générés . . . . . . . . . . . . . . . . . . . . 109
B.6 RecLand : Aﬃchage des Tweets . . . . . . . . . . . . . . . . 110

xiv

Liste des tableaux

2.1 Dates de lancement et nombre d’utilisateurs des principaux
réseaux sociaux . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2 Propriétés topologiques de jeu Twitter [Myers et al., 2014] . .
2.3 Conventions de notation sur Twitter . . . . . . . . . . . . . .

3.1 Description du jeu de données . . . . . . . . . . . . . . . . . .
3.2 Exemple de données du LSG pour le ﬁltrage . . . . . . . . . .
3.3 Propretés topologique du graphe Twitter400k . . . . . . . . .

4.1 Table des notations . . . . . . . . . . . . . . . . . . . . . . . .
4.2 Tailles des index . . . . . . . . . . . . . . . . . . . . . . . . .
4.3 Temps d’indexation (en s) . . . . . . . . . . . . . . . . . . . .
4.4 Temps de matching . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . .
4.5 Nombre de tweets remis
4.6 Temps moyens d’insertion/suppression (en Nano-Secondes)
.
4.7 Nombre d’utilisateurs pour diﬀérentes valeurs de seuil de po-
pularité . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.8 Eﬃcacité des structures d’indexation . . . . . . . . . . . . . .

5.1 Notations . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.2 Algorithmes de sélection de Landmarks . . . . . . . . . . . . .
5.3 Temps moyen de sélection et de calcul pour un landmark par
stratégie de sélection . . . . . . . . . . . . . . . . . . . . . . .
. . . .

5.4 Comparaison des stratégies de sélection de landmarks

13
15
17

39
40
41

49
56
58
59
62
62

67
67

71
94

95
96

xv

LISTE DES TABLEAUX

xvi

Chapitre 1
Introduction

1.1 Contexte

Nous vivons à l’ère de l’information. L’avènement d’Internet et des nou-
velles technologies de l’information et de la communication a provoqué une
véritable rupture qui nous destine à un monde de plus en plus inter-connecté.
Il est estimé que la quantité de données produite chaque jour équivaut à
2,5 trillions d’octets (1018) et que plus de 90% de la totalité des données
disponibles actuellement ont été produites lors des deux seules dernières an-
nées [IBM]. Le 22 Août 2014, le terme “Mégadonnées”, équivalent Français
du terme big data, a fait oﬃciellement son entrée au journal oﬃciel pour
caractériser des “données structurées ou non dont le très grand volume re-
quiert des outils d’analyse adaptés” [JORF]

Ce phénomène s’est vu ampliﬁé une première fois au début des années
2000 avec l’arrivée du Web 2.0. Cette étape a permis aux utilisateurs de plus
en plus nombreux d’accéder plus facilement à la publication de contenu via
la démocratisation des blogs et autres systèmes de collaboration tels que les
forums de discussion ou les Wikis. Cette transformation a été supportée par
une transition technologique qui a vu les pages Web passer d’un format sta-
tique (HTML), à un format interactif grâce aux langages de programmation
Web dit “dynamiques” tel que PHP, JSP ou ASP.

Peu après, la deuxième accélération fut entamée avec l’adoption à grande

1

Chapitre 1. Introduction

échelle des réseaux sociaux. Ces applications ont depuis leurs débuts eu pour
vocation de transférer les interactions sociales du monde réel vers Internet.
Axés au départ sur des communautés bien identiﬁés, tels que les amateurs
de musique (ex. MySpace 1) ou des fonctionnalités précises tel que le partage
de ﬁchiers multimédia (ex. YouTube 2, Instagram 3), ces réseaux ont très vite
absorbé la plupart des interactions entre Internautes avec des oﬀres de plus
en plus généralistes (ex. Facebook 4, Google+ 5) englobant la plupart des in-
teractions allant du partage de contenu à la communication.

Fort de ses 1,31 milliard d’utilisateurs actifs (utilisant le réseau au moins
une fois par mois), Facebook, sans doute le réseau social le plus connu, en-
registre des taux de croissance vertigineux. Il est estimé que plus de 829
millions d’utilisateurs utilisent le réseau quotidiennement [Facebook] avec
plus de 78% de connexions sur dispositif mobile (Smartphones, tablettes).
Cette rapide adoption de la part des Internautes (voir Figure 1.1) s’est vue
accompagnée par une déferlante sans commune mesure de données générées
par les utilisateurs (User Generated Content). Un utilisateur de Facebook a
en moyenne 130 connexions “d’amitié” et produit une moyenne de 36 publi-
cations par mois ce qui a pour résultat d’exposer chaque utilisateur à plus de
1500 nouvelles publications à chaque connexion sur le réseau [DMRa]. En
Septembre 2011, le nombre total de photos stockées sur les serveurs de Face-
book dépassait les 140 milliards, plus de dix mille fois plus que la collection
nationale de la bibliothèque du congrès Américain et environ 4% du nombre
total de photos jamais prises (estimé à 3,5 billions (1012) en 2011) [Bergen].

Parmi les plateformes sociales ayant aﬃché les plus fortes croissances,
un modèle particulier a émergé ces dernières années : le Micro-Blogging.
Le micro-blogging tire son nom de sa principale caractéristique, la taille des
publications (appelée tweets) y est limitée à 140 caractères. Ce modèle sim-
pliste a séduit les Internautes qui l’ont très vite adopté comme moyen pour
transmettre et commenter l’actualité. Les utilisateurs peuvent s’abonner à
d’autres utilisateurs pour ainsi recevoir leurs publications, ce qui résulte en
la présence d’un graphe de relations de suivi (following).

1. http://www.myspace.com
2. http://www.youtube.com
3. http://www.instagram.com
4. http://www.facebook.com
5. http://plus.google.com

2

Chapitre 1. Introduction

Figure 1.1 – Nombre d’utilisateurs actifs sur Facebook et Twitter entre
2010 et le second trimestre 2014

Twitter 6, le réseau social leader en matière de micro-blogging, s’est im-
posé en quelques années comme une source incontournable d’information, en
plus de sa fonction de communication. En moins de 8 ans d’existence, Twit-
ter à vu sa base d’utilisateurs actifs atteindre les 271 millions et le nombre
d’utilisateurs ayant publié au moins un tweet dépasser les 570 millions. Ces
utilisateurs sont responsables de la production de plus de 500 millions de
tweets par jour soit une moyenne de 6000 tweets par seconde (TPS) avec des
pics pouvant atteindre les 143.000 TPS 7. Chaque semaine, Twitter enre-
gistre un million de nouveau comptes crées. En contraste, ce chiﬀre était de
1000 nouveau comptes par semaine en 2008. Chaque utilisateur de Twitter
est suivi en moyenne par 208 comptes et en suit à son tour 108 [DMRb]. Il
existe cependant une grande disparité sur le réseau avec des comptes très
suivis comme le président des États-Unis Barack Obama avec presque 45
millions de suiveurs (followers) ou la chanteuse Katy Perry avec plus 55 mil-
lions de followers (chiﬀres relevés en Août 2014). Cette disparité s’observe
aussi en ce qui concerne les fréquences de publication où certains comptes
sont très proliﬁques comme par exemple Fox News (média Américain) avec
ses 135 tweets en moyenne par jour ou certains comptes robots (bots) qui
fonctionnent comme des agrégateurs automatiques de contenu et culminent
à plus de 150 tweets par jour [Cheng and Evans].

6. http://www.twitter.com
7. https://blog.twitter.com/2013/new-tweets-per-second-record-and-how

3

Chapitre 1. Introduction

Ces taux de croissance et d’utilisation enregistrés sur les plateformes
sociales représentent un déﬁ permanent autant pour les fournisseurs de ser-
vice que pour les utilisateurs ﬁnaux. Pour le premiers, il s’agit d’être capable
de dimensionner le service aﬁn de faire face au ﬂux sans cesse croissant de
tweets à transmette. Pour diverses raisons (sécurité, présence de publicité,
politiques de contrôle) les réseaux sociaux fonctionnent sur une architec-
ture centralisée. Les publications émises par les utilisateurs sont d’abord
transmises au système central qui par la suite s’occupe de les orienter et de
notiﬁer les diﬀérents utilisateurs destinataires (voir Figure 1.2).

Figure 1.2 – Architecture centralisée de Twitter

Avec 200 millions de nouveaux tweets par jour en Juillet 2011 et chaque
tweet devant atteindre les followers du compte le publiant, Twitter a du
transmettre plus de 350 milliard de tweets par jour sur son réseau 8. Cette
surcharge de traﬁc couplée à l’hétérogénéité des tailles de comptes (en nombre
de followers) avec certains comptes très suivis pose un réel challenge de
passage à l’échelle. Les premières années d’exploitation de Twitter ont été
marquées par de fréquentes interruptions de service dues au fait que la pla-

8. http://latimesblogs.latimes.com/technology/2011/07/twitter-delivers-350-billion-

tweets-a-day.html

4

Chapitre 1. Introduction

teforme n’arrivait pas à suivre le ﬂux de tweets incessant. L’image aﬃchée
sur le page d’accueil de twitter.com pendant ces interruptions en est même
devenue une icône du Web 2.0 (Figure 1.3)

Figure 1.3 – L’illustration sur la page d’accueil de Twitter.com lors des
interruptions de service (connue sous le nom de Twitter Fail Whale)

Du point de vue des utilisateurs du service, la quantité phénoménale
d’information publiée par les comptes suivis a pour eﬀet de diluer l’informa-
tion de qualité dans les ﬂux sans cesse grandissants de tweets reçus. Malgré
la présence d’un système de classement basique (voir Section 3.2), il devient
vite diﬃcile de distinguer le contenu se rapprochant des centres d’intérêt de
l’utilisateur au milieu du ﬂot global d’informations.

Dans un sondage de 2013 mené en Angleterre sur 587 participants et por-
tant sur les réseaux sociaux et la surcharge d’information [Bontcheva et al.,
2013], 33,9% des sondés ont répondu positivement à la question : Diriez-vous
que vous recevez trop de publications ? et 70,4% trouvent diﬃcile la tache
qui consiste à localiser les publications de qualité ou ayant un quelconque
intérêt au milieu des autres. Aussi, 66,3% des utilisateurs interrogés ont eu
à un moment donné la sensation de ne plus pouvoir suivre ce qu’il se passe
sur le réseau car il reçoivent trop de publications. Il en résulte un compor-
tement particulier étudié par [Kwak et al., 2011,Kivran-Swaine et al., 2011]
où les utilisateurs ont tendance à suivre un compte temporairement puis à
se désabonner rapidement car vite submergés d’informations ne répondant

5

Chapitre 1. Introduction

pas à leurs critères de qualité. Le même sondage de 2013 rapporte que 64,9%
des participants se sont déjà désabonné d’un compte car il publiait trop et
44,1% car il ne publiait pas assez de contenu jugé intéressant.

1.2 Notre Problématique

Nous sommes partis du constat que les utilisateurs des réseaux sociaux
se retrouvent confrontés en permanence à un véritable déluge d’informations
ampliﬁé par le phénomène du Web social ces dernières années. Nous nous
intéressons au déﬁ de fournir à l’utilisateur une expérience de qualité sur
le Web social. Aﬁn de parvenir à nos ﬁns, nous explorons deux approches
complémentaires.

Dans un premier temps, il s’agit de fournir un mécanisme de ﬁltrage
dans un contexte de Micro-Blogging. En eﬀet, les plateformes tels que Twit-
ter fonctionnent suivant le paradigme du Tout-ou-Rien (all-or-nothing) :
si un utilisateur A suit un autre utilisateur B sur le réseau, A va recevoir
toutes les publications de l’utilisateur B. Notre déﬁ consiste à fournir la
fonctionnalité de ﬁltrage qui permettrait à A de ne plus recevoir qu’un sous-
ensemble des publications générées par B et qui correspondent à son centre
d’intérêt.

En second lieu, il s’agit de s’attaquer au problème de la découverte d’in-
formation sur le réseau en fournissant des recommandation de comptes à
suivre. La tâche consiste en l’occurrence à fournir à A une liste triée par
pertinence de comptes à suive par rapport à un certain centre d’intérêt.

L’obstacle majeur à considérer lors de la mise en place des fonctions de
ﬁltrage et de recommandation sur les réseaux sociaux est celui du passage à
l’échelle. En eﬀet, la taille des graphes sociaux existants couplée à leurs taux
de croissance vertigineux rendent la tâche complexe. Il nous faut donc fournir
ces fonctionnalités tout en s’avisant à proposer des solutions capables de
s’adapter à des tailles et des taux de croissance semblables à ceux présentés
en section 1.1.

1.3 Contributions

Dans cette thèse, en réponse à la quantité croissante d’informations à
laquelle les utilisateurs des réseaux sociaux se trouvent exposés, nous intro-

6

Chapitre 1. Introduction

duisons des solutions visant à améliorer l’expérience utilisateur axées sur
deux stratégies :

— Le ﬁltrage eﬃcace des publications reçues à travers des structures

d’indexation spécialement conçues.

— La recommandation intelligente de sources de contenu pertinentes.

Le principal déﬁ à relever concernant ces deux tâches consiste à fournir
un service de qualité employable sur les systèmes existants. Avec des chiﬀres
sans cesse croissants, le passage à l’échelle doit constituer une préoccupation
permanente qui doit être prise en compte dès la conception et jusqu’à l’im-
plémentation des solutions de ﬁltrage ou de recommandation sur les réseaux
sociaux.

Aﬁn d’aborder le problème, nous avons d’abord menée une étude de
l’existant présentant tout d’abord une série d’études sur la nature des don-
nées sur plateformes sociales. Cette caractérisation nous a permis d’appro-
fondir notre connaissance du domaine. Cet état de l’art traite par la suite
des diﬀérentes approches adoptées en matière de ﬁltrage et de recommanda-
tion sur les réseaux sociaux et positionne notre travail vis-à-vis des travaux
cités.

Nous nous sommes ensuite intéressés aux données sociales ainsi qu’à leur
acquisition. Nous avons proposé le LSG (Labelled Social Graph) qui est un
modèle de représentation de données spéciﬁque à nos cas d’utilisation et qui
capture les intérêts des utilisateurs sous forme de graphe social étiqueté. Un
travail d’acquisition et de transformation a ensuite été eﬀectué pour aboutir
à des jeux de données représentatifs que nous présentons et détaillons.

Nous avons élaboré par la suite diverses stratégies de ﬁltrage de données
basées sur des structures de listes inverses. Ces structures exploitent les ca-
ractéristiques intrinsèques aux données issues du monde du Micro-Blogging.
Nous avons par la suite proposé un modèle analytique pour envisager leur
évolution en temps et en mémoire. Après avoir testé le comportement de ces
structures en situation de passage à l’échelle, nous avons proposé une ap-
proche hybride qui apporte un compromis et permet d’aboutir à un ﬁltrage
eﬃcace.

7

Chapitre 1. Introduction

Par la suite, basé sur le modèle élaboré à l’origine dans un contexte de
ﬁltrage, nous avons proposé une stratégie de recommandation de comptes
à suivre sur les plateformes de Micro-Blogging. Tirant parti des caracté-
ristiques intrinsèques au graphe d’intérêt, nous avons proposé un score de
recommandation doté de trois composantes (i) La topologie du graphe :
le score favorise les comptes “proches” par rapport à ceux distant dans le
graphe (ii) La sémantique : le score considère la proximité sémantique sur
les chemins entre le nœud (compte) et ses recommandations (iii) L’auto-
rité : le score mesure l’inﬂuence des comptes à recommander sur un sujet
donné et ce de manière locale ainsi que globale. Aﬁn de pouvoir fonctionner
sur des graphes de taille importante, nous avons proposé une approche par
landmarks (comptes élus par le système pour pré-calculer et stocker certains
scores) qui fournit des approximations de scores tout en réduisant considéra-
blement les temps nécessaires aux calculs des recommandations. Nous avons
ensuite mené une validation expérimentale du système de recommandation
proposé face à deux approches connues. Les expériences menées concernent
la pertinence des recommandations générés mais aussi du gain induit par les
landmarks et ainsi la capacité du système à passer à l’échelle. Une valida-
tion par des utilisateurs a aussi été menée pour tester la pertinence de notre
approche par rapport aux algorithmes concurrents.

1.4 Organisation de la thèse
Cette thèse est organisée comme suit :

Après ce chapitre d’introduction, nous présentons en chapitre 2 l’état de
l’art du domaine ciblé. Ce chapitre détaille les diﬀérentes avancées récentes
en commençant d’abord par la caractérisation du Web “social” qui permet
d’acquérir une compréhension plus précise sur la nature et les spéciﬁcités
du phénomène. Nous y présentons par la suite les diﬀérentes approches qui
ont été élaborés aﬁn d’introduire la notion de ﬁltrage d’information pour
les utilisateurs des réseaux sociaux avec une mise en avant de leur points
forts ainsi que de leur limitations. Par la suite, cette étude de l’existant se
concentre sur le domaine de la recommandation en présentant d’abord les
grandes approches adoptés pour la recommandation de contenu pour se re-
centrer par la suite sur les solutions proposées dans le contexte des réseaux
sociaux.

Le chapitre 3 a pour but de détailler les caractéristiques des données

8

Chapitre 1. Introduction

issues des plateformes sociales de type Micro-Blogging et de présenter le
modèle de données adopté par notre approche aﬁn fournir les fonctionnali-
tés de ﬁltrage et de recommandation. Nous y présentons aussi les étapes qui
nous ont permises de constituer un jeu de données représentatif et présen-
terons une caractérisation de ces données.

Dans le chapitre 4, nous présentons en détail notre solution de ﬁltrage
spéciﬁque au Mirco-Blogging nommée MicroFilter. Nous détaillerons les
diﬀérentes structures d’index élaborées ainsi qu’un modèle analytique de
coût en temps et en mémoire pour chacune des structures. Nous présente-
rons aussi les résultats expérimentaux sur le comportement de nos index sur
un jeu de données conséquent puis nous présenterons une structure hybride
qui pressente un compromis en tirant avantage d’aspects complémentaires
de deux des structures précédemment testées.

Par la suite, le Chapitre 5 présente RecLand notre système de recom-
mandation pour les réseaux sociaux. Ce chapitre s’ouvre sur la présentation
du score de recommandation proposé qui prend en considération les aspects
topographiques, sémantiques ainsi que l’autorité des utilisateurs recomman-
dés. Puis nous détaillons les algorithmes de notre approche par landmarks
qui permettent une approximation des scores de recommandation. Cette ap-
proche apporte un gain important en temps de calcul aﬁn de permettre à
notre système d’être exploité sur des graphes sociaux de tailles similaires à
celles observées en production. Finalement, nous présenterons les résultats
expérimentaux de notre système de recommandation ainsi que le résultat
d’une validation par les utilisateurs de la pertinence des recommandations
générées par notre système.

Enﬁn, le chapitre 6 clôt le document en résumant le travail réalisé au

cours de cette thèse et en présentant les perspectives de recherche.

9

Chapitre 1. Introduction

10

Chapitre 2
État de l’art

“There’s too many men
Too many people
Making too many problems
And not much love to go round
Can’t you see
This is a land of confusion”

— Genesis, Land of confusion, 1986

2.1 Introduction

Le travail présenté dans cette thèse s’articule autour des données géné-
rées par les utilisateurs des réseaux sociaux. Il est donc primordial d’abord
pour nous de comprendre les modes de fonctionnement ainsi que les diﬀé-
rentes utilisations que font les Internautes de ces plateformes sociales. La
première partie de ce chapitre est dédiée à la caractérisation du Web social,
nous y présentons les travaux qui s’intéressent à la nature de ces données
ainsi qu’au comportement des utilisateurs sur ces plateformes.
Par la suite, nous nous intéressons aux travaux récents dans le contexte du ﬁl-
trage sur les réseaux sociaux. Nous exposerons les diﬀérentes approches ainsi
que les parallèles possibles avec d’autres types d’interactions déjà identiﬁées
et étudiées telles que les systèmes de publication/souscription. La troisième
partie va présenter les solutions existantes dans le domaine des systèmes de
recommandation. Elle s’ouvre sur les grandes approches adoptées dans ce
contexte puis se recentre sur les données sociales. Plusieurs solutions existent

11

Chapitre 2. État de l’art

pour générer des recommandations sur les réseaux sociaux, nous exposerons
leurs avantages ainsi que leurs limitations. Enﬁn, nous présenterons quelques
approches utiles pour accélérer certains calculs sur les grands graphes, ap-
proches dont nous nous sommes inspirés pour adresser le déﬁ du passage à
l’échelle.

2.2 Un Web Social

Autour de l’an 2000, la première forme se rapprochant des réseaux so-
ciaux à apparaitre sur le Web fut les blogs 1. Les blogs sont des pages Web
personnelles, souvent éditées par un seul utilisateur, qui contiennent des
publications datées et organisées chronologiquement de plusieurs types : ar-
ticles divers, opinions politiques, activités quotidiennes, photos, créations
artistiques, etc. L’avènement des blogs marqua le début de la déferlante de
données générées par les utilisateurs (User Generated Content ou UGC).
Le réseau à proprement dit était alors déduit via les interactions entre uti-
lisateurs (blogueurs) qui peuvent référencer d’autres blogs ou bien laisser
des commentaires sur les publications de leur choix. Dès 2003, Kumar &
al. s’intéressent à la caractérisation du phénomène en étudiant l’ensemble
des blogs (appelé blogosphère) ainsi que leur évolution [Kumar et al., 2003].
En étudiant les quelques 750.000 liens existants entre plus de 25.000 blogs,
les auteurs déﬁnissent une structure qu’il nomment le “Time Graph” et qui
capture les interactions entre les blogs du corpus ainsi que la temporalité
de ces liens sous forme de graphe. L’étude montre entre autre que le monde
du blogging a vécu une transformation avec pic de croissance et une struc-
turation en communautés vers la ﬁn de l’année 2001, croissance qui n’a pas
cessé depuis et qui a évolué vers d’autres types d’interactions.

Les principaux réseaux sociaux vont faire leur apparition entre les années
2003 et 2006 (voir tableau 2.1). Il s’agit alors de créer et d’entretenir des
liens sociaux entre les diﬀérents utilisateurs. Les diﬀérentes plateformes so-
ciales en ligne sont souvent appelés “Médias Sociaux”. [Kaplan and Haenlein,
2010] déﬁnissent les médias sociaux comme un ensemble d’applications In-
ternet qui permettent aux utilisateurs de produire et d’échanger du contenu
(UGC), supporté technologiquement par les outils du Web 2.0.

1. Le terme blog est un anglicisme provenant de la contraction de “Web Log”, littéra-

lement “Registre Web”

12

Chapitre 2. État de l’art

Réseau social Date de mise en ligne # d’utilisateurs (en millions)
Friendster
LinkedIn

Hi5

MySpace
Facebook
Twitter
Google+

Mars 2002
Mai 2003
Juillet 2003
Août 2003
Février 2004
Mars 2006
Juin 2011

8.2 (2010)
300 (2014)
100 (2011)
36 (2013)
1310 (2014)
271 (2014)
540 (2013)

Table 2.1 – Dates de lancement et nombre d’utilisateurs des principaux
réseaux sociaux

2.2.1 Caractérisation du phénomène

[Java et al., 2007] présente l’une des première études à s’être intéressé
aux médias sociaux, plus particulièrement à la plateforme de micro-blogging
Twitter et ce dès sa première année d’existence. Parmi les résultats de l’étude
sur la communauté de moins de 100.000 utilisateurs qui constituait le Twit-
ter de l’époque, les auteurs ont démontré que Twitter constituait un réseau
du type “Small World Network”. Ce type particulier de réseau est caractérisé
par une grande inter-connectivité entre ses utilisateurs. Ce phénomène de
“petit monde" a été popularisée par Stanley Milgram et son concept de “six
degrés de séparation” [Milgram, 1967] qui stipule que n’importe quelle paire
d’individus choisie au hasard aux État-Unis peut être relié par une chaine
de six relations en moyenne 2. Dans le monde virtuel, cette valeur moyenne
a été observée et s’avère être d’autant plus petite sur les réseaux sociaux :
elle n’est que de 3.74 pour Facebook et de 3.05 pour Twitter 3 [Backstrom
et al., 2012, Myers et al., 2014]. Cette même étude a aussi mis en avant
l’aspect communautaire de ce genre de réseaux. En identiﬁant les grandes
communautés thématiques présentes dans Twitter, il apparait que les utili-
sateurs ayant des intérêts communs ont tendance à se regrouper, on parle
alors de phénomène de localité. Cette localité peut être thématique (c.à.d
les utilisateurs ayant les mêmes centres d’intérêt) mais aussi géographique
(utilisateurs se connectant avec d’autres comptes provenant de la même ré-

2. En 1929, l’écrivain Hongrois Frigyes Karinth fut le premier à émettre le postulat des

“six degrés de séparation” dans une nouvelle intitulée Láncszemek (Chaînes)

3. La déﬁnition de degré de séparation compte le nombre d’intermédiaires entre deux
nœuds du graphe social, elle est égale à distance moyenne entre deux nœuds (nombre
moyen d’arcs) moins un.

13

Chapitre 2. État de l’art

gion) comme démontré par [Gonzalez et al., 2011].

Étant donné la nature stratégique des données issues des médias sociaux,
le rôle commercial de ces plateformes ainsi que la diﬃculté inhérente à la
manipulation de grands volumes de données, très peu d’équipes de recherche
ont eu accès à des jeux de données réalistes et de tailles conséquentes [Kwak
et al., 2010,Backstrom et al., 2012,Myers et al., 2014].

La nature privée des données sur Facebook fait que ce dernier est un
des réseaux les plus fermés. Les paramètres de conﬁdentialité choisis par
les utilisateurs font que peu d’études existent sur ce réseau en comparaison
au monde du micro-blogging où les publications sont le plus souvent pu-
bliques. Dans [Backstrom et al., 2012], les auteurs présentent les résultat de
leur caractérisation du réseau social facebook se basant principalement sur
l’algorithme HyperANF [Boldi et al., 2011] qui permet une approximation
eﬃcace de la fonction de voisinage dans un graphe 4. Cette analyse sur le
plus grand réseau social jamais étudié (≈ 69 milliards de liens d’amitié entre
plus de 721 millions d’utilisateurs) a pu démontrer la nature de “petit mon-
de” du réseau avec une valeur de degré de séparation moyen de 3.74 mais
aussi que le principal eﬀet de localité existant sur le graphe était celui du à
la localité géographique partitionnant le graphe en sous-communautés.

Grâce à une batterie de serveurs autorisés à récolter des données par
Twitter, Kwak & al. ont pu étudier le comportement des utilisateurs et
apporter des éléments de réponse à la question : Twitter est-il un réseau
social, ou un média d’information ? les résultats de leurs expériences sur
41 millions d’utilisateurs liés par plus de 1,47 milliard de relations de suivi
montrent que le réseau présente un compromis entre son aspect social et son
rôle dans la diﬀusion d’information. Il montre aussi que l’application directe
de l’algorithme PageRank [Brin and Page, 1998] donne le même résultat
que le classement des utilisateurs par nombre de suiveurs (followers). Page-
Rank, l’algorithme originel du moteur de recherche Google, classe les pages
Web dans un graphe hypertexte (graphe des pages Web se référençant) en
fonction du nombre de liens référençant la page pondéré par la popularité
de celle-ci.

Cette étude à été complétée trois ans plus tard par une équipe au sein

4. La fonction voisinage NG(t) dans un graphe G retourne pour chaque t ∈ N le nombre

de paires de nœuds hx, yi telles que y est atteignable à partir de x en moins de t sauts

14

Chapitre 2. État de l’art

même de Twitter [Myers et al., 2014]. Elle retrouve les même grandes lignes
sur un graphe plus pertinent car exempt d’éventuels biais liés aux stratégies
d’acquisition de données (crawling). Nous présentons les principales mesures
calculés par cette étude dans le tableau 2.2.

Mesure

Nombre total de nœuds

Nombre total de liens de suivi

Distance moyenne entre deux nœuds

Degré sortant moyen
Degré entrant moyen

Local Clustering Coeﬃcient

Degré entrant maximum
Degré sortant maximum

% Liens mutuels

4.05
470
339
mut-deg=5
mut-deg=20
mut-deg=100

0.23
0.19
0.14

Valeur

∼175 Millions
∼20 Milliards

14,7 Millions

755.000

42%

Table 2.2 – Propriétés topologiques de jeu Twitter [Myers et al., 2014]

Ces études ont permis de mettre en avant la nature hybride des systèmes
de Micro-Blogging. En eﬀet, les valeurs élevées de degré sortant moyen 5 et de
degré sortant maximum révèlent que les utilisateurs considèrent les comptes
suivis plutôt comme des sources d’informations et non des relations d’amitié
dérogeant ainsi à la règle sur les réseaux dit sociaux. Il a été démontré en
sciences sociales qu’un individu moyen ne peut entretenir plus de 150 rela-
tions sociales stables [Dunbar, 1992].

Le local clustering coeﬃcient (traduit parfois par “coeﬃcient d’agglomé-
ration” 6) est une mesure qui évalue si deux nœuds A, B du graphe associés
chacun à un même nœud C sont connectés entre eux. Cette mesure a été
introduite par [Watts and Strogatz, 1998] pour caractériser les réseaux du
type petit monde. Une forte valeur de LCC pour un nœud indique que son
voisinage est dense (proche de former une clique). La moyenne du LCC sur

5. Le degré sortant (resp. degré entrant) désigne le nombre de comptes qu’un utilisateur

suit (resp. le nombre d’utilisateurs qui suivent un compte) dans le graphe social

6. http://fr.wikipedia.org/wiki/Analyse_des_réseaux_sociaux

15

Chapitre 2. État de l’art

tout le graphe permet caractériser le réseau. Sur les réseaux sociaux cette
mesure peut être interprétée comme la fraction d’utilisateurs dont les amis
sont eux même amis entre eux [Myers et al., 2014]

Les valeurs de LCC présentées dans le tableau 2.2 ont été calculées sur
le graphe dit “mutuel”. Il s’agit du graphe qui ne contient que les relations
du type A suit B et B suit A. Pour une valeur de degré mutuel 7 égale à 5
le LCC est égal à 0,23. Pour cette même valeur de degré [Ugander et al.,
2011] rapporte que le LCC moyen sur Facebook est de 0,4 ce qui conﬁrme
la nature plus “sociale” de Facebook. Pour un degré mutuel égal à 100, on
retrouve un LCC de 0,14 sur Twitter comme sur Facebook c.à.d que pour
un utilisateur moyen, 14% de ses voisins dans le graphe sont à leur tour liés.

Le principe d’homophilie, terme emprunté à la sociologie qui stipule que
les gens avec des goût et des intérêts similaires ont tendance à se connecter,
se traduit dans les réseaux sociaux par le fait que des comptes à faible dis-
tance sur le graphe sont plus semblables que des comptes éloignés 8. [Golder
and Yardi, 2010] présente une étude qui s’intéresse à la motivation qui mène
les utilisateurs des plateformes de micro-blogging a créer de nouveaux liens.
Il apparait que la transitivité (le fait qu’un nœud soit suivi par un compte
déjà suivi) et la mutualité sont parmi les facteurs de motivation les plus
importants considérés par les utilisateurs pour former de nouveaux liens. Ce
résultat sur la transitivité a été validé aussi par
[Romero and Kleinberg,
2010] qui montre les utilisateurs créent souvent de nouveaux liens sur le ré-
seau en court-circuitant des chemins de longueur 2 (se lient avec des amis
d’amis).

Au niveau du contenu généré par les utilisateurs des systèmes de micro-
blogging, la limitation de la taille des publications à 140 caractères pousse les
utilisateurs à adopter diverses conventions de langage. [Laboreiro et al., 2010,
Han and Baldwin, 2011] ont analysé l’aspect lexical d’un corpus de tweets
et relèvent des similitudes avec le langage communément appelé “langage
SMS”. Les principales conventions de notation utilisés dans Twitter sont
résumés dans le tableau 2.3.

7. Le nombre d’arcs réciproques pour nœud (c.à.d A → B et B → A)
8. http://lafeuille.blog.lemonde.fr/2011/12/29/homophilie-et-proximite-dans-les-rese-

aux-sociaux-de-lecteurs/

16

Chapitre 2. État de l’art

Notation
@

#

RT

#FF

Signiﬁcation
Sert à citer un autre utilisateur en précédant son
pseudonyme par un @
Avant un des mots du tweet, permet de désigner
ce mot en tant que mot-clé pour catégoriser la
publication, les mots précédés du symbole dièse
sont appelés “hashtags”
Désigne un retweet ou le fait de re-publier un
tweet reçu
Désigne le “Follow Friday”, chaque Vendredi les
utilisateurs publient des listes de comptes qu’ils
jugent intéressants à suivre

Table 2.3 – Conventions de notation sur Twitter

2.2.2 Comportement des utilisateurs

L’ensemble de notations adoptées par les utilisateurs enrichissent la sé-
mantique associée aux tweets. Ces conventions créent aussi de manière tacite
un graphe de relations implicites entre les utilisateurs. On peut distinguer
par exemple le graphe des @citations où les nœuds représentent les utili-
sateurs et les arcs la présence d’une citation entre deux nœuds ou bien le
graphe des retweets ou un arc représente le retweet d’un utilisateur d’un
tweet publié par un autre compte.

Cette sémantique peut être exploitée aﬁn de comprendre le comporte-
ment des utilisateurs et de calculer diverses métriques sur celui-ci. [Welch
et al., 2011] a passé en revue les diﬀérents liens pouvant exister entre les
utilisateurs, entre les utilisateurs et les tweets ainsi que les liens inter-tweets.
Les auteurs ont mis en avant le fait que le lien de retweet est un indica-
teur d’intérêt entre deux comptes plus fort que le lien de suivi (following).
De plus, ce lien présente l’avantage de pouvoir être facilement associé à un
centre d’intérêt précis (topic). Ce topic pouvant être extrait en analysant
simplement les retweets.

Dans [Cha et al., 2010], les auteurs comparent deux méthodes pour le
calcul de l’inﬂuence des utilisateurs sur le réseau se basant sur le degré
entrant et les @citations. Ils ont observé que le degré entrant est un bon

17

Chapitre 2. État de l’art

indicateur en ce qui concerne la popularité d’un compte mais qu’il échoue à
caractériser son inﬂuence sur le réseau (calculée en terme de retweets ou de
@-citation). Aussi, en étudiant les comptes les plus inﬂuents sur le réseau, les
auteurs ont pu montrer que l’inﬂuence sur le réseau s’obtient par un eﬀort
de cohérence de la part des comptes inﬂuents en limitant par exemple leurs
publications à un sujet précis (topic). Une autre approche dans la mesure de
l’inﬂuence des utilisateurs consiste à la calculer sur l’ensemble du réseau et
d’obtenir ainsi les top-utilisateurs sur tout le réseau [Pal and Counts, 2011].
Dans
[Vosecky et al., 2012], les auteurs utilisent aussi les liens implicites
combinés à une analyse du contenu des tweets aﬁn de ﬁltrer et classer les
publications en fonction de leur qualité.

[Achananuparp et al., 2012] propose trois modèles diﬀérents pour cap-
turer le comportement des utilisateurs sur les réseaux sociaux. Les auteurs
ont montré que ces modèles comportementaux pouvaient être employés pour
détecter des événements de manière eﬃcace en contraste avec les méthodes
basés sur l’analyse du contenu des publications.

2.2.3 La détection d’événements

L’aspect événementiel des réseaux sociaux et notamment des plateformes
de micro-blogging est incontestable. Des pics d’activité sont souvent relevés
au moment d’événements importants. Les méta-données associés à un tweet
contiennent un champ sur la position géographique de l’émetteur au mo-
ment du tweet ce qui permet, selon la nature de l’événement, de le localiser
géographiquement. Les pics d’activité peuvent alors concerner une région
précise (ex. les catastrophes naturelles) ou bien être généralisés pour des
événements d’ampleur mondiale (ex. nouvel an).

Une étude de 2010 menée par Tumasjan & al. sur Twitter pendant les
élections fédérales en Allemagne révèle que la plateforme est utilisé acti-
vement par les Internautes pour exposer et débattre de leurs opinions po-
litiques. L’analyse de plus de 100.000 tweets a permis de montrer un fort
rapprochement avec les sondages eﬀectués par des organismes spécialisés en
cette période ainsi qu’une forte corrélation avec le résultat ﬁnal du scru-
tin [Tumasjan et al., 2010].

Dans [Sakaki et al., 2010], les auteurs tirent parti de l’aspect temps-
réel des plateformes de micro-blogging. Ils présentent un algorithme pour le
monitorage de Twitter et la détection des tremblements de terres au Japon.

18

Chapitre 2. État de l’art

Grâce a la forte adoption de Twitter au Japon, le réseau agit comme un
capteur qui permet de détecter avec succès 96% des tremblements de terre
de magnitude supérieure à 3, de localiser approximativement l’épicentre et
d’émettre des bulletins d’alerte plus rapidement que les voies traditionnelles.

2.3 Le Filtrage

La nature hybride des plateformes de micro-blogging liée aux ﬂux sans
cesse croissants de données s’y écoulant introduit le besoin de mécanismes
de ﬁltrage eﬃcace pour les utilisateurs. Pour éviter le phénomène de satu-
ration (ﬂooding), certains travaux se sont concentré sur la présentation des
données aux utilisateurs des plateformes de micro-blogging aﬁn d’améliorer
la lisibilité des ﬂux reçus.

2.3.1 Stratégies de ﬁltrage

Certains travaux se sont inspirés du domaine de la recherche d’informa-
tion. [Sriram et al., 2010] présente une approche de clustering et de classiﬁca-
tion des tweets basée sur l’établissement au préalable d’un proﬁl utilisateur.
Cette technique s’appuie sur un classiﬁcateur qui s’occupe de router les
nouvelles publications vers des classes préétablies. Cette classiﬁcation peut
se baser aussi sur les sujets d’actualité abordés dans le réseau (hot trends).
Dans [Sankaranarayanan et al., 2009] par exemple, les auteurs décrivent une
méthode qui permet l’extraction de concepts à partir des tweets, et l’utilisent
pour détecter des sujets d’actualité (news) depuis Twitter. Des travaux tels
que [Weng et al., 2010,Bakshy et al., 2011] s’appuient plutôt sur l’inﬂuence
globale des utilisateurs sur le réseau, calculée via diﬀérentes techniques, pour
classer les tweets et appliquer des techniques de classement. Dans [Uysal and
Croft, 2011], les auteurs utilisent le comportement de retweet comme indi-
cateur d’intérêt et s’en servent pour faire remonter les publications les plus
retweetés dans les résultats.

Une autre technique de ﬁltrage est présentée dans [Haghani et al., 2010]
où les auteurs appliquent des algorithmes de top-k sur des ﬂux Web 2.0 tout
en considérant l’aspect temps-réel de ces données ainsi que leur fraicheur
via une fenêtre temporelle. [Albakour et al., 2013] propose une technique
de ﬁltrage avec réécriture de requêtes qui prend en considération la taille
réduite des tweets ainsi que le cycle de vie limité et l’aspect spontané de
certaines requêtes (ex. lors d’un événement particulier).

19

Chapitre 2. État de l’art

Plus généralement, le problème de la propagation de données sur le Web
2.0 avec l’existence d’un graphe sous-jacent a déjà été abordé par diﬀérents
travaux. [Silberstein et al., 2010] considère des ﬂux à haute fréquence de
mise à jour. Les auteurs rapportent le problème à un problème de calcul de
vues sur des ﬂux de données et proposent une méthode pour matérialiser
les événements du ﬂux de manière sélective aﬁn d’améliorer l’aptitude au
passage à l’échelle. Il s’agit d’adopter une approche hybride en distinguant
les comptes à forte fréquence de publication des comptes à plus faible fré-
quence. Twitter utilise une technique similaire pour créer les vues pour ses
utilisateurs (le timeline Twitter 9).

2.3.2

Indexation

Quelques travaux récents s’attaquent au problème du passage à l’échelle
pour l’indexation et la recherche d’information dans des ﬂux issus de réseaux
sociaux. [Busch et al., 2012] présente EarlyBird, le système d’indexation en
temps-réel déployé par Twitter pour fournir la fonction de recherche. Early-
Bird se base sur une structure de listes inverses qui lie les requêtes (formulées
par les utilisateurs sous forme de mots-clés) à des listes de tweets fonction-
nant en ajout-seulement (append-only). Ces listes, maintenues par le système
en ordre chronologique ascendant, permettent de récupérer eﬃcacement les
tweets les plus récents pour une requête donnée avec des temps de latence
de moins de 200 millisecondes pour l’indexation ainsi que pour recherche.
Le déﬁ étant de répondre eﬃcacement aux requêtes de recherche tout en ré-
duisant au maximum le temps nécessaire à nouveau tweet pour être indexé.

Dans TweetIndex [Chen et al., 2011], les auteurs proposent une approche
intéressante en aﬀectant une priorité d’indexation plus élevée à un nouveau
tweet si ce dernier présente une forte probabilité d’être associé à une requête
de recherche. L’indexation des tweets ayant une faible probabilité d’être re-
cherchés est quant à elle retardée.

[Wu et al., 2013], présente une approche similaire. LSII, la structure
proposée, implémente une cascade à multi-niveaux d’index de tailles crois-
santes aﬁn d’insérer les nouveaux tweet dans les plus petits index. Par la
suite, les tweets plus anciens sont déplacés vers des index plus grands (donc
moins eﬃcaces) par lots.

9. blog.evanweaver.com/2010/08/12/distributed-systems-primer-update/

20

Chapitre 2. État de l’art

2.3.3 Systèmes de publication/souscription

Des parallèles existent entre le domaine du ﬁltrage de ﬂux sociaux et les
systèmes de publication/souscription (pub/sub). Diﬀérentes structures d’in-
dexation ont été proposées pour gérer des ﬂux de nouvelles publications et
vériﬁer eﬃcacement la satisfaction de souscriptions. Le Subscribe [Pereira
et al., 2000] fut l’un des premiers systèmes pub/sub à traiter des données
hautement dynamiques tels que les données du Web. Les auteurs présentent
une structure pour évaluer la correspondance des souscriptions en comptant
le nombre de prédicats contenus.

Dans [Broder et al., 2011], les auteurs supposent un système du type
pub/sub ou les producteurs de publications ainsi que leur souscripteurs sont
liés dans un graphe logique dirigé (comme dans les réseaux sociaux) régit
par des contraintes (sous forme de prédicats). Il proposent ainsi des algo-
rithmes pour l’évaluation eﬃcace de contraintes dans un tel graphe (ex.
la propagation d’une publication dans un réseau social du type Facebook
ou les utilisateurs peuvent avoir diﬀérents paramètres de conﬁdentialité).
Dans [Hmedeh et al., 2012] , les auteurs proposent des schémas d’indexation
sur des systèmes pub/sub dans un contexte RSS aﬁn de satisfaire un grand
nombre de requêtes utilisateur le tout en prêtant une attention particulière
au passage à l’échelle.

2.4 Les systèmes de recommandation
2.4.1 Déﬁnition

Face aux ﬂux importants de données circulant sur le Web, une des ap-
proches adoptées pour améliorer l’expérience utilisateur consiste à fournir
des recommandations de contenu pertinent. D’après Chris Anderson dans
“The Long Tail”, les bouleversements qu’a subi le Web et la masse de don-
nées qui constituent Internet font que “nous quittons progressivement l’âge
de l’information pour rentrer dans l’âge de la recommandation” [Anderson,
2006].

La tâche d’un système de recommandation consiste à accomplir un ﬁl-
trage d’information aﬁn de suggérer à un utilisateur des articles à acheter
(ex. e-commerce) ou bien d’autres utilisateurs avec qui interagir/se connec-
ter (ex. réseaux sociaux) [Ricci et al., 2011]. Selon leur mode de fonc-
tionnement, les systèmes de recommandation peuvent être personnalisés

21

Chapitre 2. État de l’art

ou non-personnalisés. Les systèmes de recommandation non-personnalisés
fournissent aux utilisateurs des suggestions mais ne prennent pas en consi-
dération les préférences de ces utilisateurs. Une illustration d’un tel système
est par exemple la recommandation des articles les plus populaires sur une
boutique en ligne ce mois-ci ou bien la liste de chansons qui font le plus de
passages radio sur une période donnée (top-50).

Du fait de la richesse de la sémantique associée aux données sociales,
nous nous intéressons plus particulièrement aux systèmes de recommanda-
tion personnalisés. Ces systèmes fonctionnent en utilisant les caractéristiques
des utilisateurs, leurs préférences, proﬁls ou bien leur interactions passées
aﬁn de fournir des suggestions de contenu pertinent. Ces suggestions peuvent
aussi être vues d’un autre angle comme étant des prédictions sur les inter-
actions futures de ces mêmes utilisateurs. Trois grandes approches de sys-
tèmes de recommandation personnalisés existent : Les systèmes basés sur
le contenu, les systèmes basés sur le ﬁltrage collaboratif et les systèmes hy-
brides.

2.4.2 Les systèmes basés sur le contenu

Les systèmes de recommandation basés sur le contenu (content-based)
fonctionnent en analysant les caractéristiques des objets à recommander
(produits, etc.) puis en les regroupant. Par la suite, le système va suggérer
aux utilisateurs ayant acheté/consommé un produit quelconque par le passé,
les objets/produits estimés similaires [Ricci et al., 2011].
L’architecture générale d’un système de recommandation basé sur le contenu
s’articule autour de 3 modules principaux :

— l’analyseur de contenu – Selon la nature des données à recom-
mander (texte, éléments multimédia, pages Web, produits commer-
ciaux, etc.) une étape de pré-traitement est nécessaire aﬁn de décrire
les objets à recommander et d’en extraire les caractéristiques. Le mo-
dule d’analyse de contenu est responsable de produire une description
structurée de ces objets. Cette description va servir d’élément d’en-
trée aux autres modules.

— Le module d’apprentissage de profils – Ce module est respon-
sable de l’analyse des interactions passées de l’utilisateur sur les ob-
jets du système. En utilisant des méthodes empruntées au monde de
l’apprentissage, ce module construit une description des préférences

22

Chapitre 2. État de l’art

des utilisateurs.

— Le module de filtrage – A partir des proﬁls utilisateurs et des
descriptions des objets à recommander, ce module construit des listes
de suggestions à présenter aux utilisateurs.

[Diederich and Iofciu, 2006] présente un exemple de système de re-
commandation basé sur le contenu. Les proﬁls utilisateurs y sont déduits à
travers les étiquettes (tags) issues de l’activité d’annotation eﬀectuée par les
utilisateurs sur le système. Ce système se base par la suite sur ces proﬁls
pour générer des recommandations de collaborateurs potentiels.

2.4.3 Le ﬁltrage collaboratif

La deuxième grande famille de systèmes de recommandation est basée
sur l’hypothèse que les utilisateurs qui ont aimé des articles similaires par le
passé ont un goût similaire et vont donc apprécier les mêmes articles dans le
futur. Un des exemples les plus connus d’un tel système a été popularisé par
le site de commerce en ligne Amazon.com et son algorithme de Item-to-item
Collaborative Filtering qui se traduit sur le site par la fonctionnalité “Les
gens qui ont acheté le produit x ont aussi acheté le produit y” [Linden et al.,
2003].

L’avantage principal de cette approche est qu’elle ne nécessite pas de
description précise des objets à recommander. Les recommandations étant
basées sur l’ensemble des interactions des utilisateurs avec les objets/pro-
duits, cette méthode permet de recommander des objets complexes sans
avoir à les analyser. La plupart des services de recommandation de musique
en ligne fonctionnent sur ce mode (ex. last.fm 10) car les ﬁchiers multimédia
sont diﬃciles à analyser. Pour pouvoir fonctionner le système a besoin de
collecter des données sur les utilisateurs et leurs préférences, cette collecte
peut se faire de deux façons :

— Collecte Explicite – Dans ce cas, les utilisateurs sont sollicités
pour émettre leurs avis sur des produits/objets. Il peuvent le faire via
un système de notation (ex. une grille de 5 étoiles, un questionnaire
de satisfaction), ou bien en publiant leurs avis sur un élément donné

10. http://www.last.fm/

23

Chapitre 2. État de l’art

(ex. La fonction “J’aime” sur le réseau social Facebook permet aux
utilisateurs d’exprimer leur intérêt pour un élément donné).

— Collecte Implicite – La collecte implicite s’intéresse aux interac-
tions des utilisateurs sur le système. Les exemples de cette collecte
incluent la surveillance du nombre de visites sur une page, le nombre
de vues sur une vidéo, le temps passé sur une section donné ou de
l’historique des achats sur une plateforme de e-commerce.

[Das et al., 2007] décrit la plateforme de recommandation utilisé par
Google News. L’approche basée sur le ﬁltrage collaboratif a permis au sys-
tème d’être indépendant vis-à-vis du contenu des publications suggérées et
à la technique d’être adaptée à d’autres applications ou de gérer d’autre
langues à moindre coût.

2.4.4 Les systèmes hybrides

Chacune des approches de recommandation présentées présente des avan-
tages ainsi que des inconvénients. Par exemple, les systèmes basés sur le
contenu ont besoin d’un riche historique d’interactions pour pouvoir fonc-
tionner ; le système ne pourra pas fournir recommandations de qualité pour
un utilisateur fraichement inscrit. D’un autre côté, les systèmes du type ﬁl-
trage collaboratif ont besoin de l’existence d’une large base d’interactions
sur l’ensemble du catalogue d’objets/produits du système aﬁn de pouvoir
calculer des rapprochements entre les utilisateurs.

Une solution consiste à proposer des systèmes hybrides, qui tirent parti
des avantages des deux approches citées précédemment. Cette solution per-
met de combler les lacunes de l’une des approches sur des cas d’utilisation
précis. Ces approches hybrides peuvent être implémentées de diverses fa-
çons [Adomavicius and Tuzhilin, 2005] :

— En combinant les résultats produits par chacune des deux approches

exécutées indépendamment ;

— En sélectionnant un aspect précis d’une des approches et en l’inté-

grant à l’autre (compléter les approches) ;

— En uniﬁant les deux approches dans un modèle global.

24

Chapitre 2. État de l’art

Un grand nombre de systèmes de recommandation actuellement en ex-
ploitation fonctionne sur un modèle hybride. Parmi les systèmes hybrides
les plus connus, le système de recommandation mis en place par le géant
Américain de la vidéo à la demande sur Internet Netﬂix [Amatriain, 2013].
Après avoir proposé un prix d’un million de Dollars en 2006 aux travaux
obtenant les meilleures recommandations sur les données issues de la pla-
teforme, l’entreprise a intégré les propositions les plus pertinentes dans sa
version du système de recommandation mis en production. Il est reporté que
plus des deux tiers du total des vidéos consommées sur cette plateforme sont
issues des seules recommandations présentées aux utilisateurs ce qui reﬂète
l’importance de la capacité à fournir des recommandation de qualité.

2.4.5 Recommandations sociales

Les données issues des réseaux sociaux représentent une véritable mine
d’information pour un éventuel système de recommandation. Fonctionnant
sur l’adage “Dis moi qui tu fréquentes, je te dirai qui tu es”, nous pou-
vons identiﬁer un nouveau type de systèmes de recommandation basé sur la
présence d’une communauté d’utilisateurs liés par des liens sociaux [Ricci
et al., 2011]. Sur les plateformes sociales, ces systèmes de recommandation
permettent de recommander tout un ensemble d’informations. Les exemples
incluent des utilisateurs à suivre, des publications précises, des éléments
multimédia, des groupes (sous-communautés) à intégrer etc.

La principale caractéristique des réseaux sociaux étant l’existence d’un
graphe de relations sociales, cette donnée est l’information principale au
centre des diverses stratégies de recommandation. [Liben-Nowell and Klein-
berg, 2003] présente une étude qui compare diverses méthodes de prédiction
de liens. La prédiction de liens consiste à analyser l’état du réseau à un
instant t aﬁn d’anticiper la création de nouveaux liens à un moment t + 1.
Ces techniques sont souvent utilisées dans le contexte de la recommanda-
tion. Les méthodes présentées par Liben-Nowell & Kleinberg se basent sur
les propriétés topologiques des réseaux pour le calcul des prédictions.

Parmi les mesures présentés, la mesure de Katz présente des résultats
pertinents une fois exploitée sur des graphes issus du Web. Cette mesure,
issue du monde de la sociologie [Katz, 1953b], se base sur la connectivité
entre deux nœuds du graphe social. Plus le nombre de chemins entre deux
nœuds est élevé et plus la longueur des ces chemins est courte, plus le score
de Katz entre ces deux nœuds sera élevé. Concrètement, le score de Katz

25

Chapitre 2. État de l’art

entre un nœud u et un nœud v s’exprime comme suit :

katzβ(u, v) =

βl × |P hli

∞X

l=1

u,v| = X

p∈Pu,v

β|p|

Où β représente un facteur de décroissance (β ∈ [0, 1]), Pu,v représente
hli
u,v ⊆ Pu,v l’ensemble
l’ensemble de tous les chemins existant entre u et v et P
de tous les chemins de longueur égale à l existant entre u et v. Le facteur
β est utilisé pour donner plus d’importance aux chemins courts (c.à.d aux
nœuds proches dans le graphe) exploitant ainsi le phénomène de localité et
d’homophilie.

Une autre mesure topologique est présentée dans [Budalakoti and Bek-
kerman, 2012], les auteurs proposent de combiner deux scores de classement
de comptes basés sur deux sources diﬀérentes issues du même réseau (les
invitations sur le réseau social, ainsi que le graphe social proprement dit).
Ces données sont ensuite utilisées pour produire la liste triée des comptes
les plus inﬂuents sur le réseau.

Certains travaux appliquent des méthodes de ﬁltrage collaboratif ainsi
que des méthodes basés sur le contenu dans un contexte social. [Chen et al.,
2012] introduit une méthode pour classer des Tweets qui exploite les proﬁls
de préférences utilisateur, une mesure d’autorité du compte publiant le tweet
ainsi que la qualité de la publication. [Hannon et al., 2010] passe en revue
une série de méthodes d’extraction de proﬁls utilisateur sur le réseau Twit-
ter. Il y est testé des méthodes basées sur le contenu publié par l’utilisateur,
celui des comptes qu’il suit ainsi que celui de ses suiveurs. Un classement
basé sur le score de TF-IDF est ensuite employé pour trouver les utilisateurs
similaires. Une méthode similaire de recommandation est adoptée par [Pen-
nacchiotti et al., 2012].

Dans [Diaz-Aviles et al., 2012] les auteurs décrivent une approche qui
garde trace des interactions passées par les utilisateurs pour le calcul en
temps-réel des recommandations. Les techniques présentées par [Pennac-
chiotti et al., 2012, Diaz-Aviles et al., 2012] et [Chen et al., 2012] four-
nissent des recommandations au niveau de granularité du tweet. Le passage à
l’échelle est alors problématique étant donné le nombre important de tweets,
l’aspect temps-réel de la plateforme et les fréquences élevées de publication.

Les approches citées précédemment ne prennent pas en considération

26

Chapitre 2. État de l’art

la topologie du graphe dans le calcul des recommandations. [Weng et al.,
2010] présente une adaptation de l’algorithme PageRank au monde du micro-
blogging appelée TwitterRank. Cette approche prend en compte la structure
des liens du graphe ainsi que l’autorité des utilisateurs sur des sujets (topics)
donnés. Les topics utilisés par TwitterRank sont obtenus par l’application
de la méthode LDA (Allocation de Dirichlet Latente) qui est une technique
probabiliste permettant la caractérisation du contenu des utilisateurs. [Liang
et al., 2012] propose une méthode basée sur le contenu aﬁn de fournir des
recommandations de sujets (topics) en exploitant les liens implicites issus
des conventions adoptées sur les plateformes de micro-blogging (voir ta-
bleau 2.3). [Kywe et al., 2012] propose une technique de recommandation
de hashtags personnalisée. Certains hashtags ayant un cycle de vie extrême-
ment court, les auteurs proposent de combiner le contenu des tweets avec
une approche de ﬁltrage collaboratif sur une fenêtre temporelle d’un mois
aﬁn de recommander des hashtags pertinents aux utilisateurs.

Une approche présentée par [Chaoji et al., 2012] vise à maximiser la
découverte de nouveau contenu lors de la tâche de recommandation. Ce pro-
blème s’apparente à un problème d’optimisation multi-objectif NP-diﬃcile.
Les auteurs proposent une approximation qui atteint un degré de propaga-
tion de contenu important. Cependant l’application de cette méthode sur de
grands graphes demeure problématique.

Dans [Gupta et al., 2013], les auteurs présentent le système de recom-
mandation mis en production par Twitter pour sa fonction “Qui suivre ?”
(Who to follow ?). Il se base sur le déploiement de l’algorithme SALSA [Lem-
pel and Moran, 2001] dans un environnement centralisé. SALSA fonctionne
en créant un graphe biparti avec d’un côté le cercle de conﬁance d’un uti-
lisateur (pouvant être calculé par exemple comme l’ensemble les comptes
avec qui l’utilisateur interagit le plus ou bien à partir d’un algorithme de
marche aléatoire) et de l’autre coté les comptes les plus suivis par ce cercle
de conﬁance, considéré comme des autorités. Cette approche ne prend pas en
considération le sujet (topic) sur lequel les comptes recommandés peuvent
être une autorité.

2.5 Mesures sur les graphes sociaux

27

Chapitre 2. État de l’art

Les calculs de mesures sur les réseaux sociaux peuvent vite devenir pro-
blématiques. En eﬀet, la taille des graphes disponibles sur le Web couplée à la
complexité des algorithmes de calcul sur les graphes rendent n’importe quelle
tâche de mesure diﬃcile. Dans cette section nous présentons des techniques
d’approximation utilisées pour mesurer de manière approchée les longueurs
de plus courts chemins sur les graphes issus du Web. Nous nous sommes
inspiré de ces techniques pour proposer la stratégie de recommandation pré-
sentée en chapitre 5.

Pour accélérer les calculs de recommandation, nous pré-calculons les
scores de recommandation pour un ensemble de nœuds élus appelés land-
marks. Le calcul basé sur les landmarks est une technique connue qui fonc-
tionne sur le paradigme de “Diviser pour mieux régner”. Cette technique est
utilisée traditionnellement pour l’estimation du calcul de la longueur du plus
court chemin entre deux nœuds sur un graphe. L’idée consiste à sélectionner
un sous-ensemble de nœuds L pour lequel le système stocke et maintient les
distances vers d’autres nœuds. La distance d(u, v) entre deux nœuds u et
v est par la suite estimée en calculant le minimum de d(u, l) + d(l, v), où
l représente un landmark (l ∈ L) [Thorup and Zwick, 2001]. Le choix des
landmarks étant crucial pour une estimation précise, diverses stratégies de
sélection peuvent être employées (voir chapitre 5)

[Sarma et al., 2010] a choisi de pré-calculer les opérations liées au calcul
de la longueur du plus court chemin dans des structures appelées “Sketches”.
Ces structures sont sollicitées au moment de la requête pour fournir une es-
timation de la longueur de plus court chemin. Cette technique permet le
passage à l’échelle sur des graphes de tailles similaires aux graphes issus du
Web social. [Gubichev et al., 2010] propose une extension de l’algorithme
basé sur la structure de Sketch proposé par [Sarma et al., 2010] aﬁn de
répondre aux requêtes de calcul de la longueur du plus court chemin en per-
mettant aussi la récupération du chemin en question ce qui est utilisé aﬁn
améliorer la précision générale du système.

[Tretyakov et al., 2011] propose d’utiliser une structure arborescente
pour le stockage des données liées à l’estimation des plus courts chemins.
L’avantage de l’utilisation de cette structure réside dans le fait qu’elle sup-
porte aisément les mises à jours liées à l’évolution de la topologie du graphe.
Les auteurs introduisent aussi une stratégie de sélection de landmarks. Cette
stratégie a pour but de maximiser la zone de couverture dans laquelle le sys-
tème peut estimer les plus courts chemins dans le graphe.

28

Chapitre 2. État de l’art

[Potamias et al., 2009] contient une étude sur l’impact des stratégies de
sélection de landmarks sur la précision des estimations de longueurs de plus
courts chemins. Les auteurs ont prouvé que le problème de l’optimisation
de la zone de couverture des landmarks dans un graphe est un problème
NP-diﬃcile et ils ont démontré expérimentalement qu’un choix réﬂéchi des
stratégies de sélection de landmarks permettait d’améliorer sensiblement la
précision du système et ainsi d’obtenir de meilleurs résultats.

2.6 Conclusion

Dans ce chapitre, nous avons présenté l’état de l’art des travaux qui s’in-
téressent aux données générées par les utilisateurs des médias sociaux. Nous
avons passé en revue :

— Des études qui se sont intéressés à la caractérisation du phénomène

— Des travaux proposés aﬁn d’améliorer la lisibilité des ﬂux à travers

du Web social

des solutions de ﬁltrage

— Des systèmes de recommandations qui permettent de présenter du

contenu pertinent aux utilisateurs

— Les approches d’approximation par landmarks aﬁn d’eﬀectuer des

mesures de plus courts chemins sur de grand graphes

Ce travail nous permet de situer notre contribution qui vise à améliorer
l’expérience des utilisateurs sur les plateformes de micro-blogging à travers
l’introduction de fonctions eﬃcaces pour ﬁltrage et la recommandation.

29

Chapitre 2. État de l’art

30

Chapitre 3
Données issues des réseaux
sociaux

“Walked out this morning
Don’t believe what I saw
A hundred billion bottles
Washed up on the shore”

— The Police, Message in a bottle, 1979

3.1 Introduction

L’avènement des médias sociaux a marqué l’explosion du volume de don-
nées générés par les utilisateurs (UGC, User Generated Content) disponibles
sur le Web. Dans le chapitre précédent nous avons mis en avant l’eﬀort de
recherche qui a été eﬀectué sur ce type de données et notamment sur les
données issues des plateformes du type micro-blogging. Nous avons observé
qu’un nombre important d’études portent sur le mircro-blogging, ceci est
dû principalement à la nature publique des informations publiées sur ces
plateformes.

Dans ce chapitre, nous présentons le modèle de données que nous avons
proposé aﬁn modéliser les plateformes du type micro-blogging. Nous ex-
posons ensuite les diﬀérentes étapes qui nous ont menés à la constitution
d’un jeu de données réaliste sur lequel nous avons pu tester nos propositions

31

Chapitre 3. Données issues des réseaux sociaux

dans un contexte de ﬁltrage et de recommandation d’information. Finale-
ment, nous présenterons les caractéristiques des jeux de données obtenus en
contraste avec les caractéristiques des données réelles issues de ces plate-
formes que nous avons présenté en chapitre 2.

3.2 Le Micro-Blogging

Dans un système de micro-blogging, un utilisateur, via son compte,
s’abonne aux mises à jour d’autres comptes sur la plateforme. On dit alors
qu’un compte “suit” un autre compte. Chaque publication (désignée par
tweet dans ce qui suit) émise par un compte donné est transmise à tous les
comptes des utilisateurs qui suivent le compte émetteur. Un large graphe
social de relations de suivi existe donc entre les diﬀérents comptes sur le
système.

Aﬁn de concevoir des structures capables de gérer les logiques de ﬁltrage
et de recommandation proposées, nous avons dû prêter une attention parti-
culière à certaines caractéristiques des réseaux sociaux et des plateformes du
type micro-blogging en particulier. Ces caractéristiques, décrites en chapitre
d’introduction, se résument en :

— Publications courtes

La restriction de la taille des publications (140 caractères) nous pousse
à réﬂéchir à un traitement eﬃcace des documents indexés (ex. la taille
moyenne d’un tweet sur Twitter est de 14.7 termes [Foster et al.,
2011]). Cette restriction est due historiquement au fait que ces sys-
tèmes ont été pensés pour oﬀrir un accès via les réseaux GSM via le
protocole SMS.

— Hétérogénéité des comptes en taille

Les diﬀérentes études conduites sur le phénomène du micro-blogging
ont révélé une forte hétérogénéité en ce qui concerne la fréquence de
publication ainsi que le nombre de followers des comptes.

— La dynamicité du graphe

Comme observé dans Twitter [Kivran-Swaine et al., 2011,Kwak et al.,
2011], les utilisateurs s’abonnent et se désabonnent très souvent des
comptes suivis. Nos propositions doivent êtres capables de suivre et
de gérer eﬃcacement cette évolution.

32

Chapitre 3. Données issues des réseaux sociaux

— Un Système centralisé

Dans leur grande majorité, les systèmes de micro-blogging existants
reposent sur une architecture purement centralisée. Chaque nouvelle
publication est d’abord transmise aux serveurs centraux du système
qui, détenant le graph social, s’occupent de la faire suivre aux diﬀé-
rents followers du compte émetteur. Ceci est dû essentiellement à des
raisons de sécurité, de contrôle de conﬁdentialité et autres politiques
de placements publicitaires.

— Conventions/Notations

En raison de la simplicité du modèle, les utilisateurs des plateformes
de micro-blogging ont adopté divers conventions et notations aﬁn
d’enrichir les fonctions proposées par ces plateformes (voir section
2.2.1).

— Les listes Twitter

Une fonctionnalité appelée “listes” dans Twitter permet de regrou-
per certains utilisateurs dans un ensemble cohérent pour ainsi accé-
der à un ﬂux réduit contenant uniquement les publications des uti-
lisateurs groupés. Les utilisateurs peuvent créer leurs propres listes
ou bien s’abonner à des listes déjà existantes. Cette fonction simple
fournit un mécanisme basique de curation de contenu par une ap-
proche de regroupement (clustering) de comptes. Certains travaux
s’intéressent aux listes pour divers scénarii allant de l’identiﬁcation
de topics à la recommandation [Yamaguchi et al., 2012,Velichety and
Ram, 2013,Garcia-Silva et al., 2012]. En eﬀet, les utilisateurs souvent
groupés ensemble sont souvent associés à une thématique commune.
En revanche, cette fonctionnalité ne fait que diviser le ﬂux de données
reçues par un compte en “sous-ﬂux” indépendants.

En considérant les particularités des données issues du monde du micro-
blogging, nous présentons dans la section suivante le modèle de données
proposé pour représenter un tel système.

33

Chapitre 3. Données issues des réseaux sociaux

3.3 Modèle de données

Aﬁn de modéliser un réseau social de type micro-blogging fournissant les
fonctions de ﬁltrage et de recommandation, nous commençons par présenter
un exemple de graphe social où les utilisateurs ont des intérêts précis.

3.3.1 Exemple de graphe social

Nous supposons un graphe orienté G qui nous servira à illustrer notre
modèle de données. Michel, un utilisateur du système, décide de suivre deux
comptes très actifs sur le réseau qui sont ceux de CNN et L’AFP (Agence
France Presse). Ces deux comptes sont spécialisés dans l’actualité et publient
une quantité importante de publications par jour à propos de divers sujets.
AFP étant connu pour produire des tweets de qualité en ce qui concerne
les ﬂashs d’information, CNN suit alors AFP et reçoit tous ses tweets. D’un
autre côté AFP ne couvre pas les sujets IT et Cinéma et se base sur les
publications de CNN pour ces deux domaines. Remarquant une certaine
redondance et pour éviter d’être submergé de tweets Michel voudrait donc
recevoir les publications qui concernent l’IT et le cinéma seulement de la
part de CNN et ceux concernant la politique de la part de AFP.
Cédric de son côté décide de suivre AFP uniquement pour les publication
qui traitent de sport. Enﬁn, Ryadh suit Cédric pour les tweets qui concernent
l’IT (voir ﬁgure 3.1).

Nous nous baserons sur cet exemple pour illustrer notre modèle de don-

nées ainsi que nos propositions de ﬁltrage en chapitre 4.

3.3.2 Le système de micro-blogging

Un système de micro-blogging à l’instar de Twitter peut être représenté
sous forme de graphe G=(N, E) où l’ensemble de nœuds N représente les uti-
lisateurs (comptes) du système et l’ensemble des arcs E ⊆ N × N représente
les liens de suivi (following). Plus précisément un arc orienté e=(u, v) existe
entre un nœud u et un nœud v si l’utilisateur représenté par u est notiﬁé à
chaque fois que l’utilisateur v publie un tweet (u reçoit les mises à jour de v).

Pour un nœud n, on déﬁnit Γ+(n) l’ensemble des nœuds suivis par n

comme

Γ+ : N → 2N , Γ+(n) = {n0|(n, n0) ∈ E}

34

Chapitre 3. Données issues des réseaux sociaux

De manière similaire on déﬁnit Γ−(n) l’ensemble de nœuds qui suivent n.

Chaque nœud produit des publications ou tweets. Une publication est
déﬁnie comme une séquence de termes p =< t0, t1, t2, . . . , ti >. On note P
l’ensemble des publication et VP le vocabulaire de ces publications. A no-
ter que nous ne basons pas sur l’ordre des termes pour la correspondance
(matching) : Par conséquent nous considérons plutôt l’ensemble des termes
d’une publication p = {t0, t1, t2, . . . , ti} plutôt que la séquence. La séquence
de tweets d’un nœud n, notée ns désigne la séquence de tweets triée chrono-
logiquement ns =< p0, p1, p2, . . . , pi > publiés par n.

3.3.3 Les ﬁltres

Nous proposons un ﬁltrage basé sur des mots-clefs. Un ﬁltre F dans
notre système est représenté comme un ensemble de termes distincts F =
{t1, t2, ..., tn} où chaque terme ti appartient au vocabulaire de termes noté
VF . La taille de F, notée |F|, est le nombre total de termes distincts contenu
dans le ﬁltre. Comme dans [Yan and Garcia-Molina, 1994], nous supposons
que VF ⊆ VP . F représente l’ensemble de ﬁltres, sans contenir le ﬁltre ⊥ qui
satisfait toutes les publications, c.à.d., ⊥= VP . Une fonction label associe
un ﬁltre à chaque arc du graphe social G :

label : E → F ∪ ⊥

Nous appelons le graphe social dont les arcs sont associés à des ﬁltres
le labelled social graph (LSG). A noter que l’utilisateur peut donc expri-
mer diﬀérents intérêts à travers les ﬁltres et ce pour une source précise.
Dans l’exemple cité en 3.3.1, l’utilisateur M ichel veut récupérer tout les
tweets de CNN qui traitent de IT, politique et cinéma , et depuis AFP
seulement les tweets de politique. on obtient donc : label(M ichel, CN N) =
{IT, politics, movies} et label(M ichel, AF P) = {politics}.

La ﬁgure 3.1 présente le LSG pour l’exemple présenté.

3.3.4 La notiﬁcation

Nous supposons une logique disjonctive pour la notiﬁcation des utilisa-
teurs : L’utilisateur est notiﬁé lorsqu’il suit un compte qui publie un tweet
qui correspond à au moins un des termes de son ﬁltre. Une extension per-
mettant de gérer la conjonction ainsi que la négation est abordée dans les
pistes de recherche future. Formellement, nous déﬁnissions une notiﬁcation

35

Chapitre 3. Données issues des réseaux sociaux

Figure 3.1 – Un graphe social étiqueté (LSG)

comme suit :

L’ensemble des nœuds N à être notiﬁés pour une nouvelle publication p

à un nœud n est :

N (n, p) = {n0 ∈ N|(n0, n) ∈ E,∃t ∈ p, t ∈ label(n0, n)}

Aﬁn d’expérimenter nos approches de ﬁltrage et de recommandation,
nous avons du procéder à une étape d’acquisition en vue d’obtenir des jeux
de données conformes au modèle proposé. Cette étape est décrite dans les
sections qui suivent.

3.4 L’acquisition de données

Une des conclusions issue de notre analyse de l’état de l’art fût que,
mis à part pour quelques rares travaux dont les équipes étaient en colla-
boration directe avec les fournisseurs de service, la collecte de données sur
les plateformes sociales demeure problématique. En eﬀet plusieurs facteurs
rendent la constitution de jeux de données représentatifs complexe, voire
dans certains cas impossible.

3.4.1 Le crawling, approche et limitations

La première approche que nous avons adopté dans notre tentative d’ac-
quisition de données consistait à parcourir le graphe social de Twitter via

36

Chapitre 3. Données issues des réseaux sociaux

un programme spéciﬁquement conçu (crawler) aﬁn de récolter la structure
de graphe ainsi que les données associées aux utilisateurs. Twitter fournit en
eﬀet une interface publique de programmation (API) pour les applications
désirant exploiter l’écosystème du réseau social. Généralement ces applica-
tions sont des clients qui permettent de porter le service Twitter sur plusieurs
plateformes notamment sur les environnement mobiles.

L’API Twitter permet d’interroger le service et d’obtenir les description
d’utilisateurs, les tweets ainsi qu’un ensemble de méta-données associés aux
divers éléments récupérés. Le code aﬃché en 3.1 illustre l’anatomie simpli-
ﬁée d’un objet tweet avec les principales méta-données associés. L’objet tweet
complet tel que fourni par l’API contient lui plus de 28 méta-données (sans
prendre en compte les données associées au compte propriétaire du tweet).

1 {
2
3
4

5
6
7
8
9
10

11
12
13
14
15
16
17
18
19
20 }

" coordinates ": null ,
" created_at ": "Wed Jun 06 20:07:10 +0000 2012",
" text ": " Along with our new # Twitterbird , we ’ve also updated our

Display Guidelines : https ://t.co/ EdomjYs ",

" retweet_count ": 66,
"id": 210462857140252672,
" entities ": {

" urls ": [

{

" expanded_url ": " https :// dev. twitter .com/ terms / display -

guidelines ",

"url": " https ://t.co/ EdomjYs ",

],
" hashtags ": [

}

{

}

]

}

" text ": " Twitterbird ",

Code 3.1 – Vue simpliﬁée d’un objet tweet au format JSON

Avec l’évolution du service, l’approche commerciale de Twitter a changé
et l’entreprise a commencé à cannibaliser le marché des clients pour disposi-
tifs mobiles en rachetant les principaux acteurs du marché. Par exemple, le
client Twitter sous iOS “Tweetie” a été racheté par le réseau social et a ﬁni
par devenir le client oﬃciel de la plateforme sur Iphone 1 ou bien le logiciel
populaire “Tweetdeck” qui fournit une vue en colonnes des ﬂux sociaux a

1. https://blog.twitter.com/2010/twitter-iphone-0

37

Chapitre 3. Données issues des réseaux sociaux

vu son oﬀre être incorporée à Twitter et devenir une des fonctionnalités du
réseau social 2.

Dès lors, la stratégie de Twitter a évolué. Les données étant le bien le
plus précieux pour la plateforme sociale, Twitter a mis en place une poli-
tique de limitation pour les requêtes possibles sur son API. Ces limitations
ont très vite rendu impossible la constitution de jeux de données signiﬁcatifs
à partir de l’exploitation de l’API. Nous nous sommes heurtés à ces limita-
tions ce qui nous a poussé à arrêter le crawling direct de la plateforme et a
envisager d’autres approches.

De plus, le fait de mettre en place une stratégie de crawling en suivant
les liens entre les utilisateurs récoltés dans un réseau aussi vaste que Twitter
introduit un biais dans les données collectées et ne permet donc pas la géné-
ration d’un jeu de données représentatif. La ﬁgure 3.2 illustre un exemple de
jeu de données récolté par notre crawler. Sur cette illustration nous pouvons
observer un phénomène de “constellations” autour des comptes récoltés avec
des sauts entre ces constellations qui correspondent aux liens suivis par la
stratégie de crawling.

3.4.2 Constitution du jeu de données

Après maintes métamorphoses de son API publique, Twitter a publié une
API nommée “Streaming API” 3. Cette API est en réalité un ﬂux constant
de tweets représentant approximativement 1% du ﬂux global circulant sur
la plateforme.
En collaboration avec Forth Institute (Heraklion, Crete) 4, nous avons pu
obtenir des données Twitter sur une période de plus de quatre mois en uti-
lisant cette API ce qui nous a permis de constituer une collection de plus de
170 millions de tweets.

En parallèle, nous avons pu obtenir le graphe social représentatif de l’en-
semble du réseau de Twitter utilisé dans [Kwak et al., 2010]. Dès lors, nous
avons pu générer un jeu de données complet (graphe + tweets) et ce en
fusionnant les tweets obtenus par l’API de streaming avec la structure de
graphe social ce qui correspond à “peupler” le graphe avec les tweets des

2. https://blog.twitter.com/2011/oﬃcial-tweetdeck-has-been-acquired-twitter
3. https://dev.twitter.com/streaming/overview
4. Nous remercions Vassilis Christophides pour son aide et son implication

38

Chapitre 3. Données issues des réseaux sociaux

Figure 3.2 – Visualisation d’un extrait du graphe social obtenu par craw-
ling

utilisateurs. Le résultat obtenu fut un large jeu de données contenant 2.9
millions d’utilisateurs, 169 millions d’arcs de graphe (relations de suivi) et
plus de 33.9 millions de tweets.

Enﬁn, nous avons procédé à une analyse linguistique des publications
pour n’en retenir que celles qui étaient rédigées en Anglais ainsi que les
comptes associés. Les chiﬀres du jeu de données obtenu sont résumés dans
le tableau 3.1.

Élément

Utilisateurs

Tweets

Arcs de graphe

Valeur
2.170.784
15.717.449
148.508.857

Table 3.1 – Description du jeu de données

Ce jeu de données nous a servi de base pour l’élaboration de jeux de test

39

Chapitre 3. Données issues des réseaux sociaux

plus spéciﬁques aﬁn de tester nos approches de ﬁltrage et de recommanda-
tion.

3.5 Jeu de données pour le Filtrage

Le but de notre système de ﬁltrage est de notiﬁer eﬃcacement les utili-
sateurs de l’arrivée d’une publication contenant les ﬁltres spéciﬁés. Aﬁn de
générer une structure de LSG pour tester notre système de ﬁltrage, nous
avons dû simuler des requêtes de ﬁltrage. Pour ce faire, nous avons fait l’hy-
pothèse que la taille moyenne des ﬁltres (nombre de termes distincts d’une
étiquette sur un arc du LSG) correspond au nombre moyen de termes utili-
sés sur les recherches dans Twitter [Teevan et al., 2011] (voir 4.2).

Après avoir éliminé les URLs et autres termes du langage courant (stop-
words) des tweets, nous avons décidé de générer les ﬁltres parmi les termes
les plus fréquents et signiﬁcatifs dans les publications du publisher dans un
arc. Le tableau 3.2 illustre un échantillon du labelled social graph généré
dans un contexte de ﬁltrage.

Publisher Follower
36255965
36256156
36256607

12
12
12

Filtre

conference deadline download

DB conference
software twitter

Table 3.2 – Exemple de données du LSG pour le ﬁltrage

Le graphe social étiqueté obtenu nous a permis de tester le comporte-
ment de nos structures de ﬁltrage dans des scénarios de passage à l’échelle.
Ces expérimentations sont décrites en détail au chapitre 4. Cependant, dans
une logique de recommandation, la génération du jeu de données nécessaire
à la validation est plus complexe. Ceci est due à l’étape nécessaire de vali-
dation de la qualité des recommandations générées.

40

Chapitre 3. Données issues des réseaux sociaux

3.6 Jeu de données pour la recommandation

Basé sur la structure de graphe social généré précédemment, nous avons
dû élaborer un jeu de données spéciﬁque aﬁn de tester notre système de
recommandation. La qualité des recommandations générées étant basée en
partie sur la sémantique des liens de suivi (following), le déﬁ consiste à éti-
queter correctement les arcs du graphe social en fonction des intérêts des
utilisateurs.

A partir du graphe social, nous avons d’abord extrait un sous-graphe
représentatif de 400.000 nœuds en adoptant l’approche décrite par [Sethu
and Chu, 2012]. Le tableau 3.3 décrit les principales propriétés topologiques
du sous-graphe obtenu.

Propriété

Nombre total de nœuds

Nombre total d’arcs

Plus court chemin moyen

Degré sortant moyen
Degré entrant moyen

LCC moyen

Diamètre du graphe

Degré entrant maximum
Degré sortant maximum

Valeur
399,999
2,848,915
3.74
9.12
7.12
0.144
17
103,153
65,874

Table 3.3 – Propretés topologique du graphe Twitter400k

La valeur relativement élevée du local clustering coeﬃcient (LCC) cou-
plée à une valeur de plus court chemin moyen de 3,74 conﬁrme le fait que
notre sous-graphe présente les caractéristiques d’un réseau du type petit
monde (small world, voir 2.2.1) avec des valeurs de propriétés topologiques
similaires à celles observées pour le graphe réel de Twitter [Myers et al.,
2014].

La ﬁgure 3.3 aﬃche les distributions de degré sortant/entrant pour tout
les nœuds du sous-graphe obtenu. Nous pouvons observer un phénomène de
longue traîne qui indique une distribution du type “loi de puissance” (power
law) caractéristique des réseaux sociaux. Un tout petit nombre des comptes

41

Chapitre 3. Données issues des réseaux sociaux

Figure 3.3 – Twitter400k Degré entrant/sortant

dispose d’un très grand nombre de followers (resp. suit un grand nombre
de comptes) pendant que la plupart des comptes font partie de la classe des
petits followers (resp. suivent peu de comptes). La ﬁgure 3.4 présente une
visualisation d’un sous graphe social de 10.000 nœuds réalisé en adoptant la
même approche (la taille des nœuds sur l’image est proportionnelle à leur
nombre de followers).

Aﬁn de procéder à l’étiquetage du graphe social obtenu, nous avons uti-
lisé OpenCalais 5 pour caractériser les publications (tweets) de chacun des
nœuds du jeu de données. OpenCalais est un service en ligne (API) fourni par
Thomson Reuters qui permet d’extraire automatiquement des informations
sémantiques sur des documents textuels. Le résultat de cette étape fût l’éti-
quetage des comptes avec un topic basé sur les tweets publiés. L’étiquetage

5. http://www.opencalais.com/

42

Chapitre 3. Données issues des réseaux sociaux

Figure 3.4 – Visualisation d’un graphe social de 10.000 nœuds

s’est fait en utilisant une liste de 18 topics standards utilisés habituellement
pour classer des articles/documents 6. Cette approche a permis de catégori-
ser les deux tiers des comptes sur notre graphe social.

Aﬁn de compléter cette étape, nous avons utilisé une classiﬁcateur basé
sur la méthode de classiﬁcation probabiliste naïve bayésienne. Nous nous
sommes basés sur un pack logiciel appelé WEKA 7 pour l’étape d’appren-
tissage et de classiﬁcation. La précision du classiﬁcateur obtenu a été de
0,83. Le résultat de cette étape fut une liste contenant tout les comptes de
notre graphe social avec leur proﬁl de publieur (topics caractérisants ses pu-
blications). Le proﬁl de follower quant à lui (proﬁl d’intérêt de chacun des

6. http://www.opencalais.com/documentation/calais-web-service-api/api-metadata-

/document-categorization

7. http://www.cs.waikato.ac.nz/ml/weka/

43

Chapitre 3. Données issues des réseaux sociaux

utilisateurs) a été déterminé en calculant le TF (fréquence de termes) sur
les proﬁls publieurs des comptes suivis par un compte donné.

Enﬁn, nous avons sélectionné le topic à choisir comme étiquette pour
chaque arc comme étant le topic dans l’intersection d’un proﬁl follower avec
le proﬁl publieur correspondant ayant le plus grand score dans le proﬁl fol-
lower. Le résultat est un graphe social étiqueté sur chaque arc. Nous notons
ce jeu de données “Twitter400k”.

Notre génération d’étiquettes sur les arcs a engendré la distribution de
topics décrite dans la ﬁgure 3.5 pour les 18 topics. Cette distribution biai-
sée demeure similaire à certaines distributions de termes observées dans un
contexte Web comme par exemple sur Yahoo ! Directory [Liu et al., 2005].

Figure 3.5 – Distribution des arcs par topic

Ce jeu de données étiqueté prend en compte les intérêts des utilisateurs
du graphe social ainsi que leur proﬁl publieur et nous permet ainsi de vali-
der l’aspect qualitatif du système de recommandation proposé et décrit en
chapitre 5.

44

Chapitre 3. Données issues des réseaux sociaux

3.7 Conclusion

Dans ce chapitre nous avons présenté le modèle de données que nous pro-
posons pour représenter un système du type micro-blogging. Ce modèle de
graphe étiqueté (LSG) permet de capturer l’intérêt des utilisateurs pour les
comptes qu’ils suivent. Par la suite, nous avons décrit les diﬀérentes étapes
qui nous ont menés à la constitution de jeux de données représentatifs. Nous
avons illustré les diﬃcultés liées à la récolte de données ainsi que la diﬀérence
quand à la constitution d’un jeu de données dans un contexte de ﬁltrage et
un contexte de recommandation.

Le chapitre suivant décrit en détail l’approche que nous avons propo-
sée aﬁn de fournir un ﬁltrage eﬃcace des ﬂux sociaux et ainsi améliorer
l’expérience des utilisateurs des plateformes de micro-blogging.

45

Chapitre 3. Données issues des réseaux sociaux

46

Chapitre 4
Filtrage et indexation

4.1 Introduction

Dans le but d’améliorer l’expérience utilisateur ainsi que de réduire le
nombre de publications en circulation sur le réseau, nous avons décidé d’in-
troduire la notion de ﬁltrage dans les systèmes de type micro-blogging. Dans
le sondage réalisé par [Bontcheva et al., 2013], 55,6% des utilisateurs inter-
rogés on senti le besoin d’un outil qui leur permettrait de ﬁltrer leur ﬂux
social et d’en écarter les publications non pertinentes. L’idée principale der-
rière notre approche est de pouvoir suivre un certain compte du système
tout en réduisant le nombre de tweets reçus par l’application d’une requête
de ﬁltrage. Nous avons appelé notre système de ﬁltrage MicroFilter.

Dans ce chapitre, nous introduisons d’abord la motivation ainsi les diﬀé-
rentes structures proposées pour eﬀectuer un ﬁltrage eﬃcace en se basant sur
le modèle de données présenté en Chapitre 3. Pour chacune de ces structures,
est présentée ensuite une analyse qui permet d’établir un modèle analytique
de coût en temps et en mémoire pour les diﬀérentes propositions. Par la
suite nous présentons le comportement de nos structures observé expéri-
mentalement et qui nous a permis de proposer une structure hybride qui
oﬀre un compromis intéressant. Ce chapitre se referme par une conclusion
qui résume les diﬀérentes contributions de notre approche de ﬁltrage ainsi
que certaines pistes d’améliorations possibles.

47

Chapitre 4. Filtrage et indexation

4.2 L’indexation des ﬁltres

Actuellement, les schémas d’indexation utilisés dans les systèmes de
micro-blogging comme Twitter permettent de récupérer eﬃcacement pour
un utilisateur n l’ensemble Γ−(n) de ses followers dans le graphe social G.
Ces systèmes reposent essentiellement sur un index exploitant une table de
hachage sur l’identiﬁant du nœud. Cette technique permet de récupérer la
liste des suiveurs (followers) d’un nœud (voir [Weaver] pour un aperçu de
l’architecture de Twitter).

[Teevan et al., 2011] rapporte une taille de 1.64 termes pour les re-
cherches sur le moteur de recherche de Twitter. Nous supposons une taille
de ﬁltre similaire à cette valeur, ce choix est motivé par :

— (i) Le ﬁltrage correspond à la préférence d’un utilisateur vis-à-vis des
publications d’un compte donné. En eﬀet, ce scénario diﬀère du cas
habituel où le ﬁltrage est appliqué au ﬂux global. Nous supposons
que les besoins en ﬁltrage sur un compte spéciﬁque sont plus précis.

— (ii) Nous rencontrons souvent dans le monde du micro-blogging des
utilisateurs qui détiennent une autorité sur le graphe social sur un
sujet (topic) précis [Pal and Counts, 2011]. Twitter recommande déjà
des comptes à suivre sur le réseau pour certains topics. Avec notre
système, les utilisateurs peuvent mettre en place des ﬁltres pour re-
cevoir uniquement les tweets correspondant à ces topics.

Étant donné cette taille de ﬁltre sur un système utilisé simultanément
par plusieurs centaines de millions d’utilisateurs, le déﬁ consiste à déterminer
eﬃcacement l’ensemble Γ−(n) de followers destinataires d’une publication
donnée en se basant sur la structure de LSG. Cette problématique est d’au-
tant plus délicate pour les comptes avec un large nombre de followers.

Nous proposons de comparer 3 diﬀérentes structures d’indexation qui ex-
ploitent un stockage du graphe social sous forme de liste inverse pour gérer
le ﬁltrage. Pour satisfaire la notiﬁcation en temps-réel, en prenant en consi-
dération le débit élevé de publications (ex. Twitter a relevé des pics à plus de
8800 tweets par seconde en 2011 1 et de plus de 143.000 TPS en 2013 2), nous

1. http://yearinreview.twitter.com/en/tps.html
2. https://blog.twitter.com/2013/new-tweets-per-second-record-and-how

48

Chapitre 4. Filtrage et indexation

nous basons sur des structures qui peuvent être maintenues en mémoire cen-
trale. Cette raison élimine les structures arborescentes (Voir [Hmedeh et al.,
2012] pour une comparaison des structures basées sur le hachage et les solu-
tions arborescentes). Nos propositions sont basées sur des structures de listes
inverses qui exploitent une factorisation par rapport aux comptes publieurs,
aux suiveurs ou bien aux ﬁltres. Ces structures peuvent être facilement dé-
ployées comme extension des structures existantes déjà implantés sous forme
de listes inverses.

Nos trois variantes de listes inverses exploitent trois facteurs de factori-
sation diﬀérents : les identiﬁant de followers, les identiﬁants de publishers ou
les termes utilisés pour le ﬁltrage. Du fait que nous stockons des identiﬁants
de termes et non les termes eux-mêmes (grâce à l’utilisation d’une table de
correspondance) nous considérerons dans ce qui suit que toutes les entrées,
les identiﬁant de followers, les identiﬁants de publishers ou les identiﬁants
de termes nécessitent le même espace de stockage en mémoire (un entier sur
8-octets dans notre implantation aﬁn de gérer les identiﬁant de Twitter).
L’ensemble des paramètres qui impactent le temps de construction des index,
l’espace mémoire ainsi que les temps de recherche (matching) sont résumés
dans le tableau 4.1.

N

Le nombre total de comptes

Γ+(n) Comptes suivis par n
Γ−(n) Comptes qui suivent n

Nombre moyen de followers pour un utilisateur
Nombre moyen de termes de ﬁltre pour une paire (publisher, follower)
Taille d’une publication (termes distincts) p

ϕ
τ
|p|
(k, β) Coeﬃcients de Heaps pour les données de type micro-blogging
γ
VF
θdir
θlist
θentry Taille d’une entrée d’une posting list

Constante de la loi de Zipf pour les données de type micro-blogging
Vocabulaire des ﬁltres
Taille d’une entrée de directory
Taille d’une posting list

Table 4.1 – Table des notations

49

Chapitre 4. Filtrage et indexation

4.3 Structures et modèle analytique
4.3.1 Le PFT-index

L’index PFT (pour P ublisher−F ollower−T erm index) est un mapping
(correspondance) qui a pour clé un compte n ∈ N, et pour valeur la posting
list correspondante P ostingsP F T (n), c.à.d., l’ensemble des followers ainsi
que leurs ﬁltres : P ostingsP F T (n) = {(n1,{t1
n2, . . .}),
. . .}, avec ni ∈ Γ−(n) et tj
ni ∈ label(ni, n). Le P F T-index correspond à une
factorisation d’abord sur chaque publisher, puis pour chaque publisher une
seconde factorisation sur les identiﬁants de followers.

n1, . . .}), (n2,{t1

n1, t2

n2, t2

Exemple

La Figure 4.1 illustre le PFT-index correspondant à l’exemple présenté

en section 3.3.1.

Figure 4.1 – Le PFT-index

Occupation mémoire du PFT-index

Soient ϕ le nombre moyen de followers pour un utilisateur du système et
τ le nombre moyen de termes d’un ﬁltre pour une paire (publisher, follower).
L’index consiste en un key directory dont les posting lists contiennent les
identiﬁants des followers ainsi que les termes. L’occupation mémoire pour
le P F T-index pour un système représenté par un graphe LSG avec |N|
utilisateurs est :

∆P F T

memory(LSG) = size(directory) + total(f_id) + total(terms)

La taille du directory est le nombre de publishers qu’on suppose égal
à N (chaque compte a au moins un follower). Le nombre d’identiﬁants de

50

Chapitre 4. Filtrage et indexation

followers total(f_id) présents dans la structure est N × ϕ, et le nombre
total de termes total(terms) indexés est N × ϕ × τ. On déduit donc :
memory(LSG) = N × θdir + (N × ϕ) × θlist + (N × ϕ × τ) × θentry
∆P F T

Temps de recherche (matching) du PFT-index

En supposant un tweet p de taille |p| publié par l’utilisateur n. Le proces-
sus de notiﬁcation accède à la posting list P ostingsP F T (n) et pour chaque
follower ni vériﬁe s’il existe un terme tj dans tweet p tel que label(ni)
contient tj. Le temps moyen de matching est donc :
time (LSG, p) = ϕ × (|p| × τ)
∆P F T

Temps d’insertion/suppression du PFT-index

Pour insérer un nouveau ﬁltre nous devons parcourir la posting list

P ostingsP F T (n) jusqu’à trouver l’identiﬁant du follower à ajouter ou sup-
primer. Si le follower n’existe pas dans P ostingsP F T (n), une nouvelle entrée
est alors ajoutée. La suppression nécessite un parcours additionnel de la liste
de termes. Potentiellement, ceci peut conduire à la suppression de l’entrée
du follower. Les coûts sont dont respectivement :

∆P F T

insert(LSG) = ϕ/2

∆P F T

delete(LSG) = ϕ/2 + τ /2

4.3.2 Le PTF-index

Dans le P T F-index, (pour P ublisher − T erm − F ollower index), la
clé est cette fois-ci un compte n ∈ N et la valeur est la posting list cor-
respondante P ostingsP T F (n). La posting list est factorisée sur les termes,
chaque terme t est donc associé à une liste des followers de n qui ont choisi
t comme ﬁltre aux tweets de n. Ce qui nous donne P ostingsP T F (n) =
{(t1,{n1
t1, n2
label(ni, n).

t2, . . .}), . . .}, avec nj

∈ Γ−(n) et ti ∈

t1, . . .}), (t2,{n1

t2, n2

ti

Exemple

La Figure 4.2 illustre le PTF-index correspondant à l’exemple présenté

en section 3.3.1.

51

Chapitre 4. Filtrage et indexation

Figure 4.2 – Le PTF-index

Occupation mémoire du PTF-index

L’index est composé de N posting lists, chaque entrée doit stocker ϕ × τ
ﬁltres associés à un publisher, comme dans le P F T-index, avec les termes
pour critère de factorisation. Si l’on suppose que tout les followers d’un pu-
blisher posent des ﬁltres distincts, la taille de P ostingsP T F (n) est ϕ × τ.
Cependant nous observons que les followers expriment des intérêts similaires
dans leur comportement en suivant un publisher particulier. Par conséquent
le nombre de ﬁltres distincts sur un publisher doit être inférieur à cette va-
leur.

Nous supposons comme dans plusieurs applications basées sur les mots-
clés que le nombre total de termes dans une posting list suit une loi de
Heaps [Baeza-Yates and Ribeiro-Neto, 1999, Manning et al., 2008], c.à.d.
|P ostingsP T F (n)| = k × T β, où k et β sont des constantes et T est le
nombre total de termes dans le posting. Les coeﬃcients de Heaps k et β
dépendent fortement des caractéristiques du corpus de texte analysé et leurs
valeurs pour ce qui concerne le micro-blogging doit être déterminées dans un
travail futur. A noter que β est entre 0 et 1 (généralement entre [0.4, 0.6]).
Ce qui implique que plus le nombre de followers augmente, meilleure est la
factorisation. Ce comportement est attendu dans notre système où un grand
nombre d’utilisateurs partagent le même ﬁltre. Étant donné que le nombre
de termes dans P ostingsP T F (n) est N × (ϕ × τ) et le nombre d’entrées
indexées est toujours N × ϕ × τ, on déduit que :

memory(LSG) = N × θdir + (N × k × (ϕ× τ)β)× θlist + (N × ϕ× τ)× θentry
∆P T F

52

Chapitre 4. Filtrage et indexation

Temps de matching du PTF-index

Supposons un nouveau tweet p publié par l’utilisateur n. On accède
d’abord à la posting list du publisher n P ostingsP T F (n). puis pour chaque
entrée (ti,{n1
ti) on vériﬁe si p contient ti. A chaque fois que cela
arrive, on notiﬁe chaque nj
depuis l’entrée ti. Le temps de matching moyen
ti
est donc donné par :

ti, . . . , nk

time (LSG, p) = |p| × k × (ϕ × τ)β
∆P T F

Temps d’insertion/suppression du PTF-index

Pour insérer un nouveau ﬁltre t, nous parcourons la posting list

P ostingsP T F (n) jusqu’à trouver l’entrée qui correspond à t. Ajouter un nou-
veau ﬁltre consiste à insérer l’identiﬁant du follower qui exprime ce ﬁltre t
dans la liste adéquate. Si le terme n’existe pas dans P ostingsP T F (n), une
nouvelle entrée pour ce terme est ajoutée. La suppression nécessite un par-
cours additionnel de la liste de followers, en moyenne (ϕ×τ)/|P ostingsP T F (n)|,
et peut conduire potentiellement à la suppression de l’entrée du terme. Les
coûts sont donc respectivement :

insert(LSG) = k × (ϕ × τ)β/2
∆P T F

delete(LSG) = k × (ϕ × τ)β/2 + (ϕ × τ)/(k × (ϕ × τ)β)
∆P T F

4.3.3 Le TPF-index

Dans le T P F-index, (pour T erm−P ublisher−F ollower index), la clé est
un terme apparaissant dans un ﬁltre. Donc le directory contient tout le voca-
bulaire de ﬁltres VF . La posting list P ostingsT P F (t) associée à un terme t est
l’ensemble des publishers avec leurs followers qui ﬁltrent le publisher sur le
terme t : P ostingsT P F (t) = {(n1,{n1
n2, . . .}), . . .},
i ∈ Γ−(ni) et t ∈ label(ni, nj
avec nj
i). T P F-index correspond à une facto-
risation d’abord sur le terme de VF , puis pour chaque terme une seconde
factorisation sur l’identiﬁant du publisher.

n1, . . .}), (n2,{n1

n1, n2

n2, n2

Exemple

La ﬁgure 4.3 illustre le TPF-index correspondant à l’exemple présenté

en section 3.3.1.

53

Chapitre 4. Filtrage et indexation

Figure 4.3 – Le TPF-index

Occupation mémoire du TPF-index

Le T P F-index consiste en |VF| posting lists, une pour chaque terme du
vocabulaire des ﬁltres. Sachant que nous avons N comptes qui suivent en
moyenne ϕ autres comptes avec une taille moyenne de ﬁltre de τ, le nombre
total de termes utilisés pour le ﬁltrage est N × ϕ × τ. Nous supposons tou-
jours que la taille du vocabulaire suit une loi de Heaps donc le nombre de
termes distinct est |VF| = k × (N × ϕ × τ)β.

Nous supposons aussi que la distribution des termes dans l’ensemble de
ﬁltres suit une loi de Zipf [Baeza-Yates and Ribeiro-Neto, 1999, Manning
et al., 2008], et que le nombre de publishers dont les tweets sont ﬁltrés pour
un terme donné est proportionnel à la fréquence du terme. Par conséquent,
le nombre de publishers associés à un terme ti dont le rang de fréquence est
ri est γ/ri, où γ est une constante.
Ici aussi N×ϕ×τ entrées sont stockées, ce qui correspond aux identiﬁants

des followers. Donc l’occupation mémoire pour le T P F-index est :

ln(|VF|). on obtient donc :

memory(LSG) = (k × (N × ϕ × τ)β) × θdir
∆T P F

+(γ × ln(k × (N × ϕ × τ)β)) × θlist + (N × ϕ × τ) × θentry

54

|VF |X

i=1

memory(LSG) = |VF| × θdir + (
∆T P F

γ/i) × θlist + (|N| × ϕ × τ) × θentry

Sachant que |VF| (cid:29) 1, nous pouvons approximer P|VF |

i=1 γ/i avec γ ×

Chapitre 4. Filtrage et indexation

Temps de matching du TPF-index

Supposons un nouveau tweet p publié par l’utilisateur n. Pour chaque
terme t ∈ p on accède à la posting list de t P ostingsT P F (t). Puis pour
ni, . . .}) on vériﬁe si ni est le publisher de p, c.à.d.,
chaque entrée (ni,{n1
si ni = n. Si une entrée existe, on notiﬁe alors nj
ni et on arrête le parcours
pour ce terme. Supposant la distribution Zipf des termes, la taille moyenne
d’une posting list est de ln(|VF|)/2, et on parcourt en moyenne la moitié
pour trouver le publisher. Le temps moyen de matching est donc :

ni, n2

time (LSG, p) = |p| × (γ × ln(k × (N × ϕ × τ)β)/2)/2
∆T P F

Temps d’insertion/suppression du TPF-index

Pour insérer un nouveau ﬁltre (n, n0, t) nous devons parcourir la posting
list P ostingsT P F (t) dont la taille est en moyenne ln(|VF|)/2 jusqu’à trouver
l’entrée qui correspond à n. Ajouter un nouveau ﬁltre consiste à insérer
l’identiﬁant du follower qui pose le ﬁltre t dans la liste qui correspond. Si le
terme n’existe pas dans P ostingsT P F (t), une nouvelle entrée est rajoutée.
La suppression nécessite un parcours additionnel de la liste des followers,
en moyenne (N × ϕ × τ)/|VF| ce qui peut conduire potentiellement à la
suppression d’une entrée d’un publisher. Par conséquent, les coûts sont de
respectivement :

insert(LSG) = (γ × ln(k × (N × ϕ × τ)β)/2)/2
∆T P F

delete(LSG) = (γ × ln(k × (N × ϕ × τ)β)/2)/2 + (N × ϕ × τ)/|VF|)
∆T P F

4.4 Expérimentations

Dans cette section, nous présentons les expériences que nous avons conçues
et conduites aﬁn d’analyser (i) comment se comportent nos structures sur
des jeux de données réels collectés sur Twitter et (ii) l’impact des diﬀérents
paramètres des systèmes de micro-blogging. Ces expériences qui valident le
modèle analytique présenté plus tôt ont été conduites sur un processeur Intel
Core i5 avec une fréquence de 3.60 GHz et 16 GB de RAM. Les structures
ont été implantés en JAVA.

55

Chapitre 4. Filtrage et indexation

4.4.1 Espace mémoire

Les diﬀérents critères de factorisation font que nos structures ont des
besoins mémoire diﬀérents. Le tableau 4.2 compare l’occupation mémoire
des trois structures sur notre jeu de données pour le ﬁltrage. TPF-index
apparait comme étant la structure la moins coûteuse en espace mémoire.
Plusieurs ﬁltres sont partagés par un grand nombre d’utilisateurs ce qui nous
a permis d’obtenir une meilleure factorisation, sur les termes d’abord. Mais
aussi, on observe que beaucoup de followers ﬁltrent un publisher sur le même
terme. Par conséquent, pour un terme dans le TPF-index, on observe aussi
une importante factorisation sur l’identiﬁant du publisher, en particulier
pour les comptes à forte popularité (avec un grand nombre de followers). De
manière opposée, le PFT-index ne bénéﬁcie pas d’une bonne factorisation
vu que tous les publishers ont une entrée dans le directory et pour chaque
entrée on a une liste de termes pour chacun de ses followers.

Structure Taille d’index (MB)

PFT
PTF
TPF

9021
3777
1869

Table 4.2 – Tailles des index

Pour mesurer l’impact des diﬀérents paramètres et ainsi valider notre
modèle analytique, nous avons généré des jeux de données synthétiques avec
des nombres constants de ﬁltres (τ) pour chaque arc de graphe. Les résultats
sont reportés sur la ﬁgure 4.4.
L’occupation mémoire croit linéairement avec τ pour les index P F T et P T F.
En eﬀet, faire croitre τ n’impacte pas la taille du directory qui dépend seule-
ment du nombre de publishers, c.à.d., N. En outre pour le P F T-index, le
nombre d’éléments dans la posting list reste constant et égal au nombre de
followers. Par contre, le nombre d’entrées suit linéairement τ. Pour le P T F-
index le nombre d’éléments dépend du nombre de termes distincts utilisés
comme ﬁltres pour un publisher. En comparant avec le P F T-index on ob-
serve la même pente. Ceci révèle que τ a un faible impact sur le nombre
d’éléments pour une posting list dans le P T F-index.

La loi de Heaps proposée dans notre modèle explique ce résultat, car elle
suppose que le sous-vocabulaire des termes de ﬁltres pour un publisher donné

56

Chapitre 4. Filtrage et indexation

Figure 4.4 – Espace mémoire / τ

Figure 4.5 – Espace mémoire / N

augmente légèrement. Ainsi pour le P T F-index, comme pour le P F T-index,
la croissance τ n’impacte pas la structure mais seulement le nombre d’en-
trées. Finalement, nous notons l’impact faible de τ sur le T P F-index. La
raison est (i) la taille du directory reste constante et égale à VF , (ii) sachant
que les ﬁltres sont générés sur les tweets d’un publisher, un nouveau terme
a une grande probabilité d’être déjà présent pour le même publisher dans
la structure, donc le nombre d’éléments des listes demeure bas et augmente
lentement.

La ﬁgure 4.5 illustre l’impact de N sur les diﬀérentes structures. Toutes
les structures aﬃchent une croissance linéaire. Pour le P F T et le P T F in-
dex, ajouter un nouvel utilisateur conduit à ajouter une nouvelle entrée de

57

Chapitre 4. Filtrage et indexation

directory, une nouvelle posting list et de nouvelles entrées dans la posting
list pour ses followers avec leurs ﬁltres. Cependant, la factorisation sur les
identiﬁants de termes dans une posting list est plus eﬃcace que celle sur
les identiﬁants de followers ce qui explique la meilleure pente pour le P T F.
En ce qui concerne le T P F, après une courte étape d’initialisation qui cor-
respond à la création des diﬀérentes entrées du directory et des diﬀérents
éléments des posting lists, l’augmentation de N implique seulement de ra-
jouter de nouvelles entrées de liste. Ceci explique la croissance linéaire avec
une faible pente. Les deux ﬁgures valident le modèle analytique présenté
précédemment.

4.4.2 Temps d’indexation

Dans le tableau 4.3, nous comparons le temps nécessaire à la construc-
tion des diﬀérentes structures en mémoire centrale pour les diﬀérents jeux
de données. Uniform(1), (2) and (3) correspondent aux scénarios où chaque
arc publisher-follower est associé à respectivement 1, 2 ou 3 termes de ﬁltres.
Comme prévu, plus la taille de l’index est petite, moins de temps est dé-
pensé en sa construction. En eﬀet pour le T P F-index nous avons de plus
petites posting lists, ce qui implique que nous avons besoin de moins de
temps pour trouver l’élément de la liste où le nouveau ﬁltre doit être in-
séré. Par contre, dans le P F T-index, un coûteux parcours de larges posting
lists est nécessaire. Nous notons aussi que le temps de construction n’est
pas proportionnel à τ. Il s’avère que les éléments de posting lists sont crées
rapidement et leur nombre évolue lentement. Après cette étape, augmenter
le nombre de termes de ﬁltre pour un follower correspond essentiellement
à ajouter de nouvelles entrées dans des éléments existants ce qui se fait en
temps relativement constant et qui explique le comportement linéaire.

Structure

réaliste uniform(1) uniform(2) uniform(3)

PFT
PTF
TPF

753
512
231

736
357
198

741
444
236

1081
558
289

Table 4.3 – Temps d’indexation (en s)

58

Chapitre 4. Filtrage et indexation

4.4.3 Temps de recherche (matching)

Pour l’évaluation des temps de matching nous procédons comme suit :
Tout d’abord, le tweet est décomposé en un ensemble de termes, puis nous
utilisons l’index pour déterminer pour chaque terme du tweet l’ensemble des
followers à notiﬁer. A noter que, dû au fait que nous travaillons dans une
logique disjonctive, quand le premier matching positif se manifeste nous pou-
vons directement notiﬁer l’utilisateur correspondant. Le tableau 4.4 illustre
les temps moyens de matching pour un ﬂux de 100,000 tweets sur les diﬀé-
rents index.

On observe que le T P F-index aﬃche de mauvaises performances de mat-
ching : pour notre jeu de données réaliste, avec une valeur de temps de mat-
ching de 2.5 ms par tweet, il peut gérer moins de 400 tweets par seconde
donc insuﬃsant pour passer à l’échelle. Pour chaque terme du tweet nous
récupérons une large posting list avec potentiellement autant d’éléments que
de publishers N existants.

Par contre, le P T F-index récupère rapidement les followers à notiﬁer :
il peut traiter un tweet toutes les 15 µs, il est donc capable de gérer des pics
à plus de 66.000 tweets par seconde. Dans ce cas de ﬁgure, nous accédons
directement à la posting list correspondante au publisher. Puis, nous par-
courons tous ses éléments ce qui correspond à tous les followers du compte
et on vériﬁe pour chacun d’entre eux le matching avec les termes du tweet.
A noter que le nombre des termes d’un ﬁltre est petit (entre 1 et 3) pour
un follower, et que nous faisons le test pour tous les termes du tweet en un
seul parcours. Évidemment, ces résultats sont des valeurs moyennes et le
temps de matching est plus élevé pour les publishers à forte popularité et
plus rapide avec ceux qui ont très peu de followers.

Structure

Temps de matching (µs)

PFT PTF TPF
808
2564

15

Table 4.4 – Temps de matching

La ﬁgure 4.6 illustre l’impact de τ sur le temps de matching. Comme
dans le tableau 4.4, le P T F-index surpasse les deux autres propositions
de 2 ordres de grandeur. Nous notons que le temps de matching pour le

59

Chapitre 4. Filtrage et indexation

Figure 4.6 – Temps de matching / τ

P F T-index croit linéairement avec τ pendant que le T P F-index suit une
croissance sous linéaire. Pour le P F T-index, le matching implique un accès
direct à la posting list d’un publisher puis un parcours de tous ses éléments
en vériﬁant si les entrées associés correspondent aux termes du tweet. Aug-
menter la valeur de τ ne change ni le nombre d’entrées du directory, ni le
nombre d’éléments des listes. Donc seulement à la dernière étape, la compa-
raison avec les termes nécessite un peu plus de temps. Le nombre d’entrées
est proportionnel à τ ce qui explique la croissance linéaire.

En ce qui concerne le T P F-index, nous observons le comportement cor-
respondant à la loi de Zipf dans la distribution des fréquences de termes,
donc en augmentant τ nous rajoutons généralement des entrées dans la post-
ing list des termes les plus fréquents. Une conséquence est que plus on a de
ﬁltres indexés, plus grande est la probabilité de rajouter une entrée dans une
posting list existante. Dès lors que les tailles des posting lists ont une crois-
sance sous-linéaire et que nous parcourons autant de listes que le nombre de
termes dans le tweet, cela justiﬁe que le temps de matching croit de manière
sous linéaire par rapport à τ.

Nous illustrons aussi dans la Figure 4.7 l’évolution des temps de matching
par rapport à N. Nous notons que à la fois le P F T et le P T F-index ont un
temps de matching constant. En eﬀet, augmenter N n’impacte que la taille
du directory en y ajoutant de nouvelles entrées, mais les posting lists gardent
un nombre constant d’éléments et pour chaque élément un nombre constant

60

Chapitre 4. Filtrage et indexation

Figure 4.7 – Temps de matching / N

d’entrées. Comme pour un nouveau tweet nous parcourons seulement une
seule posting list qui correspond au publisher, le temps de matching est
constant avec N. Le T P F-index montre de meilleurs résultats que le P F T-
index pour des valeurs de N inférieures à 900.000. Le temps de matching
avec le T P F-index croit de manière sous-linéaire par rapport à N pour les
mêmes raisons que pour τ. Ces résultats conﬁrment les équations présentées
dans notre modèle analytique.

4.4.4 Eﬃcacité du ﬁltrage

Aﬁn d’évaluer l’impact du ﬁltrage sur le nombre de tweets remis, nous
avons décidé de comparer le nombre de tweets remis par le serveur de micro-
blogging avec et sans la mise en place du ﬁltrage. Nous avons testé le système
de ﬁltrage sur diﬀérentes variantes du jeu de données : Un jeu dit “réaliste”
avec un nombre ﬁltres par arêtes variant entre 1 et 3 et des jeux uniformes
avec un nombre ﬁxe de ﬁltres sur chaque arête.

Comme attendu le nombre de tweets remis chute de manière importante.
Nous mesurons un gain de presque 98% sur nos jeux de données (voir ta-
bleau 4.5). Notre logique disjonctive pour les ﬁltres justiﬁe que plus on a
de termes dans les ﬁltres, plus on doit délivrer de tweets. Cependant, nous
n’observons pas de croissance linéaire dans le nombre de tweets à remettre.
En eﬀet, il existe une grande probabilité pour un tweet de correspondre à
plusieurs termes d’un follower quand ce follower a des ﬁltres de grande taille.

61

Chapitre 4. Filtrage et indexation

Filtrage
Activé

Désactivé

Réaliste uniform(1) uniform(2) uniform(3) uniform(4)
211,651

161,196

212,364
11,035,437

244,578

267,164

Table 4.5 – Nombre de tweets remis

4.5 L’évolution du graphe social

Comme rapporté par [Kwak et al., 2011,Kivran-Swaine et al., 2011], les
utilisateurs des plateformes de micro-blogging ont un comportement de suivi
dynamique ce qui implique que le graphe social sous-jacent dans les plate-
forme comme Twitter est en constante évolution. Les relations de suivi se
font et se défont au gré de l’intérêt des utilisateurs, intérêt qui peut aussi être
temporaire (ex. les comptes créés pour des événements ponctuels). Dans le
but de gérer au mieux les notiﬁcations de tweets, nous proposons une struc-
ture hybride qui tire parti des structures PFT et PTF et qui est présentée
en section 4.6.

Aﬁn d’illustrer comment nos structures réagissent face à la dynamicité
du graphe, nous présentons les temps d’insertion/suppression moyens dans
le tableau 4.6.

Structure
PFT-index
PTF-index
TPF-index

Hybrid-index (seuil = 400)

Temps d’insertion Temps de suppression

2274
3247
3023
2498

566
1731
1057
818

Table 4.6 – Temps moyens d’insertion/suppression (en Nano-Secondes)

L’index de type TPF-index ne reﬂétant pas la structure du graphe social,
une recherche chronophage des listes doit être eﬀectuée pour les termes po-
pulaires dans le cas d’une insertion. Dans le cas d’une suppression, le même
problème se pose pour les comptes populaires suivis sur plusieurs topics.

62

Chapitre 4. Filtrage et indexation

Aussi, en concordance avec notre étude analytique, le PFT-index apparait
comme étant la structure la plus dynamique et requiert 30% de temps en
moins pour l’insertion et plus de 67% de temps en moins pour la suppression
par rapport au PTF-index. Ceci s’explique par le fait que la factorisation
exploitée par le PFT (d’abord sur le publisher puis sur les followers) cor-
respond à une factorisation sur les arêtes du graphe social. Dès lors, l’ajout
ou la suppression d’une arête peut se faire eﬃcacement. La factorisation par
publisher puis par terme dans le PTF-index ne respecte pas le stockage na-
turel du graphe sous forme de liste d’adjacence et conduit donc à des temps
de mise à jour plus importants.

4.6 Une structure hybride

Comme la plupart des plateformes sociales, les systèmes de micro-
blogging sont caractérisés par une forte hétérogénéité. La ﬁgure 4.8 ainsi
que la ﬁgure 4.9 illustrent cette hétérogénéité sur notre jeu de données. Nous
pouvons distinguer cinq classes d’utilisateurs en se basant sur leur nombre
de followers. Nous observons sur la ﬁgure 4.8 que plus de la moitié des uti-
lisateurs sont suivis par moins de 10 comptes. En parallèle, nous retrouvons
sur notre système une minorité de comptes très populaires qui sont suivis
par un grand nombre d’utilisateurs (0,78% des utilisateurs sont suivis par
plus de 1000 comptes).

En s’intéressant aux fréquences de publication, nous pouvons observer
en ﬁgure 4.9 que les classes d’utilisateurs avec le plus grand nombre de fol-
lowers sont aussi les classes avec le plus de publications. Ce phénomène est
souvent rapporté dans les réseaux sociaux [Kwak et al., 2010, Ahn et al.,
2007].

Se basant sur cet aspect, nous avons exploré la piste d’une structure hy-
bride qui combine les index du type PFT et PTF. Cette nouvelle structure
va stocker les comptes qui ont un nombre de followers inférieur à un cer-
tain seuil de manière similaire au PFT-index et les comptes ayant un grand
nombre de followers (supérieur au seuil déﬁni) en utilisant une factorisation
PTF. La motivation principale pour cette approche vient de l’observation
que la structure PTF gère mieux les comptes populaires que le PFT-index
(voir section 4.4.3).

63

Chapitre 4. Filtrage et indexation

Figure 4.8 – Utilisateurs suivant leur nombre de followers

Figure 4.9 – Utilisateurs suivant leur nombre moyens de tweets

64

Chapitre 4. Filtrage et indexation

Figure 4.10 – Espace mémoire occupé par rapport à N et au seuil choisi

4.6.1 Occupation mémoire de la structure hybride

Le paramètre clé dans le contexte hybride est la valeur choisie pour le
seuil. Le seuil représente le nombre minimal de followers qu’un compte doit
avoir pour être considéré comme compte populaire. Nous appellerons ce seuil
dans ce qui suit le seuil de popularité. En fonction de cette valeur, nous dé-
cidons de stocker un compte sous forme PFT-index (non-populaire) ou bien
sous forme de PTF-index (populaire). Les résultats concernant l’évolution
de l’espace mémoire occupé par la structure hybride en fonction du seuil de
popularité sont illustrés en ﬁgure 4.10.

Nous observons que la gestion des grand comptes (en nombre de follo-
wers) sous format PTF-index a un impact direct sur la taille occupée par
les structures d’indexation en mémoire centrale. Plus la valeur de seuil de
popularité choisie est petite, plus la taille de la structure d’index est petite.
En conséquence, nous observons que la taille mémoire de l’index hybride est
bornée par les tailles des structures PFT et PTF. Par exemple, pour un seuil
de popularité de 5, la taille mémoire occupée par la structure hybride est
similaire a celle occupée par l’index PTF. En contraste, un seuil de popula-
rité de de 400 induit une croissance de la taille mémoire de 30% par rapport
au PTF-index.

4.6.2 Temps de matching pour la structure hybride

Nous reportons les temps de matching obtenus pour la structure hybride
en ﬁgure 4.11. Nous observons que le temps de matching demeure constant

65

Chapitre 4. Filtrage et indexation

Figure 4.11 – Temps de matching pour la structure hybride par rapport
au seuil popularité

pour les valeurs de seuils de popularité entre situées 5 et 25. Avec ce para-
mètre de partitionnement de l’espace des utilisateurs, la structure hybride
a un temps de matching moyen de 15 µs, donc similaire à la valeur obser-
vée pour le PTF-index (voir section 4.4.3). Le tableau 4.7 aﬃche le nombre
d’utilisateurs (sur les 2,17 millions d’utilisateurs dans notre graphe social)
indexés sous forme de PTF et ce pour diﬀérentes valeurs de seuil de po-
pularité. Nous observons qu’à partir d’un seuil de popularité de 25, ce qui
mène à considérer près de 25% des utilisateurs en tant que comptes popu-
laires, le temps de matching croit rapidement. Cependant, nous observons
qu’avec un seuil de popularité de 400 seulement 2,5% sont considérés popu-
laires et indexés en tant que PTF mais le gain en temps de matching par
rapport à une structure de PFT est de l’ordre de 25,2 (32µs contre 808µs).
Ces gains observés conﬁrment notre intuition qui consiste à distinguer les
(rares) comptes populaires pour l’indexation.

Par rapport à la gestion de la dynamicité du graphe, il apparait que la
structure hybride gère les mises à jour plus eﬃcacement que l’index PTF et
presque aussi vite que le PFT (Tableau 4.6). Une insertion est réalisée en
2498 ns et une suppression en 818 ns (en moyenne, avec un seuil de popula-
rité de 400) par rapport à 2274 ns et 566 ns pour le PFT-index. Cela nous
pousse à conclure donc que l’utilisation d’une factorisation spéciﬁque pour
les grands comptes (en terme de followers) permet d’accroitre l’eﬃcacité

66

Chapitre 4. Filtrage et indexation

Seuil de popularité Nombre d’utilisateurs
1,349,490
959,976
547,001
337,393
199,033
209,844
54,024
16,961
2,118
896

5
10
25
50
100
200
400
1,000
5,000
10,000

Table 4.7 – Nombre d’utilisateurs pour diﬀérentes valeurs de seuil de po-
pularité

générale du système de ﬁltrage.
La structure hybride réalise un compromis intéressant entre le PTF-index
et le PFT-index. Par exemple avec la structure hybride et un seuil de po-
pularité de 400, l’index occupe 30% d’espace en plus qu’un PTF-index mais
réalise un gain de 50% par rapport à un PFT-index. En parallèle, le temps
de matching moyen obtenu est le double de celui obtenu par le PTF mais
demeure 25 fois plus petit que le temps nécessaire pour le PFT-index. Aussi,
la structure hybride aﬃche de meilleures performances que le PFT-index en
ce qui concerne la gestion de la dynamicité du graphe avec un gain de 23%
pour le temps nécessaire à l’insertion et 53% pour la suppression.

Le tableau 4.8 oﬀre un récapitulatif des points forts et points faibles des

diﬀérentes structures.

PFT-index PTF-index TPF-index Hybride

Occupation mémoire
Temps de recherche

Temps m.à.j

- -
+
+ +

+
+ +
- -

+ +
- -
-

+
+ +
+

Table 4.8 – Eﬃcacité des structures d’indexation

67

Chapitre 4. Filtrage et indexation

4.7 Conclusion

Dans ce chapitre, nous avons comparé diﬀérentes structures de listes
inverses qui permettent d’indexer des ﬁltres dans le but d’améliorer l’expé-
rience utilisateur tout en réduisant le nombre de messages transmis par le
systèmes de micro-blogging. Nous avons proposé un modèle analytique de
coût en temps et en mémoire pour ces structures. Ce modèle a été validé
expérimentalement sur un un jeu de données conséquent. La structure PTF-
index est apparue comme le candidat qui a atteint la meilleure performance
sur les critères de passage à l’échelle. Malgré une occupation mémoire deux
fois plus importante que pour le TPF-index, cette structure surpasse les
autres propositions de plusieurs ordres de grandeur en ce qui concerne le
temps de matching.

Nous avons aussi démontré que le fait d’exploiter l’hétérogénéité pré-
sente sur les plateformes sociales comme reporté par [Kwak et al., 2010]
(ex. 5% des comptes avec plus de 100.000 followers) permet d’améliorer la
performance globale du système de ﬁltrage. Notre proposition d’un ﬁltrage
hybride fournit un compromis intéressant tout en améliorant la capacité a
suivre l’évolution et la dynamicité du graphe social.

Comme pistes d’améliorations possibles, nous envisageons de considé-
rer Le clustering de ﬁltres. Cette approche permettrait de regrouper les
diﬀérents ﬁltres à l’intérieur d’une même posting list aﬁn d’atteindre de
meilleures performances. Gérer les cas de conjonction et de négation pour
les ﬁltres est aussi un autre déﬁ. Nous envisageons aussi l’exploitation d’on-
tologies pour aboutir un ﬁltrage plus “intelligent” (gérer les relations de
synonymie et les inclusions).

Finalement, étant donné les ﬁltres qu’un utilisateur peut poser sur le
système, nous sommes capables de dresser un proﬁl précis de ses intérêts.
Le chapitre suivant décrit une approche de recommandation basée sur les
données implicites au graphe social étiqueté LSG.

68

Chapitre 5

Recommandation de comptes

5.1 Introduction

Après avoir introduit un mécanisme de ﬁltrage eﬃcace sur les graphes
sociaux de type micro-blogging. Nous avons choisi d’aborder le problème
de la découverte d’information pertinente à travers la recommandation de
comptes à suivre. En eﬀet, même si le ﬁltrage permet le nettoyage du contenu
reçu par les utilisateurs des plateformes sociales, il oﬀre cependant une vue
réduite et étroite de ce qui se passe plus globalement sur le réseau. La recom-
mandation de comptes aux utilisateurs permettra de palier ce phénomène.

Dans ce chapitre, nous présentons d’abord notre motivation et nos objec-
tifs. Nous décrivons ensuite le score de recommandation proposé qui exploite
eﬃcacement toutes les données intrinsèques au graphe social étiqueté que
nous nommons LSG. Après avoir déﬁni notre score ainsi que ses compo-
santes, nous décrivons une approche qui permet l’approximation eﬃcace de
nos scores sur le graphe social en exploitant une approche par landmark.
Nous présentons ensuite les diﬀérentes expériences conduites aﬁn de valider
la qualité mais aussi l’eﬃcacité de notre approche de recommandation de
comptes. Enﬁn, une conclusion résume les contributions de notre approche
ainsi que les pistes d’amélioration envisagées.

69

Chapitre 5. Recommandation de comptes

5.2 Motivation

Toujours dans l’optique d’améliorer l’expérience des utilisateurs, nous
proposons une stratégie aﬁn de générer des recommandations personnalisées
de comptes à suivre sur une plateforme de type micro-blogging. Le score qui
est au cœur de notre stratégie de recommandation prend en compte trois
aspects déduits directement de la structure de LSG : la proximité topolo-
gique, la sémantique qui existe sur les liens entre les nœuds du graphe ainsi
que l’autorité des comptes recommandés sur des topics précis.

Comme décrit dans les chapitres 1 et 2, La taille du graphe social sous-
jacent dans les réseau sociaux soulève une question de faisabilité quant au
déploiement des stratégies de recommandations car ces stratégies impliquent
la plupart du temps des explorations locales du graphe social. Aﬁn d’accé-
lérer le processus de recommandation, nous proposons une approximation
eﬃcace des scores basée sur une approche par landmarks c.à.d la sélection
d’un ensemble de nœuds dans le graphe social, appelées “landmarks”, qui
joueront le rôle de “stations locales” (hubs) et qui emmagasineront un en-
semble de données sur leur voisinage étendu. Cet ensemble de landmarks est
déterminé en appliquant diﬀérentes stratégies de sélection que nous décri-
vons en section 5.5.

A noter que nous illustrons notre stratégie de recommandation dans un
contexte micro-blogging avec des expérimentations sur des données issues
de Twitter. Cependant, notre modèle de recommandation est plus général
et peut être aisément adapté à n’importe quelle plateforme sociale où les
utilisateurs publient du contenu textuel et reçoivent les publications des
comptes qu’il suivent sur le réseau.

5.3 Recommandation

Dans cette section, nous déﬁnissons les diﬀérentes composantes du score
de recommandation proposé. Notre système de recommandation exploite
le modèle de graphe LSG présenté et décrit en chapitre 3. Le tableau 5.1
regroupe les diﬀérentes notations utilisées dans les déﬁnitions de ce chapitre.
Aﬁn d’illustrer le fonctionnement de notre système de recommandation,
nous illustrons en Figure 5.1 un exemple de LSG avec le contenu des publi-
cations pour les comptes B et C.

70

Chapitre 5. Recommandation de comptes

N, E
Γu, Γu[t]
T
P
labeln, labele

katzβ(u, v)

σ(u, v, t)

ωp(t)
ωp(t)
auth(u, t)
εe(t)
λ, L
Pu,v
Pu,λ,v

Υk(λ)
Ru,v

resp. l’ensemble de nœuds et d’arêtes
followers de u (resp. total des followers sur un topic t)
le vocabulaire de topics
l’ensemble de toutes les publications
la fonction d’étiquetage pour les nœuds du graphe, resp.
pour les arêtes
Le score de Katz d’un nœud v pour un nœud u avec un
facteur de décroissance β
le score de recommandation d’un nœud v pour un nœud
u sur un topic t
le score d’un chemin p dans le graphe pour un topic t
le score d’un chemin p
le score d’autorité pour un nœud u sur un topic t
la pertinence d’une arête e pour un topic t
un landmark, resp. l’ensemble des landmarks
l’ensemble des chemins existants entre u et v
l’ensemble des chemins existants entre u and v passant
par le nœud λ
le k-voisinage de λ
le vecteur de recommandation de v pour u pour tous les
topics

Table 5.1 – Notations

Notre objectif est de recommander à un utilisateur u du système des
comptes pertinents à suivre pour un topic t. Divers scores et stratégies de
recommandation ont étés proposés dans le contexte des réseaux sociaux (voir
Section 2.4.5) pour recommander des comptes, des publications ou bien des
topics. Ces propositions considèrent le plus souvent soit la topologie du ré-
seau social sous-jacent soit le contenu des publications des utilisateurs. Notre
proposition, RecLand, se base sur les hypothèses suivantes :

i) La proximité topologique est une donnée cruciale pour le calcul de la
recommandation, c.à.d un compte u fait conﬁance à ses voisins di-
rects dans le graphe, aux voisins de ses voisins, etc. Cette conﬁance
s’amoindrit avec l’accroissement de la distance [Liben-Nowell and
Kleinberg, 2003].

71

Chapitre 5. Recommandation de comptes

Figure 5.1 – Exemple de LSG dans un contexte de recommandation

ii) Le nombre de chemins entre u et v est lui aussi important : un compte
v a de grandes chances d’être considéré comme important par un
compte u s’il existe un grand nombre d’autres nœuds liés à u qui
recommandent à leur tour v.

iii) La pertinence par rapport à un topic sur les chemins existants entre
u et v doit être aussi considérée dans le calcul des recommandations.

Il a été démontré que le score de Katz [Katz, 1953a] (déﬁni dans l’état de
l’art, section 2.4.5) surpasse d’autres mesures topologiques sur les réseaux
issus du Web dans un contexte de prédiction de liens [Liben-Nowell and
Kleinberg, 2003]. Ce score considère le nombre de chemins existants entre
deux nœuds ainsi que leur longueurs respectives. Nous proposons dans notre
système une extension de ce score qui intègre l’aspect sémantique c.à.d la
pertinence des chemins entre un nœud et sa recommandation par rapport à
un topic donné.

72

Chapitre 5. Recommandation de comptes

5.3.1 Le score de recommandation

Pour rappel, la mesure de Katz entre un nœud u et un nœud v s’exprime

de la façon suivante :

katzβ(u, v) =

∞X

l=1

u,v| = X

p∈Pu,v

βl × |P hli

β|p|

où Pu,v est l’ensemble de tous les chemins existants entre u et v, P

hli
u,v ⊆
Pu,v l’ensemble de tous les chemins de longueur égale à l existants entre
u et v et β ∈ [0, 1] le facteur de décroissance qui permet d’accorder plus
d’importance aux chemins courts. Une faible valeur de β implique des pré-
dictions similaires aux mesures basées sur le nombre de voisins communs car
les long chemins n’auront alors qu’une faible contribution au score total. En
se basant sur ce score topologique, nous proposons notre score de recom-
mandation.

Déﬁnition 1 (Score de recommandation) Le score de recommandation
σ(u, v, t) d’un utilisateur v pour un utilisateur u sur un topic t et les chemins
p = u (cid:32) v est déﬁni comme suit :

σ(u, v, t) = X

ωp(t) = X

p∈Pu,v

p∈Pu,v

β|p|ωp(t)

(5.1)

où le score du chemin ωp(t) est composé du score de Katz β|p|, et de
ωp(t) : le score sémantique du chemin entre u et v de longueur |p| pour un
topic t.

Le score sémantique du chemin ωp(t) prend en considération la perti-
nence des nœuds (autorité) ainsi que celle des arêtes (sur les topics) sur ce
chemin pour chaque topic. Nous explicitons ces concepts dans ce qui suit.

L’autorité d’un nœud

Nous déﬁnissions une fonction d’autorité auth(u, t) pour chaque nœud
u du graphe social sur un topic t. Cette fonction dépend du nombre d’utili-
sateurs qui suivent u sur le topic t. Le score d’autorité est composé de deux
parties :

73

Chapitre 5. Recommandation de comptes

(i) un score d’autorité locale qui assigne une valeur plus élevée aux uti-
lisateurs u qui sont “spécialisés” sur un topic t par rapport aux uti-
lisateurs qui publient sur une vaste variété de topics.

(ii) une popularité globale qui permet d’attribuer un meilleur score aux
utilisateurs les plus suivis sur t et ce dans la globalité du graphe social.

La combinaison d’une composante locale et d’une composante globale
est une approche classique traditionnellement adoptée pour l’évaluation de
l’importance d’un document (ex. le score de TF/IDF) mais aussi l’impor-
tance d’un nœud en terme d’autorité dans un graphe de pages Web [Jeh and
Widom, 2003] ou plus récemment dans le monde du micro-blogging [Gupta
et al., 2013]. Nous déﬁnissons formellement le score auth(u, t) de la manière
suivante :

Déﬁnition 2 (Le score d’autorité d’un nœud) Le score d’autorité d’un
nœud auth(u, t) s’exprime comme suit :

auth(u, t) = |Γu[t]|
| {z }
|Γu|

local

×

|

log(1 + Γu[t])

log(1 + maxu(Γu[t]))

{z

global

}

où |Γu[t]| est le nombre de followers de u sur le topic t, et |Γu| est le nombre
total de followers de u.

La composante d’autorité locale est égale à 1 lorsque u est suivi exclusi-
vement sur le topic t tandis que l’autorité globale peut être égale à 1 lorsque
u est le compte le plus suivi sur le topic t dans tout le réseau. Si aucun
utilisateur ne suit u sur t les deux composantes sont égales à zéro. Nous
avons décidé d’introduire une fonction logarithmique aﬁn de réduire l’écart
entre les comptes populaires avec un nombre important de followers et les
comptes qui ont très peu de followers.

A noter que, mis à part pour maxu(Γu[t]), toutes les composantes du
score peuvent êtres calculées “localement”, en exploitant seulement les in-
formations du nœud en question dans le LSG. Le calcul en temps réel
des recommandations implique l’estimation de la valeur de maxu(Γu[t])
ce qui peut introduire un sur-coût car cette estimation peut entrainer la
consultation de tout le graphe social. Cependant, cette valeur peut être
stockée et recalculée périodiquement. En eﬀet, malgré la dynamicité du

74

Chapitre 5. Recommandation de comptes

graphe social (qui touche particulièrement les comptes populaires), l’ap-
plication de la fonction logarithmique limite l’impact de telles variations
(log(maxu(Γu[t])) ∼ log(maxu(Γu[t]) + ∆). Par conséquent, nous pouvons
évaluer la fonction d’autorité pendant l’exécution.

Le fait de combiner une composante locale à une composante globale
dans le calcul de l’autorité d’un utilisateur permet d’assigner une valeur éle-
vée de score d’autorité sur un topic t à un compte qui a un grand nombre
de followers principalement sur ce topic t. Cela permet aussi d’assigner la
même importance à un compte généraliste et très suivi et à un compte très
spécialisé mais avec un petit nombre de followers.

Exemple 1 (Autorité globale et locale) Dans le graphe exemple illus-
tré en ﬁgure 5.1 et qui contient un aperçu des tweets publiés par les utilisa-
teurs B et C ainsi que les topics sur lesquels ils publient. L’utilisateur B est
plus pertinent sur le topic technology que l’utilisateur C. En eﬀet, B et C
ont la même autorité globale avec deux followers sur ce topic pour les deux
comptes. Cependant, le score d’autorité locale de B sur technology est plus
élevé que celui de C du fait que sur les 3 arcs entrant de B, 2 sont étiqueté
avec technology tandis que pour C ce ratio n’est que de 2 sur 6.
Pour le topic bigdata, l’autorité locale de B et de C est similaire (1 sur 3
pour B et 2 sur 6 pour C) mais il apparait que C est plus suivi sur bigdata
(avec 2 comptes contre 1 pour B). Dès lors, le score d’autorité totale de C
sur le topic bigdata est plus important.

La pertinence par arêtes

Un chemin p = u (cid:32) v dans le graphe est considéré pertinent par rapport
à un topic t lorsque les topics présents sur les arêtes constituant p sont
sémantiquement proches de t. Cela peut être vu comme une mesure de la
“conductivité” du chemin p sur le topic t. Aussi, basé sur notre hypothèse de
proximité, nous considérons qu’une arête distante sur le chemin contribue
moins au score de recommandation qu’un arête proche de u. Cet aspect est
contrôlé par un facteur de décroissance α ∈ [0, 1] qui réduit l’inﬂuence d’une
arête e plus la distance i à partir de u augmente. Plus précisément, nous
déﬁnissons la pertinence d’une arête e à la distance i de u sur un chemin p
comme suit :

75

Chapitre 5. Recommandation de comptes

εe(t) = αi × maxt0∈topics(e)(sim(t0, t))

(5.2)
Où topics(e) retourne les topics qui étiquettent une arête e et sim :
F 2 → R évalue la similarité sémantique entre deux topics t et t0. Dans notre
implantation nous utilisons la mesure de Wu and Palmer [Wu and Palmer,
1994] sur l’ontologie WORDNET 1 mais d’autres mesures peuvent tout aussi
bien être employées (ex. Resnik, Disco 2 , etc.). Le choix de la meilleure me-
sure de similarité dépasse le cadre de notre approche de recommandation.
Lorsqu’une arête e est étiquetée avec plusieurs topics, nous ne gardons que
le topics avec le plus grand score de similarité sémantique aﬁn d’éviter d’ac-
croitre artiﬁciellement les scores des arêtes étiquetées par un grand nombre
de topics.

Le score d’un chemin pour un topic

Finalement, nous considérons que l’importance d’un chemin p est élevée
lorsque la pertinence des nœuds ainsi que celle des arêtes sur ce chemin sont
élevés :

ωp(t) =X

e∈p

εe(t) × auth(end(e), t)

(5.3)

où end(e) retourne le nœud destination d’une arête dirigée e.

Le score de recommandation de v pour l’utilisateur u sur un topic t est
alors obtenu en substituant ωp(t) dans l’équation (5.1) par sa formule don-
née par l’équation (5.3).

Exemple 2 (La pertinence d’un chemin) Dans l’exemple illustré en Fi-
gure 5.1, nous voulons recommander à l’utilisateur A des comptes à suivre
sur le topic technology en eﬀectuant une exploration (pour cet example
nous supposons une exploration dans un périmètre k = 2 sauts). Les utili-
sateurs D et E peuvent êtres atteints respectivement par les chemins p1 =
A → B → D et p2 = A → C → E, chacun de longueur 2.
La pertinence de l’arête A
de C

−−−−−−−−−−−→ B est plus importante que celle
−−−−−−→ E du fait que la première est à une distance 1 de A tandis

bigdata,technology

technology

1. http://wordnet.princeton.edu/
2. http://www.linguatools.de/disco/disco_en.html

76

Chapitre 5. Recommandation de comptes

que la deuxième est à distance 2. De plus, l’autorité sur le topic technology
du nœud B calculé comme (local) × (global) = 2
log(1+2) est plus impor-
6 × log(1+2)
tante que l’autorité de C sur ce même topic qui est égale à 2
log(1+2).
Plus globalement, la pertinence sémantique des arêtes sur le chemin p1 par
rapport à technology est plus élevée que celle des arêtes sur p2 ce qui mène
à ce que que le nœud D obtienne un meilleur score de recommandation que
le nœud E.

3 × log(1+2)

Il est important de souligner que la déﬁnition du score de recomman-
dation implique aussi que nous pouvons déduire le score d’un chemin ωp(t)
pour un chemin p = u (cid:32) v de longueur |p| à partir du score ω0
p(t) de son
préﬁxe p0 de longueur |p−1| et du score de pertinence de l’arête ﬁnale εe(t) :

ωp(t) = β.ωp0(t) + βn.αn.εe(t).auth(end(e), t)

Par induction, nous déduisons la propriété de composition suivante que
nous allons exploiter dans l’estimation des scores de recommandation (voir
section 5.4.3).

Proposition 1 (Composition de scores) En supposant un chemin p =
p1.p2, avec ωp1(t) et ωp2(t) les scores de chemins de p1 et p2 pour un topic
t. Le score du chemin p est :

ωp(t) = β|p2|.ωp1 + β|p1|.α|p1|.ωp2

Notre score de recommandation peut être considéré comme une exten-
sion du score de Katz aﬁn de considérer les intérêts des followers (exprimés
sous forme d’arêtes étiquetés dans le LSG) et le score d’autorité par rapport
au topic d’intérêt pour chacun des utilisateurs présents sur le chemin.

5.3.2 La convergence du calcul des scores

La présence de cycles dans le graphe peut nous mener à considérer un
nombre inﬁni de chemins. En conséquence, les approches basées sur le score
de Katz supposent soit la convergence des scores de chemin, soit l’existence
d’un seuil pour les scores des chemin en dessous duquel les chemins sont

77

Chapitre 5. Recommandation de comptes

écartés du calcul (pruning). En utilisant une représentation matricielle, les
scores de Katz entre toutes les paires de nœuds du graphe peuvent s’exprimer
comme suit :

∞X

i=1

Kβ =

βiAi = (I − βA)−1 − I

Où A représente la matrice d’adjacence pour le graphe social dirigé et
Ak[i, j] le nombre de chemins de longueur k entre i et j. Dans ce qui suit,
nous faisons référence à Kβ pour la matrice de Katz avec le facteur de dé-
croissance β.

De cette notation matricielle, le vecteur des scores de Katz Kβ(n) pour

un nœud n peut être calculé grâce à la formule récursive suivante :

(k+1)
K
β

(n) = A.K

(k)
β (n) + B

où B est un vecteur pour qui B[n] = 1 et {B[x] = 0,∀x 6= n} (voir [Bonchi
et al., 2012]).

En se basant sur la Proposition 1, notre calcul de score pour un chemin
p.e où e est une arête et p un chemin de longueur |p| s’exprime alors de la
façon suivante :

ωp.e(t) = β.ωp + β|p|.α|p|.ωe = β.ωp + β|p|.α|p|.εe(t).auth(end(e), t)
Dès lors, notre score de recommandation d’un nœud n vers tout autre
nœud du graphe social pour un topic t peut s’exprimer de manière récursive
comme suit :

R(k+1)(t) = (β.A).R(k)(t) + (αβ.A).S(t).K

(k)
αβ (n)

où S est une matrice contenant le produit des scores de similarité et

d’autorité, déﬁnie par S[i, j] = sim(maxt0∈topics(i,j)(t0, t)) × auth(j, t).

Il a été démontré que le calcul du score de Katz Kβ converge lorsque
β < 1/σmax(A) où σmax(A) est la valeur propre la plus élevée dans A
(voir
[Bonchi et al., 2012]). Se basant sur ce résultat, nous déduisons la
condition de convergence suivante :

Proposition 2 (Convergence du calcul de score) Si β < 1/σmax(A),
alors le calcul itératif de notre score de recommandation converge.

78

Chapitre 5. Recommandation de comptes

(k)
Preuve 1 K
αβ converge si α.β < 1/σmax(A) (un calcul de score de Katz
avec un facteur de décroissance α.β). En considérant l’étape k0 comme l’étape
à laquelle la convergence est atteinte. Alors, pour chaque k > k0, nous avons
(∞)
le calcul récursif R(k+1)(t) = (β.A).R(k)(t)+C avec C = (αβ.A).S(t).K
αβ (n)
constant. La convergence pour R(k+1)(t) est atteinte quand R(∞)(t) = (β.A).R(∞)(t)+
C dès lors quand R(∞)(t) = (I − β.A)−1 × C. Ceci peut être atteint si
β < 1/σmax(A). Sachant que β > αβ, cette condition est alors suﬃsante
pour assurer la convergence.

Le score de recommandation basé sur Katz présenté suppose l’explora-
tion de tous les chemins à partir du nœud pour lequel les recommandations
sont générées. Aﬁn de générer des recommandations à la volée pendant l’exé-
cution, nous proposons un algorithme basé sur une approche par landmarks
en deux étapes :

— (i) une étape de pré-traitement qui calcule les recommandations pour
un ensemble de nœuds, pour chaque topic du vocabulaire des topics.

— (ii) une approximation en temps-réel, au moment de la requête, du
calcul des recommandations pour un nœud sur un topic donné en
exploitant les données pré-calculées.

5.4 Une estimation eﬃcace des recommandations
5.4.1 Vue d’ensemble de l’approche basée sur les landmarks
Dans notre contexte, la taille du graphe social rend diﬃcile le calcul eﬃ-
cace de recommandations basées sur des propriétés topologiques. En suppo-
sant comme candidats à la recommandations tous les nœuds atteignables en
moins de K sauts à partir du compte à recommander. La taille de l’ensemble
des candidats est (dans le pire de cas) égale à N K (pour un graphe complet)
et outK
avg dans le cas moyen où outavg représente le nombre moyen de nœuds
suivi par un compte sur le réseau. Aﬁn de contourner cette limitation, notre
idée est d’adopter une approche par landmarks aﬁn d’évaluer eﬃcacement
les recommandations.

Nous pré-calculons donc, pour un échantillon de nœuds choisis dans le
graphe (landmarks), un top-k de recommandations (k étant un paramètre

79

Chapitre 5. Recommandation de comptes

pré-établi par le système) sur chacun des topics t ∈ T . Puis, pendant l’exé-
cution, aﬁn de déterminer les recommandations pour un compte n, nous
explorons le graphe autour de n jusqu’à une profondeur k < K, où K est
la profondeur d’exploration pour un calcul à la convergence. Après avoir
récolté toutes les recommandations des diﬀérents landmarks rencontrés pen-
dant l’exploration, celles-ci sont pondérées en se basant sur notre score de
recommandation entre n et les landmarks. Une fusion des diﬀérents résultats
obtenus permet d’obtenir les recommandations ﬁnales pour n.

Figure 5.2 – Exemple de recommandation par landmarks

La Figure 5.2 illustre notre approche, n est le nœud pour lequel nous
calculons les recommandations, λ1, λ2, λ3 et λ4 sont des landmarks. En ex-
plorant le graphe en eﬀectuant un BFS (Breadth-First-Search 3, représenté
par la ligne blue en pointillés) à partir de n, seulement λ1, λ2 et λ4 ont été
rencontrés. Si l’on observe les recommandation générées, nous remarquons
que r1 n’as pas été rencontré durant l’exploration. Son score est le résultat
de la combinaison des scores obtenus à travers les chemins n − λ1 − r1 et
n − λ2 − r1. Le score de r2 est quant à lui le résultat de la combinaison
des scores n − λ1 − r1 et n − λ2 − r1 avec le score du chemin à distance

3. http://fr.wikipedia.org/wiki/Algorithme_de_parcours_en_largeur

80

nr4r3r2r1λ1λ2λ3λ4Chapitre 5. Recommandation de comptes

2 pour n − λ2 car il a été croisé durant le BFS. On remarque aussi que la
recommandation r4 a été générée uniquement grâce au landmark λ2.

A noter que cette approche estime une borne inférieure des diﬀérents
scores de recommandation proposés. Généralement, les approches basées
sur les landmarks dans un contexte de calcul de plus court chemin (voir sec-
tion 2.5) sont utilisées pour l’estimation d’une borne supérieure en exploitant
l’inégalité triangulaire. La raison est la suivante : lorsqu’un landmark λ re-
commande un compte n2 à compte n1, le calcul considère l’ensemble P1 de
tous les chemins entre n1 et λ de longueur inférieure à k1 ainsi que l’en-
semble P2 de tous les chemins existants entre λ et n2 de longueur inférieure
à k2. Cependant l’ensemble P1,2 = {pi.pj|pi ∈ P1 ∧ pj ∈ P2} est inclus dans
l’ensemble de tous les chemins existants entre n1 et n2 de longueur inférieure
à k1 + k2.

5.4.2 Pré-traitement

Dans l’étape de pré-traitement, nous supposons un sous-ensemble L ⊂ N
de nœuds, appelés landmarks tel que |L| (cid:28) |N|. En plus d’un échantillon-
nage aléatoire, diﬀérentes stratégies de sélection peuvent êtres établies aﬁn
de déterminer l’ensemble L. Par exemple, les stratégies basées sur les land-
marks dans un contexte de calcul de plus court chemin se basent essentielle-
ment sur des propriétés de “Centralité” des nœuds (Centralité d’intermédia-
rité ou de proximité 4) aﬁn de choisir les landmarks. Les caractéristiques de
notre graphe social dirigé ainsi que le double rôle des utilisateurs (publishers,
followers) nous permettent d’envisager d’autres stratégies de sélection ba-
sées sur la topologie. Parmi ces stratégies on retrouve le choix des nœuds
ayant le plus fort degré entrant (comptes les plus populaires sur le réseau) ou
bien les nœuds qui suivent le plus grand nombre de comptes (les lecteurs les
plus actifs). On peut aussi mettre en place des contraintes pour maximiser
la couverture comme par exemple obliger les landmarks choisis à respecter
une distance minimale entre eux.

Le choix de la stratégie de sélection de landmarks impacte la qualité
ainsi que les performances globales du système de recommandation. Nous
avons testé et comparé un ensemble de stratégies expérimentalement en Sec-
tion 5.5.

4. http://fr.wikipedia.org/wiki/Analyse_des_réseaux_sociaux

81

Chapitre 5. Recommandation de comptes

Pour chaque landmark λ ∈ L, nous eﬀectuons une exploration du type
BFS sans éviter les cycles. Nous appelons l’ensemble des nœuds atteints
à la profondeur k à partir de λ le k-voisinage de λ noté Υk(λ). Υ∞(λ) dé-
signe l’ensemble de tous les nœuds atteignables à partir de λ. Nous calculons
pour chaque nœud n ∈ Υ∞(λ) un vecteur de recommandation Rλ,n tel que
Rλ,n[t] = σ(λ, n, t) ainsi qu’un score de connectivité katzβ(λ, n). Le score
σ(λ, n, t) est le score de du landmark λ pour le compte n sur le topic t, et
katzβ(λ, n) représente le score de Katz présenté dans en Section 5.3.1 avec
un facteur de décroissance β, utilisé par la suite aﬁn d’estimer le score de
recommandation ﬁnal.

Notre algorithme eﬀectue une “fusion” des diﬀérents Rλ,n pour tout
n ∈ Υ∞(λ) aﬁn d’obtenir une posting list Rλ pour laquelle chaque entrée
Rλ[t] qui correspond à un terme t est associé une liste de nœuds recom-
mandés, classés par pertinence en fonction de leur score de recommandation
σ(λ, n, t). Nous gardons dans ces listes uniquement un top-k des recomman-
dations calculées.

L’algorithme 1 eﬀectue le calcul des scores de recommandation (nous
avons omis les diﬀérentes initialisation à 0 par soucis de simpliﬁcation). Les
paramètres utilisés sont le facteur de décroissance choisi pour la fonction de
Katz ainsi que la profondeur maximale pour notre exploration BFS. Cette
valeur est utilisée par l’étape de BFS pour le nœud qui pose la requête de
recommandation (voir Algorithme 2). Pour les landmarks, étant donné le
fait que la calcul se fait jusqu’à la convergence, cette valeur n’est pas utile
dans ce contexte et peut être initialisée à une valeur importante (∞).

Pour un landmark donné, cet algorithme est appelé avec en paramètre
l’ensemble de topics T . Les itérations en ligne 2 permettent d’explorer le k-
voisinage de λ. A chaque itération, nous ajoutons au k-voisinage les nœuds
atteignables avec un saut additionnel (l. 3-4). Pour tous les nœuds atteints
à cette étape (l. 5), nous calculons le score de recommandation pour chacun
des termes du vocabulaire des topics (si ce nœud à déjà été rencontré, nous
mettons à jour cette valeur) (l. 6-7) ainsi que le score de Katz pour m (l. 9).
Par la suite, nous mettons à jour le score de recommandation pour n (l. 11)
et son score de Katz (l. 12). Un test de convergence est eﬀectué en lignes 14-
20 (la diﬀérence entre deux étapes doit varier de moins d’une certaine valeur
ν). Lorsque tous les vecteurs ﬁnissent par converger, l’algorithme retourne
les listes de recommandations pour chaque topic ainsi que le score de Katz
en ligne (l. 23).

82

Chapitre 5. Recommandation de comptes

Algorithm 1: Landmark_Recomm(k, β)
Require: une longueur de chemin maximale k, un facteur de décroissance β.
Ensure: un ensemble de listes de recommandations R, un vecteur de connectivité

katzβ

σ(i+1)(λ, m, t) = σ(i+1)(λ, n, t) + β × σ(i)(λ, n, t) + βi+1.αi+1.εn,m(t))
end for
(i+1)
katz
β
end for
(i+1)
λ,n [t] = Rλ,n[t] + σ(i)(λ, n, t)
R
katzβ(λ, n)(i+1) = katzβ(λ, n) + katz

(λ, m) + β × katz

(λ, m) = katz

(i)
β (λ, n)

(i+1)
β

(i)
β (λ, n)

for all t ∈ T do

for all n ∈ Υi do

i := 0, converged := f alse

Υi+1 := Υi+1 ∪ Γ+(n)
for all m ∈ Γ+(n) do

1: Υ0 := λ,
2: while i < k and converged = f alse do
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
end if
20:
end for
21:
i := i + 1
22:
23: end while
24: return for all t ∈ T top_recommendations(Rλ,n[t]), katzβ(λ, n))

end for
if |katzβ(λ, n)(i+1) − katzβ(λ, n)(i)|/katzβ(λ, n)(i+1) < ν then
end if
for all t ∈ T do
if |R
λ,n [t] − R
(i+1)

(i)
λ,n[t] < ν then

converged := true

λ,n[t]|/R
(i)

converged := true

5.4.3 Approximation rapide des recommandations

Nous présentons dans cette section l’algorithme réalisant l’estimation des
score de recommandation à l’arrivée d’une requête, pendant l’exécution, en
se basant sur les calculs qui ont été eﬀectués pour chaque landmark à l’étape
de pré-traitement. Nous supposons que nous devons générer les recomman-
dations de comptes à suivre pour un compte n sur un topic t.

Le traitement commence par une exploration BFS à partir du nœud n

83

Chapitre 5. Recommandation de comptes

similaire à celle eﬀectuée dans l’étape de pré-traitement (voir Section 5.4.2)
pour une profondeur d’exploration maximale k. L’objectif de ce BF S est
triple : (i) l’exploration du voisinage de n et la découverte des landmarks
les plus proches, (ii) le calcul des scores de chemins pour le topic t pour
les chemins existants entre n et chaque landmark découvert et (iii) la mise
à jour des scores de recommandation stockées par les landmarks en tenant
compte des chemins entre n et les landmarks.

Aﬁn de déﬁnir notre score, nous supposons Λ ⊆ L l’ensemble des land-
marks trouvés par le BFS et Rλ la posting list contenant les recomman-
dation pour chaque λ ∈ Λ. Chaque Rλ contient pour chaque topic t une
liste des comptes recommandés Nrecomm associés à leur score de recomman-
dation Rλ,n[t] = σ(λ, n, t) et leur score de Katz katzβ(λ, n) pour chaque
n ∈ Nrecomm. Nous supposons aussi Pa,b comme étant l’ensemble des che-
mins à partir d’un nœud a vers un nœud b et Pa,b,c l’ensemble des chemins
partants d’un nœud a vers un nœud c qui passent à travers le nœud b. Se ba-
sant sur les landmarks, nous déﬁnissons le score de recommandation comme
suit :

Déﬁnition 3 (L’approximation du score de recommandation) Le sc-
topic t via un landmark λ, noté eσ(m, λ, n, t), correspond au score cumulé de
ore de recommandation approché d’un nœud n ∈ N pour un nœud m sur un

tous les chemins de Pm,λ,n.

La valeur de ce score de recommandation approché est donné par la pro-

position suivante :

Proposition 3 (Calcul approché du score de recommandation)

eσ(m, λ, n, t) = σ(m, λ, t).katzβ(λ, n) + katzβ.α(m, λ).σ(λ, n, t)

Preuve 2 Chaque chemin p de Pm,λ,n peut être décomposé en deux sous-
chemins p1 et p2 tel que p1 ∈ Pm,λ et p2 ∈ Pλ,n. Aussi, il est évident que
chaque chemin p = p1.p2 tel que p1 ∈ Pm,λ et p2 ∈ Pλ,n est un chemin de
Pm,λ,n. Par conséquent, en se basant sur la proposition 1, nous avons :

84

Chapitre 5. Recommandation de comptes

eσ(m, λ, n, t) = X
= X
β|p2|.ωp1(t) + β|p1|.α|p1|.ωp2(t)
X
= X
(β.α)|p1|.

β|p2| + X

p2∈Pλ,n
ωp1(t).

X

p∈Pm,λ,n

p1∈Pm,λ

ωp(t)

p1∈Pm,λ

p2∈Pλ,n

p1∈Pm,λ

X

p2∈Pλ,n

ωp2(t)

= σ(m, λ, t).katzβ(λ, n) + katzβ.α(m, λ).σ(λ, n, t)

Nous eﬀectuons le calcul de notre score de recommandation approché
pour un nœud n et un topic t en appliquant l’algorithme 2. Nous utilisons
l’algorithme Landmark_Recomm aﬁn de calculer les score de recomman-
dation et les scores de Katz pour n vers tous les nœuds atteignables à dis-
tance k (l. 1). En pratique, les recommandations sont calculées pour un seul
topic. Le facteur de décroissance utilisé dans ce cas est β.α. Pour tous les
landmarks rencontrés durant l’exploration, nous combinons leurs scores de
recommandation pour t avec le score calculé à partir de n vers les landmarks
comme décrit dans la Proposition 3 (l. 5).

Algorithm 2: Approx_Recomm(n, k, t, β, α)
Require: un nœud n, une profondeur max. de BFS k, un topic t, un facteur de

Ensure: une liste triée de recommandations fRn pour n

décroissance pour les chemins β et pour les arêtes α.

for all o ∈ Rm[t] do

1: (Rn, katzβ.α(n)) ←Landmark_Recomm(G, n, k, t, β.α)
2: for all m ∈ Rn do
if m ∈ L then
3:
4:
5:
6:
end if
7:
8: end for

fRn := M erge(fRn, (o, σ(n, m, t).katzβ(m, o) + katzβ.α(n, m).σ(m, o, t)))

end for

9: return fRn

Après avoir déﬁni les diﬀérentes composantes du score de recommanda-
tion proposé, une étape de validation expérimentale est nécessaire aﬁn de
tester nos hypothèses.

85

Chapitre 5. Recommandation de comptes

5.5 Expérimentations

Dans cette section, nous décrivons les expérimentations que nous avons
conduites aﬁn de valider notre approche de recommandation sur le jeu de
données “Twitter 400k” issu du réseau Twitter. Ce jeu de données est décrit
de manière détaillée en Section 3.6.

5.5.1

Implantation

Notre système de recommandation a été implanté en JAVA (JVM 1.7).
Les diﬀérentes expériences ont étés réalisées sur un serveur 64-bit avec un
processeur de 10 cœurs du type Intel Xeon à 2.20GHz et 128 Go de mémoire
centrale. Le serveur utilise un système d’exploitation Linux avec un Kernel
version 3.11.10.

Nous avons implanté nos index en exploitant une structure de listes in-
verses issue du travail réalisé sur le ﬁltrage (voir Chapitre 4). Étant donné
la surcharge induite par la JVM (Java Virtual Machine), nous avons fait le
choix de nous baser sur des structures de données basiques (Entiers sur 32
bits, tableaux) aﬁn d’améliorer l’aptitude au passage à l’échelle de notre sys-
tème en terme d’espace occupé et de temps d’exécution. Nous avons appliqué
les mêmes choix de conception pour l’implantation des stratégies concur-
rentes.

Pour plus d’eﬃcacité, nous avons pré-calculé et stocké les scores de si-
milarité sémantique (basés sur la mesure de Wu and Palmer calculée sur
WORDNET 3.0) dans une matrice de similarité maintenue en mémoire cen-
trale. Cette matrice triangulaire a été stockée sous la forme d’un tableau
avec une fonction d’accès spéciﬁque aﬁn d’optimiser le stockage et de per-
mettre la gestion éventuelle de vocabulaires de topics volumineux. Même
si, dans le jeu de données utilisé, les 18 topics standards résultent en une
matrice de similarité de 2.5 Ko, un vocabulaire de 10.000 topics nécessiterait
moins de 750Mo et pourrait donc tenir aisément en mémoire centrale.

Les recommandations calculées par les landmarks sont elles aussi in-
dexées sous forme de listes inverses : pour chaque landmark est associé l’en-
semble de nœuds recommandés ainsi que leur score de recommandation pour
chaque topic de T . Les landmarks sont choisis en appliquant les stratégies
de sélection listées dans le tableau 5.2.

86

Chapitre 5. Recommandation de comptes

5.5.2 Qualité des recommandations

Aﬁn d’estimer la qualité des recommandations générées par notre sys-
tème, nous adoptons la méthodologie décrite par [Cremonesi et al., 2010] :

i) Nous construisons un ensemble candidat de T comptes en retirant

des arêtes du graphe d’après une stratégie de sélection d’arêtes ;

ii) Pour chaque compte i de l’ensemble candidat sont choisis aléatoire-

ment 1000 comptes du graphe social ;

iii) Le système calcule les recommandations des 1001 comptes (1000
comptes choisis + compte de l’ensemble candidat) et génère une liste
triée L ;

iv) Lorsque le compte de l’ensemble candidat appartient au top-N de L

nous comptabilisons un succès (hit), sinon un échec.

v) L’itération sur l’ensemble-candidat se poursuit.

La mesure de précision (resp. rappel) que nous utilisons est décrite
par [Cremonesi et al., 2010] par la formule #hits/N.T (resp. #hits/T).
Pour nos expérimentations, la taille de l’ensemble candidat a été initiali-
sée à T = 100 et les valeurs considérées sont les moyennes calculées sur 10
essais successifs. Nous comparons la qualité des recommandations générées
avec les résultats produits par deux autres approches : la mesure standard
de Katz [Liben-Nowell and Kleinberg, 2003] qui est strictement topologique,
et TwitterRank [Weng et al., 2010] qui considère, en plus de la topologie,
une similarité entre les comptes sur des topics donnés.

La valeur choisie pour le facteur de décroissance β pour Katz et notre
proposition RecLand est de 0, 0005. Il a été reporté par [Liben-Nowell and
Kleinberg, 2003] que cette valeur permet d’obtenir de bons résultats sur les
graphes issus du Web. La valeur des coeﬃcients α et β pour TwitterRank
à été initialisée à 0.85 comme indiqué par [Weng et al., 2010]. Les résultats
présentés ont été obtenus à la convergence.

La Figure 5.3 illustre la performance des trois systèmes de recomman-
dation pour des arêtes choisies aléatoirement lors de la construction des
ensembles-candidats. Nous pouvons observer que TwitterRank est distancé
par les deux autres algorithmes. En eﬀet, seulement 4% des recommanda-
tions générées avec TwitterRank apparaissent dans le top-1. Ce taux est de
13% pour Katz et 30% pour RecLand. Il apparait donc que notre approche
apporte un gain de respectivement 7.5 et 2.3 par rapport à Katz et Twitter-

87

Chapitre 5. Recommandation de comptes

Rank sur le top-1. Sur un top-10, ce gain demeure signiﬁcatif avec des gains
respectifs de 4, 1 et de 1, 2 de RecLand par rapport à respectivement Katz
et TwitterRank.

La Figure 5.4 conﬁrme le fait que RecLand fournit de meilleures recom-
mandations. En eﬀet, pour une même valeur de rappel, nous observons que
la précision de notre approche est au minimum le double de celle obtenue
par Katz et de plus d’un ordre de grandeur plus élevée que celle obtenue par
TwitterRank. Par exemple, pour une valeur de rappel de 0, 3, RecLand
oﬀre une précision de 0, 3 lorsque Katz est à 0, 09 et TwitterRank à 0, 01.

Figure 5.3 – Rappel à N

Cependant, on observe la présence d’une grande disparité lorsque que
l’on considère les résultats sur les deux dimensions d’analyse qui sont : la
stratégie de sélection des arcs à retirer et la popularité du topic sur lequel
générer les recommandations.
Sur un top-10, la Figure 5.5 montre une faible valeur de rappel pour notre
stratégie lorsqu’on génère des recommandations pour un compte qui a moins
de 10 followers. En parallèle, les comptes populaires (ayant une valeur de
degré entrant supérieure à 100) sont la plupart du temps présents dans le
top-10 des recommandations générées avec une valeur de rappel oscillant
entre 0, 8 et 0, 9. Ce phénomène s’explique par l’approche topologique adop-

88

Chapitre 5. Recommandation de comptes

Figure 5.4 – Précision VS rappel

tée qui est basée sur l’existence de chemins, les comptes ayant un grand
nombre de chemins entrants voient ainsi leur score augmenter.

Il apparait aussi que TwitterRank obtient le meilleur résultat pour les
comptes très populaires. En eﬀet, la plupart des comptes populaires sont
étiquetés par plusieurs topics. Tandis que TwitterRank se base sur la pré-
sence ou l’absence d’un topic sans prendre en compte le nombre d’étiquettes
sur les arcs entrants, notre score s’appuie sur le nombre d’étiquettes aﬁn de
déterminer l’autorité d’un compte. Dans ce cas, la présence de plusieurs arcs
entrants avec des topic diﬀérents entraine une diminution du score d’auto-
rité du compte pour un topic donné. Inversement, un compte avec moins de
10 followers a rarement des topics diﬀérents sur ses arcs entrants. Notre ap-
proche qui consiste à considérer les topics sur les chemins entre les comptes
à recommander et leurs recommandations se montre alors particulièrement
eﬃcace.

En ce qui concerne le degré sortant des comptes pour lesquels les arcs
sont retirés, on observe que TwitterRank obtient un meilleur résultat avec
les comptes ayant un faible degré sortant (suivant peu de comptes). La rai-
son est que le fait de retirer un arc sur un compte déjà peu connecté au
réseau peut entrainer la déconnexion (complète ou partielle) d’une partie
du graphe. Comme Katz et RecLand se basent sur le nombre de chemins

89

Chapitre 5. Recommandation de comptes

communs, cela peut avoir un impact important sur les scores ﬁnaux. De ma-
nière opposée, les comptes suivant plus 1000 autres comptes oﬀrent un grand
nombre de chemins alternatifs pour atteindre les comptes recommandés.

Figure 5.5 – Rappel suivant la stratégie de suppression d’arêtes

Étant donné la distribution biaisée des topics dans le graphe social (voir
Figure 3.5 en Section 3.6), nous avons décidé d’étudier l’impact de la popula-
rité d’un topic sur les recommandations générées. Les résultats sont illustrés
en Figure 5.6 pour les topics social, leisure et technology.

Deux observations apparaissent à la lecture des résultats de cette expé-
rience. Premièrement, les meilleurs valeurs de rappel sont obtenues pour les
topics les moins populaires. Par exemple, pour un topic peu fréquent comme
social, nous obtenons une valeur de rappel pour les 10 premières recom-
mandations (top-10) de 0, 959 pour RecLand, 0, 751 pour Katz et 0, 253
pour TwitterRank. Inversement, pour un topic populaire tel que technology,
nous obtenons respectivement 0, 462, 0, 424 and 0, 09. En eﬀet, pour un to-
pic populaire, plusieurs comptes sont découverts dans un voisinage proche
du compte pour lequel les recommandations sont générées avec potentielle-
ment de meilleurs scores que les comptes des arcs retirés, ce qui explique le
fait que la valeur absolue du rappel baisse. En second lieu, nous observons
que notre approche, RecLand, surpasse les approches concurrentes dans les
trois cas de ﬁgures (topic populaire, à popularité moyenne, et peu populaire).

90

Chapitre 5. Recommandation de comptes

Figure 5.6 – Rappel suivant la popularité des topics

L’ensemble des expériences présentées ci-dessus permet de tester la capa-
cité des algorithmes à prédire les nouveaux liens crées sur le réseau. Aﬁn de
valider l’aspect qualitatif des recommandations générées nous avons soumis
les 3 approches concurrentes à une étape de validation par les utilisateurs.

5.5.3 Validation par les utilisateurs

Aﬁn d’évaluer la pertinence des recommandations générées, nous avons
conduit une tâche de validation par 54 utilisateurs (étudiants, doctorants et
membres du laboratoire) parmi lesquels 46% se déﬁnissent comme utilisa-
teurs de plateformes sociales tel que Twitter. Nous avons mis en place un
sondage en ligne où les utilisateurs doivent évaluer la pertinence d’un en-
semble de recommandations pour un topic donné sur une échelle de 1 (faible
pertinence) à 5 (forte pertinence).

Un ensemble de recommandations à évaluer est constitué par le top-3
des recommandations générées respectivement par Katz, TwitterRank ainsi
que RecLand. Nous avons donc 9 comptes recommandés pour les topic
Technology, Social et Leisure. Sur l’interface du sondage en ligne, la liste
des recommandations est triée aléatoirement, et pour chaque recommanda-

91

Chapitre 5. Recommandation de comptes

tion est aﬃchée une liste de 5 publications (tweets), choisies aléatoirement
parmi les publications du compte recommandé. La Figure 5.7 illustre un
aperçu de l’interface de notre système d’évaluation.

Figure 5.7 – Extrait de l’interface du système d’évaluation pour le topic
Technology

Figure 5.8 – Scores de pertinence obtenus par la validation par les utili-
sateurs

La Figure 5.8 présente les résultats de notre sondage. Ces résultats
montrent que RecLand et TwitterRank fournissent les recommandations
les plus pertinentes. Cependant, selon la popularité du topic pour lequel les
recommandations sont générées, des diﬀérences apparaissent. Par exemple,
on observe que le topic social oﬀre des résultat homogènes avec des scores
oscillant entre 2, 7 pour TwitterRank, 2, 8 pour Katz et 2, 9 pour RecLand.
La raison est que la déﬁnition de ce topic est vaste. En eﬀet les comptes

92

Chapitre 5. Recommandation de comptes

catégorisés social sont souvent des comptes généralistes qui publient sur
plusieurs sujets tandis que les topics leisure or technology sont moins
ambigus.

Pour ces topics, on observe que RecLand et TwitterRank surpassent
Katz, ce qui s’explique par l’avantage que ces approches ont en considé-
rant le contenu publié en plus de la topologie seule. Ainsi RecLand ob-
tient un meilleur score de pertinence sur les topic moyennement populaires
comme leisure grâce à sa capacité à recommander des comptes peu suivis,
mais spécialisés sur un sujet. par contre, sur un sujet très populaire comme
technology, TwitterRank obtient un score légèrement meilleur.

Après avoir testé la pertinence ainsi que la qualité des recommanda-
tions générées, nous avons mis en place des expérimentations qui permettent
d’évaluer le gain apporté par notre approche par landmarks.

5.5.4 Approximation du calcul de recommandations

Nous avons conduit une série d’expériences aﬁn d’illustrer les bénéﬁces de
notre approche basée sur les landmarks pour le calcul approché des scores de
recommandation. Étant donné le fait que les résultats dépendent grandement
du choix des landmarks, comme le montre [Potamias et al., 2009], nous
avons décidé d’implanter et de comparer les recommandations en se basant
sur 11 stratégies de sélection de landmarks diﬀérentes (présentées dans le
Tableau 5.2).

Construction des index de landmarks

Cette première expérience met en avant l’écart important qui peut exis-
ter dans la phase de sélection des landmarks. Le Tableau 5.3), illustre les
temps moyen de sélection et de calcul pour un landmark pour chacune des
stratégies de sélection.

Il apparait évident que les stratégies aléatoires telles que Random ou
Btw-Pub sont les plus rapides (≈ 1ms par landmark) tandis que les straté-
gies basées sur la mesure de centralité sont 4 ordres de grandeurs plus lentes
avec des temps moyens variant entre 30 et 60s (en raison de la complexité
de l’ordre de O(N 2. log N + N E) de la mesure de centralité en appliquant
l’algorithme de [Johnson, 1977]). Le tableau 5.3 illustre aussi les temps né-

93

Chapitre 5. Recommandation de comptes

Algorithme Description
Random
Follow

entre

Btw-Fol

Out-Deg

Publish

In-Deg

landmarks avec # de followers

Choix des landmarks avec une distribution uniforme
Sélection des landmarks grâce à une probabilité dépendant
de leur # de followers
Sélection des landmarks grâce à une probabilité dépendant
du # de comptes qu’ils suivent
Landmarks choisis parmi les nœuds ayant le plus grand de-
gré entrant
Sélection des
[min_follow, max_follow]
Landmarks choisis parmi les nœuds ayant le plus grand de-
gré sortant
Sélection des landmarks avec # de comptes suivis entre
[min_publish, max_publish]
Les landmarks sont les nœuds atteignables à une certaine
distance à partir d’un ensemble de nœuds “seeds”
Les landmarks sont les nœuds qui atteignent le plus de
nœuds d’un ensemble de “seeds”
Combine
Combinaison pondérée de Central et Out-Cen
Combine2 Combinaison pondérée de Btw-Fol et Btw-Pub
Table 5.2 – Algorithmes de sélection de Landmarks

Btw-Pub

Central

Out-Cen

cessaires au calcul des tables de recommandation pour chaque landmark.
Nous pouvons observer que ce calcul est indépendant de la stratégie de sé-
lection ce qui signiﬁe que la convergence est atteinte en un nombre similaire
d’itérations et en explorant un nombre similaire de chemins.

Comparaison des stratégies de sélection de landmarks

Dans cette expérience, nous évaluons la stratégie de sélection de land-
marks présenté en Section 5.4.3. Nous eﬀectuons une exploration BFS à
profondeur 2 depuis un nœud donné puis nous combinons les scores obte-
nus avec les scores des landmarks découverts en appliquant l’algorithme 2.
Nous comparons ensuite les recommandations obtenues par le calcul appro-
ché avec celles calculées à la convergence. Les résultats moyens pour 100
landmarks sont reportés sur le tableau 5.4.

D’abord, nous observons que le nombre de landmarks rencontrés pendant
l’exploration BFS à distance 2 varie d’une stratégie à l’autre allant de 7, 3

94

Chapitre 5. Recommandation de comptes

Stratégie
Random
Follow
Publish
In-Deg
Btw-Fol
Out-Deg
Btw-Pub
Central
Out-Cen
Combine
Combine2

Landmarks

sélection. (ms)
0.6
179.0
172.4
62.9
7.5
60.4
1.7
30,603.0
33,193.1
65,223.1
67,382.0

calcul. (s)
27.0
30.1
29.9
31.3
31.8
30.4
29.7
29.1
27.8
27.3
28.3

Table 5.3 – Temps moyen de sélection et de calcul pour un landmark par
stratégie de sélection

en moyenne pour les stratégies de type Combine à 25, 4 pour la stratégie
Out-Deg. Les mesures basées sur la centralité aﬃchent le moins de land-
marks trouvés. Ceci est du au fait que ces mesures choisissent les landmarks
parmi les nœuds qui forment des “ponts” entre des composantes connexes
du graphe et donc plus diﬃcilement atteignables par une exploration à pro-
fondeur 2.

Il apparait aussi que le temps de traitement est inversement proportion-
nel au nombre de landmarks trouvés, ce qui peut sembler contre-intuitif
étant donné que plus de calculs (combinaisons de scores) sont exécutés s’il
y a un nombre important de landmarks. L’explication réside dans le fait
qu’un “pruning” est eﬀectué à la rencontre d’un landmark pendant le BFS
c.à.d que les chemins qui passent par un landmark ne sont pas considérés
pour l’exploration. Le temps de calcul étant largement dominé par l’étape
d’exploration, ce choix de pruning réduit considérablement le temps global
de traitement. Nous observons que le calcul approché permet un gain allant
de 2 à 3 ordres de grandeurs en comparaison avec l’approche exacte.

Les 3 dernières colonnes du Tableau 5.4 aﬃchent les valeurs de distance
de Kendall Tau entre les résultats obtenus par la méthode approchée et la
méthode exacte (à la convergence) lorsque les landmarks stockent respec-
tivement les top-10, top-100 et top-1000 recommandations. La distance de

95

Chapitre 5. Recommandation de comptes

Stratégie
Random
Follow
Publish
In-Deg
Btw-Fol
Out-Deg
Btw-Pub
Central
Out-Cen
Combine
Combine2

#lnd Temps en ms (gain)
(225)
11.0
(599)
17.8
(449)
14.9
25.0
(899)
(216)
20.8
(770)
25.4
(225)
12.7
13.6
(225)
(284)
8.8
(300)
7.3
10.5
(245)

24
9
12
6
25
7
24
24
19
18
22

L10
0.130
0.377
0.349
0.523
0.061
0.518
0.129
0.134
0.172
0.180
0.129

L100 L1000
0.125
0.124
0.096
0.140
0.100
0.136
0.149
0.066
0.058
0.059
0.064
0.147
0.123
0.127
0.123
0.125
0.121
0.131
0.118
0.125
0.126
0.124

Table 5.4 – Comparaison des stratégies de sélection de landmarks

Kendall Tau 5 est une mesure utilisée aﬁn de comparer deux listes classées.
Plus cette valeur est importante, plus les classements comparés sont dissimi-
laires. Nous observons par exemple que les stratégies Out-Deg et In-Deg
présentent des résultats similaires par rapport à la méthode exacte. En ef-
fet, il apparait que les top-100 comptes recommandés par les deux stratégies
sont très similaires.

Le fait de garder le top-1000 recommandations permet d’atteindre des
valeurs de distance de Kendall Tau oscillant entre 0, 06 et 0, 13. En eﬀet, un
classement de 1000 compte ne va pas être très impacté par une exploration
à la convergence. Par contre, on observe qu’un top-10 va quant à lui im-
pliquer des valeurs de Kendall Tau plus importantes car un classement sur
10 comptes seulement va être fortement impacté par une exploration plus
approfondie (à la convergence).

Aussi, on remarque que pour les landmarks ayant un fort degré sortant
(la distribution de degrés en Figure 3.3 révèle que ce sont aussi ces mêmes
comptes qui ont un fort degré entrant) les listes à top-10 varient grandement
de l’approche exacte. Ceci est du simplement au fait que ces comptes sont
capables d’atteindre très vite (à saut 1 ou 2) un très grand nombre de nœuds .

Enﬁn, il important de noter que, même en gardant les top-1000 recom-
mandations pour chaque topic, l’espace occupé par l’index des recomman-
dations d’un landmark n’est que de 1,4 Mo. Nous pouvons donc aisément

5. http://en.wikipedia.org/wiki/Kendall_tau_distance

96

Chapitre 5. Recommandation de comptes

gérer les tables de landmarks en mémoire centrale.

5.6 Conclusion

Nous avons présenté dans ce chapitre RecLand, notre score de recom-
mandation qui intègre la topologie du graphe et les informations séman-
tiques concernant les intérêts des utilisateurs disponibles sur le LSG aﬁn de
recommander des comptes à suivre. Aﬁn de faire face aux éventuels calculs
prohibitifs inhérents aux larges graphes, nous avons proposé une approche
basée sur les landmarks qui nécessite une étape de pré-traitement pour un
ensemble réduit et identiﬁé de nœuds du graphe. Cette approche permet
d’atteindre un gain de 2 à 3 ordres de grandeur en comparaison avec l’ap-
proche exacte. Les expérimentations conduites ainsi que la validation par les
utilisateurs ont permis de démontrer que RecLand surpasse les approches
concurrentes.

Comme pistes d’évolutions, nous envisageons d’abord l’étude de straté-
gies de mises à jour. En eﬀet, comme reporté dans le Chapitre 4, les liens
dans les réseaux sociaux peuvent avoir un cycle de vie très éphémère. La
dynamicité du graphe impactant directement nos scores, nous avons donc
besoin de mettre en place des stratégies de rafraichissement adaptées.

Enﬁn, nous avons fait le choix de gérer la recommandation de manière
centralisée. Cette décision a été motivée par le fait que pour la manipula-
tion de larges graphes, le coût de la distribution des structure peut très vite
outrepasser le gain induit par l’approche de calcul distribué. Par exemple, le
système de recommandation mis en production pour gérer l’ensemble de la
tâche de recommandation de comptes à suivre chez Twitter est hébergé sur
un seul serveur physique [Gupta et al., 2013]. Cependant, avec la croissance
continue des tailles de graphe, des stratégies intelligentes de distribution
doivent êtres élaborées. Dans notre approche, nous pouvons envisager la
distribution du graphe en prenant en compte la connectivité des diﬀérentes
composantes, mais aussi en combinant la distribution avec la sélection de
landmarks ce qui permettrait d’eﬀectuer les calculs de pré-traitement loca-
lement, minimisant ainsi les transferts sur le réseau.

97

Chapitre 5. Recommandation de comptes

98

Chapitre 6
Conclusion

Le travail présenté dans cette thèse a pour but d’améliorer l’expérience
des utilisateurs des plateformes sociales via l’introduction de deux méca-
nismes complémentaires qui sont le ﬁltrage de ﬂux sociaux ainsi que la
recommandation de comptes à suivre sur le réseau.
Ce chapitre résume les diﬀérentes contributions de cette thèse et se referme
en présentant les perspectives de recherches envisagées pour ce travail.

6.1 Contributions

Après avoir mené une étude de l’existant qui a permis la caractérisation
des données sociales. Nous avons proposé le modèle de LSG (Labelled Social
Graph) qui permet de capturer les intérêts des utilisateurs sous forme de
graphe étiqueté. En se basant sur ce modèle, nous avons ensuite généré di-
vers jeux de données en exploitant des données réelles provenant du réseau
social Twitter.

La quantité de données à laquelle sont exposés les utilisateurs des pla-
teformes sociales ne cesse de croitre. Dans ce contexte, la première contri-
bution de ce travail de thèse est la mise en place d’un système de ﬁltrage
personnalisé pour les systèmes du type micro-blogging nommé MicroFil-
ter [Dahimene et al., 2012,Dahimene and du Mouza, 2013a,Dahimene and
du Mouza, 2013b,Dahimene et al.b].
Nous avons mis en place diverses stratégies d’indexation basées sur des struc-
tures de listes inverses. Chacune des structures proposées exploite une fac-

99

Chapitre 6. Conclusion

torisation spéciﬁque aux données issues des plateformes de micro-blogging.
Après une estimation analytique des diﬀérentes propositions, nous avons
testé expérimentalement ces stratégies de ﬁltrage aﬁn d’analyser leur com-
portement en situation de passage à l’échelle. La validation expérimentale
nous a ensuite orienté sur la piste d’une approche hybride, exploitant ainsi
l’hétérogénéité des données sociales aﬁn d’oﬀrir un compromis intéressant
en terme d’occupation mémoire et de temps de recherche (matching).

Basé sur le même modèle de graphe social étiqueté, la seconde contri-
bution de notre travail consiste en la mise en place d’un système de recom-
mandation de comptes à suivre sur une plateforme de type micro-blogging.
Nous avons appelé ce système RecLand [Dahimene et al., 2014,Dahimene
et al.a].
L’idée principale de cette stratégie de recommandation consiste en l’exploi-
tation de l’ensemble des données implicites au modèle de LSG. Chacune des
arêtes étiquetées représentant l’intérêt d’un utilisateur sur les publications
d’un compte donné, nous avons proposé un score de recommandation de
comptes à suivre axé sur trois dimensions :

(i) Une dimension topologique. En se basant sur l’idée que les mesures
topologiques sur les graphes sociaux sont un bon indicateur de si-
milarité [Liben-Nowell and Kleinberg, 2003], nous avons exploité cet
aspect pour une partie de notre score en proposant une extension du
score de Katz.

(ii) Une dimension sémantique. Chaque arc contenant une information
sur l’intérêt des utilisateurs, nous exploitons cette donnée en mesu-
rant une distance de similarité sémantique.

(iii) Une dimension d’autorité qui permet de mesurer l’inﬂuence d’un
compte sur un sujet (topic) donné en analysant la topologie des arêtes
du graphe autour du compte. Nous avons décomposé cette compo-
sante du score en une mesure d’autorité locale et une mesure d’auto-
rité globale.

L’avantage principal de cette approche est qu’elle permet l’exploitation
d’informations sémantiques sans avoir à analyser le contenu des publications.
Ces informations sont puisées directement dans la structure du graphe LSG.
Aﬁn de pouvoir répondre à la contrainte de passage à l’échelle, nous avons
introduit un algorithme qui permet d’estimer une valeur approchée de notre

100

Chapitre 6. Conclusion

score de recommandation. Cette approche se base sur un ensemble de nœuds
spéciaux appelés “landmarks” qui sont responsable de stocker un ensemble
d’informations sur leur voisinage proche. La recommandation pour un compte
donné s’eﬀectue par la suite en explorant le graphe social jusqu’à une pro-
fondeur ﬁxe, et en combinant les scores de recommandation calculés avec les
scores stockés par les diﬀérents landamrks rencontrés.

Nous avons ensuite validé expérimentalement notre proposition en com-
parant les résultats obtenus par notre stratégie de recommandation avec les
résultats de deux approches concurrentes. Cette validation a aussi été conﬁr-
mée par un sondage eﬀectué sur un ensemble d’utilisateurs. Enﬁn nous avons
évalué expérimentalement l’impact ainsi que le gain introduit par l’approxi-
mation des scores de recommandation en utilisant des landmarks.

6.2 Perspectives

Suite à ce travail, nous envisageons les perspectives de recherche sui-

vantes.

Un ﬁltrage intelligent

Nous avons mis en place une structure qui permet de répondre eﬃca-
cement aux requêtes continues de ﬁltrage lors de l’arrivée d’une nouvelle
publication. Les requêtes utilisées dans ce contexte sont un ensemble de
mots-clés que nous traitons via une logique disjonctive. Une des perspectives
envisagée est de pouvoir gérer le ﬁltrage avec des logiques de requêtes plus
complexes en introduisant la conjonction ou bien la négation. Aussi, nous
pouvons aussi envisager l’exploitation d’une ontologie (telle que Wordnet)
qui permettrait de faire des recherches approchées via une analyse séman-
tique. La réécriture de requêtes est une autre solution envisageable. Le déﬁ
consiste à introduire ces fonctionnalités tout en garantissant le passage à
l’échelle.

La gestion des mises à jour

Les arêtes des graphes sociaux peuvent avoir un cycle de vie très éphé-
mère. En eﬀet, on observe une forte dynamicité dans les structures de graphe

101

Chapitre 6. Conclusion

où les utilisateurs s’abonnent et se désabonnent fréquemment.

Un des déﬁ qui reste ouvert est la gestion eﬃcace de ces mises à jour dans
nos structures d’indexation. Nous avons analysé cet aspect dans un contexte
de ﬁltrage et abouti à une structure hybride. Il reste à étudier l’impact
de telles modiﬁcations sur nos index de recommandation et à élaborer des
stratégies de rafraichissement adaptées. Une approche souvent adoptée en
production consiste à recalculer les mesures périodiquement. On pourrait
envisager une approche plus évoluée en traitant les landmarks séparément
et en mettant à jour uniquement les tables des landmarks concernées par
d’éventuels changements de la topologie du graphe.

La distribution

Aﬁn de pouvoir suivre l’évolution des tailles des graphes sociaux, nous
devons envisager la distribution des données ainsi que des calculs sur des
clusters de plusieurs machines.

Certains travaux existants s’intéressent au problème de la distribution
de graphes. En eﬀet, choisir une subdivision de graphe est un réel déﬁ qui
doit prendre en considération la connectivité du réseau mais aussi mini-
miser le coût des transferts sur le réseau. Dans cette optique, nous nous
intéressons à l’élaboration de stratégies de distribution qui permettraient
d’exploiter notre système de recommandation sur un ensemble de nœuds en
cluster. Nous souhaitons aussi travailler sur une approche qui permettrait
d’introduire du parallélisme dans le calcul des scores de recommandations.
Ce parallélisme pourrait exister entre les nœuds des machines d’un même
cluster, mais aussi sur une même machine en exploitant l’architecture multi-
cœurs des processeurs modernes.

Une granularité plus ﬁne

Actuellement, notre système de recommandation est capable de générer
pour un utilisateur une liste triée par pertinence de comptes à suivre sur un
sujet donné.

Une piste envisagée consisterait à fournir des recommandations au ni-
veau du tweet. L’approche consisterait à proposer un ensemble de publica-
tions jugées pertinentes à un utilisateurs. Deux principaux challenges sont

102

Chapitre 6. Conclusion

introduits par cette approche : (i) La garantie de “fraicheur” des publica-
tions suggérées : en eﬀet, l’aspect temps-réel est une composante principale
des plateforme sociales, le système de devra être capable de fournir des re-
commandations “à la volée”, (ii) Les taux de publication sur les plateformes
sociales peuvent atteindre des pics prohibitifs (plus de 100.000 publications
à la seconde), le système devra être capable de suivre le rythme tout en
répondant eﬃcacement aux requêtes de recommandation.

103

Chapitre 6. Conclusion

104

Annexe A
Captures d’écran de
MicroFilter

Figure A.1 – MicroFilter : Vue d’ensemble

105

Chapitre A. Captures d’écran de MicroFilter

Figure A.2 – MicroFilter : Sélection d’un compte

Figure A.3 – MicroFilter : Paramètres

Figure A.4 – MicroFilter : Flux

106

Annexe B
Captures d’écran de
RecLand

Figure B.1 – RecLand : Vue d’ensemble

107

Chapitre B. Captures d’écran de RecLand

Figure B.2 – RecLand : Sélection d’un compte

Figure B.3 – RecLand : Paramètres

108

Chapitre B. Captures d’écran de RecLand

Figure B.4 – RecLand : Aﬃchage des résultats

Figure B.5 – RecLand : Top-k générés

109

Chapitre B. Captures d’écran de RecLand

Figure B.6 – RecLand : Aﬃchage des Tweets

110

Bibliographie

[Achananuparp et al., 2012] Achananuparp, P., Lim, E.-P., Jiang, J., and
Hoang, T.-A. (2012). Who is Retweeting the Tweeters ? Modeling, Ori-
ginating, and Promoting Behaviors in the Twitter Network. Jour. on
Transactions on Management Information Systems (TMIS), 3(3) :13.

[Adomavicius and Tuzhilin, 2005] Adomavicius, G. and Tuzhilin, A. (2005).
Toward the next generation of recommender systems : A survey of the
state-of-the-art and possible extensions. IEEE Trans. Knowl. Data Eng.,
17(6) :734–749.

[Ahn et al., 2007] Ahn, Y., Han, S., Kwak, H., Moon, S. B., and Jeong,
H. (2007). Analysis of topological characteristics of huge online social
networking services. In Proc. Intl. World Wide Web Conference (WWW),
pages 835–844.

[Albakour et al., 2013] Albakour, M., Macdonald, C., and Ounis, I. (2013).
On sparsity and drift for eﬀective real-time ﬁltering in microblogs.
In
Proc. Intl. Conf. on Information and Knowledge Management (CIKM),
pages 419–428.

[Amatriain, 2013] Amatriain, X. (2013). Big & personal : data and models
behind netﬂix recommendations. In Proceedings of the 2nd International
Workshop on Big Data, Streams and Heterogeneous Source Mining : Algo-
rithms, Systems, Programming Models and Applications, BigMine 2013,
Chicago, IL, USA, August 11, 2013, pages 1–6.

[Anderson, 2006] Anderson, C. (2006). The Long Tail : Why the Future of

Business Is Selling Less of More. Hyperion.

[Backstrom et al., 2012] Backstrom, L., Boldi, P., Rosa, M., Ugander, J.,
and Vigna, S. (2012). Four degrees of separation. In Proc. Intl. Conf. on
Web Science (WebSci), pages 33–42.

[Baeza-Yates and Ribeiro-Neto, 1999] Baeza-Yates, R. A. and Ribeiro-
Neto, B. A. (1999). Modern Information Retrieval. ACM Press / Addison-
Wesley.

111

BIBLIOGRAPHIE

[Bakshy et al., 2011] Bakshy, E., Hofman, J. M., Mason, W. A., and Watts,
D. J. (2011). Everyone’s an Inﬂuencer : Quantifying Inﬂuence on Twitter.
In Proc. Intl. Conf. on Web Search and Web Data Mining (WSDM), pages
65–74.

[Bergen] Bergen, J. Facebook stores 10,000x more photos than the Library

of Congress.
http://www.geek.com/geek-cetera/facebook-stores-10000x-more-photos
-than-the-library-of-congress-1422873/. Accessed : 12/08/2014.

[Boldi et al., 2011] Boldi, P., Rosa, M., and Vigna, S. (2011). Hyperanf : ap-
