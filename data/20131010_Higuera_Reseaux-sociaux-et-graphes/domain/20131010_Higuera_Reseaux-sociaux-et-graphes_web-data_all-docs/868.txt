http://www.theses.fr/2016PA066368.pdf

TH`ESE DE DOCTORAT DE

l’UNIVERSIT´E PIERRE ET MARIE CURIE

Sp´ecialit´e

Informatique

´Ecole doctorale Informatique, T´el´ecommunications et ´Electronique (Paris)

Pr´esent´ee par

Simon BOURIGAULT

DOCTEUR de l’UNIVERSIT´E PIERRE ET MARIE CURIE

Pour obtenir le grade de

Sujet de la th`ese :

Apprentissage de repr´esentations pour la pr´ediction de

propagation d’information dans les r´eseaux sociaux

soutenue le 10 novembre 2016

devant le jury compos´e de :

Professeur
Directeur de th`ese
Maˆıtre de conf´erence Encadrant de th`ese

M. Patrick Gallinari
M. Sylvain Lamprier
Mme. Christine Largeron Professeure
Examinatrice
M. Christophe Marsala
Examinateur
Professeur
M. Fabrice Rossi
Rapporteur
Professeur
M. Julien Velcin
Maˆıtre de conf´erence Rapporteur

2

R´esum´e Dans ce manuscrit, nous ´etudions la diﬀusion d’information dans les r´eseaux
sociaux en ligne. Des sites comme Facebook ou Twitter sont en eﬀet devenus aujourd’hui
des media d’information `a part enti`ere, sur lesquels les utilisateurs ´echangent de grandes
quantit´es de donn´ees. La plupart des mod`eles existant pour expliquer ce ph´enom`ene de
diﬀusion sont des mod`eles g´en´eratifs, bas´es sur des hypoth`eses fortes.En particulier, tous
ces mod`eles sont bas´es sur le graphe social et font l’hypoth`ese que la diﬀusion d’informa-
tion a lieu uniquement sur ce graphe, qu’il s’agisse des liens d’amiti´e sur Facebook, ou
des followers sur Twitter. Cela pose plusieurs probl`emes. Par exemple, pour des raisons
de conﬁdentialit´e, il est courant que le graphe social soit cach´e. Face `a cette observation,
nous consid´ererons dans ce manuscrit le probl`eme de la pr´ediction de diﬀusion dans le
cas o`u le graphe social est inconnu, et o`u seules les actions des utilisateurs peuvent ˆetre
observ´ees.

— Nous proposons, dans un premier temps, une m´ethode d’apprentissage du mod`ele
independent cascade consistant `a ne pas prendre en compte la dimension tempo-
relle de la diﬀusion. Des r´esultats exp´erimentaux obtenus sur des donn´ees r´eelles
montrent que cette approche permet d’obtenir un mod`ele plus performant et plus
robuste.

— Nous proposons ensuite plusieurs m´ethodes de pr´ediction de diﬀusion reposant sur
des techniques d’apprentissage de repr´esentations. Celles-ci nous permettent de
d´eﬁnir des mod`eles plus compacts, et plus robustes `a la parcimonie des donn´ees.

— Enﬁn, nous terminons en appliquant une approche similaire au probl`eme de d´etec-
tion de source, consistant `a retrouver l’utilisateur ayant lanc´e une rumeur sur un
r´eseau social. En utilisant des m´ethodes d’apprentissage de repr´esentations, nous
obtenons pour cette tˆache un mod`ele beaucoup plus rapide et performant que ceux
de l’´etat de l’art.

Abstract
In this thesis, we study information diﬀusion in online social networks. Web-
sites like Facebook or Twitter have indeed become information medias, on which users
create and share a lot of data. Most existing models of the information diﬀusion pheno-
menon relies on strong hypothesis about the structure and dynamics of diﬀusion. In this
document, we study the problem of diﬀusion prediction in the context where the social
graph is unknown and only user actions are observed.

— We propose a learning algorithm for the independant cascades model that does
not take time into account. Experimental results show that this approach obtains
better results than time-based learning schemes.

— We then propose several representations learning methods for this task of diﬀusion

prediction. This let us deﬁne more compact and faster models.

— Finally, we apply our representation learning approach to the source detection task,

where it obtains much better results than graph-based approaches.

3

Computers grow so wise and
incomprehensible that when your
surpassing creations ﬁnd the answers
you asked for, you can’t understand
their analysis and you can’t verify
their answers. You have to take their
word on faith.

Or you use information theory to
ﬂatten it for you, to simplify reality
and pray to whatever Gods survived
the millennium that your honorable
twisting of the truth hasn’t ruptured
any of its load-bearing pylons.

Maybe the Singularity happened
years ago. We just don’t want to
admit we were left behind.

Peter Watts - Blindsight

4

Remerciements

Je tiens `a remercier, dans le d´esordre :

Mes encadrants, messieurs Lamprier et Gallinari pour leur accompagnement et leurs
conseils au cours de ces quatre ann´ees de travail, ainsi que pour tous leurs retours durant
la r´edaction du pr´esent manuscrit.

Les rapporteurs pour leurs remarques sur la premi`ere version du manuscrit, ainsi que
l’ensemble du jury.

L’´equipe MLIA et mes coll`egues th´esards en particulier pour l’atmosph`ere de travail au
sein du laboratoire.

L’ensemble du personnel administratif et technique du laboratoire, sans qui aucune re-
cherche ne pourrait avoir lieu.

Mes parents, pour leur soutien et leur pr´esence tout au long de mes ´etudes dont ce ma-
nuscrit constitue aujourd’hui l’aboutissement.

Ma compagne ainsi que mes amis et anciens camarades de master, pour tout.

5

6

Remerciements

Sommaire

Remerciements

R´esum´e des principales notations utilis´ees

1 Introduction

5

11

13

1.1 D´eveloppement des r´eseaux sociaux en ligne . . . . . . . . . . . . . . . 13

1.2 Diﬀusion d’information . . . . . . . . . . . . . . . . . . . . . . . . . . . 14

1.3 Projection des utilisateurs . . . . . . . . . . . . . . . . . . . . . . . . . 15

1.4 Tˆaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15

1.5 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

I Mod´elisation de la diﬀusion

2 Mod´elisation et pr´ediction de la diﬀusion d’information : ´etat de

l’art

19

23

2.1

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23

2.2 G´en´eralit´es sur la diﬀusion . . . . . . . . . . . . . . . . . . . . . . . . . 24

2.3 Mod`eles de diﬀusion `a faible granularit´e . . . . . . . . . . . . . . . . . 26

2.4 Mod`eles de diﬀusion `a forte granularit´e . . . . . . . . . . . . . . . . . . 29

2.5 Pr´ediction de diﬀusion . . . . . . . . . . . . . . . . . . . . . . . . . . . 41

2.6 Maximisation d’inﬂuence . . . . . . . . . . . . . . . . . . . . . . . . . . 51

2.7

Identiﬁcation de leaders d’opinion . . . . . . . . . . . . . . . . . . . . . 55

2.8 D´etection de source . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58

2.9 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65

3 Relaxation et r´egularisation du mod`ele IC

67

3.1 Diﬃcult´es li´ees `a l’apprentissage d’IC . . . . . . . . . . . . . . . . . . . 67

7

8

Sommaire

3.2 Delay-Agnostic Independant Cascades (DAIC) . . . . . . . . . . . . . . 71

3.3 R´egularisation de l’apprentissage . . . . . . . . . . . . . . . . . . . . . 75

3.4 Exp´eriences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78

3.5 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85

II Apprentissage de repr´esentations pour la diﬀusion

4 Applications de l’apprentissage de repr´esentations

87

91

4.1

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91

4.2 Projection de structures relationnelles simples . . . . . . . . . . . . . . 92

4.3 Projection de structures relationnelles complexes

. . . . . . . . . . . . 93

4.4 Mod´elisation de s´equences . . . . . . . . . . . . . . . . . . . . . . . . . 96

4.5 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99

5 Apprentissage de repr´esentations pour le mod`ele IC

101

5.1 Limites de l’apprentissage explicite des probabilit´es de transmission . . 101

5.2 Projection du mod`ele IC . . . . . . . . . . . . . . . . . . . . . . . . . . 102

5.3 Exp´eriences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107

5.4 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114

6 Mod´elisation par diﬀusion de chaleur

115

6.1

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115

6.2 Mod`ele

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117

6.3 Exp´eriences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124

6.4 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131

7 D´etection de source

133

7.1

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133

7.2 Apprentissage de repr´esentations pour la d´etection de source.

. . . . . 135

7.3 Exp´eriences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139

7.4 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148

III Conclusion

8 Conclusions et perspectives

151

153

8.1 Conclusions et discussions . . . . . . . . . . . . . . . . . . . . . . . . . 153

8.2 Perspectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155

9

Bibliographie

Appendices

A Preuve de la formule de mise `a jour de DAIC (formule 3.7)

157

167

169

B Preuve de l’eﬀet du biais d’apprentissage dans DAIC (proposition

1)

173

C Preuve du polynome de mise `a jour de DAIC r´egularis´e (formule

3.11)

181

D Preuve de la validit´e de la formule de mise `a jour de DAIC r´egularis´e

(formule 3.14)

183

10

Sommaire

R´esum´e des principales notations

utilis´ees

11

12

R´esum´e des principales notations utilis´ees

N
U = {u0, u1, . . . , uN−1}
E

Predsj

Succsi
D = {(ui, tD

i ), (uj, tD

j ), . . .}

tD
i

U D
t

U D∞ ou U D
sD

ˆU D
D

D?

i,j

D−

i,j

pi,j
P D
j

d
zi ∈ Rd
ωi ∈ Rd
Q
wD ∈ RQ
fθ : RQ → Rd

Nombre d’utilisateurs ´etudi´es

Ensemble des utilisateurs

Ensemble des liens utilisateurs (orient´es)

Ensemble des pr´ed´ecesseurs de uj

Ensemble des successeurs de ui

Un ´episode de diﬀusion
Instant auquel ui devient infect´e dans D. Vaut +∞ si
ui n’est jamais infect´e.
Ensemble des utilisateurs infect´es dans D avant le temps
t, i.e tD

i < t.

Ensemble des utilisateurs infect´es dans D.

Utilisateur source de l’´episode D

Ensemble des utilisateurs infect´es dans D moins l’utili-
sateur source : ˆU D = U D \ {sD}
Ensemble des ´episodes de diﬀusion

i < tD

Ensemble des ´episodes de diﬀusion o`u il est possible que
ui ait contamin´e uj, i.e. tels que ui ∈ U D∞ et uj ∈ U D∞
avec tD
j . On parlera aussi d’exemples positifs ou de
co-participations pour le couple (ui, uj).
Ensemble des ´episodes de diﬀusion o`u il est impossible
i < ∞
que ui ait r´eussi `a contaminer uj, i.e. tels que tD
j = ∞. On parlera aussi de contre-exemples pour le
et tD
couple (ui, uj).

Probabilit´e de transmission d’information de ui `a uj

Probabilit´e que uj soit infect´e dans D

Nombre de dimensions de l’espace de repr´esentation
Repr´esentation-source de ui dans Rd
Repr´esentation-r´ecepteur de ui dans Rd
Taille du dictionnaire utilis´e pour repr´esenter le contenu.

Vecteur repr´esentant le contenu associ´e `a l’´episode D

Fonction param´etr´ee permettant d’obtenir une repr´esen-
tation du contenu dans Rd

Chapitre 1

Introduction

1.1 D´eveloppement des r´eseaux sociaux en ligne

Au cours des dix derni`eres ann´ees, les r´eseaux sociaux en ligne (ou OSN, Online Social
Networks) ont pris une importance capitale dans la vie personnelle et professionnelle de
millions, voire de milliards, de personnes. Facebook, lanc´e en 2004 et ouvert au public
en 2006, compte aujourd’hui pr`es d’un milliard d’utilisateurs quotidiens. De leur cot´e, les
utilisateurs de Twitter, lanc´e en 2006, g´en`erent environ 500 millions de tweets chaque
jour, dans 35 langues diﬀ´erentes.
D’une fa¸con plus g´en´erale, l’´emergence du « web 2.0 » [O’Reilly, 2005] a fait des utilisateurs
le moteur de nombreux services en ligne. Beaucoup de sites internet proposent aujour-
d’hui une personnalisation propre `a chaque utilisateur dans divers domaines : relations
professionnelles (LinkedIn, Viadeo), cr´eation de contenus artistiques (Youtube, Devian-
tArt, Soundcloud...), ´evaluation de produits (Amazon, Epinions, GoodReads), etc..
Ainsi, lorsqu’il d´eﬁnit le terme « web 2.0 » en 2005 [O’Reilly, 2005], O’Reilly d´eclare :
« Le service devient automatiquement meilleur `a mesure que son nombre d’uti-
lisateurs augmente. »

Le terme important est ici « automatiquement ». Selon O’Reilly, le service devient meilleur
sans qu’aucune action ne soit n´ecessaire de la part du service lui-mˆeme : ce sont les
utilisateurs qui, en agissant et en interagissant par le biais de ce service, lui donnent une
utilit´e, un int´erˆet et donc une valeur. Pour cette raison, la plupart des grands r´eseaux
sociaux en ligne, `a commencer par Facebook et Twitter, proposent des API permettant
`a des d´eveloppeurs tiers d’int´egrer certaines fonctionnalit´es de ces r´eseaux sur d’autres
sites. Il est aujourd’hui possible, sur internet, de « liker », partager, tweeter, commenter
ou ´evaluer pratiquement n’importe quel contenu. Ces actions sont g´en´eralement visibles
des autres utilisateurs, et contribuent `a la valeur du contenu concern´e.

13

14

Chapitre 1. Introduction

L’importance de ces interactions a ´egalement fait des r´eseaux sociaux en ligne un m´edia
d’information `a part enti`ere. Les utilisateurs sont aujourd’hui en mesure d’acc´eder `a une
tr`es grande quantit´e d’information par le biais des r´eseaux sociaux, et de partager cette
information avec de nombreuses autres personnes `a travers le monde. S’ils se contentent
parfois de relayer des informations issues des m´edias traditionnels (articles de journaux,
podcast de radio, etc.), les utilisateurs peuvent aussi devenir des sources : les ´ev´enements
importants sont ainsi souvent rapport´es et discut´es en premier lieu sur Twitter. Chaque
jour, des contenus de natures vari´ees partag´es de cette fa¸con « font le buzz » et deviennent
mondialement connus en ´etant rapidement vus et relay´es par de nombreuses personnes et
sites web. Ce mode de fonctionnement a d’ailleurs motiv´e le d´eveloppement de techniques
de marketing dit « viral », consistant pour les annonceurs `a encourager leurs clients `a
diﬀuser un contenu publicitaire, de mani`ere `a atteindre d’autres clients potentiels grˆace
au bouche-`a-oreille.

1.2 Diﬀusion d’information

Dans ce manuscrit, nous ´etudions ce ph´enom`ene de diﬀusion d’information. Les premiers
travaux sur ce sujet sont issus des sciences sociales et datent des ann´ees 70.

Le mod`ele fondateur de Bass [Bass, 1969] prend la forme d’´equations diﬀ´erentielles r´egis-
sant l’´evolution du nombre de consommateurs ayant adopt´e un produit consid´er´e. D’autres
mod`eles bas´es sur le mˆeme principe mais int´egrant plus de param`etres dans leur mod´eli-
sation ont ensuite ´et´e propos´es [Newman, 2003, Hethcote, 2000].

Plus r´ecemment, la grande quantit´e de donn´ees rendues disponibles par le d´eveloppement
des r´eseaux sociaux a permis l’application de mod`eles bas´es sur le graphe social. Ceux-ci
consid`erent l’information comme un virus infectant progressivement les individus d’une
population en passant de l’un `a l’autre en suivant les arcs d’un graphe social. Contraire-
ment au mod`ele de Bass, ces mod`eles visent `a mod´eliser ou `a pr´edire l’infection de chaque
utilisateur, et non pas seulement le taux d’infection d’une population ﬁx´ee. Les plus clas-
siques sont l’Independent Cascade Model (IC) et le linear Threshold Model (LT) [Kempe
et al., 2003, Goldenberg et al., 2001, Granovetter, 1978].

Dans le mod`ele IC, chaque arˆete du graphe est associ´ee `a une probabilit´e de transmission,
indiquant la probabilit´e pour un utilisateur donn´e d’infecter chacun de ses voisins : le
mod`ele est centr´e sur l’´emetteur. Dans le mod`ele LT, en revanche, chaque utilisateur est
associ´e `a un seuil indiquant `a partir de quel niveau d’inﬂuence externe il devient lui-mˆeme
infect´e : le mod`ele est centr´e sur le receveur. `A partir de ces id´ees de base, diﬀ´erentes
approches visant notamment `a prendre en compte la dimension temporelle de la diﬀusion
ont ´et´e propos´ees.

Tous ces mod`eles bas´es sur le graphe social font l’hypoth`ese que la diﬀusion d’information
a lieu uniquement sur ce graphe, qu’il s’agisse des liens d’amiti´e sur Facebook, ou des

1.3. Projection des utilisateurs

15

followers sur Twitter. Cela pose plusieurs probl`emes. Tout d’abord, les utilisateurs ´etant
souvent inscrits sur plusieurs sites internet, la diﬀusion peut avoir lieu sur plusieurs r´eseaux
en parall`ele. De plus, les liens explicites renseign´es sur un r´eseau social en ligne ne sont
pas toujours les plus pertinents pour expliquer la diﬀusion d’information [Cha et al.,
2010]. Enﬁn, pour des raisons de conﬁdentialit´e, il est courant que le graphe social soit
cach´e.

Face `a ces observations, nous consid´ererons dans ce manuscrit le probl`eme de la pr´ediction
de diﬀusion dans le cas o`u le graphe social est inconnu, et o`u seules les actions des
utilisateurs peuvent ˆetre observ´ees.

1.3 Projection des utilisateurs

Dans la plupart de nos travaux pr´esent´es ici, nous utilisons l’apprentissage de repr´esenta-
tions pour mod´eliser les relations entre les utilisateurs. L’apprentissage de repr´esentations
a ´et´e r´ecemment appliqu´e `a des domaines vari´es tel que les mod`eles de langue [Mikolov
et al., 2013b], la pr´ediction de playlists [Chen et al., 2012], la traduction automatique
[Graves et al., 2013] ou encore la reconnaissance vocale [Cho et al., 2014]. Le principe est
de projeter des ´el´ements (mots, utilisateurs, items) dans un espace de repr´esentation Rd
de dimension ﬁx´ee, de fa¸con `a ce que les distances entre ces ´el´ements dans l’espace de
repr´esentation mod´elisent certaines relations entre eux.

Dans notre cas, nous projetons les utilisateurs dans un espace latent de fa¸con `a ce que les
distances entre eux repr´esentent l’inﬂuence qu’ils ont les uns sur les autres, leur propension
`a se transmettre de l’information, leurs similarit´es ou leurs liens d’amiti´es. L’utilisation
de cette approche nous permet d’obtenir des mod`eles moins complexes que les mod`eles
de diﬀusion bas´es sur le graphe du r´eseau social, et de r´egulariser les relations entre
utilisateurs. En particulier, deux utilisateurs proches (deux amis par exemple) seront
naturellement proches des mˆemes autres utilisateurs, mod´elisant le principe : « les amis
de mes amis sont mes amis ».

1.4 Tˆaches

Dans cette section, nous d´eﬁnissons de fa¸con informelle les tˆaches ´etudi´ees dans ce ma-
nuscrit. Une d´eﬁnition plus pr´ecise de chacune d’entre elles sera donn´ee dans les chapitres
correspondants.

16

Chapitre 1. Introduction

1.4.0.1 Pr´ediction de diﬀusion

Le but de cette tˆache est de pr´edire, ´etant donn´e un ou plusieurs utilisateurs initialement
infect´es par une information (ou sources), quels seront les utilisateurs infect´es dans le
futur, `a la ﬁn de la diﬀusion. Notons bien qu’il s’agit ici d’une tˆache pr´edictive, et non
pas explicative : le but est uniquement de retrouver quels utilisateurs seront infect´es, par
par qui ou comment. Un mod`ele adapt´e `a cette tˆache peut ensuite ˆetre utilis´e pour de la
pr´ediction de buzz ou de la maximisation d’inﬂuence [Kempe et al., 2003].

1.4.0.2 D´etection de source

Cette tˆache est l’inverse de la pr´ec´edente. Le but est de retrouver la source d’une infor-
mation `a partir de l’ensemble des utilisateurs ﬁnalement infect´es par celle-ci. Suivant le
contexte, un tel mod`ele peut servir `a retrouver la source d’une fausse rumeur, l’origine
d’une fuite ou le point d´epart d’un virus informatique au sein de r´eseau.

1.5 Contributions

Dans cette section, nous d´ecrivons bri`evement les diﬀ´erentes contributions r´ealis´ees au
cours de cette th`ese et pr´esent´ees dans ce manuscrit.

1.5.0.1 Apprentissage atemporel du mod`ele IC (chapitre 3)

Lamprier, S., Bourigault, S., and Gallinari, P. (2015). Extracting diﬀusion
channels from real-world social data: A delay-agnostic learning of transmission
probabilities. In Proceedings of the 2015 IEEE/ACM International Conference
on Advances in Social Networks Analysis and Mining. ACM

Dans le mod`ele IC, chaque paire d’utilisateurs (ui, uj) d’un r´eseau social est associ´ee `a une
probabilit´e de transmission pi,j. Les premiers articles ´etudiant ce mod`ele consid´eraient des
probabilit´es de transmission ﬁx´ees a priori. Toutefois, dans la plupart des applications,
celles-ci doivent ˆetre apprises `a partir d’un ensemble d’exemples d’apprentissage. Cet
ensemble d’apprentissage prend g´en´eralement la forme d’un ensemble de s´equences d’uti-
lisateurs infect´es correspondant chacune `a une information se diﬀusant dans le r´eseau.
Par exemple, sur Youtube, chaque s´equence contiendra l’ensemble des utilisateurs ayant
visionn´e une vid´eo donn´ee. Le but est est alors de trouver les probabilit´es de transmission
maximisant la vraisemblance de cet ensemble d’apprentissage.

La diﬃcult´e vient du fait que ces exemples nous indiquent seulement quand un utilisateur
a ´et´e infect´e par une information, et pas par qui. Un algorithme d’apprentissage de type
Esp´erance-Maximisation a ´et´e propos´e par [Saito et al., 2008]. Malheureusement, celui-ci

1.5. Contributions

17

fait l’hypoth`ese qu’un utilisateur ne peut avoir ´et´e infect´e que par un voisin infect´e au pas
de temps pr´ec´edent.

Dans notre premi`ere contribution [Lamprier et al., 2015], nous consid´erons pour notre
part que cette hypoth`ese de discr´etisation du temps est trop forte, et nous proposons une
version relax´ee de cette approche en consid´erant qu’un utilisateur peut avoir ´et´e infect´e
par n’importe quel autre utilisateur pr´ec´edemment infect´e. Nous adaptons l’algorithme
en cons´equence. De plus, nous remarquons que la parcimonie des donn´ees d’apprentissage
peut conduire `a un probl`eme de sur-apprentissage, que nous proposons de limiter en intro-
duisant un m´ecanisme de r´egularisation. Nous comparons notre m´ethode d’apprentissage
`a celle de [Saito et al., 2008] sur des donn´ees r´eelles et observons un gain important sur
la tˆache de pr´ediction de diﬀusion.

1.5.0.2 Apprentissage de repr´esentations pour le mod`ele IC (chapitre 5)

Bourigault, S., Lamprier, S., and Gallinari, P. (2016b). Representation lear-
ning for information diﬀusion through social networks: An embedded cascade
model. In Proceedings of the Ninth ACM International Conference on Web
Search and Data Mining, WSDM ’16, pages 573–582, New York, NY, USA.
ACM

Dans notre premi`ere contribution, nous proposions une m´ethode permettant d’apprendre
des probabilit´es de transmission entre chaque paire d’utilisateurs d’une population ﬁx´ee.
Ces probabilit´es ´etaient apprises de fa¸con libre, c’est sans aucune contrainte a priori sur
leurs valeurs relatives. En pratique, on sait que les graphes de r´eseaux sociaux pr´esentent
de nombreuses propri´et´es particuli`eres : faible diam`etre, distribution des degr´es en loi de
puissance, structures de communaut´es... De plus, apprendre une probabilit´e de transmis-
sion pour chaque paire d’utilisateur pose un probl`eme de complexit´e.

Pour r´esoudre ces deux probl`emes, nous proposons dans notre deuxi`eme contribution
[Bourigault et al., 2016b] d’apprendre des repr´esentations latentes des utilisateurs, dans
un espace euclidien Rd. Ces repr´esentations ont pour but de mod´eliser les comportements,
interactions et similarit´es des utilisateurs, et sont apprises de fa¸con `a ce que chaque pro-
babilit´e de transmission pi,j du mod`ele IC puissent se d´eduire de la distance s´eparant les
repr´esentations des deux utilisateurs correspondants. Nous adaptons l’algorithme d’ap-
prentissage `a cette formulation. Nous observons une am´elioration des performances en
pr´ediction de diﬀusion par rapport `a notre premi`ere contribution.

1.5.0.3 Mod´elisation par Diﬀusion de Chaleur (chapitre 6)

Bourigault, S., Lagnier, C., Lamprier, S., Denoyer, L., and Gallinari, P. (2014).
Learning social network embeddings for predicting information diﬀusion. In

18

Chapitre 1. Introduction

Proceedings of the 7th ACM International Conference on Web Search and Data
Mining, WSDM ’14, pages 393–402, New York, NY, USA. ACM

Nos deux contributions pr´ec´edentes ´etaient des mod`eles explicatifs : nous proposions d’ap-
prendre des probabilit´es de transmission d’information que nous utilisions ensuite pour
simuler le processus de diﬀusion au sein d’un graphe reliant les utilisateurs.

Dans notre troisi`eme contribution [Bourigault et al., 2014], nous n’utilisons pas de mod`ele
explicatif : les utilisateurs sont projet´es dans un espace de repr´esentation Rd de fa¸con `a
ce que la diﬀusion d’information au sein de cette population puisse ˆetre vue comme un
processus de diﬀusion de chaleur dans cet espace. La diﬀusion est donc mod´elis´ee de fa¸con
continue, et non plus de fa¸con it´erative comme dans les deux contributions pr´ec´edentes.
Le mod`ele obtenu est beaucoup plus rapide en inf´erence.

Nous proposons ´egalement une extension de ce mod`ele permettant de prendre en compte
le contenu de l’information se diﬀusant. Cette extension am´eliore les r´esultats de fa¸con
importante.

1.5.0.4 D´etection de source (chapitre 7)

Bourigault, S., Lamprier, S., and Gallinari, P. (2016a). Learning distributed
representations of users for source detection in online social networks. In Pro-
ceedings of the 2016 European conference on Machine Learning and Knowledge
Discovery in Databases, ECML PKDD’16. Springer-Verlag

Enﬁn, dans notre quatri`eme contribution [Bourigault et al., 2016a], nous ´etudions la tˆache
de d´etection de source. L`a encore, notre approche consiste `a projeter les utilisateurs dans
un espace latent. Nous proposons d’utiliser les positions des utilisateurs infect´es par une
information donn´ee pour calculer une repr´esentation de cette information dans l’espace,
et utilisons celle-ci pour retrouver l’utilisateur source.

Nous comparons cette m´ethode `a diverses approches graphiques issues de l’´etat de l’art,
et montrons qu’elle nous permet d’obtenir de meilleurs r´esultats dans diﬀ´erents contextes
applicatifs tout en ´etant bien moins complexe `a utiliser en inf´erence.

Nous pr´esentons ´egalement deux extensions permettant de prendre en compte le contenu
de l’information se diﬀusant et d’apprendre l’importance de chaque utilisateur dans la
d´etection.

Remarquons que les diﬀ´erentes contributions ne sont pas pr´esent´ees, au sein de ce manus-
crit, dans l’ordre chronologique de leurs publications. Cette organisation est plus logique,
puisqu’elle nous permet de d´ecrire d’abord des m´ethodes d’apprentissage pour le mod`ele
IC (deux premi`eres contributions) avant de proposer un mod`ele de diﬀusion continu plus
rapide, puis de terminer en ´etudiant la tˆache annexe de d´etection de source.

Premi`ere partie

Mod´elisation de la diﬀusion

19

21

Dans cette premi`ere partie, nous pr´esentons un ´etat de l’art sur la mod´elisation et la
pr´ediction de la diﬀusion d’information. En particulier, nous pr´esentons le mod`ele Inde-
pendent Cascades (IC), qui est un mod`ele de diﬀusion classique, ´etudi´e et ´etendu dans de
nombreux travaux.

Nous pr´esentons ensuite une premi`ere contribution : une m´ethode d’apprentissage du
mod`ele IC permettant d’ignorer les d´elais de diﬀusion, qui nous permet d’obtenir de
meilleurs r´esultats qu’un mod`ele IC appris de fa¸con classique.

22

Chapitre 2

Mod´elisation et pr´ediction de la

diﬀusion d’information : ´etat de l’art

R´esum´e Ce chapitre pr´esente un ´etat de l’art sur la pr´ediction de diﬀusion dans les
r´eseaux sociaux. Nous ´etudions plusieurs approches correspondant `a des contextes vari´es
et `a des tˆaches diﬀ´erentes. Nous nous int´eressons ´egalement `a quelques probl´ematiques
annexes li´ees `a la pr´ediction de diﬀusion : la maximisation d’inﬂuence, l’identiﬁcation de
leaders d’opinion et la d´etection de source.

2.1 Introduction

Dans ce chapitre, nous pr´esentons un ´etat de l’art sur le sujet de la diﬀusion d’infor-
mation dans les r´eseaux sociaux et sur plusieurs tˆaches associ´es. Nous commen¸cons par
pr´esenter plusieurs mod`eles de diﬀusion d’informations. Ceux-ci peuvent ˆetre s´epar´es en
deux groupes, que nous nommerons « mod`eles `a faible granularit´e » et « mod`eles `a forte
granularit´e ».

— Un mod`ele `a faible granularit´e est une approche s’int´eressant `a une propri´et´e globale
de la diﬀusion la diﬀusion, comme par exemple le nombre d’utilisateurs infect´es par
une information donn´ee. Ce type de mod`ele est g´en´eralement bas´e sur des propri´et´es
globales du r´eseau social ´etudi´e : taille du r´eseau, connectivit´e, distribution des
degr´es, etc.

— Un mod`ele `a forte granularit´e s’int´eresse pour sa part `a la diﬀusion `a l’´echelle des
utilisateurs. Ce type de mod`ele vise en g´en´eral `a simuler la diﬀusion au sein d’un
graphe ﬁx´e.

Apr`es avoir pr´esent´e ces travaux sur la mod´elisation de la diﬀusion d’information, nous
nous int´eressons `a plusieurs probl´ematiques li´ees.

— La pr´ediction de diﬀusion consiste `a pr´edire le r´esultat de la diﬀusion d’une infor-

mation `a partir d’un ´etat initial.

23

24

Chapitre 2. Mod´elisation et pr´ediction de la diﬀusion d’information : ´etat de l’art

— La maximisation d’inﬂuence vise `a trouver quels utilisateurs initialement infect´es

permettent de maximiser l’ampleur de la diﬀusion d’information.

— L’identiﬁcation des leaders d’opinion cherche `a retrouver les utilisateurs les plus

inﬂuents d’un r´eseau social.

— Enﬁn, la d´etection de source d´esigne la tˆache inverse de la pr´ediction de diﬀusion :

retrouver, `a partir de l’´etat ﬁnal d’une diﬀusion, l’utilisateur dont elle est partie.

2.2 G´en´eralit´es sur la diﬀusion

Avant d’aborder l’´etat de l’art, nous pr´esentons de fa¸con succincte le ph´enom`ene de diﬀu-
sion d’information. Nous en proﬁtons ´egalement pour d´eﬁnir quelques notations et termes
utilis´es tout au long de ce manuscrit.

2.2.1 R´eseau Social

Soit U = {u1, u2, . . . , uN} une population de N utilisateurs faisant partie d’un r´eseau
social. Au sein de ce r´eseau social, ces utilisateurs sont reli´es par un ensemble de liens E,
qui constituent le graphe social G = (U, E). Ces liens peuvent ˆetre orient´es ou non, selon
le r´eseau social consid´er´e : les relations entre utilisateurs sont par exemple sym´etriques
sur Facebook (liens d’amiti´e) mais asym´etriques sur Twitter (abonnements). Nous notons
Predsi et Succsi les pr´ed´ecesseurs et successeurs de ui dans G. La nature exacte des
utilisateurs peut ´egalement d´ependre du type de contexte ´etudi´e : il pourra s’agir de
personnes physiques, de blogs ou sites web, par exemple.

2.2.2 Diﬀusion

Au cours du temps, diverses informations se diﬀusent au sein de la population U , prin-
cipalement par le biais du bouche-`a-oreille. Une information peut prendre beaucoup de
formes : une vid´eo ou article de blog partag´es sur Facebook, un message sur Twitter ret-
weet´e par beaucoup d’utilisateurs, un comportement particulier adopt´e progressivement
par la population (l’achat d’un produit `a la mode, par exemple), etc...

Les utilisateurs atteints par une information donn´ee sont dit infect´es, ou contamin´es. Ces
termes viennent du fait que plusieurs mod`eles issus de l’´epid´emiologie ont ´et´e appliqu´es `a
la diﬀusion d’information. Dans certains cas, on parlera aussi d’utilisateur activ´e ou ayant
adopt´e une information (termes issus du marketing).

Lorsqu’une information se propage dans la population U , nous observons en g´en´eral les
temps d’infection des diﬀ´erents utilisateurs concern´es. Nous nommons ´episode de diﬀusion

2.2. G´en´eralit´es sur la diﬀusion

25

D la s´equence d’utilisateurs infect´es, avec leurs temps d’infection associ´es :

D =(cid:0)(ui, tD

k ), . . .(cid:1)

i ), (uj, tD

j ), (uk, tD

L’exposant D des temps d’infection tD
sera parfois omis dans ce manuscrit lorsque le
i
contexte ne laissera aucune ambigu¨ıt´e. Dans la litt´erature, D est aussi nomm´e s´equence
d’activation ou trace de diﬀusion. Un ´episode de diﬀusion peut correspondre `a l’ensemble
des « likes » recueillis par un article sur Facebook, o`u `a l’ensemble des vues d’une vid´eo
sur Youtube. Il est important de noter que D indique seulement qui a ´et´e infect´e par une
information donn´ee et quand, mais pas comment ou par qui. Cette information manquante
sera souvent source de diﬃcult´es. Nous consid´erons, sans perte de g´en´eralit´e, que le premier
utilisateur est infect´e `a t = 0, et que les temps d’infection des utilisateurs suivants sont
donc indiqu´es de fa¸con relative `a celui du premier utilisateur. De plus, nous consid´erons
que les utilisateurs non infect´es dans D v´eriﬁent tD

i = +∞

Nous notons U D
t

l’ensemble des utilisateurs infect´es dans D avant le temps t, i.e :

t = {ui ∈ U|tD
U D

i < t}

En particulier, U D∞ d´esignera l’ensemble des utilisateurs infect´es dans D, et sera parfois
abr´eg´e en U D. Nous utiliserons ´egalement la notations ¯U D

t = U \ U D
t .

La notion d’´episode de diﬀusion d´eﬁnie ici est suﬃsamment abstraite pour s’appliquer `a de
nombreux contextes exp´erimentaux. Strictement parlant, n’importe quel corpus compos´e
de triplets de la forme (utilisateur,item,temps) permet de d´eﬁnir des ´episodes de diﬀusion.
Suivant l’origine des donn´ees utilis´ees et la fa¸con dont elles ont ´et´e extraites, la s´emantique
associ´ee au concept d’´episode de diﬀusion sera donc variable, et celle associ´ee au mod`ele
appliqu´e aux donn´ees le sera donc aussi. De plus, dans certains cas, la d´eﬁnition des
triplets n’est pas triviale. En particulier, retrouver dans un grand ﬂux de messages (comme
Twitter) les diﬀ´erents « sujets » discut´es constitue d´ej`a une tˆache diﬃcile, nomm´ee Topic
Detection and Tracking (TDT) dans la litt´erature. Ces consid´erations vont toutefois au
del`a du sujet ´etudi´e dans ce manuscrit. Comme dans la plupart des travaux sur la diﬀusion
d’information, nous extrairons les ´episodes de diﬀusion de fa¸con relativement simple.

2.2.3 Graphe de Diﬀusion

Lorsque l’information « qui a contamin´e qui » est connue, l’ensemble des utilisateurs in-
fect´es peut ˆetre repr´esent´e par un graphe. Ce graphe sera nomm´e graphe de diﬀusion ou,
s’il est orient´e, cascade. Dans la plupart des mod`eles, il s’agira d’un sous-graphe de G. De
plus, beaucoup d’articles font l’hypoth`ese qu’un utilisateur infect´e l’a ´et´e par un seul autre
utilisateur. Dans ce cas, le graphe de diﬀusion sera un arbre de diﬀusion. Un exemple est
donn´e en ﬁgure 2.1.

26

Chapitre 2. Mod´elisation et pr´ediction de la diﬀusion d’information : ´etat de l’art

Figure 2.1 – Exemple de graphe de diﬀusion. `A gauche, le graphe d’un r´eseau social. `A
droite, un graphe de diﬀusion repr´esentant la diﬀusion d’une information. Les num´eros
indiquent dans quelle ordre les diﬀ´erentes contaminations ont lieu. En bas, l’´episode de
diﬀusion (s´equence d’utilisateurs infect´es) correspondant.

2.3 Mod`eles de diﬀusion `a faible granularit´e

Les mod`eles de diﬀusion `a faible granularit´e visent `a mod´eliser l’´evolution, au cours du
temps, d’une grandeur caract´erisant la diﬀusion d’information. Le plus souvent, cette
grandeur sera le nombre ou le pourcentage d’utilisateurs infect´es.

2.3.1 Le mod`ele de Bass

Le premier mod`ele math´ematique d´ecrivant le ph´enom`ene du bouche-`a-oreille a ´et´e pro-
pos´e par Bass [Bass, 1969] pour expliquer la fa¸con dont les consommateurs adoptent un
produit donn´e. Dans ce mod`ele, un individu peut adopter un produit suite `a l’inﬂuence
soit de la publicit´e, soit d’autres personnes ayant d´ej`a adopt´e le produit en question (on
dira qu’il y a eu contamination).

La probabilit´e `a tout instant pour un individu d’adopter le produit par le biais de la
publicit´e est not´ee p, et la probabilit´e de contamination d’une personne par une autre est
not´ee q. En notant i(t) le ratio de consommateurs ayant adopt´e le produit au sein de la
population au temps t (de fa¸con cumulative), Bass propose l’´equation diﬀ´erentielle :

(t) = p × (1 − i(t)) + q × (i(t) × (1 − i(t)))

∂i
∂t

Le premier terme de l’´equation correspond `a l’adoption du produit par le biais de la
publicit´e, et le deuxi`eme terme `a l’eﬀet du bouche-`a-oreille.

2.3. Mod`eles de diﬀusion `a faible granularit´e

27

La solution de cette ´equation, avec la condition initiale i(0) = 0, est :

i(t) =

1 − e−(p+q).t
p e−(p+q).t
1 + q

Les valeurs de p et de q ont ´et´e mesur´ees `a p = 0.03 et q = 0.38 en moyenne sur plusieurs
centaines de courbes d’adoptions observ´ees sur de vraies campagnes marketing [Mahajan
et al., 1995], un r´esultat montrant l’importance de la diﬀusion inter-utilisateurs.

2.3.1.1 Extensions

Le mod`ele de Bass peut ˆetre appliqu´e `a la diﬀusion d’information sur les r´eseaux sociaux,
soit dans sa forme de base [Luu et al., 2012], soit dans une version ´etendue prenant en
compte davantage de param`etres.

En particulier, le mod`ele se base sur la loi d’action de masse, c’est `a dire que chaque
utilisateur est susceptible d’inﬂuencer tous les autres. Dans [Luu et al., 2012], les auteurs
observent qu’en pratique, la diﬀusion ne se fait pas dans un graphe complet, et que l’eﬀet
du bouche-`a-oreille d´epend donc de la distribution des degr´es dans le graphe social. Ils
proposent les extensions Scale-free network Linear Inﬂuence Model (SLIM) et Exponential
network Linear Inﬂuence Model (ELIM), mod´elisant la diﬀusion dans une population
o`u la r´epartition des degr´es dans le graphe social suit une loi de puissance ou une loi
exponentielle, respectivement. L’´equation devient :

(t) = p(1 − i(t)) + q (Ed(i(t)))

∂i
∂t

o`u Ed(i(t)) d´esigne le nombre moyen de voisins ayant adopt´e le produit pour les utilisateurs
non infect´es. Sa valeur d´epend de la r´epartition des degr´es et de i(t).

Dans [Lerman and Hogg, 2010], les auteurs s’int´eressent au site internet Digg et int`egrent
dans le mod`ele de Bass plusieurs param`etres tr`es sp´eciﬁques `a l’organisation de ce site, ce
qui permet une mod´elisation plus pr´ecise : nombre moyens de visites du site, r´epartition
des informations sur diﬀ´erentes pages, etc.

2.3.2 Mod`eles ´epid´emiologiques

Des mod`eles suivant la mˆeme id´ee ont ´egalement ´et´e propos´es pour mod´eliser et expliquer
la diﬀusion d’une maladie au sein d’une population [Daley et al., 2001]. Dans ces mod`eles,
chaque utilisateur se trouve dans un ´etat. A chaque instant, il peut changer d’´etat, suivant
des probabilit´es d´ependant du mod`ele.

28

Chapitre 2. Mod´elisation et pr´ediction de la diﬀusion d’information : ´etat de l’art

Le premier mod`ele de ce type a avoir ´et´e propos´e est le Susceptible-Infected-Recovered
(SIR) [Kermack and McKendrick, 1927] dans lequel chaque utilisateur peut se trouver
dans un ´etat parmi trois `a chaque instant :

— susceptible : susceptible d’ˆetre contamin´e par la maladie ´etudi´ee ;
— infected : infect´e par cette maladie ;
— recovered : gu´eri, et immunis´e contre cette maladie.

Les nombres d’utilisateurs susceptibles, infect´es et gu´eris au temps t sont not´es S(t), I(t)
et R(t), avec :

∀t : S(t) + I(t) + R(t) = N

A chaque instant, chaque utilisateur infect´e a une probabilit´e p de contaminer chaque uti-
lisateur susceptible, et chaque utilisateur infect´e a une probabilit´e r de gu´erir. L’´evolution
du syst`eme est donc r´egie par les ´equations suivantes :

 ∂S

∂I

∂t = −p.SI
∂t = p.SI − r.I
∂R
∂t = r.I

Le calcul d’une solution exacte est complexe [Harko et al., 2014], mais plusieurs m´ethodes
d’approximation existent [Keeling and Rohani, 2008, Harko et al., 2014].

De la mˆeme fa¸con qu’avec le mod`ele de Bass, quelques travaux ont montr´e que ce mod`ele
expliquait bien certains types d’´epid´emies. Des exemples concernant une ´epid´emie de
grippe et une ´epid´emie de peste sont donn´es dans [Brauer et al., 2001]. Ce mod`ele a
´egalement ´et´e utilis´e pour ´etudier la diﬀusion d’informations sur des forums en ligne [Woo
et al., 2011]. Le mod`ele SIR permet de calculer diverses propri´et´es ´epid´emiologiques. En
particulier, il est possible de montrer que si p.S(0)
r > 1, une ´epid´emie a lieu : la valeur de
I augmente jusqu’`a un maximum, puis diminue jusqu’`a 0. Sinon, la valeur de I diminue
directement.

De nombreuses variations et extensions de ce mod`ele ont pu ˆetre propos´ees [Daley et al.,
2001]. Par exemple, dans la cas d’une maladie dont il est impossible de gu´erir, la valeur de
r est ﬁx´ee `a 0, ce qui conduit au mod`ele SI. Si la gu´erison de donne pas d’immunit´e, alors
chaque utilisateur infect´e aura une certaine probabilit´e de repasser en ´etat susceptible, ce
qui conduit au mod`ele SIS avec les ´equations :

(cid:40) ∂S
∂t = −p.SI + r.I
∂t = p.SI − r.I

∂I

2.4. Mod`eles de diﬀusion `a forte granularit´e

29

Si un utilisateur gu´eri peut perdre son immunit´e avec une certaine probabilit´e s, il est
possible de d´eﬁnir le mod`ele SIRS r´egi par les ´equations suivantes :

 ∂S

∂I

∂t = −p.SI + s.R
∂t = p.SI − r.I
∂t = r.I − s.R

∂R

Toujours selon le mˆeme principe, il est ´egalement possible de consid´erer une maladie
potentiellement mortelle, de prendre en compte des naissances ou des d´ec`es au sein de
la population, de mod´eliser la transmission de l’immunit´e de la m`ere `a l’enfant ou la
vaccination d’une partie de la population, etc. [Brauer et al., 2001].

2.3.3 Apprentissage des inﬂuences globales des utilisateurs

La quantit´e de donn´ees rendues disponibles par le d´eveloppement des r´eseaux sociaux a
rendu possible la mise en place de mod´elisations bas´ees sur des propri´et´es plus pr´ecises
des utilisateurs, plutˆot que sur des m´etadonn´ees d´eﬁnies `a l’´echelle du r´eseau.

Par exemple, le Linear Inﬂuence Model (LIM) a ´et´e propos´e dans [Yang and Leskovec,
2010]. Dans cet article, les auteurs s’int´eressent `a l’´evolution du nombre d’infections (ou
« volume d’infection ») I(t). Contrairement aux approches pr´ec´edentes, cette mod´elisation
est bas´ee sur l’observation d’une sous-population O ⊂ U . Chaque utilisateur u ∈ O est
associ´e `a une fonction d’inﬂuence Iu de fa¸con `a ce que Iu(t) corresponde au nombre
d’infections provoqu´ees par u apr`es un temps t. En notant ti le temps d’infection de
chaque utilisateur ui ∈ O, le volume de diﬀusion I s’´ecrit alors :

I(t) =

Iui(t − ti)

(cid:88)

ui∈O
ti<t

Autrement dit, le nombre total d’infections est ´egal `a la somme des inﬂuences des uti-
lisateurs de O, d´ecal´ees en fonction de leurs temps d’infections. Les auteurs proposent
une m´ethode simple pour apprendre les fonctions Iu(t). Ils consid`erent le cas o`u le temps
s’´ecoule de fa¸con discontinue (par pas de temps successifs), et apprennent chaque valeur
de Iu(t) directement, pour t < Tmax. Le probl`eme d’apprentissage s’´ecrit alors comme un
probl`eme de minimisation pouvant ˆetre r´esolu eﬃcacement.

2.4 Mod`eles de diﬀusion `a forte granularit´e

Les mod`eles de diﬀusion `a forte granularit´e sont des mod`eles bas´es sur le graphe du r´e-
seau social et visant `a simuler, `a l’´echelle des utilisateurs, la diﬀusion d’information au
sein de celui-ci. Nous en pr´esentons plusieurs dans cette section, plus ou moins complexes

30

Chapitre 2. Mod´elisation et pr´ediction de la diﬀusion d’information : ´etat de l’art

et reposant sur diﬀ´erentes hypoth`eses quant aux m´ecanismes r´egissant le diﬀusion d’in-
formation.

Nous pr´esentons ici des mod`eles utilis´es dans le cadre le diﬀusion d’information, mais
ce type de mod`ele est g´en´eralement susceptible de mod´eliser de nombreux autres types
de diﬀusion [Granovetter, 1978], o`u le comportement de chaque utilisateur est inﬂuenc´e
par ceux des autres : adoption d’un nouveau produit, propagation de rumeurs ou de
maladies, diﬀusion de d´ecisions (se mettre en gr`eve par exemple), etc. `A l’origine, les
deux premiers mod`eles pr´esent´es ici (IC et LT) ´etaient utilis´es en sociologie pour expliquer
certains comportement observ´es `a l’´echelle d’une population comme le r´esultat d’actions
et d’interactions ayant lieu `a l’´echelle des individus.

2.4.1 Le mod`ele Independent Cascades (IC)

Le mod`ele « Independent Cascades » pr´esent´e ici a ´et´e d´eﬁni par [Kempe et al., 2003] pour
´etudier le probl`eme de la maximisation d’inﬂuence dans le cadre du marketing viral (dont
nous parlons plus loin dans ce chapitre). Ce mod`ele a ensuite ´et´e ´etudi´e dans [Saito et al.,
2008], et c’est celui que nous ´etudions dans plusieurs chapitres de ce manuscrit. Historique-
ment, le mod`ele IC d´eﬁni par [Kempe et al., 2003] se base sur les travaux de [Goldenberg
et al., 2001] et de [Granovetter, 1973], qui utilisaient des mod`eles similaires pour ´etudier
l’impact du ph´enom`ene de bouche-`a-oreille dans des campagnes publicitaires.

Dans le mod`ele IC, chaque lien (ui, uj) du graphe est associ´e `a une probabilit´e de trans-
mission pi,j. La diﬀusion se d´eroule de fa¸con it´erative.

— `A l’instant initial t = 0, un ensemble d’utilisateurs UI ⊂ U devient infect´e.
— Lorsqu’un utilisateur devient infect´e `a un pas de temps t, il dispose d’une unique
chance de contaminer chacun de ses successeurs uj ∈ Succsi selon la probabilit´e pi,j.
Si la contamination a lieu, uj devient infect´e au temps t + 1. Ainsi, un utilisateur
n’est contagieux que pendant un seul pas de temps.

— La diﬀusion se poursuit tant que de nouveaux utilisateurs deviennent infect´es.

Un exemple de diﬀusion est donn´e en ﬁgure 2.2.

Le mod`ele IC est donc centr´e sur l’´emetteur : ce sont les actions des ´emetteurs de contenu
(transmission/non-transmission) qui sont mod´elis´ees. De plus, ce mod`ele fait une hypo-
th`ese d’ind´ependance : la probabilit´e qu’une transmission ait lieu sur un lien (ui, uj)
particulier est toujours la mˆeme, et ne d´epend pas des pr´ec´edentes tentatives d’infections
sur uj.

Dans [Kempe et al., 2003], les probabilit´es de transmission sont consid´er´ees connues, et
les auteurs s’int´eressent uniquement au probl`eme de la maximisation d’inﬂuence. Dans
[Goldenberg et al., 2001], les auteurs utilisent un mod`ele assez proche, et consid`erent
que chaque lien peut ˆetre un lien fort (associ´e `a une probabilit´e pi,j = pF ) ou un lien
faible (associ´e `a une probabilit´e pi,j = pf < pF ). Ils ´etudient l’impact des liens faibles

2.4. Mod`eles de diﬀusion `a forte granularit´e

31

(a)

(b)

(c)

(d)

Figure 2.2 – Exemple de diﬀusion selon le mod`ele IC. Quatre it´erations sont ici repr´e-
sent´ees. Les utilisateurs encadr´es sont ceux ayant ´et´e contamin´es, ceux encadr´es en rouge
sont les « nouveaux infect´es », i.e. ceux infect´es `a l’it´eration courante et qui tentent donc
d’infecter chaque voisin.

sur la diﬀusion d’un produit par bouche-`a-oreille en simulant l’´evolution du syst`eme pour
diﬀ´erentes valeurs de pf et pF .

En pratique, les probabilit´es de transmission ne sont pas connues. Pour appliquer ce
mod`ele `a un r´eseau social r´eel, il est donc n´ecessaire d’inf´erer les valeurs de ces probabilit´es
`a partir d’un ensemble d’´episodes de diﬀusion.

Ce probl`eme d’apprentissage a ´et´e ´etudi´e dans [Gruhl et al., 2004], qui proposait un
algorithme de type EM consid´erant que chaque utilisateur infect´e avait ´et´e contamin´e par
exactement un utilisateur. Une approche plus pr´ecise a ensuite ´et´e propos´ee par [Saito
et al., 2008]. L’algorithme de cet article consid`ere que chaque utilisateur infect´e a ´et´e
contamin´e par au moins un autre utilisateur, ce qui correspondant mieux au mod`ele IC.
La principale diﬃcult´e de cet apprentissage provient du fait qu’un utilisateur infect´e dans
un ´episode de diﬀusion peut avoir ´et´e contamin´e par n’importe lequel de ses voisins, et
qu’il n’est pas possible de savoir lequel avec certitude. Par exemple, dans la ﬁgure 2.2,
nous pouvons voir qu’`a la troisi`eme it´eration, lorsque l’utilisateur orange devient infect´e,
il peut avoir ´et´e contamin´e soit par l’utilisateur blanc, soit par l’utilisateur vert. Si cette
information ´etait connue, l’estimation des probabilit´es de transmission serait triviale : il
suﬃrait de diviser le nombre d’infections r´eussies par le nombre de tentatives d’infection
de uj par ui pour estimer pi,j. Ce n’est pas le cas, et l’apprentissage des probabilit´es
devient donc un probl`eme d’estimation `a partir d’informations incompl`etes, pour lequel

32

Chapitre 2. Mod´elisation et pr´ediction de la diﬀusion d’information : ´etat de l’art

[Saito et al., 2008] propose un algorithme de type esp´erance-maximisation (EM). Nous
reviendrons plus en d´etail sur cet algorithme dans le chapitre 3.

2.4.2 Le mod`ele Linear Threshold (LT)

Le mod`ele « linear threshold » pr´esent´e ici est ´egalement issu de [Kempe et al., 2003]. Une
version plus simple de ce mod`ele avait d’abord ´et´e ´etudi´ee en sociologie par [Granovetter,
1978] pour analyser les eﬀets de seuil dans le comportement des groupes. De nombreuses
versions de ce mod`ele appliqu´ees `a diverses probl´ematiques avait ensuite ´et´e propos´ees
([Kempe et al., 2003] cite une dizaines de travaux en exemple).

Dans le mod`ele LT de [Kempe et al., 2003], chaque lien (ui, uj) est associ´e `a une valeur
wi,j repr´esentant l’inﬂuence de ui sur uj, avec la contrainte :

(cid:88)

ui∈Predsj

∀uj ∈ U :

wi,j ≤ 1

A chaque fois qu’une information se diﬀuse dans G, chaque utilisateur uj tire un seuil
d’inﬂuence sj ∈ [0, 1] uniform´ement. Comme pour le mod`ele IC, la diﬀusion est simul´ee
de fa¸con it´erative. `A chaque pas de temps t > 0, chaque utilisateur uj non-infect´e le
devient si et seulement si :

(cid:88)

Predsj ∩Ut

wi,j ≥ sj

o`u Ut d´esigne l’ensemble des utilisateurs infect´es avant t. La diﬀusion continue tant que
de nouveaux utilisateurs deviennent infect´es. Un exemple de diﬀusion en donn´e en ﬁgure
2.3.

`A l’inverse du mod`ele IC, le mod`ele LT est centr´e sur le r´ecepteur : c’est le comportement
du r´ecepteur uj qui est mod´elis´e avec le seuil sj. De plus, ce mod`ele fait une hypoth`ese
d’additivit´e de l’inﬂuence : la propension d’un utilisateur `a s’infecter croˆıt avec son nombre
de voisins infect´es.

Comme dans le cas du mod`ele IC, [Kempe et al., 2003] consid`ere que les poids sont connus
et ´etudie uniquement le probl`eme de la maximisation d’inﬂuence.

L’apprentissage des param`etres du mod`ele LT `a partir d’un ensemble d’´episodes de dif-
fusion observ´es a ´et´e ´etudi´e dans [Goyal et al., 2010]. Les poids wi,j y sont estim´es en
utilisant diﬀ´erentes heuristiques relativement simples, bas´ees sur le nombre d’´episodes de
diﬀusion auxquels les utilisateurs de chaque couple (ui, uj) participent. Les mod`eles LT
ainsi appris sont test´es sur des donn´ees r´eelles issues de Flikr 1, au moyen de courbes ROC,
et obtiennent de bonnes performances.

1. https://www.flickr.com/

2.4. Mod`eles de diﬀusion `a forte granularit´e

33

(a)

(c)

(b)

(d)

Figure 2.3 – Exemple de diﬀusion selon le mod`ele LT. Quatre it´erations sont ici repr´e-
sent´ees. Un utilisateur devient infect´e `a partir du moment o`u la somme des poids des liens
provenant d’utilisateurs infect´es d´epasse son seuil d’activation.

Une m´ethode plus pr´ecise pour apprendre les param`etres du mod`ele LT a ´et´e propos´ee
dans [Vaswani and Duttachoudhury, ]. Elle consiste `a maximiser la vraisemblance des
param`etres W = (wi,j)(ui,uj )∈E par rapport `a un ensemble d’´episodes de diﬀusion D.
Cette vraisemblance se calcule assez simplement en remarquant que la probabilit´e qu’un
utilisateur uj devienne infect´e au temps t est ´egale `a la probabilit´e que le seuil sj tir´e soit
inf´erieur `a la somme des poids des voisins infect´es `a ce moment, soit :



wi,j

sj ≤ (cid:88)
(cid:88)

wi,j

ui∈Predsj ∩U D

t

ui∈Predsj ∩U D

t

P D

i (t) = P

=

Le calcul ne fait donc pas intervenir les seuils tir´es, uniquement les poids des relations.
La vraisemblance vaut alors :

 (cid:89)

(cid:89)

Tmax−1(cid:89)

D∈D

t=0

L(W ;D) =

i (t + 1)(cid:1) (cid:89)
(cid:0)P D

i (t + 1)(cid:1)

(cid:0)1 − P D

ui∈(U D

t+1\U D
t )

ui∈ ¯U D

t+1

Cette vraisemblance est optimis´ee par [Vaswani and Duttachoudhury, ] avec plusieurs
techniques (gradient, esp´erance - maximisation, point int´erieur). Cette m´ethode d’ap-
prentissage est ´evalu´ee sur des ´episodes de diﬀusion synth´etiques g´en´er´es avec le mod`ele
LT. L’´evaluation se fait en comparant les valeurs de W apprises aux vraies valeurs, et

34

Chapitre 2. Mod´elisation et pr´ediction de la diﬀusion d’information : ´etat de l’art

sur des tˆaches de pr´ediction de diﬀusion. Les r´esultats indiquent que l’algorithme d’ap-
prentissage parvient bien `a retrouver les vraies valeurs de W . En revanche, la m´ethode
d’apprentissage n’est pas test´ee sur des donn´ees r´eelles.

Comparaison : Les mod`eles IC et LT ont principalement ´et´e compar´es dans le cadre des
tˆaches de maximisation d’inﬂuence et d’identiﬁcation de leaders d’opinion. En particulier,
[Fushimi et al., 2008] ´etudie le comportement des deux mod`eles sur la tˆache d’identiﬁcation
de leaders d’opinion, avec des graphes issus de r´eseaux sociaux en ligne. L’inﬂuence I(ui)
d’un utilisateur y est d´eﬁnie comme l’esp´erance du nombre d’utilisateurs infect´es `a l’issue
d’une diﬀusion commen¸cant par cet utilisateur ui et suivant un mod`ele diﬀusion donn´e. Ils
observent que l’inﬂuence d’un utilisateur est d’avantage corr´el´ee `a son degr´e sortant avec le
mod`ele LT qu’avec le mod`ele IC. Ils montrent ´egalement que la pr´esence de communaut´es
d’utilisateurs dans les graphes a un impact bien plus important sur les inﬂuences des
utilisateurs au sens du mod`ele IC.

2.4.3 G´en´eralisation de IC et LT

L’article [Kempe et al., 2003] a ´egalement propos´e des versions « g´en´eralis´ees » des mo-
d`eles IC et LT, permettant de lever l’hypoth`ese d’ind´ependance du mod`ele IC et celle
d’additivit´e du mod`ele LT. Il est ensuite possible de montrer que toute instance du mo-
d`ele IC g´en´eralis´e est ´equivalente `a une certaine instance du mod`ele LT g´en´eralis´e, et
vice-versa.

2.4.3.1 IC g´en´eralis´e

Au lieu de consid´erer des probabilit´es de transmission pi,j constantes, le mod`ele IC g´en´era-
lis´e consid`ere que la transmission se fait avec une probabilit´e pi(j, X), o`u X est l’ensemble
des utilisateurs ayant d´ej`a tent´e de contaminer uj mais ayant ´echou´e. L’hypoth`ese d’in-
d´ependance du mod`ele IC disparaˆıt : la contamination de uj par ui peut d´ependre des
pr´ec´edentes tentatives d’infections sur uj. Typiquement, pi(j, X) pourra ˆetre croissante ou
d´ecroissante suivant |X|, pour mod´eliser diﬀ´erents comportements possibles. Le mod`ele
IC normal correspond au cas o`u pi(j, X) = pi,j.

2.4.3.2 LT g´en´eralis´e

Predsj ∩Ut

Dans le mod`ele LT g´en´eralis´e, la condition d’infection(cid:80)

wi,j ≥ sj est remplac´ee
par une forme plus g´en´erale : gj(Predsj ∩Ut) ≥ sj, o`u gj : 2U → [0, 1] est une fonction

2.4. Mod`eles de diﬀusion `a forte granularit´e

monotone avec gj(∅) = 0 associant `a un ensemble d’utilisateurs 2 l’inﬂuence qu’ils exercent

sur uj. Le mod`ele LT normal correspond au cas o`u gj(X) =(cid:80)

ui∈X wi,j.

35

2.4.4 Mod`eles continus

Les mod`eles LT et IC sont des mod`eles it´eratifs dans lesquels le temps est discr´etis´e et la
diﬀusion `a lieu de fa¸con synchrone, `a chaque pas de temps. En pratique, l’information se
propage de fa¸con continue, et `a des vitesses variables. Des versions continues des mod`eles
IC et LT ont donc ´et´e propos´ees.

2.4.4.1 CTIC et CTLT

Une version continue du mod`ele IC, nomm´ee Continuous Time IC (CTIC) a ´et´e d´eﬁnie
dans [Saito et al., 2009].

— Dans cette version, chaque lien (ui, uj) du graphe est associ´e `a un param`etre tem-

porel ri,j, en plus de sa probabilit´e de transmission pi,j.

— Quand l’utilisateur ui devient infect´e au temps ti, il tente de contaminer chaque

successeur uj, comme dans le mod`ele IC.

— Si cette contamination r´eussi, l’utilisateur uj devient infect´e au temps ti + di,j, o`u

di,j est un d´elai tir´e selon une loi exponentielle de param`etre ri,j.

(cid:40)

P (di,j = x) =

ri,je−xri,j
0

si x >= 0

sinon

Ainsi, la diﬀusion suivant ce lien prend en moyenne un temps di,j = 1
ri,j

.

Le mod`ele IC classique peut ˆetre vu comme un cas particulier de CTIC dans lequel les
d´elais de transmission valent toujours 1.

L’apprentissage des param`etres pi,j et ri,j de cette version a ´egalement ´et´e ´etudi´e par
Saito dans [Saito et al., 2009]. Il propose un algorithme esp´erance-maximisation similaire
`a [Saito et al., 2008], prenant en compte le fait qu’un utilisateur observ´e dans une s´equence
d’activation peut avoir ´et´e contamin´e par n’importe quel pr´ed´ecesseur infect´e avant lui,
et pas uniquement par ceux infect´es au pas de temps pr´ec´edent.

Une extension similaire du mod`ele LT, CTLT, a ´et´e propos´ee dans [Saito et al., 2010b].
Cette fois-ci, chaque utilisateur ui est associ´e `a un param`etre temporel ri. Lorsque l’in-
ﬂuence exerc´ee sur ui par ses voisins au temps t d´epasse son seuil d’activation si, ui ne
devient infect´e qu’au temps t + di, apr`es un d´elai tir´e de la mˆeme fa¸con que dans le mod`ele
CTLT, selon une loi exponentielle de param`etre ri.

2. Nous utiliserons dans ce manuscrit la notation 2X pour d´esigner l’ensemble des parties d’un ensemble
X. L’utilisation de la notation P(X) serait en eﬀet source de confusion, car nous seront ´egalement amen´es
`a manipuler des probabilit´es P (X) dans divers contextes.

36

Chapitre 2. Mod´elisation et pr´ediction de la diﬀusion d’information : ´etat de l’art

Notons que dans certains travaux, ces deux mod`eles sont ´egalement nomm´es AsIC et
AsLT (pour asynchronous IC ou LT).

Comparaison : Les mod`eles CTIC et CTLT ont ´et´e compar´es dans [Saito et al., 2010a,
Saito et al., 2010c], avec des donn´ees r´eelles issues du site Doblog 3, dont sont extraits
plusieurs ensembles d’apprentissages correspondant `a des sujets diﬀ´erents. Seul le cas o`u
les param`etres des mod`eles sont uniformes sur l’ensemble du r´eseau est ´etudi´e dans cet
article. Les auteurs observent que le mod`ele CTIC explique mieux la diﬀusion de la plupart
des types d’information pr´esents dans le corpus. Seuls certains sujets pr´ecis, correspondant
g´en´eralement `a des ´episodes de diﬀusion plus longs, sont mieux expliqu´es par un mod`ele
CTLT.

2.4.4.2 Mod`ele continu de Leskovec et Gomez-Rodrigez : NetRate

Un mod`ele proche de CTIC a ´egalement ´et´e utilis´e par Leskovec et Gomez-Rodriguez
[Gomez-Rodriguez et al., 2011]. Celui-ci reprend l’id´ee de CTIC mais ne d´eﬁnit pas de
probabilit´es de transmission pi,j, uniquement un param`etre temporel ri,j sur chaque lien.
Lorsqu’un utilisateur ui devient infect´e, il transmet l’information `a chaque successeur uj
apr`es un d´elai di,j, tir´e selon une distribution de probabilit´e param´etr´ee par ri,j Cette dis-
tribution est g´en´eralement une loi exponentielle ou une loi de puissance [Gomez-Rodriguez
et al., 2011], mais d’autres formes sont possibles [Farajtabar et al., 2015]. Avec une loi
exponentielle, ce mod`ele devient ´equivalent `a un mod`ele CTIC o`u toutes les probabilit´es
de transmissions seraient ´egales `a 1. Une faible propension `a transmettre de l’information
sera repr´esent´ee dans ce mod`ele par une valeur ri,j tr`es faible, au lieu d’une valeur de pi,j
tr`es faible.

Dans [Gomez Rodriguez et al., 2010], les auteurs consid`erent que ri,j est toujours ´egal
`a une constante sur tous les liens du graphe. Dans [Gomez-Rodriguez et al., 2011], ils
proposent une m´ethode pour apprendre les valeurs de ri,j. Ne pas utiliser de probabilit´es
de transmission pi,j leur permet notamment d’utiliser des m´ethodes d’optimisation conti-
nue plus simples qu’un algorithme EM. Ce mod`ele a ensuite ´et´e utilis´e pour des tˆaches
d’inf´erence de graphe (voir section 2.4.7) ou de d´etection de source (voir section 2.8).

2.4.5 Int´egration du contenu et des attributs utilisateurs.

Dans les mod`eles vus jusqu’`a pr´esents, aucune distinction n’est faite a priori entre les
diﬀ´erents utilisateurs et les diﬀ´erentes informations se diﬀusant. En pratique, le type d’in-
formation se diﬀusant ainsi que les proﬁls des utilisateurs sont susceptibles d’avoir un

3. http://www.doblog.com

2.4. Mod`eles de diﬀusion `a forte granularit´e

37

impact non-n´egligeable sur la diﬀusion. Par exemple, une information concernant la poli-
tique internationale ne se diﬀusera pas de la mˆeme fa¸con et aupr`es des mˆemes utilisateurs
qu’une information concernant un r´esultat sportif. Divers travaux ont donc propos´e des
techniques permettant d’int´egrer cette information dans des mod`eles similaires `a IC ou
LT. Ces techniques consistent en g´en´eral `a d´eriver les param`etres d’un mod`ele IC `a par-
tir des propri´et´es des utilisateurs ou du contenu de l’information. Dans cette section, τi
d´esignera le proﬁl de l’utilisateur ui, et wD le contenu de l’information se diﬀusant dans
l’´episode D. La nature exacte de ces proﬁls et du contenu d´ependent du r´eseau social
´etudi´e.

2.4.5.1 Int´egration des attributs utilisateurs

Dans [Saito et al., 2011], les auteurs consid`erent pour chaque lien (ui, uj) du graphe le
vecteur xi,j de mˆeme taille que les proﬁls τi et τj, et dont chaque composante xa
i,j est
d´eﬁnie par :

i,j = e|τ a
xa

i −τ a
j |

Ce vecteur est ensuite utilis´e pour d´eﬁnir les valeurs des param`etres d’un mod`ele CTIC
pi,j et ri,j :

1

pi,j =

1 + e−<θ,xi,j >
ri,j = e−<φ,xi,j >

o`u θ et φ sont deux vecteurs de param`etres de mˆeme taille que les vecteurs d’attributs.
Les auteurs proposent un algorithme EM pour apprendre les valeurs de ces param`etres.
Cependant, le mod`ele n’est test´e que sur des donn´ees synth´etiques, avec des attributs
utilisateurs g´en´er´es de fa¸con artiﬁcielle sur des graphes issus donn´ees r´eelles.

Une id´ee similaire a ´et´e propos´ee par [Guille and Hacid, 2012] et test´ee sur des donn´ees
r´eelles. Pour chaque liens (ui, uj), les auteurs d´eﬁnissent une douzaine de propri´et´es li´ees
aux actions et interactions de ces deux utilisateurs. Diverses m´ethodes d’apprentissage
automatique sont ensuite utilis´ees pour pr´edire, `a partir de ces propri´et´es, si un contenu
donn´e va se diﬀuser de l’utilisateur ui `a l’utilisateur uj. Les auteurs ´evaluent leur approche
sur des donn´ees r´eelles issues de Twitter et constatent entre autres que la propri´et´e la plus
importante pour pr´edire la diﬀusion de ui vers uj est leur nombre de voisins communs
dans G.

2.4.5.2 Int´egration du contenu et des attributs utilisateurs

Dans [Lagnier et al., 2013], les auteurs d´eﬁnissent un mod`ele centr´e sur le r´ecepteur
(comme le mod`ele LT) bas´e sur trois propri´et´es calcul´ees au cours de la diﬀusion :

— la similarit´e entre le proﬁl τi de l’utilisateur et le contenu diﬀus´e wD ;

38

Chapitre 2. Mod´elisation et pr´ediction de la diﬀusion d’information : ´etat de l’art

— l’activit´e de ui, c’est `a dire sa propension g´en´erale `a devenir infect´e (calcul´ee sur

les ´episodes d’apprentissage) ;

— l’inﬂuence de ses voisins sur cet utilisateur, i.e. le nombre de voisins infect´es.

Ces propri´et´es permettent de calculer une probabilit´e d’infection de l’utilisateur ui en
appliquant une fonction logistique dont les param`etres sont appris sur les ´episodes d’ap-
prentissage. Ce mod`ele est test´e sur des ´episodes de diﬀusion r´eels, sur une tˆache de
pr´ediction de diﬀusion, et obtient de meilleurs r´esultats que les mod`eles classiques.

2.4.5.3 Int´egration du contenu seul

Enﬁn, des versions des mod`eles IC et LT prenant en compte le contenu de l’information se
diﬀusant ont ´et´e propos´ees dans [Barbieri et al., 2013b], TIC et TLT (pour Topic-aware
IC et LT). Dans ces mod`eles, le contenu d’une information se propageant est repr´esent´e
par une distribution de probabilit´e sur Q topics, i.e wD ∈ [0, 1]Q avec

Q−1(cid:88)

wq

D = 1

Ce vecteur peut notamment ˆetre obtenu au moyen d’une LDA (Latent Dirichlet Alloca-
tion).

q=0

Dans le mod`ele TIC, chaque lien (ui, uj) est associ´e `a un ensemble de Q probabilit´es de
transmissions (pq
i,j)q=0..Q−1. Quand une information de contenu wD se propage, la proba-
bilit´e de transmission d’un utilisateur ui `a uj vaut alors :

Q−1(cid:88)

q=0

Q−1(cid:88)

pD
i,j =

D.pq
wq

i,j

wD

i,j =

D.wq
wq

i,j

De la mˆeme fa¸con, dans le mod`ele TLT, chaque lien est associ´e `a un ensemble de poids
(wq
i,j)q=0..Q−1, et l’inﬂuence d’un utilisateur ui sur un utilisateur uj pour une information
de contenu wD est :

Des algorithmes de type EM sont propos´es pour apprendre les param`etres de ces mod`eles.
Ils obtiennent de meilleurs r´esultats que les versions « sans contenu » sur des corpus
r´eels.

q=0

2.4. Mod`eles de diﬀusion `a forte granularit´e

39

2.4.6 Mod´elisation de plusieurs diﬀusions

Tous les articles pr´esent´es jusqu’ici mod´elisent la diﬀusion d’une seule information `a la
fois. Plusieurs informations se diﬀusant en parall`ele sont donc consid´er´ees de fa¸cons in-
d´ependantes. Quelques travaux se sont toutefois int´eress´es au cas o`u plusieurs diﬀusions
simultan´ees pouvaient avoir une inﬂuence les unes sur les autres.

En particulier, [Myers and Leskovec, 2012] consid`ere que la probabilit´e qu’un utilisateur
ui de Twitter expos´e `a une s´equence d’informations (I1, I2, I3...) d´ecide de retweeter l’in-
formation Ix d´epend des k informations pr´ec´edentes suivant la formule :

Pi(Ix|Ix−1, . . . , Ix−N ) = Pi(Ix) +

f (Ix, Iy) + γi

x−1(cid:88)

y=x−N

o`u Pi(Ix) est la probabilit´e a priori que l’utilisateur ui retweete l’information Ix, f (Ix, Iy)
correspond `a l’inﬂuence (positive ou n´egative) de l’exposition `a l’information Iy sur la
probabilit´e de retweeter Ix, et γi est un biais propre `a chaque utilisateur. L’inﬂuence
de chaque information sur chaque autre (la fonction f ) est calcul´ee en partitionnant les
informations en clusters, et en apprenant les inﬂuences de chaque cluster sur chaque autre.
Les param`etres de ce mod`ele (infection a priori, biais et inﬂuences inter-clusters) sont
appris en maximisant la vraisemblance d’un ensemble d’apprentissage d’environ 18000
diﬀusions simultan´ees. Les exp´eriences eﬀectu´ees montrent que l’inclusion de l’inﬂuence
entres les diﬀ´erentes informations augmente les performances en pr´ediction de plus de
200%.

La diﬀusion de plusieurs informations a ´egalement ´et´e ´etudi´ee dans le cadre de la maxi-
misation d’inﬂuence (voir section 2.6.3.1)

2.4.7 Inf´erence de graphe

Il arrive dans certaines applications que le graphe du r´eseau social au sein duquel l’infor-
mation se diﬀuse soit cach´e ou inconnu. Pour appliquer un mod`ele de diﬀusion de type
IC ou LT dans une telle situation, il est alors n´ecessaire d’inf´erer ce graphe `a partir des
´episodes de diﬀusion observ´es.

L’inf´erence de graphe consiste `a pr´edire les liens existant entre les ´el´ements d’un ensemble
ﬁx´e. Dans le contexte de la diﬀusion d’information, le but est de retrouver le graphe social
G = (U, E) `a partir d’un ensemble d’´episodes de diﬀusion observ´es D sur la population
U . Nous pr´esentons dans cette sous-section quelques travaux sur le sujet. Le principe
g´en´eral est toujours le mˆeme : faire l’hypoth`ese d’un certain mod`ele de diﬀusion, puis
rechercher les liens les plus vraisemblables par rapport `a D avec le mod`ele de diﬀusion en
question.

40

Chapitre 2. Mod´elisation et pr´ediction de la diﬀusion d’information : ´etat de l’art

2.4.7.1 NetInf

Dans ce premier article [Gomez Rodriguez et al., 2010], les auteurs se basent sur l’intuition
suivante : plus un utilisateur uj a tendance `a ˆetre infect´e peu de temps apr`es un utilisateur
ui, plus l’existence d’un lien (ui, uj) est vraisemblable.

Les auteurs utilisent le mod`ele CTIC, en faisant l’hypoth`ese que tous les liens partagent
la mˆeme probabilit´e de transmission pi,j = p et le mˆeme param`etre temporel ri,j = r.
Ils cherchent alors l’ensemble de k liens ˆE de vraisemblance maximum par rapport `a
l’ensemble d’´episodes de diﬀusion observ´es D sous le mod`ele CTIC :

(cid:88)

D∈D

ˆE = arg max

|E|≤k

log P (D|E)

que la fonction `a optimiser f (E) = (cid:80)

Limiter la taille de l’ensemble de liens du graphe `a k est obligatoire, sinon une solution
triviale consisterait `a retrouver le graphe complet. Le probl`eme d’optimisation est donc
combinatoire, et les auteurs d´emontrent qu’il est NP-complet. Ils observent cependant
D∈D log P (D|E) est sous-modulaire, et qu’il est
donc possible d’obtenir une bonne solution en utilisant un algorithme glouton : partir de
l’ensemble vide, et ajouter `a chaque it´eration le lien maximisant le gain marginal (voir
section 2.6.1).

2.4.7.2 NetRate

Dans [Gomez-Rodriguez et al., 2011], les auteur proposent d’utiliser le mod`ele continu
pr´esent´e dans la section pr´ec´edente pour l’inf´erence de lien (NetRate). Ils consid`erent un
graphe complet reliant tous les utilisateurs de U , et apprennent les param`etres temporels
R = (ri,j)(ui,uj )∈U 2 sur tous les liens de ce graphe, `a partir d’un ensemble d’´episodes de
diﬀusion D, en consid´erant le probl`eme d’optimisation suivant :

(cid:40)
minimiserR −(cid:80)

s.c.

D∈D log P (D|R)

∀(ui, uj), ri,j ≥ 0

Les liens pr´edits sont ceux dont le param`etre ri,j est strictement sup´erieur `a 0. Ce mod`ele
est test´e sur plusieurs jeux de donn´ees r´eels et artiﬁciels, et les auteurs observent une
am´elioration des performances par rapport `a NetInf. Notons qu’il est possible de r´eduire
consid´erablement la complexit´e de l’apprentissage en supprimant a priori tous les liens
(ui, uj) pour lesquels il n’existe aucun exemple potentiel de diﬀusion dans D, i.e aucun
´episode D dans lequel les deux utilisateur sont infect´e, avec ui infect´e avant uj.

Cette approche fut ensuite am´elior´ee dans [Daneshmand et al., 2014], o`u les auteurs
´etudient l’impact du nombre de cascades observ´ees sur la qualit´e de la pr´ediction, et
proposent d’ajouter une r´egularisation (cid:96)1 sur les valeurs de R pour am´eliorer la stabilit´e

2.5. Pr´ediction de diﬀusion

41

du mod`ele. Une version am´elior´ee de NetRate utilisant un noyau a aussi ´et´e propos´ee
dans [Du et al., 2012]. Plus tard, [Gomez-Rodriguez et al., 2013] ont propos´e une version
plus g´en´erale o`u la probabilit´e d’infection d’un utilisateur est une fonction des temps
d’infections de tous les utilisateurs pr´ec´edents dans l’´episode de diﬀusion.

2.4.7.3 InfoPath

Enﬁn, une version dynamique du probl`eme a ´et´e ´etudi´ee dans [Gomez Rodriguez et al.,
2013]. En eﬀet, un r´eseau social peut ´evoluer au cours du temps : des utilisateurs peuvent
ajouter des contacts pour cr´eer de nouveaux liens, ou en supprimer certains autres. De
plus, un lien entre deux utilisateurs peut changer d’intensit´e : deux personnes peuvent par
exemple rester amies sur Facebook mais se perdre de vue et ne plus ´echanger beaucoup
d’information.

L’algorithme InfoPath est une extension de celui de NetRate. Au lieu d’observer un
seul ensemble d’´episodes d’apprentissage D, les auteurs observent une s´equence d’en-
semble d’´episodes (D0,D1,D2 . . . ). Suivant le contexte applicatif, ces ensembles peuvent
ˆetre observ´es au rythme d’un par jour ou d’un par semaine, par exemple. Le but est
d’´etudier, `a chaque fois qu’un nouvel ensemble est observ´e, l’´evolution des param`etres de
diﬀusion.

`A chaque pas de temps T , les auteurs r´esolvent le probl`eme de pr´ediction de liens selon
NetRate sur l’ensemble des cascades observ´ees jusqu’`a pr´esent D0∪D1∪···∪DT , en ajou-
tant une pond´eration w(t) pour donner plus d’importance aux cascades r´ecentes :

(cid:40)
minimiserRT −(cid:80)

s.c.

D∈Dt≤T w(t) log P (D|RT )

∀(ui, uj), rT

i,j ≥ 0

Ce probl`eme est optimis´e, `a chaque pas de temps, au moyen d’une descente de gradient
stochastique. De plus, les valeurs de RT sont initialis´ees avec celles de RT−1. De cette
fa¸con, les liens pr´edits ´evoluent progressivement avec le temps.

Cet algorithme est d’abord test´e sur des donn´ees enti`erement synth´etiques, g´en´er´ees en
suivant le mod`ele utilis´e en pr´ediction, et obtient de bonnes performances. Malheureu-
sement, les auteurs ne disposent pas d’un jeu de donn´ees ´etiquet´ees correspondant `a ce
contexte exp´erimental. Ils ´evaluent donc leur mod`ele de fa¸con empirique, en observant
l’´evolution du graphe pr´edit au cours du temps.

2.5 Pr´ediction de diﬀusion

Dans ce manuscrit, nous nous int´eressons principalement `a la tˆache de pr´ediction de
diﬀusion. Le but est de pr´edire quels utilisateurs seront infect´es par une information au

42

Chapitre 2. Mod´elisation et pr´ediction de la diﬀusion d’information : ´etat de l’art

bout d’un certain temps Tmax en connaissant uniquement l’´etat du r´eseau `a un temps initial
Tinit, sans forc´ement expliquer comment ils le seront. Typiquement, Tinit correspond `a un
temps de l’ordre de quelques heures (apr`es la d´ebut de la diﬀusion) et Tmax `a un temps de
l’ordre de quelques jours. En d’autres termes, il s’agit de pr´edire U D
Tmax `a partir de U D
Tinit
et d’un ensemble r d’informations compl´ementaires (telles que le contenu de l’information
se diﬀusant), en d´eﬁnissant une fonction de pr´ediction f telle que :

U D
Tmax = f (U D
Tinit

, r)

Plusieurs mesures ont ´et´e propos´ees pour l’´evaluation des performances d’une telle fonc-
tion. Par exemple, [Najar et al., 2012] et [Lagnier et al., 2013] utilisent des mesures de
pr´ecision ou de rappel. De leur cot´e, [Saito et al., 2010b] utilisent une divergence de
Kullback-Leibler entre les probabilit´es ﬁnales d’infection pr´edites et celles observ´ees aﬁn
d’´evaluer la pr´ediction r´ealis´ee. Dans [Kondor and Laﬀerty, 2002], les auteurs mesurent un
taux d’erreur. Enﬁn, [Barbieri et al., 2013b] visualise des courbes « taux de faux positifs
- taux de vrais positifs ».

Toutes ces mesures traduisent des objectifs diﬀ´erents, et sont susceptibles de ne pas favo-
riser les mˆemes mod`eles, comme nous le montrons dans le chapitre 5.

2.5.1 Application de mod`eles de diﬀusion dans le graphe

Les mod`eles de diﬀusion `a forte granularit´e pr´esent´es en section 2.4 peuvent ˆetre utilis´es
dans un cadre pr´edictif : l’´etat du r´eseau `a Tmax peut ˆetre obtenu en simulant la diﬀusion
`a partir de son ´etat `a Tinit.

2.5.1.1 Simulation du mod`ele IC

Ces mod`eles explicatifs, et IC en particulier, ´etant g´en´eralement des processus stochas-
tiques, il est n´ecessaire d’utiliser une estimation de type « Monte-Carlo ». Cette m´ethode
consiste simplement, ´etant donn´e l’ensemble U D
, `a simuler plusieurs fois le proces-
sus de diﬀusion selon le mod`ele de diﬀusion consid´er´e, et `a compter le nombre d’ins-
tances dans lesquelles chaque utilisateur ui est infect´e pour en d´eduire la probabilit´e
P (ui ∈ U D
). Dans le cas du mod`ele IC, cette proc´edure est ´equivalente `a une
percolation de liens [B´ota et al., 2013] :

Tmax|U D

Tinit

Tinit

— pour chaque lien (ui, uj) du graphe, conserver ce lien avec une probabilit´e pi,j ou

le supprimer avec une probabilit´e 1 − pi,j ;

— trouver dans le sous-graphe ainsi obtenu tous les utilisateurs pouvant ˆetre atteints

depuis les utilisateurs initialement infect´es.

Ce processus est ´equivalent `a une simulation du mod`ele IC, et peut ˆetre r´ep´et´e pour
obtenir la mˆeme estimation qu’avec la m´ethode pr´ec´edente..

2.5. Pr´ediction de diﬀusion

43

2.5.1.2 Heuristiques bas´ees sur la distance dans le graphe

D’autres m´ethodes exploitent le fait que les r´eseaux sociaux sont des graphes parcimonieux
et que les probabilit´es de transmission sont souvent assez faibles [B´ota et al., 2013], ce qui
limite la « port´ee » de la diﬀusion. Cette observation permet d’appliquer des heuristiques
bas´ees sur la proximit´e entre les utilisateurs.

Par exemple, une m´ethode d’approximation pour le mod`ele IC a ´et´e propos´ee dans [Ki-
mura and Saito, 2006]. Celle-ci est bas´ee sur le calcul des plus courts chemins dans
le graphe. En eﬀet, en consid´erant que la longueur de chaque lien (ui, uj) est ´egale `a
log(1 − pi,j), les longueurs des chemins deviennent inversement proportionnelles `a leurs
probabilit´es. Consid´erer uniquement le plus court chemin d’un utilisateur initial ux `a un
autre utilisateur uy revient donc `a approximer la probabilit´e d’infection ﬁnale de uy avec
la probabilit´e du chemin le plus vraisemblable.

Une autre m´ethode de ce genre a ´egalement ´et´e utilis´ee dans [Chen et al., 2010, Chen
et al., 2009] pour le mod`ele LT, et a ´et´e adapt´ee au mod`ele IC dans [B´ota et al., 2013].
Elle consiste ´egalement `a consid´erer uniquement les chemins les plus courts, c’est `a dire
les plus vraisemblables, en calculant la probabilit´e d’infection ﬁnale de chaque utilisateur
uniquement partir de son voisinage dans le graphe, plutˆot que sur le graphe entier.

2.5.1.3 M´ethodes `a noyaux

Noyau de mod`eles de diﬀusion Au lieu d’utiliser directement un mod`ele de diﬀusion
`a forte granularit´e, [Rosenfeld et al., 2016] proposent d’appliquer une m´ethode `a noyau.
La m´ethode `a noyau propos´ee est appliqu´ee `a la pr´ediction du nombre d’utilisateurs infec-
t´es `a Tmax `a partir de la liste des utilisateurs infect´es `a Tinit, mais peut parfaitement ˆetre
appliqu´ee `a la pr´ediction de l’´etat ﬁnal de chaque utilisateur. Le but des auteurs est de
pr´edire le nombre d’utilisateurs infect´es `a la ﬁn d’une diﬀusion partant d’un ensemble UI
d’utilisateurs-sources, sous l’hypoth`ese d’un certain mod`ele de diﬀusion connu, en parti-
culier IC ou LT. Cette valeur est not´ee f (UI, θ) = E[y|UI, θ], o`u E[y|UI, θ] est l’esp´erance
du nombre y d’utilisateurs infect´es `a partir de UI dans le mod`ele de diﬀusion consid´er´e,
et θ est l’ensemble des param`etres de ce mod`ele. Par exemple, si le mod`ele de diﬀusion
est le mod`ele IC, θ sera l’ensemble des probabilit´es de transmission.

Cet ensemble θ doit ˆetre appris `a partir d’un ensemble d’exemples prenant la forme de X
couples (U x

I , yx). L’apprentissage des param`etres s’´ecrit alors :

(cid:88)

(U x

I ,yx)

min

θ

1
X

(f (U x

I , θ) − yx)2

Cet apprentissage est complexe, mais les auteurs montrent qu’il est possible d’utiliser un
noyau K, ce qui permet de r´ealiser l’optimisation sur un espace plus large contenant toutes

44

Chapitre 2. Mod´elisation et pr´ediction de la diﬀusion d’information : ´etat de l’art

les fonctions f (., θ) possibles :

min

α

1
X

(g(U x

I , α) − yx)2

avec :

g(UI, α) =

αxK(UI, U x
I )

(cid:88)

(U x

I ,yx)

(cid:88)

U x
I

La d´eﬁnition du noyau K utilis´e d´epend du mod`ele de diﬀusion. Plusieurs noyaux sont
d´ecrits, dont ceux des mod`eles IC et LT. Cette approche est test´ee sur des r´eseaux artiﬁ-
ciels et r´eels, et obtient de meilleurs r´esultats que diverses m´ethodes utilisant directement
le graphe pour simuler la diﬀusion.

Noyau de diﬀusion d´eﬁnis sur les graphes Certains types de noyaux d´eﬁnis sur
les graphes peuvent aussi ˆetre appliqu´es `a la diﬀusion d’information. En eﬀet, la diﬀusion
d’information sur un graphe (au sens du mod`ele IC) peut ˆetre vue comme une s´erie de
marches al´eatoires partant d’une source ﬁx´ee (ou de plusieurs). Ce processus peut ˆetre
repr´esent´e par un noyau de diﬀusion ou noyau de chaleur [Kondor and Laﬀerty, 2002]
d´eﬁni sur le graphe.

L’utilisation d’un tel noyau consiste `a repr´esenter l’infection d’un utilisateur ui au temps
t par une valeur continue xi(t), interpr´et´ee comme une quantit´e de chaleur. `A chaque pas
de temps, chaque utilisateur « chaud » (i.e. infect´e) transmet une partie de sa chaleur `a ses
voisins plus « froids » (i.e non-infect´es). En notant x(t) le vecteur compos´e de l’ensemble
des valeurs xi(t) pour ui ∈ U , l’´evolution du syst`eme suit :
x(t + 1) − x(t) = βHx(t)

o`u β est un hyperparam`etre et H est l’oppos´e de la matrice laplacienne du graphe :

−degr´e(ui)

1

0

Hi,j =

si i = j
si (ui, uj) ∈ E
sinon

Il est alors possible de calculer une solution analytique :

x(t) = etβHx(0)

L’expression etβH peut ˆetre d´evelopp´ee en

etβH = I + tβH +

t2β2
2!

H 2 +

t3β3
3!

H 3 + ...

2.5. Pr´ediction de diﬀusion

45

Intuitivement, etβH est donc une matrice repr´esentant le r´esultat moyen de plusieurs ´etapes
de diﬀusion dans le graphe. Une fois cette expression pos´ee, dans le cas o`u seule la valeur
ﬁnale `a Tmax nous int´eresse, l’estimation s’´ecrit donc :

avec :

x(Tmax) = Kx(Tinit)

K = e(Tmax−Tinit)βH

(2.1)

(2.2)

Le calcul exact du noyau de chaleur K n´ecessite de diagonaliser H :

H = T −1DT
eβH = T −1eβDT

La diagonalisation ´etant une op´eration complexe, [Kondor and Laﬀerty, 2002] ´etudie le
cas de graphes particuliers sur lesquels des formules plus simples existent.

Ce noyau correspond `a un mod`ele de diﬀusion simple, o`u chaque utilisateur transmet une
portion β de sa chaleur `a chacun de ses voisins. Plusieurs extensions, permettant de ra-
jouter des poids sur les liens, de les orienter ou de rajouter des biais sur les utilisateurs ont
´et´e propos´ees dans [Ma et al., 2008]. Chaque extension conduit `a une d´eﬁnition diﬀ´erente
du noyau K.

2.5.1.4 Limites des approches bas´ees sur la diﬀusion dans le graphe

L’utilisation de ces approches bas´ees sur le graphe pose toutefois probl`eme. En eﬀet, celles-
ci font implicitement l’hypoth`ese que l’information ne peut se diﬀuser que sur les liens de
ce graphe. Cette hypoth`ese est en pratique assez forte [Yang and Leskovec, 2010], pour
plusieurs raisons.

Tout d’abord, la multiplication des services en ligne fait que les utilisateurs font souvent
partie de plusieurs r´eseaux sociaux parall`eles. L’information devient ainsi susceptible de
suivre des « chemins d´etourn´es », et de passer d’un utilisateur `a un autre en suivant des
liens ne faisant pas partie de l’unique r´eseau consid´er´e.

De la mˆeme fa¸con, la diﬀusion au sein du graphe n’est pas toujours le seul facteur expli-
quant l’infection des utilisateurs. Divers ´el´ements propres au fonctionnement du service
´etudi´e peuvent avoir un impact sur cette diﬀusion. Sur Twitter par exemple, un utilisa-
teur peut recevoir de l’information par le biais des personnes auxquelles il s’est abonn´e,
mais aussi par le biais de la liste des « trending topics », qui regroupe l’ensemble des
informations les plus populaires du moment. Il est toutefois possible, dans certains cas, de
mod´eliser cette « inﬂuence ext´erieure » un ajoutant dans le graphe un utilisateur virtuel
u0, reli´e `a tous les utilisateurs et consid´er´e comme toujours infect´e [Gomez Rodriguez
et al., 2010].

46

Chapitre 2. Mod´elisation et pr´ediction de la diﬀusion d’information : ´etat de l’art

D’autre part, le graphe explicite renseign´e sur un r´eseau social n’est pas toujours le plus
pertinent pour expliquer la diﬀusion [Huberman et al., 2008]. Ainsi, dans [Cha et al.,
2010], nous apprenons que le nombre de « followers » d’un utilisateur donne assez peu
d’information sur la nature de son inﬂuence dans Twitter, contrairement `a son nombre de
« retweets » et de « mentions ». Les auteurs observent ainsi que les comptes de journaux
ou de chaˆınes d’informations g´en`erent g´en´eralement beaucoup de retweets, alors que les
comptes de c´el´ebrit´es sont plus rarement retweet´es mais g´en`erent plus de « mentions ». De
plus, il a ´et´e montr´e que sur Twittter, les liens faibles (i.e. les liens reliant des utilisateurs
ayant peu de connaissances communes) jouaient un rˆole important dans la diﬀusion d’in-
formation [Zhao et al., 2010, Granovetter, 1973]. Utiliser directement le graphe explicite
peut revenir `a ignorer cette h´et´erog´en´eit´e dans la nature mˆeme de ces liens.

Enﬁn, il est possible que le graphe du r´eseau social soit inconnu, totalement ou partielle-
ment. Cela peut ˆetre dˆu `a diﬀ´erentes raisons. La liste des amis ou des contacts est parfois
une information priv´ee. Sur Facebook par exemple, un utilisateur peut d´ecider de mas-
quer cette liste. Sur Twitter, l’API oﬀerte aux d´eveloppeurs limite le nombre de requˆetes
possibles chaque heure, ce qui rend impossible l’extraction du graphe complet. L’eﬀet de
ces restrictions a d’ailleurs ´et´e ´etudi´e dans [Morstatter et al., 2013].

Tous ces ´el´ements sont susceptibles de limiter la pertinence d’un mod`ele de diﬀusion `a
forte granularit´e. D’autres m´ethodes de pr´ediction ont donc ´et´e propos´ees.

2.5.2 R´egression directe

Dans [Najar et al., 2012], les auteurs pr´edisent le vecteur x(Tmax) repr´esentant l’´etat
des utilisateurs du r´eseau au temps Tmax `a partir de x(Tnit) en utilisant l’apprentissage
automatique. Diﬀ´erents mod`eles, en particulier une r´egression lin´eaire et une r´egression
logistique, sont utilis´es pour r´ealiser la pr´ediction, leurs param`etres ´etant appris par des-
cente de gradient. Il est int´eressant de remarquer que la pr´ediction avec un classiﬁeur
lin´eaire s’´ecrit :

x(Tmax) = θ.x(Tinit)

o`u θ ∈ RN×N la matrice des param`etres. On retrouve la mˆeme forme que l’´equation 2.1.
Cette approche revient donc en quelque sorte `a « apprendre » un noyau de chaleur au lieu
de le calculer `a partir d’un graphe.

Les mod`eles appris sont ´evalu´es sur des ´episodes de diﬀusion artiﬁciels avec des mesures
issues de la recherche d’information, et compar´es aux mod`eles IC et LT. Les auteurs
observent que leur mod`ele obtient des performances similaires aux mod`eles IC et LT
lorsque le graphe est connu, et des performances bien meilleures que celles des mod`eles
explicatifs lorsque le graphe utilis´e pour g´en´erer les donn´ees n’est que partiellement connu.
Cette robustesse est un avantage important des approches pr´edictives par rapport aux
approches explicatives.

2.5. Pr´ediction de diﬀusion

2.5.3 Recommandation

47

Le probl`emes de recommandation a ´et´e tr`es largement ´etudi´e ces derni`eres ann´ees, en
particulier depuis la cr´eation du Netﬂix Challenge 4. Le but de la recommandation est de
sugg´erer `a un utilisateur un ensemble d’items susceptibles de l’int´eresser, au vu de son
activit´e pass´ee. Ce type de suggestion est par exemple visible sur Amazon : un utilisateur
ayant achet´e un smartphone se verra par la suite recommander divers accessoires pour
celui-ci.

Les probl`emes de recommandation et de pr´ediction de diﬀusion (`a forte granularit´e)
peuvent ˆetre vues comme deux facettes d’un mˆeme cadre plus large : associer des uti-
lisateurs `a des items.

— Dans le cadre de la recommandation, il s’agit principalement, ´etant donn´e un uti-

lisateur, de trouver `a quels items le relier pour les lui recommander.

— Dans le cadre de la diﬀusion, le but est invers´e : `a partir d’un item, l’objectif est

de trouver quels utilisateurs vont ˆetre infect´es.

Pour autant, les deux probl´ematiques ne sont pas ´equivalentes : les syst`emes de recomman-
dation ne se placent pas dans un contexte s´equentiel la plupart du temps et ne s’´evaluent
pas de la mˆeme fa¸con que les mod`eles de diﬀusion. De plus, la pr´ediction de diﬀusion
consid`ere en g´en´eral l’inﬂuence existant entre les utilisateurs, l`a o`u la recommandation
s’int´eresse aux similarit´es entres eux. Cependant, ces deux aspects (inﬂuence et simila-
rit´e) peuvent ˆetre d´elicats `a distinguer [Aral et al., 2009], et il apparaˆıt donc que les deux
probl´ematiques peuvent se recouper [Zhang et al., 2007].

Dans le cadre de la pr´ediction de diﬀusion, il peut donc ˆetre pertinent de s’int´eresser aux
m´ethodes utilis´ees en recommandation.

Les m´ethodes les plus r´epandues aujourd’hui en recommandation sont celles dites de
ﬁltrage collaboratif, consistant `a observer des similarit´es dans les comportements des uti-
lisateurs et `a pr´edire quels produits recommander `a l’un d’eux en utilisant les compor-
tements d’autres utilisateurs similaires. Citons notamment les travaux de [Koren et al.,
2009], utilisant la factorisation matricielle. Le principe est le suivant : nous observons
partiellement une matrice M ∈ [0, 5]N×nbItems. Chaque ligne correspond `a un utilisateur
et chaque colonne `a un produit. Chaque case de la matrice correspond `a une note laiss´ee
par un utilisateur `a un produit (traditionnellement entre 0 et 5 ´etoiles). Certaines cases
de M ne sont pas observ´ees, le but ´etant de pr´edire leurs valeurs. Pour cela, la factori-
sation matricielle consiste `a observer que la matrice M « compl´et´ee » peut se factoriser
ainsi :

M ≈ RU × RI

avec :

RU ∈ RN×d

4. http://www.netflixprize.com

48

Chapitre 2. Mod´elisation et pr´ediction de la diﬀusion d’information : ´etat de l’art

Cette factorisation peut ˆetre obtenue en minimisant le coˆut :

L(RU , RI) =

||M i,j − Ri,.

U .R.,j

(i,j)∈observ´ees

RI ∈ Rd×nbItems

(cid:88)

I ||2 + λ(cid:0)||Ri,.

I ||2(cid:1)

U ||2 + ||R.,j

La somme est calcul´ee uniquement sur les composantes connues de la matrice M . Le
second terme est un terme de r´egularisation. La matrice RU peut ainsi ˆetre vue comme
une projection des utilisateurs dans un espace `a d dimensions (une ligne par utilisateur)
et la matrice RI comme une projection des produits dans le mˆeme espace (un produit
par colonne). Une composante manquante M i,j sera pr´edite en utilisant Ri,.
I , c’est
`a dire la similarit´e dans l’espace latent entre l’utilisateur et le produit correspondants.
L’avantage de cette formulation est que les utilisateurs ayant donn´e des notes similaires se
verront attribuer des repr´esentations proches. De la mˆeme fa¸con, des produits bien not´es
par les mˆemes utilisateurs seront ´egalement projet´es `a des emplacements similaires. Cette
propri´et´e permet de pr´edire de nouvelles relations entre les utilisateurs et les produits. Par
exemples, si deux produits ont re¸cu de bonnes notes de la part des mˆemes utilisateurs, les
utilisateurs ayant not´e un seul de ces deux produits se verront recommander l’autre.

U .R.,j

Ce mod`ele s’´etant montr´e particuli`erement eﬃcace, de nombreuses extensions ont ´et´e pro-
pos´ees, prenant en compte divers ´el´ements suppl´ementaires comme les propri´et´es connues
des produits ou celles des utilisateurs. L’utilisation de ce type d’approche dans le contexte
d’une population reli´ee par un r´eseau social a ´egalement ´et´e ´etudi´ee [Ma et al., 2011, Ja-
mali and Ester, 2010]. En particulier, dans [Jamali and Ester, 2010], les auteurs proposent
le mod`ele SocialMF consistant `a int´egrer dans la factorisation matricielle un a priori repr´e-
sentant la conﬁance des utilisateurs les uns envers les autres. Cette conﬁance se propage
dans le r´eseau de la mˆeme mani`ere que de l’information : si l’utilisateur u1 fait conﬁance
aux notes donn´ees par l’utilisateur u2 qui lui-mˆeme fait conﬁance `a l’utilisateur u3, alors
u1 fera vraisemblablement conﬁance `a u3. D`es lors, on peut consid´erer que la « conﬁance
`a u3 » s’est propag´ee de u2 `a u1.

Les liens existant entre les tˆaches de pr´ediction de diﬀusion et de recommandation, ainsi
que l’eﬃcacit´e des m´ethodes de factorisation matricielle, nous conduirons `a utiliser des
approches similaires d’apprentissage de repr´esentations dans nos travaux (chapitres 5, 6
et 7).

2.5.4 Pr´ediction de Volume

Notons enﬁn que la pr´ediction de diﬀusion peut aussi se r´ealiser `a faible granularit´e, c’est `a
dire uniquement en visant `a pr´edire des propri´et´es g´en´erales d’une diﬀusion d’information,
en particulier le volume.

2.5. Pr´ediction de diﬀusion

49

2.5.4.1 Pr´ediction du taux d’adoption ﬁnal

Dans beaucoup d’applications, comme la « pr´ediction de Buzz », le but peut ˆetre de
pr´edire le nombre d’utilisateurs infect´es `a un horizon Tmax, not´e I(Tmax), en connaissant
sa valeur `a un instant Tinit mesur´ee assez tˆot, ainsi que d’autres param`etres observ´es `a
Tinit. Plusieurs approches assez simples pour r´esoudre ce probl`eme existent

R´egression simple La plus classique consiste `a utiliser le fait que dans de nombreux
cas, l’´evolution de I v´eriﬁe :

log(I(Tmax)) ≈ α × log(I(Tinit)).

La pr´ediction I(Tmax) peut donc se faire en mesurant la valeur de α. Cette formule peut
ˆetre appliqu´ee `a divers contextes, comme la popularit´e d’une vid´eo sur Youtube ou le
nombres de votes d’un article post´e sur Digg [Szabo and Huberman, 2010].

Plus proche voisin Une m´ethode non-param´etrique a ´et´e ´etudi´ee dans [Chen et al.,
2013]. Cet article vise `a pr´edire les « trending topics » de Twitter. Le mod`ele propos´e est
bas´e sur une approche de type plus proche voisin : pour pr´edire si une information i va
devenir un trending topic en observant seulement les premi`eres valeurs de I(t) pour t <
Tinit, ces valeurs sont compar´ees `a celles observ´ees sur un ensemble de s´eries temporelles
d’apprentissage ´etiquet´ees en « trending/non-trending ». Si la s´erie temporelle la plus
proche de celle de i pour t < Tinit correspond `a un trending topic, la pr´ediction est que i
en sera ´egalement un. Le mod`ele est test´e sur des donn´ees issues de Twitter. En testant
plusieurs valeurs de Tinit, le mod`ele parvient `a un taux de vrais positifs de 95%, tout en
d´etectant les trending topics avant que Twitter ne les d´esigne comme tels dans 79% des
cas (un trending topics est d´etect´e « avant Twitter » lorsque Tinit est inf´erieur au temps
`a partir duquel le sujet est apparu dans la liste des tendances).

2.5.4.2 Int´egration du Contenu et attributs utilisateurs

De la mˆeme fa¸con que dans la sous-section 2.4.5, il est possible de d´eﬁnir des mod`eles
bas´es sur le contenu de l’information diﬀus´ee ou sur certaines propri´et´es sp´eciﬁques des
utilisateurs. Dans la cas de la pr´ediction du volume de diﬀusion, les propri´et´es prises en
compte d´ependent beaucoup de la nature du r´eseau social consid´er´es. Pour cette raison,
les articles proposant des approches bas´ees sur le contenu sont souvent sp´eciﬁques `a un
site particulier.

Sur Twitter Dans [Tsur and Rappoport, 2012], les auteurs proposent un mod`ele per-
mettant de pr´edire la popularit´e I(Tmax) d’un hashtag sur Twitter apr`es un certain temps

50

Chapitre 2. Mod´elisation et pr´ediction de la diﬀusion d’information : ´etat de l’art

Tmax. La fonction de pr´ediction utilis´ee est une fonction lin´eaire dont les param`etres sont
appris au moyen d’une descente de gradient stochastique. Cette fonction lin´eaire est ap-
pliqu´ee `a une repr´esentation vectorielle du hashtag prenant en compte de nombreuses
caract´eristiques de celui-ci :

Contenu du Hashtag : longueur, nombre de mots, projection du hashtag sur un

dictionnaire, mots fr´equemment associ´es, etc.

Topologie : nombre moyen et maximum de followers des utilisateurs ayant utilis´e le

hashtag avant Tinit, nombre de retweets, etc.

Temporalit´e : diﬀ´erentes valeurs du nombre d’utilisateurs infect´es I(t) pour t < Tinit
On remarque bien ici que le mod`ele est propre `a Twitter et pourrait diﬃcilement ˆetre
utilis´e tel quel sur un autre site. Le mod`ele est test´e sur un large corpus de tweets. Il
apparaˆıt que les caract´eristiques temporelles sont plus informatives que les celles li´ees au
contenu, mais qu’un mod`ele prenant en compte toutes les caract´eristiques d´ecrites est
meilleur.

Sur Facebook Un travail semblable a ´et´e eﬀectu´e dans [Cheng et al., 2014] en colla-
boration avec Facebook, sur des donn´ees constitu´ees de photos post´ees sur Facebook et
diﬀus´ees par le biais de partages successifs sur une large population d’utilisateurs.

Au lieu de pr´edire I(Tmax) en fonction d’observations r´ealis´ees `a Tinit, un cadre pr´edictif
plus g´en´eral est d´eﬁni. Les auteurs observent en eﬀet que la r´epartition des tailles ﬁnales
des ´episodes de diﬀusion suit une loi de puissance d’exposant α ≈ 2. Ils posent donc
comme objectif de pr´edire, apr`es avoir observ´e les n premiers utilisateurs ayant partag´e
une photo donn´ee, si celle-ci va ˆetre partag´ee au moins 2n fois ou non. Il s’agit donc
d’un probl`eme de classiﬁcation binaire. De plus, la valeur de n n’est pas ﬁx´ee : le mod`ele
doit ˆetre applicable `a n’importe quel « point » de la diﬀusion, pour pr´edire si le nombre
d’utilisateurs infect´es va doubler ou non.

L’avantage de cette formulation est qu’elle rend le probl`eme de classiﬁcation ´equilibr´e :
parmi les photos partag´ees au moins n fois, environ la moiti´e sera ﬁnalement partag´ee au
moins 2n fois (loi de puissance d’exposant α ≈ 2). De la mˆeme fa¸con que dans [Tsur and
Rappoport, 2012], l’article utilise donc un mod`ele de classiﬁcation (une r´egression logis-
tique) appliqu´e `a un vecteur de repr´esentation calcul´e `a partir des n premiers utilisateurs
infect´es, bas´e sur de nombreuses caract´eristiques :

Contenu de la photo : Tags, mots utilis´es dans la description, propri´et´es de l’image...

Propri´et´es de l’utilisateur-source : Age, nombre d’amis, activit´e sur Facebook...

Propri´et´es des utilisateurs ayant repartag´e la photo : Age moyen, nombre d’amis...

Topologie : Nombre de liens dans le graphe de diﬀusion, taille du voisinage de ce

graphe, profondeur...

Temporalit´e : temps ´ecoul´e depuis la diﬀusion de la photo, temps moyen entre les

infections, etc.

2.6. Maximisation d’inﬂuence

51

Les premiers r´esultats obtenus en pr´ediction sont tr`es proches de ceux de [Tsur and
Rappoport, 2012] : la pr´ecision est de 79%, les caract´eristiques temporelles sont les plus
informatives et un classiﬁeur prenant en compte toutes les caract´eristiques est meilleur.
De plus, les auteurs observent que l’importance des diﬀ´erentes caract´eristiques ´evolue
beaucoup avec la valeur de n. En particulier, plus n augmente, moins les caract´eristiques
de l’utilisateur initial et de la photo sont importantes dans la pr´ediction.

L’article va plus loin et propose ´egalement de pr´edire la forme du graphe de diﬀusion,
repr´esent´ee par l’indice de Wiener de ce graphe. L’indice de Wiener est d´eﬁni comme la
sommes des longueurs des plus courts chemins entres tous les sommets du graphe. Plus
celui-ci est faible, plus le graphe est compact. En adoptant un crit`ere de classiﬁcation
similaire, le mod`ele parvient ´egalement `a pr´edire cet indice.

2.6 Maximisation d’inﬂuence

Nous avons vu dans la section pr´ec´edente quelques m´ethodes permettant de pr´edire le vo-
lume ﬁnal de diﬀusion d’une information. A partir de l`a, le but de la tˆache de « maximisa-
tion d’inﬂuence » est de trouver comment agir sur un r´eseau social de fa¸con `a maximiser ce
volume ﬁnal. Dans la plupart des cas, l’action sur le r´eseau social consistera `a s´electionner
l’ensemble des utilisateurs initiaux `a partir desquelles l’information se diﬀusera.

La principale application de ce probl`eme est celle du marketing viral : un annonceur d´esire
par exemple envoyer `a un certain nombre d’utilisateurs d’un r´eseau un exemplaire gratuit
d’un produit dont il veut faire la promotion. Son but est alors de trouver quels utilisateurs
cibler de fa¸con `a d´eclencher une diﬀusion la plus large possible.

2.6.1 Mod`eles IC et LT

La formulation la plus courante du probl`eme a ´et´e donn´ee par Kempe dans [Kempe et al.,
2003]. Soit σ : 2U → R une fonction associant `a un ensemble d’utilisateurs initiaux UI ⊂ U
l’esp´erance du nombre d’utilisateurs infect´es apr`es une propagation d’information partant
de UI sous l’hypoth`ese d’un mod`ele de diﬀusion connu. Le probl`eme de la maximisation
d’inﬂuence revient alors `a consid´erer la maximisation sous contraintes suivante :

(cid:40)

maxUI σ(UI)
s.c.

|UI| ≤ k

Dans l’article fondateur du probl`eme de maximisation d’inﬂuence[Kempe et al., 2003], les
auteurs consid`erent le cas d’un mod`ele de diﬀusion IC ou LT dont tous les param`etres
sont connus (graphe, probabilit´es de transmission ou poids). Il est montr´e que dans ce
cas, le probl`eme est NP-diﬃcile. Cependant, les auteurs d´emontrent que la fonction σ est

52

Chapitre 2. Mod´elisation et pr´ediction de la diﬀusion d’information : ´etat de l’art

sous-modulaire dans le cas des mod`eles de diﬀusion IC et LT, ind´ependamment de leurs
param`etres, i.e :

∀U(cid:48)

I,∀UI ⊆ U(cid:48)

I,∀s (cid:54)∈ U(cid:48)

I : σ(UI ∪ {s}) − σ(UI) ≥ σ(U(cid:48)

I ∪ {s}) − σ(U(cid:48)
I)

un ensemble UI tel que σ(UI) soit une approximation `a(cid:0)1 − 1

(cid:1) pr`es de la valeur maximale

Une propri´et´e importante des fonctions sous-modulaires est qu’il est possible de trouver

e

de σ au moyen d’un algorithme glouton :

— partir de l’ensemble UI = ∅ ;
— ajouter `a chaque it´eration l’utilisateur maximisant le gain marginal : UI ← UI ∪
— continuer jusqu’`a atteindre |UI| = k.

{arg maxU σ(UI ∪ {ui})} ;

Cet algorithme glouton est test´e sur des graphes r´eels, avec les mod`eles IC et LT, et
compar´e `a diﬀ´erentes heuristiques permettant de choisir les utilisateurs initiaux : utilisa-
tion des degr´es sortants, utilisation de la centralit´e de distance des utilisateurs ou tirage
al´eatoire. Chaque m´ethode est test´ee pour diﬀ´erentes valeurs de k, puis les mod`eles IC
ou LT sont utilis´es pour simuler la diﬀusion `a partir des utilisateurs initiaux s´election-
n´es par chaque m´ethode. L’algorithme glouton propos´e parvient toujours `a infecter plus
d’utilisateurs, quelques soient la valeur de k et le mod`ele de diﬀusion.

Une extension de ce travail, consid´erant des mod`eles plus g´en´eraux que IC et LT a ensuite
´et´e propos´ee dans [Kempe et al., 2005].

La principale limite de cette approche est celle du passage `a l’´echelle : chaque it´eration
de l’algorithme glouton n´ecessite d’estimer O(N ) valeurs de σ, N ´etant le nombre d’uti-
lisateurs. Cette estimation de σ repose sur une m´ethode de Monte-Carlo, le calcul exact
serait #P -diﬃcile. Plusieurs optimisations ont donc ´et´e propos´ees [Chen et al., 2009, Chen
et al., 2010]. En particulier, [Chen et al., 2010] propose ´egalement d’optimiser de fa¸con
gloutonne une fonction sous-modulaire, mais en basant le calcul de σ sur la recherche des
plus courts chemins dans le graphe, qui peuvent ˆetre calcul´es une seule fois au moyen
d’un algorithme de Dijkstra. Cette approche obtient des r´esultats tr`es proches de ceux de
[Kempe et al., 2003], tout en ´etant plus rapide de plusieurs ordres de grandeur.

2.6.2 Version temporelle

Le probl`eme a ´egalement ´et´e ´etudi´e dans le cadre des approches continues de mod´elisation
de la diﬀusion, comme celles d´ecrites en section 2.4.4. Ainsi, dans [Gomez Rodriguez et al.,
2012], les auteurs ´etudient le cas du mod`ele NetRate [Gomez-Rodriguez et al., 2011] pour
rechercher les utilisateurs permettant de maximiser la diﬀusion. Rappelons que dans ce
mod`ele de diﬀusion, chaque utilisateur infect´e ui contamine chacun de ses voisins uj apr`es
un d´elai di,j tir´e selon une loi exponentielle de param`etre ri,j. De la mˆeme fa¸con que les
articles pr´ec´edents, les auteurs d´emontrent que la fonction σ d´ecoulant de ce mod`ele est

2.6. Maximisation d’inﬂuence

53

sous-modulaire, et proposent un algorithme glouton pour l’optimiser, ainsi que plusieurs
techniques permettant d’en acc´el´erer grandement le calcul.

L’algorithme est test´e sur des graphes et des ´episodes de diﬀusion artiﬁciels et r´eels, et
obtient de meilleurs r´esultats que les m´ethodes de [Kempe et al., 2003] et de [Chen et al.,
2010] grˆace `a la prise en compte de la dimension temporelle, en particulier si l’horizon
temporel consid´er´e Tmax est faible.

Une autre possibilit´e a ´et´e ´etudi´ee par [Ma et al., 2008]. Dans cet article, les auteurs
utilisent un noyau de chaleur d´eﬁnie sur un graphe, similaire `a l’approche pr´esent´ee en
section 2.5.3. Ce noyau permet aux auteurs de faciliter le calcul de σ, et de proposer
plusieurs heuristiques pour s´electionner les utilisateurs initiaux. Ils ´etudient ´egalement le
cas o`u ces utilisateurs initiaux peuvent devenir infect´es `a des temps diﬀ´erents.

2.6.3 Contextes de diﬀusion n´egative

Dans certaines applications, d’autres param`etres peuvent entrer en jeu dans le cadre du
marketing viral. En particulier, divers ´el´ements n´egatifs peuvent venir limiter la propaga-
tion de l’information.

2.6.3.1 Comp´etition entre plusieurs annonceurs.

Il arrive r´eguli`erement que plusieurs annonceurs soient en comp´etition pour tenter de
g´en´erer un « buzz » autour de leur marque. Ce fut par exemple le cas en 2013, lorsque
les constructeurs Sony et Microsoft s’apprˆetaient `a sortir leurs nouvelles consoles de jeu
[Mosca, 2013].

Ce cas est ´etudi´e dans [Bharathi et al., 2007], comme un probl`eme de th´eorie des jeux. Une
extension du mod`ele CTIC est d´eﬁnie, dans laquelle plusieurs informations se diﬀusent
en parall`ele, mais o`u chaque utilisateur n’est infect´e que par la premi`ere information
l’atteignant. Chaque joueur ji s´electionne un ensemble de k utilisateurs `a infecter au
d´epart, avec pour objectif de maximiser sa propre fonction σi indiquant l’esp´erance du
nombre d’utilisateurs ﬁnalement infect´es par le produit vendu par ji.

Il est montr´e que si un joueur ji connaˆıt les strat´egies de tous les autres, σi devient
une fonction sous-modulaire pouvant ˆetre maximis´ee avec l’algorithme glouton d´ecrit pr´e-
c´edemment. Une strat´egie optimale pour le premier joueur est ´egalement donn´ee, mais
seulement sur certains types de graphes.

54

Chapitre 2. Mod´elisation et pr´ediction de la diﬀusion d’information : ´etat de l’art

2.6.3.2

´Emergence d’opinions n´egatives.

Lorsqu’ils ´echangent des informations ou des id´ees, les utilisateurs ne sont pas toujours
positifs. Un utilisateur n’ayant pas aim´e un produit achet´e en ligne pourra par exemple
laisser une note d´efavorable `a ce produit sur le site web du vendeur, et exprimer son
m´econtentement aupr`es de ses amis. Pour cette raison, une campagne de marketing virale
peut parfois se retourner contre l’annonceur en g´en´erant un « Bad Buzz ».

La maximisation d’inﬂuence dans ce contexte a ´et´e ´etudi´ee dans [Chen et al., 2011]. Les
auteurs d´eﬁnissent le mod`ele IC-N, une extension du mod`ele IC o`u chaque information se
propageant est associ´ee `a un « facteur de qualit´e » q. Les utilisateurs de UI ont chacun
une probabilit´e q d’avoir une opinion positive, et une probabilit´e 1− q d’avoir une opinion
n´egative. La diﬀusion se fait ensuite de la mˆeme fa¸con que dans un mod`ele IC.

Lorsqu’un utilisateur est contamin´e par un autre utilisateur avec une opinion positive,
il adopte cette opinion positive avec une probabilit´e q, ou l’opinion n´egative avec une
probabilit´e 1−q. En revanche, lorsqu’un utilisateur est contamin´e par un utilisateur ayant
une opinion n´egative, il adopte directement l’opinion n´egative. Les opinions n´egatives se
propagent donc mieux, ce qui est un r´esultat conforme `a la r´ealit´e. L’algorithme propos´e
dans [Chen et al., 2010] est adapt´e `a cette formulation.

Deux r´esultats particuli`erement int´eressants sont donn´es.

— D’une part, l’impact de q sur la s´election de UI peut ˆetre calcul´e en fonction du

graphe.

— D’autre part, dans le cas d’une valeur de q faible, la s´election de UI favorise les
utilisateurs ayant un degr´e ´elev´e. Ce r´esultat peut sembler contre-intuitif, mais
peut s’expliquer ainsi : s´electionner les utilisateurs ayant un degr´e sortant ´elev´e
revient `a favoriser les diﬀusions « courtes », o`u la majeure partie de la diﬀusion
se fait entre les utilisateurs initiaux et leurs voisins, ce qui r´eduit la probabilit´e
que beaucoup d’opinions n´egatives ´emergent : plus la distance entre une source et
un utilisateur est grande, plus la probabilit´e que l’information devienne n´egative
durant son trajet entre ces deux utilisateurs est ´elev´ee.

2.6.3.3 Pr´esence de liens n´egatifs dans le graphe.

Enﬁn, il existe ´egalement des r´eseaux sociaux sign´es, contenant des relations utilisateurs
n´egatives. Une relation n´egative peut indiquer qu’un utilisateur a une mauvaise opinion
d’un autre, ou ne lui fait pas conﬁance. Dans ce cas, un avis positif sur un produit,
partag´e par une utilisateur ui peut conduire `a un avis n´egatif sur ce mˆeme produit chez
un utilisateur uj. L’article [Li et al., 2013] s’int´eresse `a ce cas.

La diﬀusion se fait selon un syst`eme de vote : `a chaque pas de temps, chaque utilisa-
teur adopte l’´etat (infect´e / non-infect´e) le plus repr´esent´e parmi ses voisins. Les auteurs

2.7. Identiﬁcation de leaders d’opinion

55

proposent des algorithmes pour la maximisation d’inﬂuence `a court et long terme, et
s’´evaluent sur des graphes sign´es r´eels : slashdot et epinions.

2.7 Identiﬁcation de leaders d’opinion

En parall`ele de l’´etude du probl`eme de maximisation d’inﬂuence, d’autres travaux se sont
attaqu´es `a l’identiﬁcation des utilisateurs les plus inﬂuents d’un r´eseau, en se basant exclu-
sivement sur les propri´et´es du r´eseau social ou de ses utilisateurs, sans faire d’hypoth`eses
sur le mod`ele de diﬀusion. Beaucoup d’articles dans ce domaine s’int´eressent tout parti-
culi`erement `a Twitter, car il s’agit d’un r´eseau tr`es largement utilis´e, o`u il est assez facile
de r´ecolter des donn´ees.

Dans le cadre de la maximisation d’inﬂuence, Kempe proposait une formulation rigoureuse
du probl`eme [Kempe et al., 2003]. N´eanmoins, dans le cadre plus g´en´eral de l’identiﬁcation
des leaders d’opinion, il n’existe pas de d´eﬁnition pr´ecise. Suivant le contexte et le r´eseau
´etudi´e, les termes « leaders d’opinion » ou « inﬂuenceurs » peuvent avoir des sens diﬀ´erents.
Nous d´ecrivons ici diverses propositions illustrant la vari´et´e des d´eﬁnitions possibles.

2.7.1 Approches Topologiques : mesures de centralit´e

Une approche intuitive pour la d´etection de leaders d’opinion serait de consid´erer tout
simplement les degr´es des utilisateurs dans le graphe social : il semble raisonnable de
consid´erer qu’un utilisateur reli´e `a beaucoup d’autres est un utilisateur important et
inﬂuent.

Plusieurs articles [Cha et al., 2010, Kwak et al., 2010, Weng et al., 2010] ont ´etudi´e cette
possibilit´e sur Twitter, o`u le nombre d’abonn´es est couramment utilis´e par les utilisateurs
pour mesurer leur inﬂuence au sein du r´eseau. Leur conclusion est qu’il s’agit en v´erit´e d’un
assez mauvais indicateur de l’inﬂuence des utilisateurs. Selon [Weng et al., 2010] ceci peut
s’expliquer par le fait que les liens d’un r´eseau social correspondent souvent `a plusieurs
s´emantiques diﬀ´erentes qui se superposent. L’existence d’un lien peut indiquer l’inﬂuence
d’un utilisateur sur un autre, mais peut aussi indiquer le fait qu’ils partagent certains
centres d’int´erˆet. Tous les liens ne correspondent donc pas `a des relations d’inﬂuence, et
le degr´e des utilisateurs ne traduit donc pas forc´ement leur inﬂuence globale.

Sur Twitter, divers travaux proposent donc d’utiliser le nombre moyen de retweets des
tweets de l’utilisateur, ou le nombre de « mentions 5 » d´esignant cet utilisateur chaque
heure [Cha et al., 2010] pour ´evaluer son inﬂuence. Ces mesures semblent plus pertinentes,
mais sont diﬃciles `a ´evaluer en l’absence de v´erit´e-terrain.

5. Terme utilis´e sur Twitter pour d´esigner l’action consistant `a mentionner le nom d’un autre uti-
lisateur dans un Tweet. Une « mention » peut servir `a r´epondre `a un Tweet ou `a prendre `a parti un
utilisateur.

56

Chapitre 2. Mod´elisation et pr´ediction de la diﬀusion d’information : ´etat de l’art

Le fait que les degr´es des utilisateurs ne repr´esentent pas toujours l’importance de ceux-
ci est un r´esultat connu dans le domaine de l’analyse des graphes. Par exemple, dans
[Freeman, 1978], diﬀ´erentes mesures de centralit´e avait ´et´e compar´ees :

— mesures bas´ees sur le degr´e ;
— mesures bas´ees sur la proximit´e des utilisateurs, les utilisateurs centraux ´etant ceux

proches de tous les autres ;

— mesures bas´ees sur l’interm´ediarit´e, les utilisateurs centraux ´etant ceux se trouvant

souvent sur les plus courts chemins du graphe.

Il apparaˆıt que ces mesures donnent des r´esultats assez diﬀ´erents. En particulier, les
utilisateurs de centralit´es « moyennes » ont tendance `a ˆetre tr`es diﬀ´erents d’une mesure
`a l’autre.

Une probl´ematique tr`es similaire est le calcul de l’importance des pages internet dans un
r´eseau hypertexte, notamment utilis´ee pour classer les r´esultats d’une recherche d’infor-
mation. Dans ce contexte, l’algorithme PageRank [Page et al., 1999] a permis l’´emergence
de moteurs de recherche performants sur le Web. Il s’agit d’une mesure de centralit´e d´eﬁ-
nie r´ecursivement : l’importance d’une page est proportionnelle `a l’importance des pages
pointant vers elle. Dans le cas de Twitter, l’importance d’un utilisateur est proportionnelle
`a l’importance de ses abonn´es. Intuitivement, le PageRank d’un sommet dans un graphe
indique la probabilit´e qu’un agent se d´epla¸cant al´eatoirement dans ce graphe passe par ce
sommet. `A chaque pas, l’agent a une petite probabilit´e 1−d de se transporter directement
`a une page al´eatoire au lieu de suivre un lien.

PageRank(ui) =

1 − d
|U| + d

PageRank(uj)

(cid:88)

uj∈Succsi

Notons bien que dans le cas de Twitter, l’ensemble Succsi d´esigne les followers de l’uti-
lisateur ui, i.e. les ceux `a qui ui est susceptible de diﬀuser de l’information. Certains
auteurs ont propos´e d’utiliser le PageRank comme mesure de l’inﬂuence d’un utilisateur
sur Twitter. Une premi`ere tentative se trouve dans [Kwak et al., 2010], les r´esultats ´etant
´evalu´es empiriquement. Dans [Weng et al., 2010], une version prenant en compte le fait
que l’inﬂuence des utilisateurs d´epend du sujet discut´e est ´egalement propos´ee. Toutefois,
il n’existe pas de v´erit´e-terrain pour ´evaluer rigoureusement ces r´esultats, qui restent donc
purement exploratoires.
Dans le mˆeme ordre d’id´ee, [Kitsak et al., 2010] propose d’utiliser la notion de k − noyau
pour d´eﬁnir l’inﬂuence d’un utilisateur dans un graphe. Le k − noyau d’un graphe d´esigne
sa plus grande composante connexe au sein de laquelle tous les sommets sont de degr´es
au moins k. Plus k est ´elev´e, plus le k − noyau sera r´eduit. L’inﬂuence d’un utilisateur ui
est la valeur de k la plus ´elev´e telle que ui ∈ k − noyau. L’intuition sous-jacente est donc
similaire `a celle du PageRank : les utilisateurs les plus inﬂuents sont ceux appartenant `a
des k−noyau pour k assez ´elev´e, c’est `a dire ceux ´etant reli´es `a beaucoup d’utilisateurs eux
mˆemes reli´es `a beaucoup d’autres utilisateurs. Des tests utilisant des mod`eles de diﬀusion

2.7. Identiﬁcation de leaders d’opinion

57

de type SIS et SIR sont eﬀectu´es et montrent que l’inﬂuence d’un utilisateur ui ainsi
calcul´ee avec des k − noyaux est un meilleur indicateur de la taille moyenne des cascades
partant de cet utilisateur que son degr´e.

Enﬁn, une autre m´ethode de ce type, inspir´ee de l’algorithme HITS [Kleinberg, 1999] est
d´ecrite dans [Romero et al., 2011]. Dans cet article, les auteurs observent que sur Twitter,
il est possible de d´eﬁnir l’inﬂuence d’un utilisateur ui sur un de ses abonn´es uj en calculant
le pourcentage pi,j de tweets de ui retweet´es par uj. La diﬃcult´e est d’´etendre cette notion
d’inﬂuence locale (sur un utilisateur) `a une notion d’inﬂuence globale (sur le r´eseau). Les
auteurs proposent donc de d´eﬁnir deux valeurs pour chaque utilisateur : sa passivit´e et
son inﬂuence.

— La passivit´e d’un utilisateur est sa tendance `a ne pas ˆetre inﬂuenc´e par le contenu

post´e par les utilisateurs inﬂuents auxquels il est expos´e.

— L’inﬂuence d’un utilisateur est sa capacit´e a inﬂuencer les utilisateurs les plus

Les deux valeurs sont donc d´eﬁnies de fa¸con r´ecursive. Plus pr´ecis´ement :

passifs (i.e. ˆetre retweet´e).

(cid:40)

Inﬂuence(ui) = (cid:80)
Passivit´e(ui) = (cid:80)

uj abonn´e `a ui

ui abonn´e `a uj

pi,j Passivit´e(uj)
pj,i Inﬂuence(uj)

Ces valeurs sont estim´ees it´erativement, en ´etant successivement mises `a jour en utilisant
les valeurs de l’it´eration pr´ec´edente. L’algorithme est notamment compar´e `a un algorithme
de PageRank, et il est montr´e que la popularit´e des urls se diﬀusant sur Twitter est
d’avantage corr´el´ee `a l’inﬂuence ainsi calcul´ee des utilisateurs les partageant qu’`a leurs
scores de PageRanks.

2.7.2 Approches bas´ees sur les propri´et´es des utilisateurs

Les approches topologiques ont souvent le d´efaut d’ˆetre coˆuteuses en termes de complexit´e
algorithmique. D’autres m´ethodes, bas´ees sur des propri´et´es locales des utilisateurs ont
´et´e propos´ees.

Une approche pr´edictive est pr´esent´ee dans [Bakshy et al., 2011]. Les auteurs y ´etudient
la diﬀusion d’hyperliens au sein de Twitter. Ils apprennent un arbre de r´egression visant `a
pr´edire l’inﬂuence d’un utilisateur (d´eﬁnie comme la taille moyenne des cascades d´ebutant
par celui-ci) en fonction de plusieurs propri´et´es de cet utilisateur : nombre de tweets, de
followers, anciennet´e, etc... Les tests eﬀectu´es montrent que ce mod`ele pr´edit assez bien
l’inﬂuence des utilisateurs, mais que la qualit´e de la pr´ediction souﬀre beaucoup du fait
que les cascades longues soit tr`es rares.

Un mod`ele similaire se trouve dans [Pal and Counts, 2011]. Chaque utilisateur y est repr´e-
sent´e par un vecteur de caract´eristiques bas´ees sur son activit´e, son nombre de retweets,
son utilisation des hashtags, etc. Toutes ces caract´eristiques correspondent `a des propri´e-

58

Chapitre 2. Mod´elisation et pr´ediction de la diﬀusion d’information : ´etat de l’art

t´es susceptibles d’indiquer l’importance d’un utilisateur. L’identiﬁcation des utilisateurs
les plus inﬂuents se fait ensuite en observant les distributions des valeurs de ces caract´e-
ristiques au sein de la population, et en retenant les utilisateurs ayant des caract´eristiques
signiﬁcativement plus ´elev´ees que la moyenne. Les r´esultats sont ´evalu´es en comparant les
utilisateurs d´esign´es par le mod`ele `a ceux choisis par des exp´erimentateurs.

2.8 D´etection de source

`A mesure que l’utilisation des r´eseaux sociaux s’est d´evelopp´ee, ceux-ci ont ´et´e de plus
en plus utilis´es pour diﬀuser des rumeurs, fausses informations ou des contenus vol´es
ou pirat´es [Hooton, 2015]. Ce ph´enom`ene a motiv´e un certains nombre de travaux sur le
probl`eme de la d´etection de source. Il s’agit en fait du probl`eme inverse de la pr´ediction de
diﬀusion : le but est de retrouver l’utilisateur ayant partag´e une information, la source, en
observant le r´esultat de cette diﬀusion (typiquement, l’ensemble des utilisateurs infect´es).
Dans cette section, nous pr´esentons diﬀ´erents travaux sur ce probl`eme.

2.8.1 Mesure de centralit´e de rumeur

L’article fondateur de la d´etection de source dans le cadre de la diﬀusion d’information
dans les r´eseaux sociaux date de 2010 [Shah and Zaman, 2010]. Cet article consid`ere que
le graphe de diﬀusion G = (U, E) est connu et non-orient´e. Les auteurs se basent sur un
mod`ele de diﬀusion similaire `a NetRate : au temps t = 0, un utilisateur-source us cr´e´e une
information, et devient infect´e. Tout utilisateur infect´e ui transmet l’information `a chacun
de ses voisins uj apr`es un temps di,j tir´e ind´ependamment pour chaque voisin selon une
loi exponentielle de param`etre ﬁx´e pour tout le r´eseau.

L’ensemble UT des utilisateurs infect´es `a un certain temps T est observ´e, et l’objectif
est alors de retrouver lequel d’entre eux est l’utilisateur source. Notons bien que dans
ce contexte, les temps d’infections de ces utilisateurs sont inconnus au moment de r´ea-
liser la pr´ediction. Les auteurs d´eﬁnissent un estimateur de type maximum de vraisem-
blance :

ˆus = arg max

us∈UT

P (UT|us)

o`u P (UT|us) d´esigne la probabilit´e que l’ensemble des utilisateurs de UT soient infect´es au
temps T sachant que l’utilisateur source est us, sous l’hypoth`ese du mod`ele de diﬀusion
d´ecrit plus haut. Malheureusement, le calcul de la valeur de P (UT|us) est complexe, car
l’information partant de us peut avoir suivi diﬀ´erents chemins pour atteindre les utilisa-
teurs de UT .

Les auteurs s’int´eressent donc d’abord au cas particulier o`u G est un arbre. Dans ce cas,
le calcul est largement simpliﬁ´e car il n’existe qu’un seul chemin possible entre n’importe

2.8. D´etection de source

59

Utilisateur

a

b

c
d
e

ordres d’infections possibles
abcde, abdce, adbce, abced,
abdec, adbec, abecd, abedc,
adebc, aebcd, aebdc, aedbc
badec, baedc, badce, baecd,
bacde, baced, bcade, bcaed
cbade, cbaed
dabce, dabec, daebc
dabcd, dabdc, dadbc

RC

12

8

2
3
3

Figure 2.4 – Exemple de l’utilisation de la mesure de Rumor Centrality (RC). `A gauche,
le sous-graphe des utilisateurs infect´es. `A droite, la liste pour chaque source potentielle
des ordres d’infections possibles `a partir de cette source. La RC d’une source potentielle
est ´egale au nombre d’ordres possibles `a partir de cette source.

quelle source potentielle us et n’importe quel utilisateur. Lorsque l’ensemble UT est ob-
serv´e, l’ordre exact dans lequel les diﬀ´erents utilisateurs ont ´et´e infect´es `a partir d’une
source possible us ∈ UT est inconnu, mais les liens du graphe G permettent toutefois de
d´eduire un ordre partiel sur UT pour cette source us. D`es lors, il est possible d’´enum´erer
l’ensemble Ordres(UT , us) des ordres d’infections possibles de UT `a partir de us, i.e. tels
que :

— us est infect´e en premier ;
— aucun utilisateur n’est infect´e avant qu’au moins un de ses pr´ed´ecesseurs dans G

ne le soit.

Une mesure RC baptis´ee « centralit´e de rumeur » est ensuite d´eﬁnie avec :

RC(UT , us) = |Ordres(UT , us)|

Il est montr´e que l’estimation de la source peut s’´ecrire :
P (UT|us) = arg max
us∈UT

ˆus = arg max

us∈UT

RC(UT , us)

Un exemple d’utilisation de la mesure RC est donn´e en ﬁgure 2.4. Les auteurs proposent
un algorithme eﬃcace, de type « passage de messages », pour calculer la valeur de RC.
Cet algorithme est bas´e sur la relation suivante entre les centralit´es de deux utilisateurs
ui et uj voisins dans le graphe (toujours dans le cas o`u G est un arbre) :

RC(UT , ui) = RC(UT , uj)

SubT reej
i

N − SubT reei

j

o`u SubT reei
j d´esigne le nombre de nœuds dans le sous-arbre obtenu en partant de uj et
en s’´eloignant de ui. L’ensemble des centralit´es de rumeur peut donc ˆetre calcul´e de fa¸con
r´ecursive, `a partir de la centralit´e d’un nœud quelconque. Dans le cas g´en´eral o`u G est un
graphe quelconque, l’heuristique suivante est propos´ee.

60

Chapitre 2. Mod´elisation et pr´ediction de la diﬀusion d’information : ´etat de l’art

— Pour chaque source possible us ∈ UT , extraire un arbre T (us, G) en utilisant une
— Calculer la RC(UT , us) dans cet arbre T (us, G)

exploration en largeur d’abord de G partant de us et limit´ee `a UT ;

L’utilisation de l’arbre T (us, G) extrait avec une exploration en largeur d’abord est jus-
tiﬁ´ee par le fait que la longueur du plus court chemin entre la source et n’importe quel
autre utilisateur dans T (us, G) est ´egale `a celle dans le graphe G. En d’autres termes, au
lieu de consid´erer tous les chemins possibles pour calculer la valeur de P (UT|us), seuls les
plus courts - et donc les plus vraisemblables - sont pris en compte.

Plusieurs r´esultats th´eoriques sont fournis, concernant la probabilit´e de d´etection sur
diﬀ´erents types de graphe. Les auteurs montrent ainsi que si G est un arbre r´egulier de
degr´e d = 2 (ou « graphe-ligne »), la probabilit´e de d´etection de la source tend vers 0. En
revanche, si G est un arbre r´egulier de degr´e d > 2, la probabilit´e de d´etection est non-
triviale. L’heuristique pour les graphes g´en´eraux est test´ee sur des ´episodes de diﬀusions
synth´etiques g´en´er´ees sur des graphes r´eels, et compar´ee `a une mesure de centralit´e de
distance classique consistant `a choisir la source minimisant la somme des distances aux
utilisateurs infect´es :

(cid:88)

ui∈UT

ˆus = arg min
us∈UT

Dist(us, ui)

o`u D(us, ui) est la longueur du plus court chemin entre us et ui. Les auteurs observent que
leur approche obtient de meilleurs r´esultats, en terme de distance `a la vraie source, que la
mesure de centralit´e de distance. Ce travail a ensuite ´et´e poursuivi dans [Shah and Zaman,
2012], o`u des r´esultats th´eoriques sont donn´es pour d’autres types de graphes.

2.8.2 Autres estimateurs

En parall`ele, [Luo et al., 2015b] se sont int´eress´es au cas o`u l’information peut se diﬀuser
selon des mod`eles de type SI, SIR, SIRI ou SIS (d´ecrits en section 2.3.2) dans un graphe. `A
la place d’un estimateur de type vraisemblance maximale, les auteurs utilisent l’estimateur
suivant, pr´ec´edemment d´eﬁni dans [Zhu and Ying, 2013] :

ˆus = arg max

us∈UT

max

tree∈T (UT )

P (tree|us)

o`u T (UT ) d´esigne l’ensemble des arbres couvrants de UT , et P (tree|us) est la probabilit´e
que l’information partant de la sources us se diﬀuse en suivant l’arbre de diﬀusion tree dans
le graphe, sous l’hypoth`ese du mod`ele de diﬀusion consid´er´e. Ainsi, les auteurs consid`ere
uniquement l’arbre de diﬀusion enracin´e en us le plus vraisemblable pour chaque source
potentielle us au lieu de calculer la valeur exacte de P (UT|us) en ´enum´erant tous les arbres
possibles. L’id´ee est donc la mˆeme que celle utilis´ee dans [Shah and Zaman, 2010] pour
les graphes quelconques.

2.8. D´etection de source

61

Dans ce cadre, les auteurs proposent d’utiliser un centre de Jordan. Celui-ci est d´eﬁni
par :

JC(UT ) = arg min
us∈UT

max
ui∈(UT )

Dist(us, ui)

Il est montr´e que le Centre de Jordan de UT constitue un estimateur « universel » de ˆus,
c’est `a dire s’appliquant aux diﬀ´erents mod`eles de diﬀusion possibles (SI, SIR, SIRI, etc...)
Intuitivement, l’utilisation du centre de Jordan revient `a s´electionner la source minimisant
le nombre de pas n´ecessaires pour contaminer les utilisateurs de UT . Ce centre pr´esente
l’avantage de pouvoir ˆetre calcul´e en temps O(|U| × |E|).

Les auteurs exp´erimentent cet estimateur sur des graphes r´eels avec des ´episodes de diﬀu-
sion artiﬁciels, en se comparant `a d’autres mesures de centralit´e, et observent de meilleurs
r´esultats avec le centre de Jordan.

Plus tard, le probl`eme a ´egalement ´et´e abord´e dans [Dong et al., 2013]. Cet article ´etudie
le cas o`u il existe un a priori sur les diﬀ´erentes sources possibles. Plusieurs r´esultats
th´eoriques sont donn´es, concernant l’impact du nombre de sources possibles a priori et du
type de graphe consid´er´e.

2.8.3 Contexte d’observation partielle

Tous les travaux pr´ec´edents consid`erent que l’´etat de l’ensemble des utilisateurs du r´eseau
est observ´e `a un temps T . Plus r´ecemment, le cas o`u seuls les ´etats d’une partie O ⊂ UT
des utilisateurs sont observ´es a ´et´e ´etudi´e dans [Seo et al., 2012]. Les utilisateurs de O
ainsi observ´es sont dits « monitor´es »

Diﬀ´erentes m´ethodes pour s´electionner les utilisateurs `a monitorer sont d´eﬁnies : centralit´e
dans le graphe, degr´es, maximisation de la distance entre moniteurs, etc... De plus, une
heuristique bas´ee sur quatre mesures diﬀ´erentes visant `a retrouver la sources `a partir de
l’´etat (infect´e/non-infect´e) des utilisateurs monitor´es est ´egalement propos´ee.

Les heuristiques de s´election d’utilisateurs sont test´ees sur des donn´ees r´eelles issues de
Twitter. Les auteurs observent que la meilleure est celle consistant `a choisir les utilisateurs
de fa¸con `a ce que les distances entre eux dans G soient toujours sup´erieures `a un certain
seuil k. Cela revient `a « ´eparpiller » au maximum les utilisateurs monitor´es dans le graphe,
ce qui constitue un r´esultat intuitif : ´eparpiller les utilisateurs permet de mieux couvrir le
graphe et donc de maximiser la quantit´e d’information observ´ee.

Prise en compte des temps d’infection Dans le contexte o`u seul l’´etat d’une partie
des utilisateurs est observ´e, il devient int´eressant d’´etudier le cas o`u les temps d’infection
de ces utilisateurs observ´es sont connus (le cas o`u tous les utilisateurs sont observ´es
avec leurs temps d’infection est trivial, la source ´etant dans ce cas le premier utilisateur
infect´e).

62

Chapitre 2. Mod´elisation et pr´ediction de la diﬀusion d’information : ´etat de l’art

Une premi`ere tentative se trouve dans [Pinto et al., 2012]. Soit DO un ´episode de diﬀusion
« partiel » o`u seuls les ´etats et les temps d’infections du sous-ensemble d’utilisateurs O
sont observ´es. Les utilisateurs non observ´es sont not´es H = U \ O, et nous avons donc :
D = DO∪DH. Les auteurs consid`erent que la diﬀusion suit un mod`ele o`u chaque utilisateur
infect´e transmet l’information `a chacun de ses successeurs apr`es un d´elai tir´e sur chaque
lien selon une loi gaussienne de param`etres ﬁx´es. Il d´eﬁnissent ensuite un estimateur par
maximum de vraisemblance :

ˆus = arg max

us∈U

P (DO|us)

o`u P (DO|us) est la probabilit´e d’observer l’´episode partiel DO quand us est la source,
sous l’hypoth`ese du mod`ele de diﬀusion d´ecrit. L`a encore, ce calcul est tr`es complexe. En
eﬀet, le mod`ele de diﬀusion d´eﬁni ne permet pas de calculer P (DO|us) directement : cette
probabilit´e n’est d´eﬁnie que lorsque O = U , c’est `a dire lorsque D est enti`erement observ´e.
Pour estimer cette probabilit´e dans le cas d’une observation partielle, il est donc n´eces-
saire d’´enum´erer l’ensemble des observations manquantes possibles pour les utilisateurs
cach´es.

(cid:32)

(cid:90)

ˆus = arg max

us∈U

x ∈DH possibles
DH

P (DH ∪ DO|us)

dtDH

j

(cid:33)

(cid:89)

ui∈H

Le calcul de cette vraisemblance doit donc prendre en compte deux sources d’incertitude :
celle concernant les ´etats et les temps d’infection des utilisateurs non-observ´es et celle
concernant les chemins suivis par l’information. Le calcul exact ne passant pas l’´echelle, les
auteurs adoptent une m´ethodologie similaire `a celle de [Shah and Zaman, 2010], le premier
article pr´esent´e dans cette section : ils commencent par ´etudier le cas o`u le graphe G est un
arbre, ce qui supprime la complexit´e li´ee `a l’´enum´eration des chemins possibles. Dans ce
cas, la vraisemblance d’une source peut-ˆetre calcul´ee de fa¸con exacte, avec une complexit´e
lin´eaire. Dans le cas o`u G est un graphe quelconque, l’estimation de la vraisemblance
d’une source se fait dans l’arbre T (us, G) extrait de G avec une recherche en largeur
d’abord `a partir de us. De la mˆeme fa¸con que dans [Shah and Zaman, 2010], cela revient
`a consid´erer seulement l’arbre de diﬀusion le plus vraisemblable plutˆot que tous les arbres
possibles.

Enﬁn, l’article [Farajtabar et al., 2015] s’est plac´e dans un contexte similaire, mais en
consid´erant cette fois que le graphe G est inconnu. Ce graphe est donc estim´e `a partir
d’un ensemble d’´episodes de diﬀusion d’apprentissage D en utilisant une extension de l’al-
gorithme NetRate d´ecrite dans [Daneshmand et al., 2014]. La d´etection de source se fait
toujours avec un estimateur de maximum de vraisemblance, suivant le mod`ele de diﬀusion
NetRate [Gomez-Rodriguez et al., 2011]. De la mˆeme fa¸con que dans l’article pr´ec´edent
[Pinto et al., 2012], cette vraisemblance est diﬃcile `a calculer `a cause de la complexit´e
li´ee `a la pr´esence d’utilisateurs dont l’´etat est inconnu. Toutefois, plutˆot que de proposer
une heuristique bas´ee sur l’extraction de l’arbre de diﬀusion le plus vraisemblable, les au-
teurs proposent une m´ethode d’approximation bas´ee sur l’int´egration par ´echantillonnage

2.8. D´etection de source

63

pr´ef´erentiel. En eﬀet, l’int´egration peut ˆetre approxim´ee par une somme :

(cid:90)

(cid:32)

P (DH ∪ DO|us)

x ∈DH possibles
DH

dtDH

j

≈ 1
Γ

P (DH

x ∪ DO|us)

(cid:89)

ui∈H

(cid:33)

X(cid:88)

x=1

x )x=1..X est un ensemble de valeurs possibles de la partie cach´ee DH, tir´ees al´eatoire-
o`u (DH
ment, et 1
Γ un terme de normalisation. Ainsi, au lieu de r´ealiser une int´egration sur toutes
les valeurs possibles de DH, nous approximons cette int´egrale en tirant seulement X va-
leurs possibles de DH. La qualit´e de cette approximation augmente avec X. L’int´egration
par ´echantillonnage pr´ef´erentiel consiste ensuite `a favoriser les valeurs plus probables de
DH, qui ont un impact plus grand sur le calcul de la somme. Pour cela, l’´echantillonnage
pr´ef´erentiel utilise les longueurs des plus courts chemins dans le graphe de fa¸con `a favoriser
le tirage de temps d’infection « vraisemblables » pour les utilisateurs cach´es.

Contrairement aux autres mod`eles pr´esent´es dans cette section, celui-ci est test´e sur des
donn´ees r´eelles, mais ne parvient `a retrouver la source que dans le cas o`u plusieurs diﬀu-
sions partant d’une mˆeme source sont observ´ees, ce qui n’est pas r´ealiste dans beaucoup
d’applications.

2.8.4 La d´etection de source comme probl`eme adverse

Une formulation int´eressante du probl`eme de d´etection de source a ´et´e donn´ee par [Luo
et al., 2015a]. Le contexte est ici celui d’un jeu opposant deux joueurs : une source diﬀusant
des informations dans un r´eseau, et l’administrateur dudit r´eseau cherchant `a identiﬁer
la source (pour la bannir du r´eseau parce qu’elle diﬀuse du contenu ill´egal, par exemple).
L’objectif du joueur « source » est d’infecter un maximum d’utilisateurs (ce qui est associ´e
`a une r´ecompense) sans ˆetre rep´er´ee (ce qui est associ´e `a un coˆut). L’objectif du joueur
« administrateur » est de retrouver cette source tout en inspectant un minimum d’utilisa-
teurs, cette inspection ayant un coˆut. Les auteurs formulent une s´erie d’hypoth`eses sur les
m´ecanismes de diﬀusion et les actions possibles des joueurs, et ´etudient l’existence d’un
´equilibre de Nash dans ce contexte. Ils remarquent en particulier que si un ´equilibre de
Nash existe, la strat´egie optimale de l’administrateur est d’inspecter uniquement le centre
de Jordan.

2.8.5 D´etection de plusieurs sources

Dans la plupart des applications, une seule source est `a l’origine de chaque rumeur. Cer-
tains travaux ont toutefois ´etudi´e le cas o`u plusieurs utilisateurs lancent une rumeur en
mˆeme temps.

Dans [Lappas et al., 2010], les auteurs se placent dans le cadre du mod`ele IC et d´eﬁnissent
le probl`eme des k-eﬀectors. ´Etant donn´e un vecteur d’activation a, i.e. un vecteur binaire

64

Chapitre 2. Mod´elisation et pr´ediction de la diﬀusion d’information : ´etat de l’art

de taille N indiquant quels utilisateur ont ´et´e infect´es par une information, le but est de
retrouver un ensemble X d’utilisateurs minimisant le coˆut :
|a(i) − α(i, X)|

(cid:88)

C(X) =

ui∈U

o`u α(i, X) d´esigne la probabilit´e que l’utilisateur ui devienne infect´e durant une diﬀusion
d´emarrant par l’ensemble X. De la mˆeme fa¸con que dans [Shah and Zaman, 2010], les
auteurs montrent que le probl`eme est diﬃcile (NP-diﬃcile, dans ce cas) et commencent
par ´etudier le cas o`u G est un arbre, et proposent deux heuristiques. Si G est un graphe
quelconque, ils proposent d’extraire un arbre couvrant et appliquent leurs heuristiques sur
cet arbre. L’approche est test´ee sur des donn´ees de diﬀusion de mots-cl´es au sein d’une
communaut´e de chercheurs.

L’utilisation des centres de Jordan pour la d´etection de source a ´egalement ´et´e ´etudi´ee
dans le cas de la d´etection de plusieurs sources [Luo et al., 2015b].

Une autre approche se trouve dans [Prakash et al., 2012]. Les auteurs proposent ici une
m´ethode permettant de pr´edire le nombre de sources, puis leurs identit´es. La m´ethode
propos´ee, baptis´ee Netsleuth, est bas´ee sur le principe de longueur de description mi-
nimale : le but des auteurs est de d´ecrire parfaitement l’ensemble d’utilisateurs infect´es
UT en utilisant le moins de bits possible.

Pour cela, ils consid`erent que la diﬀusion se fait selon un mod`ele SI : `a chaque pas de
temps, chaque utilisateur infect´e tente de contaminer chacun de ses voisins, avec une
probabilit´e de succ`es ´egale `a β. Pour encoder de la fa¸con la plus eﬃcace possible un
´episode de diﬀusion, les auteurs utilisent la proc´edure suivante.

— Encoder le nombre de sources, avec un code favorisant les valeurs plus faibles (qui

sont plus probables).

fois le nombre x de sources connu, il existe seulement (cid:0)N

(cid:1) ensembles de sources

— Encoder l’identit´e des sources. Cela peut se faire eﬃcacement en remarquant qu’une

x

(cid:0)(cid:0)N

x

(cid:1)(cid:1) bits.

possibles. En d´eﬁnissant un ordre sur ces ensembles, cette information peut ˆetre
encod´ee en log2

— Encoder le nombre d’it´erations n´ecessaires pour infecter tous les utilisateurs.
— Pour chacune de ces it´erations, encoder la liste des nouveaux utilisateurs infect´es.
Cette information peut ˆetre compress´ee en observant que seule une partie des uti-
lisateurs peuvent ˆetre contamin´es `a chaque pas de temps (ceux dont au moins un
voisin est d´ej`a infect´e), ce qui r´eduit grandement le nombre de bits n´ecessaires.

Les auteurs cherchent l’ensemble de sources minimisant le nombre de bits n´ecessaires pour
d´ecrire UT suivant cette proc´edure, aﬁn de trouver le nombre de sources et leurs identit´es.
Cette minimisation ´etant complexe, une approximation utilisant un algorithme glouton
est propos´ee. Celle-ci est bas´ee sur l’extraction des vecteurs propres de la matrice lapla-
cienne du graphe des utilisateurs infect´es. Contrairement `a beaucoup d’autres travaux
pr´esent´es dans cette section, cet article n’est donc pas bas´e sur un maximum de vrai-

2.9. Conclusion

65

semblance. NetSleuth est test´e sur des graphes artiﬁciels et r´eels, avec des ´episodes de
diﬀusion synth´etiques, et parvient bien `a retrouver le nombre de sources ainsi que leurs
identit´es.

2.9 Conclusion

Dans ce chapitre, nous avons pr´esent´e un ´etat de l’art sur le sujet de la diﬀusion d’infor-
mation dans les r´eseaux sociaux. La diversit´e des tˆaches et des travaux nous montre que
l’expression recouvre en pratique un champ applicatif assez vaste. Nous pouvons toute-
fois d´egager plusieurs diﬃcult´es communes `a la plupart des articles pr´esent´es. Dans cette
th`ese, nous serons nous aussi confront´es `a ces probl`emes.

La diﬀusion d’information est un ph´enom`ene rare : chaque jour, une ´enorme
quantit´e d’information est g´en´er´ee sur internet. Toutefois, seule une inﬁme partie
de celle-ci devient particuli`erement populaire. De nombreux travaux indiquent que
la r´epartition des tailles des cascades suit une loi de puissance (en g´en´eral de para-
m`etre α ≈ 2 [Cheng et al., 2014]). Ce d´es´equilibre peut ˆetre source de diﬃcult´es. Le
manque de longues cascades rend notamment les donn´ees rares, ce qui complique
l’apprentissage des param`etres d’un mod`ele ou l’extraction des caract´eristiques des
utilisateurs. De plus, pr´edire un ph´enom`ene rare est toujours d´elicat.

La diﬀusion d’information est un ph´enom`ene chaotique : s’il est possible d’ob-
server des r´egularit´es `a un niveau de diﬀusion global, les comportements des utili-
sateurs et leurs interactions sont tr`es variables et d´elicats `a caract´eriser.

Les mod`eles ont une complexit´e calculatoire importante : avec le d´eveloppe-
ment des r´eseaux sociaux en ligne, la taille de ceux-ci a largement augment´e. Prati-
quement tous les mod`eles bas´es sur le graphe social se heurtent `a des probl`emes de
passage `a l’´echelle. Il devient rapidement n´ecessaire de proposer des heuristiques
pour remplacer un calcul exact dans le graphe, ou de d´eﬁnir des m´ethodes ne
reposant pas sur ce graphe.

Les probl´ematiques peuvent ˆetre propres `a chaque r´eseau : la notion de « r´e-
seau social en ligne » est assez ﬂoue et d´esigne de tr`es nombreux services web
fonctionnant de fa¸cons diﬀ´erentes. Il est ainsi courant qu’un mod`ele soit d´eﬁni
pour un r´eseau particulier et ne s’adapte pas, ou mal, `a un autre. De plus, les
possibilit´es sont ´etroitement li´ees `a la disponibilit´e des donn´ees : de nombreuses
informations pertinentes ne sont pas accessibles par le biais des API oﬀertes par les
grands r´eseaux sociaux en ligne. Par exemple, si Twitter ´etait tr`es ouvert durant
ses premi`eres ann´ees, il l’est beaucoup moins aujourd’hui : il n’est plus possible de
r´ecup´erer l’int´egralit´e du traﬁc facilement.

Les tˆaches sont mal d´eﬁnies : pour les diﬀ´erentes tˆaches que nous avons pr´esen-
t´ees, il n’existe pas de d´eﬁnition formelle consensuelle (exception faite de la maxi-

66

Chapitre 2. Mod´elisation et pr´ediction de la diﬀusion d’information : ´etat de l’art

misation d’inﬂuence). Les articles cit´es ´etudient des contextes exp´erimentaux vari´es
et pas toujours compatibles entre eux. L’´evaluation des performances reste ´egale-
ment un probl`eme ouvert. En particulier, dans un certain nombre de travaux sur
la pr´ediction de diﬀusion ou la d´etection de sources pr´esent´es dans ce chapitre,
l’´evaluation est r´ealis´ee sur des ´episodes de diﬀusion synth´etiques g´en´er´es selon un
mod`ele connu dans un graphe r´eel, et non pas sur des ´episodes issus de donn´ees
r´eelles. Cela est susceptible de limiter la pertinence des r´esultats ainsi obtenus. De
la mˆeme fa¸con, sur la tˆache de maximisation d’inﬂuence, les mod`eles sont ´evalu´es
en simulant la diﬀusion dans un r´eseau social, et non pas en observant de vraies
exp´eriences de marketing viral dans un r´eseau.

Chapitre 3

Relaxation et r´egularisation du

mod`ele IC

R´esum´e Ce chapitre pr´esente une premi`ere contribution, publi´ee dans [Lamprier et al.,
2015]. Nous proposons d’apprendre les param`etres du mod`ele IC selon la m´ethode de [Saito
et al., 2008] mais en relaxant les contraintes sur des d´elais de transmission, aﬁn d’obtenir
un mod`ele plus robuste que [Saito et al., 2008], que nous testons sur des donn´ees r´eelles.
Nous proposons ´egalement de r´egulariser les probabilit´es apprises aﬁn de limiter l’eﬀet du
surapprentissage sur certains corpus.

3.1 Diﬃcult´es li´ees `a l’apprentissage d’IC

Dans ce chapitre, nous nous int´eressons au mod`ele Independent Cascades, qui est `a la base
de nombreux travaux pr´esent´es dans le chapitre 2. Sa capacit´e `a expliquer de mani`ere
relativement r´ealiste de nombreux processus de diﬀusion, tout en conservant une certaine
simplicit´e grˆace `a ses hypoth`eses d’ind´ependance, en fait en eﬀet un des mod`eles les plus
´etudi´es.

Nous avons vu dans le chapitre 2 que le mod`ele IC ´etait un mod`ele g´en´eratif bas´e sur le
graphe social : lorsqu’un utilisateur ui devient infect´e, il tente de contaminer chacun de
ses voisins uj avec une certaine probabilit´e de r´eussite pi,j. L’apprentissage du mod`ele IC
revient donc `a apprendre une probabilit´e de transmission sur chaque lien du graphe social,
`a partir d’un ensemble D d’´episodes de diﬀusion observ´es. Nous noterons P cet ensemble
de probabilit´es.
Une diﬃcult´e de l’apprentissage de P vient de la notion d’´episode de diﬀusion. Rappelons
qu’un ´episode de diﬀusion D d´esigne une s´equence d’utilisateurs infect´es par une mˆeme

67

68

Chapitre 3. Relaxation et r´egularisation du mod`ele IC

Figure 3.1 – Un exemple d’´episode de diﬀusion et de cascades possibles. Les structures
de cascades repr´esentent plusieurs fa¸cons dont l’information a pu se transmettre dans le
r´eseau.

information, avec leurs temps d’infection associ´es :

i ), (uj, tD

j ), (uk, tD

D =(cid:0)(ui, tD

k ), . . .(cid:1)

Dans un ´episode de diﬀusion, nous savons quand a ´et´e infect´e chaque utilisateur, mais
nous ne savons pas par qui. Un exemple se trouve en ﬁgure 3.1. Dans cet exemple, nous
pouvons constater que plusieurs structures de diﬀusions, ou « cascades », sont susceptibles
d’expliquer un mˆeme ´episode de diﬀusion.

Si cette information manquante ´etait connue, l’estimation des param`etres du mod`eles IC
serait simple. En eﬀet, il suﬃrait pour estimer chaque pi,j de compter le nombre d’´episodes
de diﬀusion o`u l’utilisateur ui a contamin´e l’utilisateur uj, et de diviser cette valeur par
le nombre d’´episodes o`u ui a tent´e de contaminer uj (voir section 3.2.1). Dans un ´episode
de diﬀusion D, nous pouvons savoir quelles tentatives de transmission ont eu lieu : chaque
utilisateur, lorsqu’il devient infect´e dans D, tente de contaminer chacun de ses voisins non
infect´es. En revanche, nous ne savons pas quelles tentatives ont r´eussi.

L’incertitude li´ee `a cette information manquante peut ˆetre limit´ee en ajoutant certains a
priori. En particulier, tous les mod`eles graphiques font l’hypoth`ese qu’un utilisateur infect´e
a forc´ement ´et´e contamin´e par un de ses pr´ed´ecesseurs d´ej`a infect´es. Il est ´egalement
possible d’ajouter un a priori sur le d´elais de transmission, i.e. le temps mis par un
utilisateur pour en contaminer un autre. Ces possibilit´es sont discut´ees dans les prochaines
sous-sections.

3.1.1 Graphe du r´eseau social

Le mod`ele IC classique, comme beaucoup d’autres mod`eles pr´esent´es dans le chapitre 2,
fait l’hypoth`ese que la diﬀusion ne peut avoir lieu que sur les liens du graphe du r´eseau
social, suppos´e connu. Ainsi, un utilisateur infect´e dans un ´episode de diﬀusion ne peut

3.1. Diﬃcult´es li´ees `a l’apprentissage d’IC

69

avoir ´et´e contamin´e que par l’un de ses voisins pr´ec´edemment infect´es. Cela restreint les
structures de cascades possibles pour un ´episode de diﬀusion donn´e.

Toutefois, il est `a noter que quand aucun graphe explicite n’est disponible, ou lorsque
les relations connues ne repr´esentent pas les canaux de diﬀusion ´etudi´es (voir chapitre 2,
section 2.5.1.4), les probabilit´es de diﬀusion peuvent ˆetre d´eﬁnies sur le graphe complet
reliant tous les utilisateurs. Cela revient alors `a apprendre les canaux de diﬀusion uni-
quement `a partir des comportements observ´es, sans a priori sur le graphe de diﬀusion
sous-jacent, de la mˆeme fa¸con que dans [Gomez-Rodriguez et al., 2011]. C’est dans ce
cadre que nous nous placerons dans ce chapitre et dans ce manuscrit.

3.1.2 Discr´etisation du temps

Le mod`ele IC classique fait l’hypoth`ese que la contamination a lieu durant des pas de
temps cons´ecutifs : lorsqu’un utilisateur devient infect´e au pas de temps t, il dispose d’une
unique chance d’infecter chacun de ses voisins au pas de temps t + 1. En cons´equence, un
utilisateur infect´e au temps t dans un ´episode de diﬀusion D ne peut avoir ´et´e contamin´e
que par un utilisateur ayant lui mˆeme ´et´e contamin´e au temps t − 1.

Cependant, dans les corpus issus de sites internet, le temps est renseign´e sous forme d’un
« timestamp », i.e. le nombre de secondes ´ecoul´ees depuis le 1er janvier 1970. Or, il est
bien ´evident que dans le cas de la diﬀusion d’information sur les r´eseaux sociaux, il est
impossible qu’un utilisateur contamine un de ses voisins apr`es une dur´ee d’une seconde,
qui est bien trop courte. Il est donc n´ecessaire de d´eﬁnir une « longueur de pas de temps »
raisonnablement grande (par exemple, quelques minutes sur Twitter ou quelques heures
sur Facebook).

Cela pose une diﬃcult´e majeure : comment choisir le bon « pas de temps » ? Avec un pas
de temps trop grand, de nombreux utilisateurs peuvent ˆetre regroup´es au sein d’une mˆeme
it´eration du mod`ele, ce qui risque de masquer de tr`es nombreuses relations entre eux. `A
l’inverse, un pas de temps trop court peut rendre impossible la mod´elisation d’´episodes
o`u l’interval de temps entre deux infections est trop long.

La ﬁgure 3.2 illustre ce probl`eme. Nous montrons comment un mˆeme ´episode de diﬀusion
peut ˆetre discr´etis´e de diﬀ´erentes mani`eres. Sur cette ﬁgure, nous pouvons voir que les re-
lations utilisateurs susceptibles d’ˆetre inf´er´ees `a partir d’un ´episode de diﬀusion d´ependent
beaucoup du pas de temps consid´er´e. Par exemple, avec un pas de temps de une seconde,
il est impossible que l’utilisateur vert ait ´et´e contamin´e par l’utilisateur gris, alors que cela
est possible avec un pas de temps de une ou deux minutes. Avec un pas ﬁx´e `a dix minutes,
toutes les infections ont lieu au temps initial et l’´episode de diﬀusion repr´esent´e `a gauche
n’apporte donc aucune information. Cet exemple simple illustre le fait que le choix d’une
valeur de pas de temps constitue un a priori fort sur la dynamique de la diﬀusion, et qu’il

70

Chapitre 3. Relaxation et r´egularisation du mod`ele IC

Figure 3.2 – Importance du choix du pas de temps

n’existe pas de « bonne » solution, a fortiori sur des ensembles de plusieurs dizaines de
milliers d’´episodes de diﬀusion.

3.1.3 Mod´elisation du temps

Pour d´epasser cette simple discr´etisation du temps et les diﬃcult´es qu’elle soul`eve, plu-
sieurs articles ont propos´e de mod´eliser les d´elais d’infections, conjointement aux pro-
babilit´es d’infection. C’est notamment le cas du mod`ele CTIC et du mod`ele continu de
Leskovec (NetRate), d´ecrits dans le chapitre 2 :

— le mod`ele CTIC est une extension du mod`ele IC qui consid`ere que lorsqu’un uti-
lisateur ui en contamine un autre uj (ce qui se produit avec une probabilit´e pi,j),
l’infection a lieu apr`es un d´elai di,j tir´e selon une certaine loi de probabilit´e, de
param`etre ri,j devant ´egalement ˆetre appris pour chaque lien ;

— le mod`ele NetRate consid`ere que la probabilit´e de transmission de uj par ui d´epend
du temps : `a chaque instant t, la probabilit´e que ui contamine uj d´epend du temps
´ecoul´e depuis l’infection de ui, suivant une certaine loi de probabilit´e de param`etre
ri,j. Ce mod`ele est en fait ´equivalent `a un mod`ele CTIC dont les probabilit´es de
transmission seraient toutes ´egales `a 1.

Toutefois, les r´egularit´es sur les d´elais d’infection nous semblent diﬃciles `a extraire d’´epi-
sodes de diﬀusion issus de donn´ees r´eelles. Estimer l’inﬂuence qu’ont les utilisateurs les uns
sur les autres constitue d´ej`a un probl`eme diﬃcile. Ajouter `a ce probl`eme l’extraction de
r´egularit´es sur les d´elais d’infections `a partir de donn´ees de diﬀusion tr`es parcimonieuses
complexiﬁe encore la tˆache. De plus, dans ces mod`eles, les d´elais d’infection observ´es
dans les donn´ees d’apprentissage ont un impact non-n´egligeable sur les probabilit´es ap-
prises. L’apprentissage des probabilit´es peut donc souﬀrir de la grande variance de ces
d´elais.

3.2. Delay-Agnostic Independant Cascades (DAIC)

71

3.2 Delay-Agnostic Independant Cascades (DAIC)

Face `a ces diﬃcult´es, il peut apparaˆıtre viable de s’abstraire de cette dimension temporelle
pour la mod´elisation de la diﬀusion. Cela nous a amen´e `a une contribution introductive `a ce
travail de th`ese, consistant en la proposition d’un algorithme d’apprentissage du mod`ele
IC o`u nous consid´erons qu’un utilisateur uj ∈ D peut avoir ´et´e infect´e par n’importe
lequel de ses pr´ed´ecesseurs d´ej`a infect´es, ind´ependamment de leurs temps d’infections.
Cela revient de fait `a consid´erer que les d´elais de transmission suivent une loi uniforme.
Nous baptisons cet algorithme « Delay-Agnostic IC », ou DAIC.

Cette approche est ´egalement justiﬁ´ee par le fait que la mod´elisation des d´elais de conta-
mination, et donc la pr´ediction des temps d’infections, n’est pas essentielle dans de nom-
breuses applications. Par exemple, dans le cas du probl`eme de maximisation d’inﬂuence
pr´esent´e dans le chapitre 2, il est seulement n´ecessaire de pr´edire quels utilisateurs seront
infect´es, ou combien, mais pas quand.

3.2.1 Apprentissage

Dans notre mod`ele, comme dans le mod`ele IC, chaque utilisateur devenant infect´e dispose
d’une unique chance d’infecter chacun de ses voisins. Toutefois, nous consid´erons que cette
contamination peut avoir lieu apr`es un d´elai quelconque, et pas forc´ement au pas de temps
suivant comme dans le mod`ele IC classique. Un utilisateur uj infect´e dans un ´episode de
diﬀusion D est donc susceptible d’avoir ´et´e contamin´e par n’importe quel pr´ed´ecesseur
infect´e avant lui.

Nous suivons ensuite la m´ethodologie d´eﬁnie dans [Saito et al., 2008] pour apprendre
l’ensemble des probabilit´es de transmission P. Soit uj un utilisateur, et D un ´episode
∩ Predsj) est nomm´e « ensemble des infecteurs potentiels »
de diﬀusion. L’ensemble (U D
tj
de uj. Cet ensemble correspond `a l’ensemble des utilisateurs tentant de transmettre `a
uj l’information consid´er´ee. Dans notre cas il s’agit donc de l’ensemble des pr´ed´ecesseurs
de uj infect´es avant lui. La probabilit´e d’infection de uj dans un ´episode D est donc la
∩ Predsj) transmette l’information `a
probabilit´e qu’au moins un des utilisateurs de (U D
tj
uj. Cette probabilit´e est not´ee P (uj|U D
,P) et vaut :

(3.1)

tj

,P) = 1 − (cid:89)

P (uj|U D

tj

(1 − pi,j)

ui∈(U D
tj

∩Predsj )

Rappelons ici que pi,j d´esigne la probabilit´e de transmission de ui vers uj.

La probabilit´e d’observer un ´episode de diﬀusion D d´epend alors de la probabilit´e d’ob-
server :
— l’infection de chaque utilisateur uj ∈ U D∞, en connaissant l’ensemble des utilisateurs

infect´es avant lui U D
tj

;

72

Chapitre 3. Relaxation et r´egularisation du mod`ele IC

— la non-infection de chaque utilisateur uj ∈ ¯U D∞.

P = (D|P) =

=

,P) × (cid:89)
,P) × (cid:89)

uj∈ ¯U D∞

P (uj|U D

tj

P (uj|U D

tj

(cid:89)
(cid:89)

uj∈U D∞

uj∈U D∞

(1 − P (uj|U D∞,P))
(cid:89)

(1 − pi,j)

uj∈ ¯U D∞

ui∈U D∞

(3.2)

La log-vraisemblance d’un ensemble de param`etres P (les probabilit´es de transmission)
par rapport `a un ensemble D d’´episodes de diﬀusion observ´es est donc donn´ee par :

L(P;D) =

=

(cid:88)
(cid:88)

D∈D

D∈D

log P (D|P)

 (cid:88)

uj∈U D∞

log(P D

j ) +



log(1 − pi,j)

(cid:88)

(cid:88)

uj∈ ¯U D∞

ui∈U D∞

(3.3)

o`u P D
babilit´es s’´ecrit alors :

j est une ´ecriture simpliﬁ´ee de P (uj|U D
P (cid:63) = arg max

,P). Le probl`eme d’apprentissage des pro-
L(P;D)

tj

P

Malheureusement, l’optimisation de cette log-vraisemblance est diﬃcile, `a cause de la d´eﬁ-
nition de P D
j (´equation 3.1). Toutefois, comme nous l’avons expliqu´e au d´ebut du chapitre,
l’estimation de P serait largement facilit´ee si nous savions qui a infect´e qui (ou plus exac-
tement : quelles tentatives de contamination ont r´eussi ). Cette information manquante
correspond donc `a un facteur latent du mod`ele. C’est pr´ecis´ement dans ce genre de situa-
tion qu’un algorithme d’esp´erance-maximisation est indiqu´e [Dempster et al., 1977]. Nous
suivons donc la m´ethodologie de [Saito et al., 2008] pour optimiser L(P;D).

contamination ont r´eussi dans D. Nous notons :

i→j

D∈D,(ui,uj )∈E

l’information manquante, indiquant quelles tentatives de

Soit X = (cid:0)X D

(cid:1)

(cid:40)

X D

i→j =

1 si ui a r´eussi `a contaminer uj dans D
0 sinon

Si l’information X ´etait connue, la log-vraisemblance d’un ensemble de param`etres P par
rapport aux donn´ees compl´et´ees (D,X ) serait ´egale `a la log-vraisemblance des contami-
nations et des non-contaminations indiqu´ees par X :
L (P; (D,X )) =

(cid:0)X D
i→j log(pi,j) +(cid:0)1 − X D

(cid:1) log(1 − pi,j)(cid:1)

(cid:88)

i→j

(cid:88)
(cid:88)

D∈D

(cid:88)
(cid:88)

uj∈U D∞

+

D∈D

uj∈ ¯U D∞

ui∈U D∞

ui∈(U D
tj

(cid:88)

∩Predsj )
log(1 − pi,j)

(3.4)

3.2. Delay-Agnostic Independant Cascades (DAIC)

73

En pratique, X est inconnu mais nous pouvons calculer l’esp´erance de X D
i→j lorsque uj
est infect´e dans un ´episode D et que ui fait partie de ses infecteurs potentiels, en nous
basant sur une estimation courante de P not´ee ˆP. Cela se fait en appliquant le th´eor`eme
de Bayes, et en remarquant que l’esp´erance de X D
i,j est ´egale `a la probabilit´e que sa valeur
soit ´egale `a 1 :

(cid:21)

(cid:20)

E

=

=

=

ˆpi,j
ˆP D
j

i→j|uj ∈ U D∞, ui ∈ (U D
X D

∩ Preds
i→j = 1|uj ∈ U D∞, ui ∈ (U D
i→j = 1, ui ∈ (U D

), ˆP
∩ Preds
∩ Predsj), ˆP) × P (X D

), ˆP)

P (uj ∈ U D∞|X D

= P (X D

tj

tj

j

j

tj

P (uj ∈ U D∞|ui ∈ (U D
∩ Predsj), ˆP)

tj ∩ Predsj), ˆP)

1 × P (X D

i→j = 1|ui ∈ (U D

tj

P (uj ∈ U D∞|ui ∈ (U D

tj ∩ Predsj), ˆP)

i→j = 1|ui ∈ (U D

tj

∩ Predsj), ˆP)

i→j cette valeur. Rappelons bien ici que P D

Nous notons ˆP D
j d´esigne la probabilit´e qu’au
moins une tentative de transmission vers uj dans D ait r´eussi (´equation 3.1), alors que
P D
i→j d´esigne la probabilit´e que la tentative de transmission depuis ui vers uj dans D ait
r´eussi.

Nous pouvons alors calculer l’esp´erance de la vraisemblance d’un ensemble de param`etres
P connaissant les donn´ees compl´et´ees (D,X ) et une estimation courante ˆP :

(cid:104)L (P; (D,X ))| ˆP(cid:105)
ΦD(P| ˆP) +
(cid:88)
(cid:88)
(cid:16) ˆP D
(cid:88)

D∈D

(cid:88)
(cid:16)

uj∈ ¯U D∞

ui∈U D∞

i→j log(pi,j) +

1 − ˆP D
i→j

(cid:17)

(cid:17)

log(1 − pi,j)



log(1 − pi,j)

Q(P| ˆP) = EX

=

avec :

ΦD(P| ˆP) =

(cid:88)

uj∈U D∞

ui∈(U D
tj

∩Predsj )

(3.5)

(3.6)

Remarquons la similarit´e entre les ´equations 3.5 et 3.3. Dans [Dempster et al., 1977], il
est montr´e que la suite P (n+1) = arg maxP Q(P|P (n)) converge vers un maximum local
quand n augmente.

Annuler la d´eriv´ee de Q(P| ˆP) par rapport aux param`etres P nous permet de maximiser
l’esp´erance Q `a chaque it´eration de l’algorithme EM. Pour chaque lien (ui, uj) ∈ E, nous

74

Chapitre 3. Relaxation et r´egularisation du mod`ele IC

obtenons la formule de mise `a jour :

pi,j ←

avec :

(cid:80)
D∈D?
i,j| + |D−
i,j|

ˆpi,j
ˆP D
j

|D?

i,j

(3.7)

— D?

i,j : ensemble des ´episodes de diﬀusion o`u il est possible que ui ait contamin´e

uj, c’est `a dire o`u ui est infect´e avant uj :

D?
i,j = {D ∈ D|(ui ∈ U D∞) ∧ (uj ∈ U D∞) ∧ (tD

j )}
i < tD

— D−

i,j : ensemble des ´episodes de diﬀusion o`u il est impossible que ui ait r´eussi `a
contaminer uj, c’est `a dire o`u ui est infect´e et uj ne l’est pas. Les ´episodes de D−
sont appel´es des « contre-exemples » pour le couple d’utilisateurs (ui, uj).

i,j

D−
i,j = {D ∈ D|(ui ∈ U D∞) ∧ (uj (cid:54)∈ U D∞)}

— ˆP D
j

: l’estimation courante de P D
j

calcul´ee selon l’´equation 3.1 avec les valeurs

courantes ˆpi,j.

La d´emonstration de la formule 3.7 est donn´ee en annexe A, et l’algorithme 1 r´esume
l’ensemble de la proc´edure d’apprentissage. Remarquons enﬁn que la formule de mise `a
jour 3.7 peut ˆetre comprise intuitivement ainsi : si nous connaissions X , l’estimation de
P aurait la forme :

(cid:80)
X D
D∈D?
i,j
i,j| + |D−
i,j|

|D?

i,j

pi,j =

(3.8)

En d’autres termes, il suﬃrait de diviser le nombre de fois o`u ui a r´eussi `a transmettre
une information `a uj par le nombre de fois o`u il a essay´e de le faire. L’information X ´etant
manquante, la formule 3.7 est une estimation de la valeur de la formule 3.8.

Par rapport `a [Saito et al., 2008], l’estimation de pi,j est similaire mais se base sur bien
plus d’exemples, car elle consid`ere beaucoup plus de cas comme ´etant des possibilit´es
d’infection. Cela nous permet d’obtenir un mod`ele plus r´ealiste et robuste, tout en ´evitant
les diﬃcult´es li´ees `a l’apprentissage des d´elais de diﬀusion.

Remarquons enﬁn que la formule de mise `a jour 3.7 fait que ˆpi,j > 0 =⇒ pi,j > 0. Il en
d´ecoule, par r´ecurrence, que les valeurs de P apprises par l’algorithme 1 ne sont jamais
nulles, car elles sont initialis´ees al´eatoirement sur l’intervalle ]0, 1[.

3.3. R´egularisation de l’apprentissage

75

Algorithme 1 : Delay-Agnostic IC (DAIC)
Entr´ees :
U : Ensemble d’utilisateurs ;
D : Ensemble d’´episodes de diﬀusion d’apprentissage ;
M : Nombre d’it´erations
Sorties :
P = (pi,j)(ui,uj )∈U 2 ;
1 pour (ui, uj) ∈ U 2 faire

2

3

4

ˆpi,j = 0 ;
si |D?

i,j| > 0 alors
Initialiser ˆpi,j au hasard dans ]0, 1[ ;

ﬁn
5
6 ﬁn
7 it ← 0 ;
8 tant que it < M faire
9

pour (ui, uj) tel que |D?

(cid:80)

i,j| > 0 faire

pi,j ←

ˆpi,j
ˆP D
j

D∈D?
i,j
i,j|+|D−
|D?
i,j|

10

11

12

ﬁn
ˆP ← P
it ← it + 1

13
14 ﬁn
15 retourner ˆP

3.3 R´egularisation de l’apprentissage

3.3.1 Biais d’apprentissage

Dans l’algorithme d’apprentissage que nous avons pr´esent´e, les probabilit´es de transmis-
sion sont apprises en maximisant la vraisemblance de l’ensemble d’apprentissage, c’est `a
dire en cherchant les probabilit´es expliquant au mieux les ´episodes de diﬀusion observ´es,
en suivant la m´ethodologie d´eﬁnie dans [Saito et al., 2008].

Cela a pour cons´equence d’introduire un biais dans l’apprentissage, li´e `a l’h´et´erog´en´eit´e
des fr´equences d’apparition des utilisateurs dans l’ensemble d’apprentissage. En eﬀet, nous
pouvons voir qu’avec la formule 3.7, des paires d’utilisateurs avec peu (ou pas) de « contre-
exemples » dans l’ensemble d’apprentissage risquent de masquer les contaminations dans
d’autres ´episodes. Un « contre-exemple » pour un param`etre pi,j est un ´episode de diﬀusion
D dans lequel ui est infect´e et uj ne l’est pas, ce qui signiﬁe que ui n’a pas r´eussi `a
contaminer uj. L’ensemble D−

i,j correspond `a l’ensemble de ces contre-exemples.

76

Chapitre 3. Relaxation et r´egularisation du mod`ele IC

Figure 3.3 – Illustration du probl`eme de biais d’apprentissage

.

l’estimation de pi,j `a la n-i`eme it´eration de l’algorithme EM. Nous avons la

Soit p(n)
i,j
proposition suivante :
Proposition 1. Pour tout lien (ui, uj) ∈ E tel que |D−i,j| > 0, s’il existe pour chaque
´episode D ∈ D?

tj ∩ Predsj tel que |D−k,j| = 0, alors :
i,j un utilisateur uk ∈ U D
lim
n→+∞

p(n)
i,j = 0

La d´emonstration de cette proposition se trouve en annexe B.

Une illustration de la proposition 1 est donn´ee en ﬁgure 3.3. Dans cette ﬁgure, nous pou-
vons voir plusieurs exemples positifs entre l’utilisatrice noire et l’utilisateur gris (les trois
premiers ´episodes de diﬀusion) ainsi qu’un contre exemple de diﬀusion pour ce couple
d’utilisateurs. Par contre, pour les couples d’utilisateurs jaune-gris, blanc-gris et vert-gris,
il n’existe aucun contre-exemple de diﬀusion : chaque fois que le premier utilisateur est
infect´e, le second l’est aussi. Cet ensemble d’´episodes de diﬀusion conduit `a l’apprentissage
des probabilit´es repr´esent´ees `a droite. On constate que la probabilit´e de transmission de
l’utilisatrice noire `a l’utilisateur gris est nulle (ou, plus exactement, tend vers 0). L’al-
gorithme d’apprentissage consid`ere en fait que les infections de l’utilisateur gris dans
les ´episodes de diﬀusion observ´es sont parfaitement expliqu´ees par des probabilit´es de
transmissions `a 1 pour les paires jaune-gris, blanc-gris et vert-gris, et de 0 (une valeur
arbitrairement faible) pour noire-gris. Ainsi, des utilisateurs rares (jaune, blanc et gris)
ont compl`etement masqu´e la relation entre noire et gris, pourtant bien plus pr´esents dans
l’ensemble d’apprentissage. Sur cet exemple th´eorique, cela n’est pas forc´ement gˆenant.
Mais en pratique, les donn´ees extraites de corpus r´eels sont tr`es bruit´ees, et les utilisateurs
ont des comportements tr`es chaotiques. Les utilisateurs rares peuvent donc correspondre
`a du bruit dans les donn´ees. Ce ph´enom`ene devient alors probl´ematique, car il limite les
capacit´es de g´en´eralisation du mod`ele.

3.3. R´egularisation de l’apprentissage

77

Notons enﬁn que ce probl`eme est ´egalement pr´esent dans l’algorithme original de [Saito
et al., 2008], mais de fa¸con moins prononc´ee car celui-ci consid`ere beaucoup moins d’in-
fecteurs potentiels.

3.3.2 Maximum a posteriori

Pour r´esoudre ce probl`eme, nous proposons d’ajouter un a priori sur les probabilit´es de
transmission apprises. Le probl`eme s’´ecrit alors sous la forme d’un maximum a poste-
riori :

(cid:89)

(cid:89)
P (U D∞|P)
(cid:88)

pi,j∈P

D∈D
L(P;D) +

P (cid:63) = arg max

P

= arg max

P

f (pi,j)

log f (pi,j)

pi,j∈P

(3.9)

(3.10)

o`u f est l’a priori appliqu´e aux probabilit´es de transmission. Plusieurs fonctions sont envi-
sageables, nous proposons d’utiliser une loi exponentielle car celle-ci favorise les solutions
parcimonieuses et les probabilit´es de transmission faibles. En eﬀet, comme nous l’avons
vu dans le chapitre 2, la diﬀusion est un ph´enom`ene rare. Il est donc peu vraisemblable
d’avoir des probabilit´es de transmission ´elev´ees sur de nombreuses relations. Avec une
distribution exponentielle f (pi,j) = λe−λpi,j , le probl`eme se simpliﬁe facilement en :

L(P;D) − λ



pi,j

(cid:88)

pi,j∈P

P (cid:63) = arg max

P

Il s’agit donc d’une r´egularisation (cid:96)1 des probabilit´es apprises.

En reprenant la m´ethode d´ecrite dans la section pr´ec´edente, nous obtenons `a chaque
´etape de maximisation de l’algorithme EM l’´equation polynomiale suivante pour chaque
param`etre pi,j, que nous devons r´esoudre pour maximiser Q(P| ˆP) :

avec :

i,j − βpi,j + γ = 0

λp2

β = |D?

(cid:88)
i,j| + |D−
i,j| + λ
ˆpi,j
ˆP D
j

D∈D?

i,j

γ =

(3.11)

(3.12)

(3.13)

La d´emonstration de ce r´esultat est donn´ee en annexe C.

78

Chapitre 3. Relaxation et r´egularisation du mod`ele IC

Ce polynˆome permet de d´eduire la nouvelle formule de mise `a jour des param`etres pour
l’algorithme EM :

∆

(3.14)

pi,j ← β − √

2λ

La d´emonstration de de la validit´e de cette formule de mise `a jour est donn´ee en annexe
D.

L’utilisation d’un a priori de loi exponentielle pour les probabilit´es de transmission permet
d’´eviter que les relations peu observ´ees convergent vers des probabilit´es trop ´elev´ees, ce
qui limite le probl`eme du biais : les utilisateurs rares p`esent en eﬀet moins sur l’appren-
tissage du mod`ele. N´eanmoins nous avons observ´e dans nos exp´eriences pr´eliminaires que
les probabilit´es apprises ´etaient ﬁnalement trop faibles et conduisaient `a des ´episodes de
diﬀusion pr´edits trop courts. Nous proposons donc comme heuristique, apr`es l’apprentis-
sage de la version r´egularis´ee, d’eﬀectuer une it´eration de l’algorithme EM normal, aﬁn
d’obtenir des probabilit´es de transmission plus ´elev´ees tout en ´evitant les probl`emes du
biais d’apprentissage.

3.4 Exp´eriences

Dans cette section, nous ´evaluons notre mod`ele, DAIC, en le comparant `a diverses ap-
proches issues de l’´etat de l’art.

3.4.1 Mod`eles de R´ef´erence

Nous comparons notre approche DAIC `a un mod`ele IC appris selon la pr´ec´edure classique
d´ecrite dans [Saito et al., 2008], ainsi qu’aux mod`eles NetRate [Gomez-Rodriguez et al.,
2011] et CTIC [Saito et al., 2009] d´ecrits plus haut.

De plus, comme nous l’avons expliqu´e au d´ebut du chapitre, nous nous pla¸cons dans ce
manuscrit dans le contexte d’un r´eseau social dont le graphe est inconnu ou inexistant.
Toutefois, les mod`eles consid´er´es ici (y compris DAIC) restent valides lorsqu’ils sont ap-
pliqu´es au graphe complet, reliant tous les utilisateurs entre eux. C’est ce que nous faisons
dans ce chapitre et dans tout ce manuscrit. Cela rend l’apprentissage plus long, mais il est
i,j| > 0, les
possible de l’acc´el´erer on consid´erant uniquement les liens (ui, uj) telles que |D?
autres ayant n´ecessairement une probabilit´e de transmission de 0 `a l’issue de l’apprentis-
sage [Gomez-Rodriguez et al., 2011]. Cette propri´et´e est prise en compte dans l’algorithme
1 en lignes 3 et 9.

3.4. Exp´eriences

79

3.4.2 Exp´eriences sur des donn´ees synth´etiques

Pour analyser les performances des diﬀ´erentes approches, nous commen¸cons par eﬀectuer
des exp´eriences sur des jeux de donn´ees artiﬁciels.

3.4.2.1 G´en´eration des corpus synth´etiques

Notre but dans ces exp´eriences est de comprendre comment les diﬀ´erents mod`eles se
comportent par rapport `a la variabilit´e des d´elais entre deux infections successives.

Nous commen¸cons donc par g´en´erer des ´episodes de diﬀusion artiﬁciels sur un r´eseau inva-
riant d’´echelle de 100 utilisateurs, construit avec le mod`ele de Barab´asi-Albert [Albert and
Barab´asi, 2002]. Les probabilit´es de transmission sont g´en´er´ees au hasard, uniform´ement
sur l’intervalle [0, 1]. Ce graphe est utilis´e pour g´en´erer des ´episodes de diﬀusion mais n’est
pas utilis´e pendant l’apprentissage, pour respecter le contexte exp´erimental ﬁx´e. Nous g´e-
n´erons des ´episodes de diﬀusion sur ce graphe en tirant un ensemble de sources (de 1 `a
3 utilisateurs) avant d’eﬀectuer une simulation de diﬀusion en utilisant une variante du
mod`ele IC : lorsqu’un utilisateur infect´e au temps t contamine un de ses voisins, ce voisin
devient infect´e apr`es un d´elai δD
i,j, qui est tir´e pour chaque paire d’utilisateur et chaque
´episode de diﬀusion :

Les d´elais γi,j et ξD

i,j sont tir´es selon des lois exponentielles de moyennes µ et σ :

δD
i,j = 1 + γi,j + ξD
i,j

− x
µ

γi,j ∼ 1
µ

e

− x
σ

e

i,j ∼ 1
ξD
σ

(3.15)

(3.16)

La valeur µ nous permet donc de contrˆoler la variance des d´elais de transmission entre
les diﬀ´erentes paires d’utilisateurs, alors que la valeur σ nous permet de contrˆoler celle
de ces d´elais d’un ´episode de diﬀusion `a l’autre. Si, durant la g´en´eration des donn´ees,
un d´elai de transmission trop long est tir´e (i.e. conduisant `a une contamination apr`es un
horizon temporel ﬁx´e `a 1000), la contamination correspondante est ignor´ee et n’est pas
inclue dans l’´episode de diﬀusion g´en´er´e.

Notons que nous avons ´egalement envisag´e d’autres m´ethodes de construction du r´eseau
social (comme utiliser un r´eseau r´eel) et de g´en´eration des ´episodes de diﬀusion. Toutefois,
nous n’avons pas observ´e de r´esultats signiﬁcativement diﬀ´erents, car la principale diﬀ´e-
rence entre les diﬀ´erents mod`eles ´etudi´es est leur gestion de la dimension temporelle.

´Evaluation

3.4.2.2
Nous comparons les probabilit´es de transmission P (cid:63) apprises par les diﬀ´erents algorithmes
`a celles utilis´ees pour g´en´erer les donn´ees, not´ees P t = (pt
i,j)(ui,uj ). Nous utilisons pour cela

80

Chapitre 3. Relaxation et r´egularisation du mod`ele IC

Figure 3.4 – MSE des probabilit´es de diﬀusion apprises P par rapport `a P (cid:63), pour diﬀ´e-
rentes valeurs de µ et σ.

une mesure MSE (Mean Squared Error ) calcul´ee sur l’ensemble des probabilit´es :

(cid:88)

M SE =

1

N × (N − 1)

3.4.2.3 R´esultats

i,j − p(cid:63)
(pt

i,j)2

(ui,uj )∈U 2,ui(cid:54)=uj

La ﬁgure 3.4 pr´esente les scores de MSE obtenues par les mod`eles IC, NetRate, CTIC
et DAIC sur les corpus artiﬁciels. Dans la ﬁgure de gauche, nous ´etudions l’impact de
la variance des d´elais de diﬀusion entre les paires (param`etre µ) pour une valeur de σ
ﬁx´ee `a 10−5. Une faible valeur de σ indique que les d´elais de diﬀusion sont stables d’un
´episode de diﬀusion `a l’autre. `A l’inverse, sur la ﬁgure de droite, nous ´evaluons l’impact
de la variance des d´elais de diﬀusion entre ´episodes (param`etre σ) pour une valeur de µ
ﬁx´ee `a 10−5. Pour chaque conﬁguration, les r´esultats sont moyenn´es sur 10 corpus de 1000
cascades.

Lorsque µ et σ tendent vers 0 (coin inf´erieur gauche de chaque ﬁgure), les d´elais de
transmission tendent vers 1, c’est `a dire qu’un utilisateur infect´e contamine ses voisins au
pas de temps suivant, ce qui correspond au cadre du mod`ele IC classique. Et eﬀectivement,
dans ce cas, nous pouvons voir que le mod`ele IC obtient de meilleures performances, car
son algorithme d’apprentissage est justement restreint aux d´elais de diﬀusion de 1. Notre
mod`ele, DAIC, consid`ere qu’un utilisateur infect´e peut avoir ´et´e contamin´e par n’importe
quel utilisateur infect´e avant lui, ce qui ne correspond pas `a cette conﬁguration. Les
mod`eles NetRate et CTIC sont plus souples que le mod`ele IC, mais consid`erent tout de
mˆeme que les d´elais de transmission plus courts sont plus vraisemblables, et obtiennent
donc dans ce contexte une MSE meilleure que celle de DAIC.

llllllllll0.0e+005.0e−041.0e−031.5e−03mMSE012351050100200300lICNetRateCTICDAICllllllllll0.0e+005.0e−041.0e−031.5e−03sMSE012351050100200300lICNetRateCTICDAIC3.4. Exp´eriences

81

En revanche, tout change lorsque la valeur de µ ou de σ augmente. La MSE du mod`ele
IC monte tr`es rapidement, car les d´elais de diﬀusion deviennent plus longs alors qu’IC
est incapable de prendre en compte l’inﬂuence d’un utilisateur sur un autre pour un d´elai
sup´erieur `a 1. Les mod`eles NetRate, CTIC et DAIC ne sont pas touch´es par ce probl`emes
et conservent une meilleure MSE.

Sur les courbes de gauche, nous pouvons voir que CTIC se comporte mieux que NetRate
par rapport aux variations des d´elais entre les diﬀ´erents liens. CTIC consid`ere en eﬀet
les d´elais et les probabilit´es de transmission de fa¸cons ind´ependantes, ce qui lui permet
d’inf´erer de bonnes probabilit´es de transmission mˆeme pour des paires d’utilisateurs ayant
de longs d´elais de transmission, contrairement `a NetRate. Nous pouvons ´egalement voir,
sur les courbes de droite, que CTIC est plus robuste que NetRate aux variations des d´elais
entres les ´episodes de diﬀusion.

Sur les deux ensembles de courbes, nous pouvons voir qu’`a mesure que µ et σ augmentent,
notre mod`ele DAIC obtient de meilleurs r´esultats que les mod`eles de r´ef´erence. Il est plus
robuste aux variations des d´elais puisqu’il ne les prend pas du tout en compte durant son
apprentissage.

L’augmentation de la MSE pour les valeurs de µ et σ sup´erieures `a 100 peut ˆetre en partie
expliqu´ee par le fait qu’`a partir de ces valeurs, les ´episodes de diﬀusion deviennent plus
courts car certaines infections sont g´en´er´ees au del`a de l’horizon temporel, et donc ignor´ees.
Cela masque certaines contaminations et r´eduit la quantit´e de donn´ees disponibles pour
l’apprentissage. Une autre explication possible est qu’avec des d´elais ´elev´es, les d´elais δD
i,j
peuvent devenir suﬃsamment longs pour qu’un utilisateurs infect´e tard puisse avoir ´et´e
contamin´e par n’importe quel utilisateur pr´ec´edent. Cela rend l’apprentissage plus diﬃcile,
mais correspond bien `a l’hypoth`ese sur laquelle est bas´ee notre mod`ele DAIC, qui obtient
donc une meilleure MSE.

3.4.3 Exp´eriences sur des donn´ees r´eelles

3.4.3.1 Tˆache de pr´ediction de diﬀusion

Les mod`eles consid´er´es dans cette section apprennent des probabilit´es de transmission
et/ou des d´elais de transmission entre les utilisateurs d’un r´eseau social. En pratique,
nous ne connaissons malheureusement pas les « vraies » valeurs de ces param`etres. Il nous
est donc impossible d’´evaluer ces mod`eles en comparant les valeurs apprises `a celles d’une
« v´erit´e-terrain ».

Nous ´evaluons donc ces mod`eles sur une tˆache de pr´ediction similaire `a celles d´ecrites dans
le chapitre 2, section 2.5 : notre but est de retrouver l’ensemble des utilisateurs infect´es
dans un ´episode de diﬀusion de test `a partir des utilisateurs initiaux. Pour cela, les mod`eles
appris sont utilis´es en simulation pour pr´edire un ensemble d’utilisateurs ﬁnaux.

82

Chapitre 3. Relaxation et r´egularisation du mod`ele IC

Figure 3.5 – Score F 1 des diﬀ´erents mod`eles en pr´ediction de diﬀusion sur les donn´ees
artiﬁcielles, pour diﬀ´erentes valeurs de µ et σ.

`A chaque simulation, les r´esultats obtenus sont ´evalu´es avec une mesure de pr´ecision
et une mesure de rappel. La pr´ecision est le taux d’utilisateurs pr´edits comme infect´es
faisant eﬀectivement partie de U D∞. Le rappel est le taux d’utilisateur de U D∞ infect´es
dans la simulation. Puis, chaque mod`ele est ´evalu´e `a chaque simulation avec une mesure
F 1 :

F 1 =

2 × Precision × Rappel
Precision + Rappel

Cette mesure est moyenn´ee sur l’ensemble des simulations et l’ensemble des ´episodes de
diﬀusion de test.

Remarquons que dans le mod`ele NetRate, chaque utilisateur infect´e ﬁnit forc´ement par
contaminer l’ensemble de ses voisins, `a mesure que le temps ´ecoul´e tend vers l’inﬁni. La
simulation de diﬀusion selon ce mod`ele est donc eﬀectu´ee en posant un horizon temporel
Tmax. Tout utilisateur infect´e apr`es cet horizon est consid´er´e comme non infect´e. Cet hori-
zon temporel est ´egal `a celui observ´e dans les ´episodes de diﬀusion d’apprentissage.

La ﬁgure 3.5 pr´esentent les scores F 1 obtenus par les diﬀ´erents mod`eles en pr´ediction de
diﬀusion, pour plusieurs valeurs de µ et σ de la mˆeme fa¸con que dans la ﬁgure pr´ec´edente.
Les mod`eles sont appris sur des jeux de donn´ees de 1000 ´episodes de diﬀusion, et test´e
sur des ensembles de test de la mˆeme taille. Nous pouvons constater que les diﬀ´erentes
observations faites sur la ﬁgure 3.4 sont ´egalement applicables `a la ﬁgure 3.5. Cela conﬁrme
l’id´ee selon laquelle l’´evaluation des mod`eles en pr´ediction de diﬀusion permet de rendre
compte de la qualit´e des probabilit´es de transmission apprises.

llllllllll0.000.050.100.15mF1012351050100200300lICNetRateCTICDAICllllllllll0.000.050.100.15sF1012351050100200300lICNetRateCTICDAIC3.4. Exp´eriences

3.4.3.2 Corpus r´eels

83

Nous utilisons dans nos exp´eriences cinq jeux de donn´ees issus de divers sites internet.
Nous extrayons de chaque corpus des ´episodes de diﬀusion, avec une m´ethode d´ependant
du fonctionnement du site utilis´e.

Digg : Digg est un portail d’information en ligne 6. Les utilisateurs de ce site peuvent
y partager des articles o`u des vid´eos issus de diverses sources, et attribuer des
« digg » aux contenus qu’ils ont appr´eci´es. Les diﬀ´erents contenus partag´es appa-
raissent ensuite sur la page d’accueil ou sur d’autres pages de Digg, suivant leur
popularit´e. Nous avons utilis´e l’API de Digg pour r´ecup´erer l’historique complet du
site sur une p´eriode d’un mois. Nous en avons extrait des ´episodes de diﬀusion en
consid´erant que chaque contenu partag´e sur Digg correspondait `a une information,
et que chaque « digg » constituait une infection d’un utilisateur.

ICWSM : En 2009, `a l’occasion de la conf´erence ICWSM (International AAAI Confe-
rence on Weblogs and Social Media), un corpus de 44 millions de posts de blogs
avait ´et´e publi´e. Nous en extrayons des ´episodes de diﬀusion en consid´erant des
ensembles de posts se citant les uns les autres par le biais d’hyperliens. Les auteurs
de chaque groupe de posts ainsi reli´es sont consid´er´es comme infect´es par une mˆeme
information.

Enron : Ce corpus est compos´e d’emails ´echang´es par environ 150 personnes, prin-
cipalement des managers d’Enron American Corporation. Nous consid´erons dans
ce corpus que chaque adresse email correspond `a un utilisateur. Nous formons des
´episodes de diﬀusion en suivant la m´ethode d´ecrite dans [Klimt and Yang, 2004],
en consid´erant des s´equences de messages formant des conversations. Ces conver-
sations sont extraites en s´electionnant des messages contenant au moins deux mots
en communs et dont l’exp´editeur est le r´ecepteur d’un message pr´ec´edent dans la
s´equence.

Twitter : Ce corpus a ´et´e construit en utilisant l’API de Twitter. Nous avons com-
menc´e par r´ecup´erer une liste de 5000 utilisateurs ayant utilis´e les hashtag #obama,
#romney ou #us2012, durant la campagne pr´esidentielle am´ericaine de 2012. Puis,
nous avons captur´e l’int´egralit´e de leurs messages sur une p´eriode de deux semaines.
Des ´episodes de diﬀusion ont ensuite ´et´e extraits en formant des s´equences de tweets
contenant un mˆeme hashtag. Les hashtags utilis´es moins de cinq fois ont ´et´e ignor´es.

Memetracker : Le corpus memetracker a ´et´e d´ecrit dans [Leskovec et al., 2009]. Les
´episodes repr´esentent la diﬀusion de petites citations sur un large ensemble de sites
d’information et de blogs durant la campagne pr´esidentielle am´ericaine de 2008.

Chaque corpus a ´et´e ﬁltr´e pour garder une sous-population d’utilisateurs les plus actifs.
La table 3.1 donne quelques statistiques sur les corpus utilis´es : nombre d’utilisateurs,
nombres d’´episodes de diﬀusion et taille moyenne de ces ´episodes.

6. www.digg.com

84

Chapitre 3. Relaxation et r´egularisation du mod`ele IC

|D| (cid:80)

D∈D

20172
20027
1867
4815
6724

|U|

4587
2270
1557
4165
30907

Digg

ICWSM
Enron
Twitter

Memetracker

|U D∞|
|D|
8.26
2.21
3.30
22.54
20.21

Table 3.1 – Statistiques sur les corpus utilis´es.

Les ´episodes de diﬀusion extraits de chaque corpus sont repartis en un ensemble d’appren-
tissage, un ensemble de validation et un ensemble de test au moyen d’un tirage al´eatoire sur
l’ensemble des ´episodes. La mˆeme proc´edure sera utilis´ee dans les chapitres suivants.

3.4.3.3 R´esultats

IC
N etRate
CT IC
DAIC0
DAIC5
DAIC10

Digg
0.036
0.102
0.119
0.127
0.128
0.127

ICWSM Enron Twitter Memetracker

0.097
0.358
0.482
0.665
0.665
0.665

0.033
0.105
0.132
0.162
0.164
0.164

0.013
0.027
0.032
0.026
0.035
0.044

0.012
0.048
0.061
0.073
0.087
0.082

Table 3.2 – Mesure F1 obtenues par les mod`eles sur les corpus r´eels. Les scores en gras
sont signiﬁcativement meilleurs que ceux de CTIC (selon un test de Student `a 99%).

La table 3.2 indique les r´esultats obtenus par les mod`eles. Chaque r´esultat indique le score
F 1 moyen obtenu sur 1000 ´episodes de diﬀusion de test. Nous utilisons la notation DAICλ
pour d´esigner notre mod`ele, λ ´etant le param`etre de la loi exponentielle utilis´ee comme a
priori dans l’´equation 3.10.

Pour apprendre le mod`ele IC de fa¸con classique, nous devons d´eﬁnir un pas de temps,
ce qui est d´elicat avec des ´episode de diﬀusion r´eels (cf. chapitre 3). Apr`es quelques ex-
p´eriences pr´eliminaires, nous avons d´ecid´e d’utiliser comme pas de temps le d´elai moyen
entre deux infections successives dans les ´episodes de diﬀusion de l’ensemble d’apprentis-
sage. Cette heuristique nous permet d’obtenir un nombre raisonnable d’exemples positifs
pour chaque paire d’utilisateurs. Toutefois, les r´esultats obtenus par IC, pr´esent´es dans la
table 3.2, montrent que ce mod`ele ne parvient pas `a apprendre des probabilit´es de trans-
mission pertinentes et obtient un score F 1 bien inf´erieur `a celui des autres approches.
Ce score s’approche mˆeme de 0 sur Twitter et Memetracker, ce qui indique que les d´e-
lais de transmission sur ces corpus sont trop variables pour trouver un pas de temps
acceptable.

3.5. Conclusion

85

`A l’exception du corpus Twitter, notre approche DAIC obtient des r´esultats signiﬁcati-
vement meilleurs que les autres. Cela conﬁrme notre id´ee selon laquelle l’infection d’un
utilisateur peut ˆetre expliqu´ee par n’importe quel autre utilisateur infect´e, et que les d´elais
de transmission suivent une loi proche de la loi uniforme.

Le mod`ele CTIC, en faisant l’hypoth`ese que les d´elais plus courts sont plus vraisemblables,
concentre son apprentissage sur certains liens et perd en capacit´e de pr´ediction. De plus,
les utilisateurs apparaissant rarement dans D ont un impact n´egatif sur la pertinence des
probabilit´es apprises.

Bien que notre approche ne puisse pas pr´edire les temps d’infection comme NetRate et
CTIC, elle nous permet de mieux identiﬁer les principaux liens emprunt´es par l’informa-
tion. En consid´erant uniquement l’ordre dans lequel les utilisateurs ont ´et´e infect´es, sans
chercher `a mod´eliser les temps d’infection, notre approche se concentre sur la pr´ediction
de l’information de qui infecte qui, sans favoriser une source plutˆot qu’une autre sur la
base de son temps d’infection.

Sur le corpus Twitter, la possibilit´e pour un utilisateur infect´e d’avoir ´et´e contamin´e par
n’importe quelle autre semble mener au probl`eme de biais d’apprentissage d´ecrit en section
3.3.1. En eﬀet, sur ce corpus, beaucoup d’´episodes de diﬀusion contiennent des utilisateurs
rares, ce qui conduit `a une faible capacit´e de g´en´eralisation. Utiliser un a priori, comme
propos´e dans la formule 3.10, nous permet toutefois d’am´eliorer grandement les r´esultats
de DAIC sur ce corpus. Plus g´en´eralement, sur les corpus contenant des ´episodes de
diﬀusion assez longs (Twitter et Memetracker), l’impact des utilisateurs rares est plus
´elev´e, et c’est sur ces corpus que l’utilisation de la r´egularisation permet d’am´eliorer nos
r´esultats.

Notons enﬁn que la valeur optimale de λ d´epend du corpus consid´er´e : 10 sur Twitter
au lieu de 5 sur Memetracker. En pratique, cette valeur peut ˆetre ﬁx´ee au moyen d’un
processus de validation crois´ee.

3.5 Conclusion

L’apprentissage de mod`eles explicatifs de diﬀusion est une tˆache diﬃcile, en particulier
avec des donn´ees issues de r´eseaux sociaux en ligne, particuli`erement bruit´ees, parcimo-
nieuses et partielles. Nous avons vu dans le chapitre 2 divers mod`eles explicatifs pour la
diﬀusion d’information reposant sur diﬀ´erentes hypoth`eses. Malheureusement, des hypo-
th`eses trop fortes ou une mod´elisation trop ﬁne peuvent se heurter `a la qualit´e des donn´ees
d’apprentissage disponibles. En particulier, nous avons pr´esent´e au d´ebut de ce chapitre
les probl`emes li´es `a la prise en compte du temps.

Dans ce chapitre, nous avons pr´esent´e deux contributions :

86

Chapitre 3. Relaxation et r´egularisation du mod`ele IC

— nous avons propos´e une version relax´ee de l’algorithme d’apprentissage du mod`ele

IC, qui consid`ere l’ordre des infections plutˆot que les temps exacts ;

— nous avons ´egalement d´ecrit une m´ethode de r´egularisation permettant d’obtenir
un mod`ele plus robuste, qui s’est r´ev´el´ee utile sur les jeux de donn´ees les plus
grands et les plus bruit´es.

Les r´esultats obtenus sur des donn´ees artiﬁcielles et r´eelles ont montr´e la pertinence de
cette approche, et ont conﬁrm´e notre id´ee selon laquelle la mod´elisation des d´elais de
transmission complexiﬁait l’apprentissage des probabilit´es. Ces d´elais de transmission, en
plus d’ˆetre tr`es variables, ne sont pas toujours importants dans certaines applications.
Ne pas les mod´eliser ne sera donc g´en´eralement pas consid´er´e comme une limite d’un
mod`ele.

Deuxi`eme partie

Apprentissage de repr´esentations

pour la diﬀusion

87

89

Dans cette partie, nous proposons d’appliquer des m´ethodes d’apprentissage de repr´esen-
tations `a la mod´elisation et `a la pr´ediction de diﬀusion d’information.

Nous commen¸cons par d´ecrire la m´ethodes d’apprentissage de repr´esentations et par pr´e-
senter quelques travaux l’utilisant pour diverses tˆaches. Nous appliquons ensuite l’appren-
tissage de repr´esentations `a trois probl`emes diﬀ´erents :

— l’apprentissage des probabilit´es de transmission du mod`eles IC ;
— la d´eﬁnition d’un mod`ele discriminant mod´elisant la diﬀusion d’information comme

de la diﬀusion de chaleur ;

— le probl`eme de la d´etection de source.

L’utilisation de l’apprentissage de repr´esentations nous permet notamment de d´eﬁnir des
mod`eles plus compacts et rapides.

90

Chapitre 4

Applications de l’apprentissage de

repr´esentations

R´esum´e Nous pr´esentons dans ce chapitre quelques travaux utilisant l’apprentissage
de repr´esentations dans des contextes applicatifs vari´es. Ce rapide tour d’horizon nous
permet de constater la diversit´e des applications possibles de ce type d’approche, ainsi
que d’en d´egager les principes g´en´eraux.

4.1 Introduction

L’apprentissage de repr´esentations (Representation Learning ou RL) s’est largement d´e-
velopp´e au cours des derni`eres ann´ees, et a permis d’obtenir des r´esultats prometteurs sur
diverses tˆaches mettant en jeu des d´ependances relationnelles complexes [Bengio et al.,
2013]. Le principe g´en´eral des approches reposant sur l’apprentissage de repr´esentations
est le suivant :

Projeter des ´el´ements quelconques dans un espace de repr´esentation (g´en´era-
lement Rd) de fa¸con `a ce que les distances ou les similarit´es entre ces ´el´ements
dans l’espace mod´elisent une ou plusieurs relations existant entre eux en de-
hors de cet espace.

Les projections des ´el´ements dans Rd sont nomm´ees « repr´esentations distribu´ees ». Ce
type d’approche pr´esente plusieurs avantages :

— d´eﬁnir une repr´esentation compacte des donn´ees, ce qui peut ˆetre important pour

certaines applications o`u l’utilisation des donn´ees brutes serait trop coˆuteuse ;

— r´egulariser les relations entre les ´el´ements, des ´el´ements similaires ou similaires
aux mˆeme autres ´el´ements ´etant projet´es `a des emplacements proches, ce qui peut
permettre de d´ecouvrir certaines relations implicites.

Dans ce chapitre, nous pr´esentons quelques applications de cette approche aﬁn d’en d´ega-
ger les grandes lignes. Nous pr´esentons d’abords plusieurs articles ´etudiant la projection de

91

92

Chapitre 4. Applications de l’apprentissage de repr´esentations

structures relationnelles simples ou complexes, puis nous nous int´eressons `a la pr´ediction
de s´equences.

4.2 Projection de structures relationnelles simples

4.2.1 Positionnement multidimensionnel

Historiquement, l’une des plus anciennes applications de l’apprentissage de repr´esenta-
tions est celle du positionnement multidimensionnel (Multidimensional Scaling ou MDS )
[Kruskal, 1964]. ´Etant donn´ee une matrice M ∈ RN×N d´ecrivant les dissimilarit´es ou les
distances entre N ´el´ements, le but du MDS est de construire N repr´esentations des ´el´e-
ments dans un espace multidimensionnel de fa¸con `a ce que les dissimilarit´es ou distances
indiqu´ees dans M soient le mieux respect´ees possible dans l’espace de repr´esentation. Cela
se fait en minimisant une fonction de coˆut nomm´ee stress :

StressM (z0, z1, z2....) =

(M i,j − ||zi − zj||)2

(cid:115) (cid:88)

i(cid:54)=j=0,...,N−1

Ici, zi d´esigne la projection du n-i`eme item. Cette mesure favorise donc les projections
z telles que les distances entre les utilisateurs soient proches (au sens de la norme eucli-
dienne) des distances indiqu´ees dans M .

L’algorithme propos´e pour minimiser le stress est une proc´edure it´erative consistant `a
initialiser les zi au hasard puis `a les d´eplacer, `a chaque it´eration, dans la direction du
gradient du stress.

L’approche est valid´ee sur divers ensembles de donn´ees r´eelles ou synth´etiques. Les r´esul-
tats sont ´evalu´es en observant la valeur ﬁnale de stress atteinte, ou en visualisant sur une
courbes les couples de valeurs (M i,j,||zi − zj||2) pour tous les (i, j). Les auteurs eﬀectuent
´egalement des exp´eriences en « reconstruction ». Ils g´en`erent al´eatoirement des valeurs de
zi, puis calculent `a partir de celles-ci une matrice M , avec M i,j = ||zi − zj||. Ils appliquent
ensuite l’algorithme d’apprentissage `a cette matrice M , et observent que leur m´ethode
parvient `a retrouver correctement les zi originaux.

4.2.2 Graphe orient´e

Le probl`eme de projection d’un graphe orient´e a ´et´e ´etudi´e dans [Chen et al., 2007]. Les
auteurs posent la fonction de coˆut suivante :

PageRank(ui)

(cid:88)

ui

(cid:88)

uj∈Succs(ui)



pi,j||zi − zj||2

(4.1)

4.3. Projection de structures relationnelles complexes

93

pi,j d´esigne ici le poids du lien reliant l’utilisateur ui `a l’utilisateur uj dans le graphe, et zi
est la projection de l’utilisateur ui dans l’espace de repr´esentation. Le PageRank (d´ecrit
en section 2.7.1) permet de calculer l’importance d’un utilisateur dans ce graphe. Cette
fonction de coˆut exprime donc le fait que deux utilisateurs reli´es dans le graphe devraient
ˆetre plus proches l’un de l’autre dans l’espace de repr´esentation, en particulier si ui est
un utilisateur « central » dans le graphe.

La m´ethode propos´ee pour optimiser cette fonction consiste `a extraire les vecteurs propres
d’une matrice calcul´ee `a partir de la matrice d’adjacence du graphe et du PageRank des
utilisateurs. Cette m´ethode est test´ee sur un graphe de pages web extraites des sites
internets de trois universit´es am´ericaines, reli´ees par des liens hypertextes. Les pages
d’un mˆeme site ont tendance `a ˆetre plus dens´ement reli´ees entre elles. Ce graphe est
projet´e dans un espace `a deux dimensions et les auteurs observent que les points sont
s´epar´es en trois groupes correspondant eﬀectivement aux trois universit´es. Ce r´esultat
empirique est ensuite conﬁrm´e en eﬀectuant des exp´eriences en classiﬁcation dans l’espace
de repr´esentation. Les performances en classiﬁcation ´etant bonnes, les auteurs concluent
que les proximit´es calcul´ees dans l’espace de repr´esentation sont pertinentes.

4.3 Projection de structures relationnelles complexes

L’apprentissage de repr´esentations a ´egalement ´et´e utilis´e pour projeter des ´el´ements reli´es
entre eux par des relations explicites plus complexes : multigraphes, graphes h´et´erog`enes,
r´eseaux urbains, etc... Ces projections peuvent permettre de capturer certaines relations
implicites ou de visualiser plus facilement un ensemble d’´el´ements li´es.

4.3.1 Filtrage collaboratif

Nous avons parl´e dans la sous-section 2.5.3 du ﬁltrage collaboratif. Celui-ci consid`ere une
matrice M contenant les notes donn´ees par des utilisateurs `a des produits. Cette matrice
peut ´egalement ˆetre vue comme la matrice d’adjacence d’un graphe biparti ,valu´e, reliant
des utilisateurs `a des produits. Pour pr´edire de nouvelles relations, la m´ethode de factori-
sation matricielle consistant `a factoriser M ≈ RU × RI est une forme d’apprentissage de
repr´esentations o`u les utilisateurs et les produits sont projet´es dans le mˆeme espace, de
fa¸con `a ce qu’un utilisateur soit similaire aux produits auxquels il a attribu´e une bonne
note.

Ces projections permettent ensuite de pr´edire la note qui serait attribu´ee par un utilisateur
`a un produit donn´e, et donc de trouver d’autres items susceptibles de l’int´eresser.

94

Chapitre 4. Applications de l’apprentissage de repr´esentations

4.3.2 Base de connaissances

L’article [Bordes et al., 2011] utilise l’apprentissage de repr´esentations pour projeter
des bases de connaissances complexes : WordNet (une grande collection de mots re-
li´es par de nombreuses relations s´emantiques) et Freebase (une vaste base structur´ee de
connaissances vari´ees). Ces bases prennent la forme d’ensembles de triplets du type (en-
tit´e1,relation,entit´e2). Par exemple, WordNet peut contenir le triplet (“voiture”,“instance de”,“v´ehicule”)
et Freebase un triplet comme (“Marylin Monroe”,“profession”,“actrice”).

Les auteurs proposent une m´ethode de descente de gradient stochastique permettant d’ap-
prendre non seulement une projection zi pour chaque entit´e i, mais aussi une paire de
matrices (Rr

2) pour chaque type de relation r, de fa¸con `a ce que la mesure :

1, Rr

Sr(zi, zj) = ||zi.Rr

1 − zj.Rr

2||1

(4.2)

soit plus ´elev´ee pour les paires d’entit´es (zi, zj) pour lesquelles le triplet (zi, r, zj) existe
dans la base consid´er´ee. Ainsi, chaque relation est associ´ee `a une certaine transformation
de l’espace de repr´esentation. Notons que le fait que d’utiliser deux matrices par relation
permet de d´eﬁnir des mesures Sr asym´etriques correspondant `a des relations orient´ees. Le
mod`ele est test´e en r´epartissant les triplets en un ensemble d’apprentissage et un ensemble
de test, et en observant la capacit´e du mod`ele appris `a retrouver le troisi`eme ´el´ement des
triplets de l’ensemble de test `a partir des deux autres.

Cette probl´ematique a donn´e lieu `a de nombreuses variantes de cette m´ethode, bas´ees sur
diﬀ´erentes repr´esentations des relations. Par exemple, [Bordes et al., 2013] propose une
autre fa¸con de d´eﬁnir Sr(zi, zj). Chaque relation r est cette fois-ci associ´ee `a une repr´e-
sentation ωr situ´ee dans le mˆeme espace de repr´esentation que les entit´es, et l’expression
de Sr devient :

Sr(zi, zj) = ||(zi + ωr) − zj||1

Chaque relation correspond donc `a une translation des repr´esentations des entit´es. Ce
principe a ensuite ´et´e utilis´e dans [Lin et al., 2015b] et [Wang et al., 2014]. R´ecemment,
[Lin et al., 2015a] a propos´e une m´ethode permettant de prendre le compte le fait que
certaines relations peuvent s’additionner pour en obtenir de nouvelles. Par exemple, la
relation indiquant dans quelle ville est n´ee une personnalit´e peut s’ajouter `a celle indiquant
dans quel pays se trouve une ville pour obtenir la relation indiquant dans quel pays est
n´ee une personnalit´e.

4.3.3 Graphe h´et´erog`ene

Le mˆeme genre de m´ethode a ´et´e utilis´ee dans [Jacob et al., 2014] pour le probl`eme de
l’´etiquetage de nœuds dans un graphe h´et´erog`ene. La tˆache d’´etiquetage de nœuds consiste
`a classiﬁer les nœuds d’un graphe sur la base d’un ensemble de nœuds d´ej`a ´etiquet´es. Un

4.3. Projection de structures relationnelles complexes

95

graphe h´et´erog`ene est un graphe contenant diﬀ´erentes types de nœuds, chaque type ´etant
associ´e `a un ensemble d’´etiquettes possibles. Dans des graphes homog`enes, ce probl`eme
est souvent r´esolu par des m´ethodes de « propagation d’´etiquettes », qui consistent `a poser
comme contrainte qu’un nœud devrait avoir la mˆeme ´etiquette que ses voisins, ce qui n’est
pas applicable directement dans un graphe h´et´erog`ene puisque les voisins d’un nœud n’ont
pas forc´ement le mˆeme type et donc pas forc´ement des ´etiquettes « valides » Les auteurs
proposent d’apprendre des repr´esentations des nœuds en posant qu’un nœud doit avoir
une repr´esentation proche de celles de ses voisins, ce qui est repr´esent´e par un coˆut de la
forme :

(4.3)

(cid:88)

wi,j||zi − zj||2

i,j

o`u wi,j est le poids du lien reliant le nœud i au nœud j, ou 0 si le lien n’existe pas. De plus,
chaque ´etiquette k est associ´ee `a un classiﬁeur fθk. Les param`etres θ de ces classiﬁeurs et
les projections z des nœuds sont appris en mˆeme temps, en minimisant la somme d’un
coˆut de classiﬁcation et du coˆut de projection indiqu´e plus haut. Le coˆut de classiﬁcation
empˆeche que tous les ´el´ements soient projet´es au mˆeme point.

Le mod`ele est test´e sur un corpus issu de DBLP, contenant des articles scientiﬁques et leurs
auteurs. Les auteurs sont ´etiquet´es avec leurs domaines de recherche, et les articles sont
´etiquet´es avec les conf´erences dans lesquelles ils sont parus. Un corpus Flickr, contenant
des images et des utilisateurs, est ´egalement utilis´e. Chaque utilisateur est reli´e `a ses photos
et `a ses amis (les relations sont donc elles-mˆemes h´et´erog`enes). Les photos sont ´etiquet´ees
par des tag renseign´es sur le site et les utilisateurs sont ´etiquet´ees par les groupes auxquels
ils appartiennent. Le mod`ele appliqu´e `a ces deux corpus obtient de meilleurs r´esultats (en
classiﬁcation) que les m´ethodes consistant `a transformer le graphe h´et´erog`ene en plusieurs
graphes homog`enes (un par type de nœud) aﬁn d’appliquer une propagation d’´etiquettes
classique sur chacun de ces graphes.

4.3.4 Images annot´ees

Enﬁn, l’apprentissage de repr´esentations a aussi ´et´e appliqu´e `a l’annotation d’images [Wes-
ton et al., 2011]. Les images sont d´ecrites sous la forme de grands vecteurs de caract´e-
ristiques visuelles extraites des images. Les auteurs apprennent en mˆeme temps les para-
m`etres θ d’un projecteur lin´eaire fθ de ces images dans un espace de repr´esentation de
faible dimension, ainsi qu’une repr´esentation zi dans ce mˆeme espace pour chaque an-
notation (ou tag) i possible. En pr´ediction, le score d’un tag i pour une image donn´ee
s’´ecrit :

si(img) = fθ(img).zi

(4.4)

Ces param`etres sont appris en minimisant un coˆut d’ordonnancement, avec un algorithme
stochastique.

96

Chapitre 4. Applications de l’apprentissage de repr´esentations

Le mod`ele propos´e est test´e sur deux corpus d’images annot´ees issus du net, dont Image-
Net, en ´etant compar´e `a des classiﬁeurs multi-´etiquettes classiques (un plus proche voisin
et un s´eparateur `a vaste marge). Leur m´ethode obtient de meilleurs r´esultats que les
classiﬁeurs classiques.

Ce mod`ele a ensuite ´et´e ´etendu dans [Gong et al., 2014], o`u les auteurs consid`erent le cas
o`u en plus des images et des tags, ils disposent ´egalement d’un a priori sur la s´emantique
de ces images et de ces tags. Ils proposent de projeter cette nouvelle information dans
le mˆeme espace latent avec une fonction d’apprentissage similaire `a [Weston et al., 2011]
pour am´eliorer les capacit´es de g´en´eralisation du mod`ele.

Plus g´en´eralement, la probl´ematique d’annotation d’images a donn´e lieu `a une tr`es abon-
dante litt´erature ces deux derni`eres ann´ees, reposant souvent sur l’apprentissage de re-
pr´esentation : annotation par des mots-clefs, annotation par des phrases, g´en´eration de
description `a partir d’une image, etc.

4.4 Mod´elisation de s´equences

L’apprentissage de repr´esentations a ´egalement ´et´e appliqu´e `a des donn´ees s´equentielles,
c’est `a dire `a des ensembles d’´el´ements ordonn´ees dans le temps. Dans ce contexte, l’ap-
prentissage de repr´esentations ne vise plus seulement `a mod´eliser des relations statiques
entres les ´el´ements d’un ensemble, mais aussi des relations temporelles.

4.4.1 Mod`eles de langage

Un mod`ele de langage est un mod`ele d´eﬁnissant la probabilit´e d’observer une phrase
quelconque dans un langage donn´e. Le mod`ele de langage le plus courant est celui dit
des « N-grammes » consistant `a d´eﬁnir la probabilit´e d’une phrase S = (m0, m1, m2...)
comme la probabilit´e jointe de chaque mot de cette phrase conditionnellement aux N
mots pr´ec´edents :

(cid:89)

mi∈S

P (S) =

p(mi|mi−1, mi−2, . . . , mi−N +1)

L’ensemble des mots possibles est not´e M . La distribution conditionnelle p est apprise
statistiquement sur des corpus de plusieurs millions de phrases. Bien que cette m´ethode
donne de bons r´esultats, sa complexit´e pose probl`eme, le mod`ele devenant rapidement
trop complexe `a mesure que N augmente. De plus, la quantit´e de donn´ees n´ecessaires `a
l’apprentissage devient vite bien trop importante. En eﬀet, le nombre de groupes de mots
possibles est ´egal `a |M|N , et augmente donc de fa¸con exponentielle avec N .

L’application de l’apprentissage de repr´esentations aux mod`eles de langage consiste `a
d´eﬁnir la probabilit´e conditionnelle p(mi|mi−1, mi−2, . . . , mi−N +1) comme une fonction

4.4. Mod´elisation de s´equences

97

des repr´esentations des mots concern´es. Cela r´eduit grandement la complexit´e spatiale du
probl`eme, et permet d’utiliser une valeur de N plus grande. De plus, l’utilisation d’un
espace de repr´esentation am´eliore la capacit´e de g´en´eralisation du mod`ele. En eﬀet, les
mots similaires ont tendance `a ˆetre projet´es proches les uns des autres, et sont donc ensuite
pr´edits dans les mˆemes contextes. Ainsi, le mod`ele est capable d’associer une probabilit´e
non-nulle `a un mot mi ´etant donn´e un contexte mi−1, mi−2, . . . , mi−N +1 mˆeme si aucun
exemple d’apprentissage n’existe pour la suite de mots mi, mi−1, mi−2, . . . , mi−N +1

Par exemple, dans [Bengio et al., 2006], les auteurs posent :

p(mi|mi−1, mi−2, . . . , mi−N +1) = f (i, mi−1, mi−2, . . . , mi−N +1)

= gθ(i, zi−1, zi−2, . . . , zi−N +1)

o`u zi d´esigne la projection du mot mi et gθ est une fonction consistant `a :

— concat´ener les repr´esentations distribu´ees des mots zi−1, zi−2, . . . , zi−N +1 en un seul

grand vecteur d’entr´ee ;

— appliquer ce vecteur d’entr´ee `a un r´eseau de neurones classique `a une couche cach´ee
utilisant l’ensemble de poids θ, donnant sur sa couche de sortie une valeur par mot
du dictionnaire ;

— appliquer une fonction de type « softmax » sur les valeurs de sortie pour obtenir

une distribution de probabilit´es, et renvoyer celle du i-`eme mot.

Les repr´esentations des mots et les param`etres θ du r´eseau de neurones sont appris en
mˆeme temps, en maximisant la vraisemblance d’un grand corpus de textes (plus de 10
millions de mots) au moyen d’une mont´ee de gradient stochastique parall´elis´ee. L’approche
obtient des r´esultats bien meilleurs qu’un mod`ele N -grammes classique.

Word2Vec Cette id´ee fut ensuite reprise dans les mod`eles Word2Vec [Mikolov et al.,
2013a]. Le mˆeme principe g´en´eral y est utilis´e dans des contextes diﬀ´erents.

— D’une part, les auteurs proposent de pr´edire un mot quelconque d’un texte `a partir
des N mots le pr´ec´edant et des N mots le suivant. Pour cela, les repr´esentations de
ces 2N mots sont moyenn´ees, et la « repr´esentation moyenne » obtenue est utilis´ee
pour pr´edire le mot courant `a partir d’un classiﬁeur log-lin´eaire. Ce mod`ele est
nomm´ee Continuous bag-of-words model (CBOW)

— D’autre part, les auteurs s’int´eressent au probl`eme inverse : pr´edire les N mots
suivants et les N mots pr´ec´edents `a partir d’un mot quelconque d’un texte. Ce
mod`ele est baptis´e Skip-gram.

Les auteurs remarquent que certaines relations syntaxiques et s´emantiques se retrouvent
dans l’espace de repr´esentation appris. On observe par exemple que zFrance ≈ zGr`ece −
zAth`enes + zParis. La mˆeme principe fonctionne pour d’autres relations, comme par exemple
“fr`ere-sœur” et “p`ere-m`ere” ou “penser-pensant” et “lire-lisant”. Les auteurs s’´evaluent donc
en particulier sur un ensemble de test constitu´e de quadruplets de mots comme ceux d´ecrits

98

Chapitre 4. Applications de l’apprentissage de repr´esentations

ci-dessus, et obtiennent une pr´ecision de 61% avec CBOW et 56% avec skip-gram, contre
47% pour un mod`ele de langage neuronal classique.

Cette correspondance entre d’une part les relations s´emantiques ou syntaxiques existant
entre les mots et d’autre part les relations alg´ebriques existant entre leurs repr´esentations
constitue la principale force de l’apprentissage de repr´esentations.

Les mod`eles de langage ainsi appris peuvent ensuite servir `a des tˆaches comme la recon-
naissance de parole [Schwenk, 2007, Graves et al., 2013] ou la traduction automatique
[Cho et al., 2014].

4.4.2 Autres s´equences

Les mod`eles de langage d´ecrits dans la sous-section pr´ec´edente peuvent en pratique ˆetre
appliqu´es `a n’importe quelles donn´ees prenant la forme de s´equences de symboles. Plusieurs
travaux ont ainsi utilis´e des approches d’apprentissage de repr´esentations appliqu´ees `a
d’autres types de donn´ees s´equentielles.

4.4.2.1 Pr´ediction de Playlists

Par exemple, dans [Chen et al., 2012], les auteurs ´etudient le probl`eme de g´en´eration
de listes de lecture sur les sites de streaming de musique. Le but est de g´en´erer auto-
matiquement, `a partir d’un point de d´epart (une chanson particuli`ere), une s´equence de
pistes similaire aux listes de lecture cr´e´ees par les utilisateurs. L’id´ee g´en´erale est la mˆeme
que celle des mod`eles de langage, `a savoir que la probabilit´e d’une s´equence de musiques
S = (m0, m1, m2...) vaut :

(cid:89)

i>0

P (S) =

p(mi|mi−1)

Au lieu d’utiliser un r´eseau de neurones, la probabilit´e p est d´eﬁnie avec une fonction
softmax appliqu´ees aux distances entre les repr´esentations des musiques.

p(mi|mi−1) =

(cid:80)

exp(||zi − zi−1||2)
mj∈M exp(||zj − zi−1||2)

M d´esigne ici l’ensemble des musiques. Les repr´esentations de celles-ci sont apprises en
maximisant la vraisemblance d’un ensemble de listes de lecture d’apprentissage. Les au-
teurs proposent ´egalement plusieurs extensions permettant d’int´egrer certains donn´ees
comme la popularit´e ou le genre musical des musiques. Ils visualisent les projections ap-
prises sur un espace `a deux dimensions et observent notamment que les chansons d’un
mˆeme artiste ont tendance `a ˆetre regroup´ees, ce qui est un r´esultat non-trivial puisque
cette information n’est pas utilis´ee pendant l’apprentissage.

4.5. Conclusion

99

4.4.2.2 Recommandation s´equentielle

Les mod`eles de pr´ediction de s´equences d´ecrits dans cette section ont aussi ´et´e appliqu´es
`a la recommandation dans un contexte s´equentiel o`u l’utilisateur acc`ede `a des items les
uns apr`es les autres, la recommandation consistant `a pr´edire le prochain item visit´e. Un
exemple se trouve dans [Gu`ardia-Sebaoun et al., 2015] : dans cet article, le formalisme de
Word2Vec est utilis´e pour apprendre des repr´esentations distribu´ees des items `a partir des
s´equences d’items vus par les utilisateurs. Celles-ci sont ensuite utilis´ees pour apprendre
des repr´esentations des utilisateurs, indiquant comment ceux-ci se « d´eplacent » d’un item
`a l’autre au sein de l’espace de repr´esentation.

4.5 Conclusion

Dans ce chapitre, nous avons pr´esent´e de fa¸con succincte quelques travaux appliquant
des m´ethodes d’apprentissage de repr´esentations `a des tˆaches tr`es vari´ees. Cependant, et
malgr´e la diversit´e des tˆaches, nous pouvons d´egager plusieurs principes g´en´eraux.

— Le but est de projeter des donn´ees symboliques dans un espace de repr´esentation
continu Rd. Ces projections peuvent ˆetre apprises ad hoc ou ˆetre issues d’une trans-
formation depuis un autre espace. Les donn´ees projet´ees peuvent ˆetre homog`enes
ou h´et´erog`enes (i.e tous les ´el´ements peuvent ˆetre de mˆeme nature ou pas).

— Une ou plusieurs mesures d´eﬁnies sur Rd permettent de mod´eliser certaines re-
lations existant entre les ´el´ements projet´es. Ces mesures peuvent ˆetre d´eﬁnies a
priori (une distance ou une similarit´e) ou bien ˆetre elles-mˆemes apprises (mesures
param´etr´ees).

— L’apprentissage se fait g´en´eralement de fa¸con stochastique, sur la base d’un en-
semble d’exemples ´el´ementaires prenant la forme de tuples d’´el´ements reli´es par
une certaine relation. La fonction de coˆut est g´en´eralement une somme sur l’en-
semble de ces tuples (remarquons `a ce propos la similitude entre les equations 4.1,
4.2, 4.3 et 4.4). L’apprentissage stochastique permet en outre d’utiliser de grands
volumes de donn´ees.

— L’utilisation d’un espace de repr´esentation permet de compresser l’information
contenue dans ces exemples, et de pr´edire de nouvelles relations entres les ´el´ements.
Dans ce manuscrit, nous appliquons une approche similaire `a celles d´ecrites ici `a des
probl´ematiques li´ees `a la diﬀusion d’information dans les r´eseaux sociaux. En eﬀets, les
´episodes de diﬀusion constituent des donn´ees s´equentielles, et les r´eseaux sociaux en ligne
peuvent ˆetre vus comme des graphes h´et´erog`enes.

Projeter les utilisateurs dans un espace de repr´esentation permet de retrouver diverses
propri´et´es connues des r´eseaux sociaux : pr´esences de communaut´es, faible diam`etre, tran-
sitivit´e des relations, etc... En particulier, la transitivit´e des relations (« les amis de mes
amis sont mes amis ») est naturellement traduite par l’in´egalit´e triangulaire de la distance.

100

Chapitre 4. Applications de l’apprentissage de repr´esentations

L’apprentissage de repr´esentations nous permettra ´egalement de proposer des mod`eles plus
rapides et d’´etudier facilement des cas o`u le graphe du r´eseau social est inconnu.

Chapitre 5

Apprentissage de repr´esentations

pour le mod`ele IC

R´esum´e Ce chapitre d´ecrit notre seconde contribution, publi´ee dans [Bourigault et al.,
2016b]. Nous appliquons une m´ethode d’apprentissage de repr´esentations `a l’apprentis-
sage des probabilit´es de transmission du mod`ele IC : les utilisateurs sont projet´es dans un
espace Rd, et leurs repr´esentations sont utilis´ees pour d´eﬁnir les probabilit´es de transmis-
sions. Cette m´ethode nous permet d’obtenir des r´esultats l´eg`erement sup´erieurs `a ceux du
chapitre 3.

5.1 Limites de l’apprentissage explicite des probabi-

lit´es de transmission

Dans le chapitre 3, nous avons propos´e une m´ethode d’apprentissage des param`etres du
mod`ele IC, et nous nous sommes int´eress´es au cas o`u le graphe du r´eseau social ´etait
inconnu. Pour utiliser un mod`ele IC dans ce contexte, il est possible de r´ealiser une
inf´erence de graphe (d´ecrite dans la section 2.4.7 dans le chapitre 2) ou de consid´erer le
graphe complet, ´eventuellement limit´e aux paires d’utilisateurs pour lesquelles au moins
un exemple positif existe dans l’ensemble d’apprentissage. C’est ce que nous avons fait.
Malheureusement, consid´erer le graphe complet du r´eseau implique une grande complexit´e
spatiale, le mod`ele IC apprenant un param`etre ind´ependant pour chaque lien du graphe.
De plus, utiliser le graphe complet revient `a ignorer de nombreuses propri´et´es sp´eciﬁques
des relations entre utilisateurs dans les r´eseaux sociaux : distribution des degr´es en loi de
puissance, faible diam`etre, etc... [Mislove et al., 2007].

Une propri´et´e importante de ces r´eseaux sociaux est la pr´esence de communaut´es, que l’on
peut d´eﬁnir comme des groupes d’utilisateurs similaires, plus dens´ement connect´es les uns
aux autres et interagissant d’avantage entre eux. R´ecemment, [Barbieri et al., 2013a] a

101

102

Chapitre 5. Apprentissage de repr´esentations pour le mod`ele IC

montr´e que dans le cadre de la diﬀusion d’information, les communaut´es pouvaient non
seulement ˆetre form´ees d’utilisateurs interagissant beaucoup les uns avec les autres (on
parle de communaut´es coh´esives), mais aussi d’utilisateurs interagissant avec les mˆemes
autres groupes d’utilisateurs (on parle alors de communaut´es bimodales). L’impact de ces
communaut´es sur la diﬀusion d’information a ´et´e ´etudi´e dans [Barbieri et al., 2013a, Yang
et al., 2014] :

— S’il y a diﬀusion entre les utilisateurs a et b d’une part, et entre les utilisateurs b et
c d’autre part, alors il est vraisemblable qu’il y ait diﬀusion entre les utilisateurs a
et c (communaut´es coh´esives)

— S’il y a diﬀusion entre les utilisateurs a et c, entre les utilisateurs a et d et entre
les utilisateurs b et c, alors il est vraisemblable qu’il y ait de l’inﬂuence entre les
utilisateurs b et d (communaut´es bimodales)

Une illustration de ces principes est donn´ee en ﬁgure 5.1.

Figure 5.1 – R´egularit´es sur les relations utilisateurs. Lorsque les liens en noir existent,
les liens rouges sont plus vraisemblables.

Dans le mod`ele DAIC du chapitre 3 avec un graphe complet (ou dans l’apprentissage
classique du mod`ele IC [Saito et al., 2008]), les probabilit´es de transmission sont estim´ees
sans prendre en compte ces propri´et´es et leurs impact sur les probabilit´es de diﬀusion. Cela
peut conduire `a des structures de graphe de diﬀusion irr´ealistes, `a causes de probabilit´es
de transmission ne suivant pas les principes ´evoqu´es plus haut.

5.2 Projection du mod`ele IC

5.2.1 Apprentissage de Repr´esentations

Pour r´esoudre les deux probl`emes li´es `a l’apprentissage des probabilit´es de transmission
(complexit´e spatiale et prise en compte des r´egularit´es des relations utilisateurs), nous
proposons d’utiliser une approche bas´ee sur l’apprentissage de repr´esentations, pour mo-
d´eliser les relations entre utilisateurs. Le principe est donc de projeter les utilisateurs dans
un espace Rd de fa¸con `a ce que les distances entre eux permettent de mod´eliser les pro-
babilit´es de transmission. La ﬁgure 5.2 illustre cette approche. L’utilisation d’un espace
de repr´esentation r´eduit consid´erablement le nombre de param`etres `a apprendre et prend
naturellement en compte les deux propri´et´es d´ecrites plus haut. En particulier, l’expres-

5.2. Projection du mod`ele IC

103

0.2

0.1

A

F

E

0.6

0.1

B

0.5

0.3

C

0.2

D

A

D

B

C

F

E

Figure 5.2 – Passage d’un graphe de diﬀusion `a un espace de repr´esentation vectoriel. `A
gauche, les valeurs associ´ees aux liens repr´esentent les probabilit´es de transmission entre
utilisateurs. `A droite, ces probabilit´es de transmission sont calcul´ees en fonction de la
distance s´eparant les utilisateurs. Les cercles r´epr´esentent des lignes de niveau d’´equipro-
babilit´e depuis l’utilisatrice A.

sion « les amis de mes amis sont mes amis » est implicitement mod´elis´ee par l’in´egalit´e
triangulaire dans l’espace Rd.

Notre probl`eme diﬀ`ere des approches de pr´ediction de s´equences pr´esent´ees dans le cha-
pitre 4 par le fait que l’information se diﬀuse de mani`ere arborescente, et non selon une
s´equence bien d´eﬁnie comme c’est le cas dans tous les domaines o`u des techniques de ce
genre ont ´et´e employ´ees. Cela complexiﬁe le probl`eme car, comme nous l’avons vu dans le
chapitre 3, nous ne savons pas par qui chaque utilisateur d’un ´episode de diﬀusion a ´et´e
infect´e.

Notre m´ethode peut se rapprocher de certaines approches probabilistes, en particulier celle
de [Barbieri et al., 2013a]. Dans cet article, chaque utilisateur est associ´e `a un ensemble de
variables latentes traduisant son appartenance `a des communaut´es. Ces variables latentes
permettent de g´en´erer des liens et des ´episodes de diﬀusion entre les utilisateurs. Ce mod`ele
suppose toutefois la connaissance du graphe.

Une autre m´ethode de ce type, pr´esent´ee dans le chapitre 2, se trouve dans [Guille and
Hacid, 2012]. L`a aussi, la diﬀusion d’un utilisateur `a un autre d´epend d’un ensemble
de propri´et´es de ces utilisateurs. Ces variables sont toutefois mesur´ees et non pas ap-
prises.

5.2.2 Formulation

Au lieu d’apprendre explicitement l’ensemble des probabilit´es de transmission P, chaque
utilisateur ui est associ´e `a deux repr´esentations latentes zi et ωi dans l’espace Rd. La
projection zi mod´elise le comportement de ui en tant qu’´emetteur de contenu, et ωi son
comportement en tant que r´ecepteur. Les ensembles de projections sont not´es Z = (zi)ui∈U
et Ω = (ωi)ui∈U .

104

Chapitre 5. Apprentissage de repr´esentations pour le mod`ele IC

Nous proposons de d´eﬁnir les probabilit´es de transmission pi,j du mod`ele IC selon une
fonction f : Rd × Rd → [0, 1] de ces projections :

pi,j = f (zi, ωj)

(5.1)

Apprendre deux projections par utilisateur nous permet ainsi d’obtenir des probabilit´es
de transmission asym´etriques.

La fonction f peut ˆetre d´eﬁnie de multiples fa¸cons. Nous proposons de consid´erer la
fonction logistique suivante :

f (zi, ωj) =

1

1 + exp(z(0)

i + ω(0)

j +

i − ω(x)
(z(x)

j )2)

(5.2)

d−1(cid:80)

x=1

o`u z(x) est la x-`eme composante du vecteur z. Le choix d’une fonction logistique permet de
d´eﬁnir des probabilit´es d´ecroissantes en fonction des distances s´eparant les repr´esentations
´emetteur Z et r´ecepteur Ω dans l’espace de projection. D’autre part, de par sa forme
en S, l’utilisation de cette fonction implique un impact plus important des variations
survenant sur les distances mod´er´ees, tombant dans la partie de plus forte pente de la
fonction. Cela permet de focaliser l’attention sur les inﬂuences moins ´evidentes lors de
l’apprentissage. `A noter ´egalement que la fonction ainsi d´eﬁnie consid`ere la premi`ere
composante de chaque repr´esentation comme une valeur de biais : z(0)
j mod´elisent
respectivement la tendance g´en´erale de ui `a transmettre de l’information et la tendance
g´en´erale de uj `a devenir infect´e.

et ω(0)

i

Une fois cette fonction pos´ee, nous pouvons reprendre le d´eveloppement du mod`ele IC de
la mˆeme fa¸con que dans le chapitre 3, en rempla¸cant pi,j par f (zi, ωj) et sans nous limiter
au graphe des « exemples positifs » (c’est `a dire aux couples (ui, uj) tels que |D?
i,j| > 0).
Ainsi, la probabilit´e d’un ´episode de diﬀusion D s’´ecrit :

P (D|Z, Ω) =

(1 − f (zi, ωj))

(cid:89)

uj∈U D∞

P (uj|U D

, Z, Ω) × (cid:89)
,Z, Ω) = 1 − (cid:89)

tj

(cid:89)

uj∈ ¯U D∞

ui∈U D∞

avec :

j = P (uj|U D
P D

ti

(1 − f (zi, ωj))

ui∈U D
ti

(5.3)

La vraisemblance des ensembles de projections Z, Ω par rapport `a un ensemble d’´episodes
de diﬀusion s’´ecrit donc :
L(Z, Ω;D) =

log P (D|Z, Ω)

(cid:88)
(cid:88)

D∈D

D∈D

 (cid:88)

uj∈U D∞

=

log(P D

j ) +

log(1 − f (zi, ωj))

(5.4)

(cid:88)

(cid:88)

uj∈ ¯U D∞

ui∈U D∞



5.2. Projection du mod`ele IC

105

L’apprentissage des projections utilisateurs `a partir d’un ensemble d’´episodes de diﬀusion
D prend donc la forme :

Z (cid:63), Ω(cid:63) = arg max

L(Z, Ω;D)

Z,Ω

`A partir de ces ´equation, nous pouvons reprendre le d´eveloppement de l’algorithme EM
de la mˆeme fa¸con que dans le chapitre 3, page 72. Nous arrivons `a la fonction d’esp´erance
Q(Z, Ω| ˆZ, ˆΩ) de la forme :



log(1 − f (zi, ωj))

(5.5)

(cid:16)

1 − ˆP D
i→j

(cid:17)

(cid:17)

log(1 − f (zi, ωj))

(cid:88)

D∈D

ΦD(Z, Ω| ˆZ, ˆΩ) +
(cid:16) ˆP D
(cid:88)

(cid:88)

(cid:88)

uj∈ ¯U D∞

ui∈U D∞

Q(Z, Ω| ˆZ, ˆΩ) =

avec :
ΦD(Z, Ω| ˆZ, ˆΩ) =

(cid:88)

uj∈U D∞

ui∈(U D
tj

∩Predsj )

et :

i→j log(f (zi, ωj)) +

ˆP D

i→j =

f (ˆzi, ˆωj)

ˆP D
j

L’utilisation d’un espace de repr´esentation fait que les diﬀ´erentes probabilit´es de trans-
mission ne sont plus libres : les contraintes g´eom´etriques rendent leurs valeurs interd´e-
pendantes. Maximiser Q(.| ˆZ, ˆΩ) ne peut alors plus se d´ecomposer en un ensemble de
sous-probl`emes convexes comme cela peut ˆetre le cas avec un mod`ele DAIC, et l’´etape
de maximisation ne poss`ede donc pas de solution analytique comme c’´etait le cas dans
le chapitre 3, avec l’´equation 3.7. N´eanmoins, il est possible de d´eﬁnir une proc´edure de
mont´ee de gradient stochastique convergeant vers un bon maximum local.
L’algorithme 2 d´etaille la proc´edure utilis´ee pour apprendre Z et Ω. Il s’agit d’un algo-
rithme EM, similaire `a celui du chapitre 3, mais o`u l’´etape de maximisation est remplac´ee
par un pas de gradient stochastique visant `a augmenter la valeur de Q. Une it´eration se
d´eroule ainsi :

1. Ligne 7 : tirage uniforme d’un ´episode de diﬀusion D et d’un utilisateur uj n’´etant

pas la source de D ;

2. Lignes 9 `a 12 : si uj fait partie de D, calcul des estimations courantes ˆP D

j et ˆpi,j
pour chaque utilisateur ui infect´e avant uj (selon les formules 5.3 et 5.1 en utilisant
les valeurs courantes de zi et ωj) ;

3. Lignes 13 `a 22 : mise `a jour des valeurs de Z et Ω avec un pas de gradient pour
augmenter la valeur de Q(Z, Ω| ˆZ, ˆΩ). Si uj est infect´e dans D, cette mise `a jour fait
intervenir la d´eriv´ee de ΦD(Z, Ω| ˆZ, ˆΩ) (lignes 16 `a 19). Sinon, elle fait intervenir
la d´eriv´ee de log(1 − f (zi, ωj)) (lignes 19 `a 21). Le pas d’apprentissage  est ﬁx´e `a
10−4.

106

Chapitre 5. Apprentissage de repr´esentations pour le mod`ele IC

Algorithme 2 : Apprentissage du mod`ele IC projet´e
Entr´ees :

U : l’ensemble des utilisateurs ; D : l’ensemble des ´episodes de diﬀusion;
d : le nombre de dimensions ;
f req : la fr´equence des tests de convergence;

 : le pas d’apprentissage;

Sorties :
Z = {∀ui ∈ U : zi ∈ Rd} ; Ω = {∀ui ∈ U : ωi ∈ Rd} ;

Tirage uniforme de ωi ∈ [−1, 1]d;

1 nbP robas ←(cid:80)

D∈D(cid:80)

D

2 pour ui ∈ U faire

ti+1|;
Tirage uniforme de zi ∈ [−1, 1]d ;

ui∈U D∞ |U

it ← 0;

3
4 ﬁn
5 oldL ← −∞ ;
6 tant que true faire
Tirage uniforme de D ∈ D et uj ∈ ¯U D
1 ;
7
β ← |D| × | ¯U D
1 | ×
j < ∞ alors
si tD
ˆpi,j ← f (zi, ωj) ;
ˆP D

j ← 1 −(cid:81)

nbP robas ;

9

8

1

ui∈(U D
tj

∩Predsj )(1 − f (zi, ωj))

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

ﬁn

30
31 ﬁn

ﬁn
pour ui ∈ U D

tj faire

;

;

∂zi

i ← ∂ log f (zi, ωj)
ξ+
j ← ∂ log f (zi, ωj)
ξ+
si tD

∂ωj
j < ∞ alors

zi ← zi + β ×  ×(cid:0) ˆpi,j
ωj ← ωj + β ×  ×(cid:0) ˆpi,j

ˆP D
j

∂zi

∂ωj

i ← ∂ log(1 − f (zi, ωj))
ξ−
j ← ∂ log(1 − f (zi, ωj))
ξ−
(cid:1);
(cid:1);

i + (1 − ˆpi,j
ξ+
ˆP D
j
j + (1 − ˆpi,j
ξ+
ˆP D
j

)ξ−

)ξ−

ˆP D
j

j

i

;

;

sinon

zi ← zi + β ×  × ξ−

i

;

ωj ← ωj + β ×  × ξ−
j ;

ﬁn

L ← Calcul de la log-vraisemblance selon (5.4) avec Z et Ω
si L ≤ oldL alors

ﬁn
it ← it + 1;
si it mod f req = 0 alors

retourner (Z, Ω);

ﬁn
oldL ← L;

5.3. Exp´eriences

107

4. Lignes 20 `a 30 : test de convergence toutes les freq it´erations (1000000 dans notre
cas). Le processus s’arrˆete si la log-vraisemblance sur D n’a pas suﬃsamment aug-
ment´e depuis le dernier test.

Notons enﬁn qu’`a cause du tirage eﬀectu´e `a la ligne 7, les diﬀ´erents couples (ui, uj) ne
sont pas associ´ees aux ´episodes de D dans les mˆemes proportions que dans la formule
5.4 : les paires d’utilisateurs apparaissant dans les ´episodes plus courts sont tir´ees plus
souvent.

Dans notre proc´edure de tirage al´eatoire, la probabilit´e de consid´erer les relations vers un
utilisateur uj dans un ´episode D est ´egale `a :

1

|D| × |U

D

1 |

Or, nous voudrions que chaque relation de transmission soit consid´er´ee dans les mˆemes
proportions que dans Q(Z, Ω| ˆZ, ˆΩ), c’est `a dire tir´ee avec une probabilit´e :

1(cid:80)
(cid:80)

D∈D

ui∈U D∞

|U

D

ti+1|

dont le d´enominateur est not´e nbP robas (ligne 1) dans l’algorithme. Cette valeur corres-
pond au nombre total de relations consid´er´ee dans la formule Q. Nous calculons donc, en
ligne 8, un poids β permettant de corriger ce biais.
|D| × | ¯U D
|U

(cid:80)

(cid:80)

β =

1

|
ti+1|

D

D∈D

ui∈U D∞

Cette valeur β est utilis´ee lors de la mise `a jour des param`etres (lignes 16 et 21).

5.3 Exp´eriences

5.3.1 Corpus et mod`eles de r´ef´erence

Dans nos exp´eriences, les jeux de donn´ees suivants ont ´et´e utilis´es :

Lastfm : corpus issu d’un site d’´ecoute de musique en streaming, collect´e pendant
un an par [Celma, 2010]. Chaque ´episode regroupe les ´ev´enements d’´ecoute d’un
morceau.

Irvine : corpus pr´esent´e dans [Opsahl and Panzarasa, 2009] regroupant les partici-
pations d’´etudiants de l’universit´e d’Irvine `a des forums en ligne. Chaque ´episode
regroupe l’ensemble des participations `a un ﬁl de discussion particulier.

108

Chapitre 5. Apprentissage de repr´esentations pour le mod`ele IC

Corpus
Irvine
Icwsm

Memetracker

Digg

Twitter
LastFm

|U|
847
2270
498
3295
2841
986

|E|
74871
4775
229073
689416
884832
708159

Densit´e

|D| Appr.

|D| Test Taille Episode Moy.

0.1
0.001
0.9
0.06
0.09
0.72

433
19027
10000
17000
10000
10000

49
1000
1000
1000
1000
1000

14.6
2.22
2.17
2.43
20.5
7.25

Table 5.1 – Quelques statistiques sur les jeux de donn´ees.

Twitter, Memetracker, ICWSM et Digg : pr´esent´es dans le chapitre 3, page

83.

La table 5.1 donne quelques statistiques sur les jeux de donn´ees utilis´es : nombre d’uti-
lisateurs, nombre de liens et densit´e du graphe, nombre d’´episodes en apprentissage et
en test et enﬁn taille moyenne des ´episodes de diﬀusion. Comme dans le chapitre pr´ec´e-
dent, le graphe utilis´e pour apprendre les mod`eles est le graphe complet priv´e des arˆetes
correspondant `a des paires d’utilisateurs sans exemples positifs D?
i,j.

Nous comparons notre mod`ele `a un mod`ele DAIC appris en utilisant notre algorithme
pr´esent´e dans le chapitre 3, ainsi qu’aux mod`eles NetRate et CTIC d´ej`a pr´esent´es dans le
mˆeme chapitre.

5.3.2

´Evaluation

De la mˆeme fa¸con que dans le chapitre 3, nous ne connaissons pas les vraies probabilit´es
de transmissions `a comparer aux probabilit´es d´eﬁnies par les diﬀ´erents mod`eles. Nous
´evaluons donc les mod`eles de fa¸con indirecte, en pr´edisant `a partir d’une ou plusieurs
sources U D
1 la probabilit´e pour chaque utilisateur de devenir infect´e, en simulant un grand
nombre de fois la diﬀusion avec les probabilit´es apprise. Comme nous l’avons expliqu´e
en conclusion du chapitre 2, il n’existe pas de d´eﬁnition formelle couramment admise
du probl`eme de « pr´ediction de diﬀusion ». Dans ce chapitre, nous comparons donc les
probabilit´es d’infection ﬁnales pr´edites `a U D∞ sur un ensemble d’´episodes de diﬀusion
de test en utilisant plusieurs mesures diﬀ´erentes aﬁn d’observer leurs comportements et
comparer les mod`eles selon plusieurs logiques diﬀ´erentes.

MSE :

les probabilit´es d’infection pr´edites sont compar´ees au vraies valeurs (0 ou 1)

avec une mesure d’erreur quadratique.

Log-Vraisemblance :

la log-vraisemblance de l’ensemble des ´episodes de diﬀusion
de test selon les diﬀ´erents mod`eles. Les probabilit´es sont projet´ees sur l’intervalle
[10−5, 1 − 10−5] pour ´eviter de calculer log(0)

F1 :

la mesure classique F 1 , d´eﬁnie comme dans le chapitre pr´ec´edent.

5.3. Exp´eriences

109

MAP :

les utilisateurs sont class´es par ordre d´ecroissant de probabilit´e d’infection,
et la liste est ´evalu´ee par Mean-Average-Precision. La pr´ecision moyenne calcul´ee
sur un ´episode de diﬀusion D est d´eﬁnie comme :

N−1(cid:88)

k=0

Pmoy =

1
|U D∞|

(Pk × rel(k))

o`u Pk est la pr´ecision au rang k (le taux d’utilisateurs eﬀectivement infect´es dans D
parmi les k utilisateurs les mieux class´es) et rel(k) vaut 1 si le k-i`eme utilisateur de
la liste fait partie des utilisateurs infect´es dans D, 0 sinon. La MAP est la moyenne
de la pr´ecision moyenne ainsi calcul´ee sur l’ensemble des ´episodes de test.

Figure 5.3 – Dur´ee (en secondes) de l’apprentissage de notre mod`ele jusqu’`a convergence,
et log-vraisemblance obtenue en test, sur le jeu de donn´ees Digg.

Avant de comparer notre mod`ele `a ceux pr´esent´es ci-dessus, nous ´etudions l’impact du
nombre de dimensions sur la dur´ee de l’apprentissage (sur un ordinateur de bureau ´equip´e
d’un processeur Intel(R) Core(TM) i7 CPU 950@3.07GHz) et sur les performances du
mod`ele. Nous ne reportons en ﬁgure 5.3 que les r´esultats obtenus sur Digg, mais les
tendances observ´ees sur les autres jeux de donn´ees sont similaires. Nous remarquons que
la dur´ee de l’apprentissage augmente logarithmiquement avec le nombre de dimensions,
mais que la qualit´e du mod`ele augmente peu au del`a de 25 dimensions. Dans la suite,
nous utilisons donc un espace de dimension d = 25 pour l’apprentissage.

5.3.3 R´esultats

Les r´esultats sont pr´esent´es en table 5.2. Nous pouvons tout d’abord remarquer que notre
mod`ele (IC Proj) obtient des r´esultats toujours au moins aussi bons que ceux du mo-
d`ele DAIC. La comparaison entre les r´esultats de DAIC et ceux de NetRate et CTIC
conduit pour sa part `a des conclusions similaires `a celles du chapitre 3, le mod`ele DAIC
´etant presque toujours meilleur. Ces r´esultats montrent que nous parvenons `a calculer

lllllll0100003000050000Number of DimensionsTime to Converge (sec)25102550100250lllllll−70−65−60−55−50−45Number of DimensionsAverage Log−Likelihood on Test Episodes25102550100250110

Chapitre 5. Apprentissage de repr´esentations pour le mod`ele IC

Corpus

Irvine

ICWSM

MemeTracker

Digg

Twitter

LastFM

CTIC
IC Proj
DAIC

NetRate

CTIC
IC Proj
DAIC

NetRate

CTIC
IC Proj
DAIC

NetRate

CTIC
IC Proj
DAIC

NetRate

CTIC
IC Proj
DAIC

NetRate

CTIC
IC Proj

NetRate

Mod`ele MSE
15,31
DAIC
15,42
15,29
14,53∗

-960,5
-892,13
-771,42∗
-532,5∗

LogVrai. MAP
0,079
0,078
0,080
0,079
-8,3
0,77
-9,01
0,72
-8,46
0,76
-6,14∗
0,78
-795,85
0,22
-850,48
0,17
-802,52
0,22
-791,3
0,23
-69,5
0,411
-64,01∗
0,409
-64,18∗
0,413
-51,75∗
0,434∗
-412,75
0,047
-428,78
0,039
-401,56
0,049
-223,15∗ 0,056∗
0,132
-409,5
0,112
-413,02
0,128
-409,3
0,151∗
-405

F1

nbParams

0,020
0,019
0,020
0,025∗
0,651
0,357
0,482
0,651
0,0585
0,0442
0,0551
0,0632∗
0,201
0,199
0,201
0,198
0,012
0,011
0,012
0,013
0,026
0,022
0,025
0,027

74871
74871
149742
42350
4775
4775
9550
113500
229073
229073
458146
24900
689416
689416
1378832
164750
884832
884832
1769664
142050
708159
708159
1416318
49300

0,2
0,23
0,22
0,19
32,62
34,55
33,27
32,15

2,1
1,95
1,92∗
1,79∗
6,70
6,91
6,72
5,47∗
12,13
13,91
12,12
11,62∗

Table 5.2 – R´esultats obtenus sur les diﬀ´erents corpus. Les valeurs marqu´ees d’un ast´e-
risque sont signiﬁcativement meilleures que celles obtenues par DAIC (Test-t de Student
95%), et celles en gras indiquent le meilleur r´esultat obtenu sur chaque corpus.

5.3. Exp´eriences

111

correctement les probabilit´es de transmission dans un espace vectoriel. Il est important
de remarquer que cela se fait le plus souvent avec un nombre de param`etres (colonne de
droite) largement inf´erieur au mod`ele DAIC, sauf sur le corpus ICWSM, dont le graphe
des exemples positifs est tr`es creux.

Il est int´eressant de remarquer que les mesures se comportent de fa¸cons assez diﬀ´e-
rentes :

1. La log-vraisemblance des ´episodes de test est signiﬁcativement meilleure avec notre
IC projet´e sur Irvine, ICWSM, Digg et Twitter. Cela peut se comprendre en ob-
servant la table 5.1 : on remarque que ces corpus sont ceux dont le graphe a une
densit´e assez faible (de 0.001 `a 0.1 contre 0.72 et 0.9 pour les corpus LastFM
et Memetracker). Rappelons que le « graphe » d’un corpus d´esigne ici le graphe
construit `a partir de D et contenant tous les liens (ui, uj) tels qu’il existe au moins
un ´episode o`u uj apparaˆıt apr`es ui, et uniquement ceux-ci. D`es lors, sur ces corpus,
le mod`ele DAIC classique ne peut apprendre qu’un nombre limit´e de probabilit´es
de transmissions. Il arrive donc fr´equemment que certaines infections observ´ees
dans l’ensemble de test ne puissent pas ˆetre expliqu´ees correctement par ce mod`ele
DAIC, ce qui conduit `a une vraisemblance plus faible. Notre approche, en revanche,
est capable d’inf´erer des probabilit´es de transmission pertinentes pour les paires
d’utilisateurs n’ayant aucun exemple positif grˆace `a l’utilisation d’un espace de re-
pr´esentation (par exemple, en suivant l’un des principes illustr´es en ﬁgure 5.1). Cela
explique que IC projet´e obtienne une meilleure log-vraisemblance sur les ´episodes
de test de ces corpus.

2. La MSE de notre mod`ele est signiﬁcativement meilleure sur Irvine, Digg, Twitter
et LastFM. Remarquons qu’il s’agit de jeux de donn´ees sur lesquels la diﬀusion
est en fait d´elicate `a caract´eriser : le fait que deux utilisateurs interagissent avec
le mˆeme item ne veux pas forc´ement dire qu’il y a eu diﬀusion de l’un `a l’autre,
il peut s’agir uniquement d’une corr´elation sur leurs centres d’int´erˆet. Distinguer
les relations de corr´elation des relations d’inﬂuence est une tˆache diﬃcile, les deux
concepts ´etant ´etroitement li´es [Anagnostopoulos et al., 2008].

3. La mesure MAP se comporte d’une fa¸con similaire `a la MSE, et indique que IC
projet´e est meilleur que DAIC sur pratiquement les mˆemes corpus. En eﬀet, la
mesure MAP favorise les pr´edictions telles que les utilisateurs de U D∞ aient des
probabilit´es plus ´elev´ees que ceux de ¯U D∞. La MSE r´ecompensant les probabilit´es
d’infections ﬁnales proches de 1 pour les utilisateurs de U D∞ et 0 pour les autres, il
est logique qu’un mod`ele avec une meilleure MSE ait ´egalement tendance `a obtenir
une meilleure MAP.

4. La mesure F1, en revanche, n’indique pas que le mod`ele IC Projet´e est signiﬁ-
cativement meilleur sur les mˆemes corpus que la MAP. Les deux mesures sont
pourtant des fonctions de la pr´ecision et du rappel, mais la mesure MAP accorde
plus d’importance `a la pr´ecision dans les premiers rangs. Il est toutefois int´eres-
sant de remarquer que les corpus sur lesquels IC projet´e obtient un score MAP

112

Chapitre 5. Apprentissage de repr´esentations pour le mod`ele IC

signiﬁcativement meilleur sont ceux des r´eseaux sociaux fonctionnant en « hub »,
c’est `a dire o`u un utilisateur se connectant sur le site consid´er´e voit d’abord une
liste des informations les plus populaires du moment, ´eventuellement pond´er´ees par
ses centres d’int´erˆet (tubes sur LastFM, “trends” sur Twitter, informations “hot”
sur Digg). Certains utilisateurs vont alors syst´ematiquement interagir avec certains
contenus ainsi mis en avant. Une explication possible de la meilleure MAP obte-
nue par IC projet´e sur ces corpus est donc que l’utilisation d’un biais ω(0)
dans
la formule 5.2 permet de mod´eliser ce comportement, et de pr´edire un score plus
´elev´e pour ces utilisateurs ayant tendance `a suivre les informations populaires et `a
ˆetre plus souvent infect´es, ce qui permet d’obtenir une meilleure MAP. Une autre
explication possible de ces r´esultats est que sur ces corpus, la pr´esence de hubs fait
que la diﬀusion a lieu de fa¸con plus « globale » : plus une information est populaire,
plus elle a de chances d’infecter de nouveaux utilisateurs `a travers tout le r´eseau.
Ce ph´enom`ene est mieux repr´esent´e par notre mod`ele, o`u chaque utilisateur a une
chance d’infecter tous les autres dans l’espace de repr´esentation

j

Le premier point ´evoqu´e ci-dessus peut ˆetre v´eriﬁ´e en calculant le coeﬃcient de Jaccard
entre l’ensemble des liens du graphe des exemples positifs extrait des ´episodes d’appren-
tissage et celui du graphe extrait des ´episodes de test. Rappelons que le coeﬃcient de
Jaccard mesure la similarit´e entre deux ensembles et est ´egal au rapport entre la taille de
leur intersection et la taille de leur union. Les valeurs obtenues sont indiqu´ees en table 5.3.
Nous pouvons voir que les valeurs du coeﬃcient sont bien plus faibles sur Irvine, ICWSM,
Digg et Twitter, ce qui signiﬁe que beaucoup d’interactions utilisateurs dans les ´episodes
de test ne sont jamais observ´ees dans les ´episodes d’apprentissage. Cela conﬁrme notre
analyse.

Corpus
Irvine

ICWSM

MemeTracker

Digg

Twitter
LastFM

Coeﬃcient de Jaccard

0.05
0.17
0.77
0.26
0.37
0.71

Table 5.3 – Coeﬃcients de Jaccard entre les liens du graphe des exemples posiﬁfs des
´episodes d’apprentissage et les liens du graphe des exemples posiﬁfs des ´episodes de test.

Globalement, les r´esultats pr´esent´es ici indiquent que le mod`ele IC projet´e, o`u les proba-
bilit´es d´ependent des repr´esentations des utilisateurs, fonctionne aussi bien que le mod`ele
DAIC o`u les probabilit´es sont apprises s´epar´ement. De plus, ce mod`ele IC projet´e parvient
`a obtenir des r´esultats signiﬁcativement meilleurs dans certains cas, tout en apprenant
beaucoup moins de param`etres. Ces r´esultats nous apprennent aussi que la diﬀusion d’in-
formation est un ph´enom`ene complexe et prot´eiforme. Les jeux de donn´ees collect´es ici
sont de tailles et de densit´es tr`es diﬀ´erentes, et chacun poss`ede son propre « type » de

5.3. Exp´eriences

113

Figure 5.4 – Pr´ecision-Rappel de la d´etection de relations sur Memetracker.

diﬀusion (retweets, discussion, recommandation). Les diﬀ´erentes mesures utilis´ees corres-
pondent ´egalement `a des principes d’´evaluation diﬀ´erents, et n’ont pas donn´e les mˆemes
r´esultats sur tous les corpus.

N´eanmoins, d’une fa¸con g´en´erale, les r´esultats mettent en avant les propri´et´es avanta-
geuses de cette approche : des r´esultats meilleurs avec moins de param`etres `a apprendre,
une meilleure capacit´e de g´en´eralisation et une capacit´e `a mod´eliser diﬀ´erents types de
diﬀusion.

5.3.4 D´etection de Relations d’Inﬂuence

Pour compl´eter les exp´erimentations men´ees, nous ´evaluons notre mod`ele sur sa capa-
cit´e `a retrouver un ensemble de relations de diﬀusion connues `a partir d’un ensemble D
d’´episodes de diﬀusion observ´es. De la mˆeme fa¸con que dans [Gomez-Rodriguez et al.,
2011, Gomez Rodriguez et al., 2010], l’id´ee est d’utiliser les hyperliens liant des messages
du corpus memetracker comme l’ensemble de relations `a identiﬁer. `A chaque fois qu’un
utilisateur de ce corpus poste un message contenant un hyperlien vers un autre message,
nous cr´eons un lien de l’auteur du second message vers l’auteur du premier. Les liens du
graphe ainsi construit correspondent donc de fa¸con certaine `a des liens de diﬀusion.

Pour chaque paire (ui, uj), la probabilit´e pi,j apprise selon chacun des mod`eles est inter-
pr´et´ee comme la probabilit´e d’existence d’un lien entre ces deux utilisateurs. Nous trions
les probabilit´es ainsi apprises par chaque mod`ele et ´evaluons les r´esultats avec une courbe
de Pr´ecision-Rappel. Les r´esultats sont pr´esent´es en ﬁgure 5.4. Nous indiquons aussi ceux
obtenus par les mod`eles CTIC et NetRate.

00.20.40.60.810.050.10.150.20.250.30.350.4RecallPrecisionEmbedded ICICNetrateCTIC114

Chapitre 5. Apprentissage de repr´esentations pour le mod`ele IC

Cette exp´erience illustre la meilleure capacit´e de notre mod`ele `a identiﬁer des liens d’in-
ﬂuence pertinents `a partir d’´episodes de diﬀusion, sa courbe de precision en fonction du
rappel se situant au dessus de celle des autres mod`eles. De plus, le fait de projeter les
utilisateurs dans un espace de repr´esentation pour d´eﬁnir les probabilit´es de transmission
permet au mod`ele de d´ecouvrir des relations sans exemple de diﬀusion dans les ´episodes
observ´es, et donc d’obtenir de meilleurs r´esultats sur cette tˆache de pr´ediction de liens.
Enﬁn, dans cette approche, les contraintes g´eom´etriques permettent aussi d’´eviter le pro-
bl`eme du biais d’apprentissage d´ecrit dans le chapitre 3, section 3.3.1. En eﬀet, les valeurs
des probabilit´es de transmission ne sont pas ind´ependantes et ne peuvent pas prendre
de valeurs extrˆemes (proches de 0 ou 1) sans avoir d’eﬀets sur le reste des repr´esenta-
tions.

5.4 Conclusion

Dans ce chapitre, nous avons pr´esent´e une version « projet´ee » du mod`ele IC, les proba-
bilit´es de transmission ´etant d´eﬁnies de fa¸con indirecte `a partir des distances s´eparant
les utilisateurs dans un espace de repr´esentation. Cette approche permet d’une part de
r´egulariser les relations en limitant l’impact du bruit et du surapprentissage, et d’autre
part d’inf´erer des probabilit´es de transmission entre des utilisateurs pour lesquels aucun
exemple positif n’existe. Cette capacit´e de g´en´eralisation est importante, les donn´ees issues
de r´eseaux sociaux ´etant souvent bruit´ees et parcimonieuses.

Les r´esultats obtenus en pr´ediction de liens ont montr´e la capacit´e de notre mod`ele `a rep´e-
rer les liens les plus pertinents. Les r´esultats en pr´ediction de diﬀusion ont montr´e que la
version projet´ee du mod`ele IC fonctionnait mieux que la version DAIC, voire bien mieux
dans certains contextes, tout en n´ecessitant d’apprendre moins de param`etres. Les diﬀ´e-
rences dans le comportement des mesures d’´evaluations nous ont ´egalement montr´e que la
diﬀusion ´etait un ph´enom`ene complexe, d´elicat `a caract´eriser et `a ´evaluer, et ´etroitement
li´e au fonctionnement du site sur lequel il a lieu.

Chapitre 6

Mod´elisation par diﬀusion de chaleur

R´esum´e Ce chapitre d´ecrit une troisi`eme contribution, publi´ee dans [Bourigault et al.,
2014]. Nous utilisons l’apprentissage de repr´esentations pour projeter les utilisateurs dans
un espace Rd de fa¸con `a ce que la diﬀusion d’information puisse cette fois ci ˆetre mod´elis´ee
comme un processus de diﬀusion de chaleur au sein mˆeme de cet espace. Le mod`ele obtenu
est donc continu, et non plus it´eratif. Il obtient des r´esultats similaires `a ceux du chapitre
pr´ec´edent tout en ´etant plus rapide en inf´erence. Nous pr´esentons ´egalement une extension
permettant de prendre en compte le contenu de l’information se diﬀusant.

6.1 Introduction

6.1.1 Mod`eles explicatifs ou pr´edictifs

Dans les chapitres 3 et 5, nous avons ´etudi´es des mod`eles explicatifs, visant `a inf´erer
pr´ecis´ement comment l’information se diﬀuse d’un utilisateur `a l’autre. `A chaque fois, nous
avons ´evalu´e les performances de nos mod`eles et des mod`eles de r´ef´erences sur la tˆache de
pr´ediction de diﬀusion : notre but ´etait de retrouver, `a partir d’un ensemble d’utilisateurs
initiaux, quels seraient les utilisateurs ﬁnalement infect´es, l’´evaluation se faisant avec des
mesures issues de la recherche de documents (F1 et MAP). Cette m´ethode d’´evaluation
´etait rendue n´ecessaire par l’absence de v´erit´e terrain sur les d´eroulement pr´ecis de la
diﬀusion d’un utilisateur `a l’autre.

Il est important de remarquer que nous avons utilis´e un mod`ele explicatif et g´en´eratif
pour une tˆache de pr´ediction. Le mod`ele IC repose sur une simulation du processus de
diﬀusion lui-mˆeme, et permet donc non-seulement de pr´edire quels utilisateurs seront
infect´es, mais aussi par qui. Durant l’´etape d’apprentissage, c’est bien cette propri´et´e
qui est apprise : retrouver quels sont les chemins emprunt´es par l’information (sous la
forme de probabilit´es de transmission). Nous avons d’ailleurs pu ´evaluer la capacit´e de

115

116

Chapitre 6. Mod´elisation par diﬀusion de chaleur

Figure 6.1 – Exemple de diﬀusion d’information continue dans un espace de repr´esen-
tation. L’utilisateur source diﬀuse de la chaleur dans l’espace. Les cercles color´es repr´e-
sentent des lignes de niveau de chaleur, et les indices des utilisateurs l’ordre dans lequel
ils deviennent infect´es.

notre approche `a identiﬁer les liens de diﬀusion dans le chapitre 5 (ﬁgure 5.4). Cette
information apprise est ensuite utilis´ee pour pr´edire quels utilisateurs seront infect´es. La
tˆache de pr´ediction de diﬀusion est donc r´esolue par l’interm´ediaire d’une tˆache « annexe ».
Dans l’optique d’une probl´ematique purement pr´edictive, une autre approche est toutefois
possible. Vladimir Vapnik [Vapnik, 2013] ´ecrivait ainsi :

« Pour r´esoudre un probl`eme donn´e, ´evitez de r´esoudre un probl`eme plus g´e-
n´eral en tant qu’´etape interm´ediaire »

Dans ce chapitre, nous proposons donc une nouvelle approche du probl`eme, ´egalement ba-
s´ee sur l’apprentissage de repr´esentations, mais n’utilisant plus de mod`ele explicatif.

6.1.2 Diﬀusion de chaleur

Notre id´ee est de projeter les utilisateurs du r´eseau dans un espace continu de fa¸con `a ce
que la diﬀusion d’information dans le r´eseau social puisse ˆetre vue comme un processus
de diﬀusion de chaleur dans cet espace : plus un utilisateur est chaud `a un instant t, plus
il est infect´e ou a de chances d’ˆetre infect´e `a cet instant, d’une fa¸con similaire `a [Kondor
and Laﬀerty, 2002]. Une illustration du principe est donn´ee en ﬁgure 6.1.

Comme dans le chapitre pr´ec´edent, l’utilisation d’un espace de repr´esentation continu
nous permet de d´eﬁnir un mod`ele relativement compact, et de r´egulariser les relations
entre utilisateurs. De plus, le probl`eme d’apprentissage des repr´esentations des utilisateurs
devient un probl`eme d’optimisation continue pouvant ˆetre r´esolu par une descente de
gradient classique. Enﬁn, l’utilisation du mod`ele en inf´erence est bien plus simple. Le
calcul peut ˆetre eﬀectu´e rapidement, sans avoir `a r´ealiser des simulations comme dans
la partie pr´ec´edente. Nous proposons ´egalement une extension de ce mod`ele permettant
d’int´egrer le contenu de l’information se diﬀusant.

6.2. Mod`ele

6.2 Mod`ele

6.2.1 Noyaux

6.2.1.1 Noyaux de diﬀusion de chaleur

117

Consid´erons l’espace de repr´esentation Rd. Un processus de diﬀusion de chaleur dans cet
espace est d´eﬁni par une fonction f : Rd×R+ → R o`u f (x, t) repr´esente la temp´erature en
un point x au temps t. Cette fonction est caract´eris´ee par l’´equation de la chaleur :

(cid:40) ∂f
∂t − ∆f = 0
f (x, 0) = f0(x)

(6.1)

o`u f0(x) repr´esente l’´etat initial et ∆ est l’op´erateur Laplacien (la d´eriv´ee seconde par
rapport `a l’espace) . Nous d´eﬁnissons ensuite K : R+ × Rd × Rd → R tel que K(t, y, x)
corresponde `a la temp´erature au point x `a l’instant t avec une source initiale situ´ee en y,
c’est `a dire avec les conditions initiales suivantes :

K(0, y, x) = δ(y − x) = f0(x)

(6.2)

o`u δ est la fonction Dirac (valant 1 en 0 et 0 partout ailleurs). Dans un espace euclidien
de dimension d, l’´equation diﬀ´erentielle 6.1 avec les conditions initiales 6.2 poss`ede une
solution appel´ee noyau de chaleur :

K(t, y, x) = (4πt)− d

2 e− ||y−x||2

4t

(6.3)

6.2.1.2 D´eﬁnition d’un noyau pour la diﬀusion d’information

L’id´ee est d’utiliser le ph´enom`ene physique de diﬀusion de chaleur pour traiter la tˆache de
pr´ediction de diﬀusion d’information sur les r´eseaux sociaux. En conservant la notation
Z = (zi)ui∈U pour d´esigner l’ensemble des projections des utilisateurs, il est possible de
r´e´ecrire le noyau de diﬀusion d´eﬁni par la formule 6.3 comme une fonction KZ(t, sD, ui)
retournant un score de contamination pour l’utilisateur ui `a l’instant t d’une diﬀusion
ayant ´et´e initi´ee par l’utilisateur sD :

KZ(t, sD, ui) = (4πt)− d

2 e− ||zsD

4t

−zi||2

(6.4)

Il s’agit alors de d´eterminer les valeurs optimales de Z `a partir de D. Pour cela, nous
d´eﬁnissons une fonction de coˆut :

L(Z;D) =

l(KZ(., sD, .), D)

(6.5)

(cid:88)

D∈D

118

Chapitre 6. Mod´elisation par diﬀusion de chaleur

o`u l(KZ(., sD, .), D) mesure, pour une source sD, un coˆut entre la pr´ediction du noyau
KZ et l’´episode D. Ce coˆut sera pr´esent´e dans la sous-section suivante. Enﬁn, le probl`eme
ﬁnal consiste alors `a trouver Z∗ tel que :

Z∗ = argminZ L(Z;D)

(6.6)

6.2.1.3 Fonction de coˆut

Comme nous l’avons dit dans l’introduction, notre but est de pr´edire les utilisateurs infec-
t´es directement, sans passer par l’estimation de l’information manquante « quelles conta-
minations ont eu lieu ». Nous proposons de r´ealiser l’apprentissage des repr´esentations
des utilisateurs en contraignant uniquement le noyau `a contaminer les utilisateurs dans le
mˆeme ordre que dans les ´episodes d’apprentissage, sans passer par la mod´elisation de la
dynamique temporelle qui serait un probl`eme plus complexe `a r´esoudre, et sans chercher
`a identiﬁer les transmissions ayant eu lieu. Nous d´eﬁnissons pour cela deux contraintes
sur chaque ´episode de diﬀusion D de l’ensemble d’apprentissage D :

— pour tout couple d’utilisateurs (ui, uj) tel que ui et uj soient contamin´es dans l’´epi-
j , KZ doit ˆetre d´eﬁni de fa¸con `a ce que ∀t, KZ(t, sD, ui) >
— pour tout couple d’utilisateurs (ui, uj) tel que ui ∈ U D∞ et uj (cid:54)∈ U D∞, KZ doit ˆetre

sode D et tel que tD
KZ(t, sD, uj) ;
d´eﬁni de fa¸con `a ce que ∀t, KZ(t, sD, ui) > KZ(t, sD, uj).

i < tD

(cid:0)∀(ui, uj) ∈ U 2,∀D ∈ D?
(cid:0)∀(ui, uj) ∈ U 2,∀D ∈ D−

i,j,∀t(cid:1) : KZ(t, sD, ui) > KZ(t, sD, uj)
i,j,∀t(cid:1) : KZ(t, sD, ui) > KZ(t, sD, uj)

Soit :

La fonction KZ est d´ecroissante selon la distance s´eparant les projections des utilisateurs
concern´es pour t ﬁx´e, i.e :
∀(ui, uj, uk, t) ∈ U ×U ×U ×R+,||zk−zi||2 ≤ ||zk−zj||2 =⇒ KZ(t, uk, ui) ≥ KZ(t, uk, uj)

Les contraintes peuvent donc ˆetre r´e´ecrites, plus simplement, ainsi :

(cid:0)∀(ui, uj) ∈ U 2,∀D ∈ D?
(cid:0)∀(ui, uj) ∈ U 2,∀D ∈ D−

i,j

(cid:1) : ||zsD − zi||2 < ||zsD − zj||2
(cid:1) : ||zsD − zi||2 < ||zsD − zj||2

i,j

(6.7)

(6.8)

Ces contraintes expriment le fait que des utilisateurs infect´es plus tˆot dans un ´episode D
doivent ˆetre plus proches de la source sD dans l’espace de repr´esentation que ceux infect´es
plus tard (ou jamais). En utilisant une fonction de type hingeloss, nous pouvons exprimer

ces contraintes en d´eﬁnissant une fonction de coˆut d’ordonnancement lrang :
max(0, 1 − (||zsD − zj||2 − ||zsD − zi||2))

lrang(KZ(., sD, .), D) =

6.2. Mod`ele

ui,uj∈U 2
D∈D?
i,j

(cid:88)
(cid:88)
(cid:88)

i,j

+

lrang(KZ(., sD, .), D) =

ui,uj∈U 2
D∈D−

119

(6.9)

max(0, 1 − (||zsD − zj||2 − ||zsD − zi||2))

max(0, 1 − (||zsD − zj||2 − ||zsD − zi||2))

)

ui,uj∈U 2
∪D−

D∈(D?
i,j

i,j

Nous baptisons ce mod`ele « HDK », pour « Heat Diﬀusion Kernel ».

6.2.1.4 Relation temps-probabilit´e

Remarquons que nous avons d´eﬁni ce mod`ele HDK de fa¸con `a ce qu’un utilisateur infect´e
dans un ´episode de diﬀusion d’apprentissage D soit plus proche de la source qu’un utilisa-
teur non-infect´e, mais aussi de fa¸con `a ce qu’un utilisateur infect´e plus tˆot soit plus proche
de la source qu’un utilisateur infect´e plus tard. Ainsi, la distance s´eparant un utilisateur
quelconque de la source d’une information repr´esente `a la fois sa propension `a ˆetre infect´e
par cette information et sa tendance `a ˆetre infect´e plus ou moins rapidement par celle-ci.
Nous avons donc, implicitement, consid´er´e en d´eﬁnissant notre fonction de coˆut qu’un
utilisateur infect´e plus tˆot dans un ´episode de diﬀusion d’apprentissage ´etait ´egalement
plus susceptible d’ˆetre infect´e, puisque ces deux propri´et´es sont mod´elis´ees par la distance
dans l’espace de repr´esentations.
Cette hypoth`ese sur la « relation temps-probabilit´e » nous permet d’am´eliorer la robustesse
du mod`ele en augmentant le nombre d’exemples sur lesquelles l’apprentissage de celui-
ci se base. Par exemple, les ´episodes de diﬀusion (u1, u2, u3, u4) et (u1, u4, u3, u2) utilis´es
en apprentissage seraient ´equivalents si nous ne consid´erions pas l’ordre des utilisateurs
infect´es apr`es la source u1.

Nous justiﬁons cette hypoth`ese par les observations suivantes :

1. Un utilisateur proche de la source dans le graphe d’un r´eseau social (au sens de
la longueur du plus court chemin) a plus de chances d’ˆetre contamin´e par les
informations ´emanant de cette source, car moins de transmissions sont n´ecessaires.

2. Pour la mˆeme raison, un utilisateur proche de la source dans le graphe d’un r´e-
seau social a ´egalement tendance `a ˆetre infect´e plus tˆot par les informations en
provenance de cette source.

Le fait qu’un utilisateur soit infect´e tˆot dans un ´episode d’apprentissage D peut donc
indiquer qu’il avait ´egalement plus de chances d’ˆetre infect´e.

120

Chapitre 6. Mod´elisation par diﬀusion de chaleur

Cette hypoth`ese est ´egalement justiﬁ´ee par les r´esultats obtenus par Manuel Gomez-
Rodrigez et Jure Leskovec dans leurs travaux sur l’inf´erence de graphe [Gomez Rodriguez
et al., 2010, Gomez-Rodriguez et al., 2011, Gomez Rodriguez et al., 2013], bas´es sur
une id´ee similaire. Notons toutefois que contrairement `a eux, nous avons uniquement
consid´er´e cette relation temps-probabilit´es de fa¸con relative, et non pas absolue : nous ne
cherchons pas `a reproduire les temps d’infection exacts, uniquement l’ordre dans lequel
les utilisateurs sont infect´es.

6.2.2 Algorithme d’apprentissage

Le coˆut ﬁnal `a minimiser est :

Lrang(Z;D) =

(cid:88)

D∈D

lrang(KZ(., sD, .), D)

(6.10)

Diﬀ´erentes m´ethodes peuvent ˆetre utilis´ees pour optimiser la fonction objectif. Nous pro-
posons d’utiliser la descente de gradient stochastique d´ecrite dans l’algorithme 3. Apr`es
avoir initialis´e al´eatoirement les projections des utilisateurs (ligne 2), l’algorithme ´echan-
tillonne `a chaque it´eration un ´episode D (ligne 8) et deux utilisateurs ui et uj, avec uj
un utilisateur non-infect´e dans D ou infect´e apr`es ui (lignes 9, 10). Si les contraintes
d´eﬁnies en equations 6.7 et 6.8 ne sont pas respect´ees avec une marge suﬃsante pour cet
´episode et ces utilisateurs (ligne 15), les projections zi, zj et zsD sont d´eplac´ees dans la
direction du gradient de la fonction de coˆut, selon un pas d’apprentissage α (lignes 16 `a
17). L’apprentissage continue ainsi jusqu’`a ce que la valeur de LZ ne diminue plus (ligne
22).

Comme dans le chapitre pr´ec´edent, le tirage eﬀectu´e en lignes 8 `a 10 introduit un biais,
les diﬀ´erents triplets d’utilisateurs n’´etant pas consid´er´es dans les mˆemes proportions que
dans la fonction de coˆut (´equations 6.9 et 6.10).

Le tirage al´eatoire de l’algorithme consid`ere chaque triplet (sD, ui, uj) dans l’´episode D
avec une probabilit´e :

Nous voudrions que chaque triplet soit tir´e selon la mˆeme probabilit´e que dans l’´equation
6.10, soit :

1

i +1|

tD

|D| × |U D∞| × | ¯U D
1(cid:80)
(cid:80)

|U

i +1|

D
tD

D∈D

ui∈U D∞

6.2. Mod`ele

121

Nous calculons donc un facteur de correction β, appliqu´e lors de la mise `a jour des para-
m`etres (lignes 16 `a 17).

(cid:80)
|D| × |U D∞| × | ¯U D
i +1|
i +1|

(cid:80)

tD

|U

D
tD

β =

D∈D

ui∈U D∞

6.2.3 Diﬀusion bas´ee sur le contenu

Nous proposons maintenant une extension du mod`ele pr´ec´edent capable de prendre en
compte le contenu de chaque ´episode de diﬀusion. En eﬀet, dans la r´ealit´e, deux ´epi-
sodes partant de la mˆeme source mais concernant des sujets diﬀ´erents n’infecteront pas
les mˆemes utilisateurs, ou pas dans le mˆeme ordre. Nous consid´erons que le contenu d’un
´episode de diﬀusion D est repr´esent´e par un vecteur wD ∈ RQ. Suivant le contexte appli-
catif, le vecteur wD pourra correspondre `a une repr´esentation d’un texte (sac de mots ou
tf-idf), ou `a un vecteur de caract´eristiques extraites d’une image, par exemple.

L’extension propos´ee se base sur le principe suivant : le contenu d’un ´episode D a pour
eﬀet de modiﬁer les repr´esentations des utilisateurs, et donc de modiﬁer la fa¸con dont ce
contenu se propage.

Pour cela, nous apprenons les param`etres θ d’une fonction lin´eaire permettant d’obtenir
une repr´esentation du contenu dans Rd, d´eﬁnie ainsi :

fθ(wD) = wD.θ

en consid´erant que la repr´esentation du contenu wD est un vecteur-ligne et que θ est une
matrice `a Q lignes et d colonnes. C’est cette repr´esentation fθ(wD) ∈ Rd qui est ensuite
utilis´ee pour modiﬁer les repr´esentations des utilisateurs. Nous avons explor´e deux fa¸cons
diﬀ´erentes de modiﬁer ces repr´esentations. Dans les deux cas, les param`etres θ sont appris
en mˆeme temps que Z en adaptant l’algorithme de descente de gradient.

6.2.3.1 Translation

Dans cette version, la repr´esentation de l’utilisateur-source est translat´ee dans l’espace
de repr´esentation selon le vecteur fθ(wD) (on retrouve une id´ee similaire dans [Bordes
et al., 2013]). La diﬀusion a donc lieu, dans l’espace de repr´esentation, depuis le point
zsD + fθ(wD). La fonction K devient devient :

K transZ,θ (wD, t, sD, ui) = (4πt)− d

2 e− ||zsD

+fθ (wD )−zi||2

4t

(6.11)

Une illustration du principe est donn´ee en ﬁgure 6.2. Ce mod`ele est baptis´e « HDK-T ».

122

Chapitre 6. Mod´elisation par diﬀusion de chaleur

Algorithme 3 : Apprentissage de repr´esentations pour la pr´ediction de diﬀusion (HDK
- Heat Diﬀusion Kernel)
Entr´ees :

U : ensemble des utilisateurs ; D : ensemble des ´episodes de diﬀusion;
d : nombre de dimensions ; α : pas d’apprentissage;
f req : fr´equence des tests de convergence;
Z = {∀ui ∈ U : zi ∈ Rd} ;
Tirage uniforme de zi ∈ [−1, 1]d ;

Sorties :
1 pour ui ∈ U faire

2
3 ﬁn
4 oldL ← +∞ ;
5 τ ← 0 ;

6 nbTriplets ←(cid:80)

D∈D(cid:80)

ui∈U D∞ | ¯UtD

i +1| ;

i < tD

j ou uj ∈ ¯U D∞ ;

9

7 tant que vrai faire
Tirer D ∈ D ;
8
Tirer ui ∈ U D∞ ;
Tirer uj ∈ U avec tD
− zi||2 ;
di ← ||zsD
dj ← ||zsD
− zj||2 ;
δd ← dj − di ;
β ← |D|×|U D∞|×| ¯U D

tD
i
nbTriplets
si δd < 1 alors

+1

|

;

10

11

12

13

14

zi ← zi + α × β × 2(zsD
− zi) ;
zj ← zj + α × β × 2(zj − zsD
) ;
+ α × β × 2(zi − zj) ;
zsD

← zsD

ﬁn
si τ mod f req = 0 alors

L ← Lrang(Z);
si L ≥ oldL alors
retourner Z;

ﬁn
oldL ← L ;

ﬁn
τ ← τ + 1 ;

15

16

17

18

19

20

21

22

23

24

25

26

27
28 ﬁn

6.2. Mod`ele

123

Figure 6.2 – Prise en compte du contenu, version HDK-T. Une mˆeme source partage
deux contenus w1 et w2. Ceux-ci sont projet´es avec la fonction f , et leurs repr´esentations
sont translat´ees dans l’espace suivant f (w1) et f (w2). Les indices pr`es des utilisateurs
indiquent dans quel ordre ils sont contamin´es par chaque contenu.

6.2.3.2 D´eformation

Dans cette deuxi`eme version, les projections de tous les utilisateurs sont modiﬁ´ees de la
fa¸con suivante : la x-i`eme composante z(x)
i de chaque repr´esentation zi est multipli´ee par la
x-i`eme composante du vecteur fθ(wD). La nouvelle repr´esentation z(cid:48)
i de chaque utilisateur
s’´ecrit donc :

∀x ∈(cid:74)0, d − 1(cid:75), z

(cid:48)(x)
i = z(x)

i

. (fθ(wD))(x)

Cette expression peut s’´ecrire :

z(cid:48)
i = zi.(I fθ(wD))

o`u I fθ(wD) est la matrice diagonale de taille d × d dont les valeurs sont ´egales `a celles du
vecteur fθ(wD). Il s’agit donc d’une matrice de changement d’´echelle. Cette modiﬁcation
des repr´esentations des utilisateurs conduit `a la d´eﬁnition de K suivante :

K morph

Z,θ

(wD, t, sD, ui) = (4πt)− d

2 exp

(cid:18)
−||zsD.I fθ(wD) − zi.I fθ(wD)||2

(cid:19)

4t

L’application de ce changement d’´echelle revient donc `a consid´erer que la diﬀusion d’infor-
mation ne se fait plus de fa¸con uniforme dans Rd, mais `a une vitesse diﬀ´erente le long de
chaque dimension : plus la valeur de la x-i`eme composante du vecteur fθ(wD) est ´elev´ee,
plus la diﬀusion est lente le long de la x-i`eme dimension de l’espace de repr´esentation.

Une illustration du principe est donn´ee en ﬁgure 6.3. Ce mod`ele est baptis´e « HDK-
M ».

124

Chapitre 6. Mod´elisation par diﬀusion de chaleur

Figure 6.3 – Prise en compte du contenu, mod`ele HDK-M. Les deux contenus w1 et
w2 ne se diﬀusent pas `a la mˆeme vitesse sur les diﬀ´erentes dimensions de l’espace de
repr´esentation : le contenu w1 se difuse plus vite sur l’axe horizontal, et le contenu w2
se diﬀuse plus vite sur l’axe vertical. Les indices pr`es des utilisateurs indiquent dans quel
ordre ils sont contamin´es par chaque contenu.

6.2.4 Version asym´etrique

Enﬁn, de la mˆeme fa¸con que dans le chapitre 5, nous pouvons ´egalement d´eﬁnir une
version « asym´etrique » du mod`ele, en apprenant deux projections zi et ωi par utilisateur,
permettant de mod´eliser son comportement en tant que source et son comportement en
tant que r´ecepteur, respectivement. La fonction K s’´ecrit alors :

K asymZ,Ω (t, sD, ui) = (4πt)− d

−ωi||2

2 e− ||zsD

4t

(6.12)

Les projections des utilisateurs sont apprises en appliquant le mˆeme algorithme `a cette
d´eﬁnition de KZ. Des versions asym´etriques peuvent ´egalement ˆetre d´eﬁnies de la mˆeme
fa¸con pour les extensions prenant en compte le contenu, HDK-T et HDK-M.

6.3 Exp´eriences

Dans cette section, nous ´evaluons les diﬀ´erentes versions du mod`ele HDK et de ses exten-
sions en r´ealisant plusieurs exp´eriences sur des donn´ees r´eelles et artiﬁcielles. Nous nous
comparons aux mod`ele DAIC (chapitre 3) et IC projet´e (chapitre 5) en utilisant la mesure
MAP sur un ensemble d’´episodes de diﬀusion de test. Nous eﬀectuons ´egalement quelques
´evaluations empiriques, d´ecrites en ﬁn de section.

6.3.1 Donn´ees artiﬁcielles

Nous commen¸cons par ´etudier le comportement du mod`ele HDK sur des donn´ees artiﬁ-
cielles. Pour cela, nous consid´erons que le contenu d’une information est constitu´e d’un

6.3. Exp´eriences

125

Mod`ele \ Q

DAIC
IC proj.

Version

Sym´etrie

HDK

HDK-T

HDK-M

Sym´etrique

Asym´etrique

Sym´etrique

Asym´etrique

Sym´etrique

Asym´etrique

5 mots

20 mots

40 mots

0,30
0,30

0,13
0,21
0,21
0,15
0,29
0,28
0,15
0,26
0,25
0,18
0,35
0,34
0,16
0,40
0,46
0,19
0,58
0,58

d
5
40
80
5
40
80
5
40
80
5
40
80
5
40
80
5
40
80

0,16
0,17

0,11
0,15
0,15
0,12
0,19
0,18
0,12
0,20
0,18
0,14
0,23
0,24
0,12
0,27
0,31
0,15
0,38
0,38

0,11
0,11

0,08
0,09
0,09
0,09
0,10
0,10
0,09
0,13
0,12
0,10
0,14
0,14
0,08
0,13
0,17
0,10
0,16
0,21

Table 6.1 – Valeurs de MAP obtenues par les diﬀ´erents mod`eles sur les donn´ees artiﬁ-
cielles. Les performances de notre mod`ele sont donn´ees pour plusieurs tailles d de l’espace
de repr´esentation, en version sym´etrique ou asym´etrique, et avec ou sans prise en compte
du contenu.

seul mot parmi un dictionnaire de taille Q. Pour chacune des Q valeurs possibles de wD,
nous construisons un graphe al´eatoire invariant d’´echelle sur une population de 1000 uti-
lisateurs, en utilisant l’algorithme de Barab´asi-Albert. Nous tirons ensuite, pour chaque
arˆete du graphe, une probabilit´e de transmission uniform´ement entre 0 et 0.1. Ces graphes
pond´er´es sont ensuite utilis´es pour g´en´erer 10000 ´episodes d’apprentissage et 10000 ´epi-
sodes de test. Chaque ´episode est g´en´er´e en tirant une source ui ∈ U et un contenu wD
compos´e d’un mot parmi Q, puis en simulant une diﬀusion selon le mod`ele IC sur le graphe
correspondant `a wD. La proc´edure est r´ep´et´ee pour diﬀ´erentes valeurs de Q. Remarquons
qu’une valeur de Q = 1 correspond `a des ´episodes de diﬀusion artiﬁciels g´en´er´es selon un
seul mod`ele IC.

Les r´esultats sont donn´es en table 6.1. Tout d’abord, nous pouvons voir que les perfor-
mances de tous les mod`eles d´ecroissent quand la variance du contenu (nombre de mots
consid´er´es) augmente. La tˆache devient en eﬀet de plus en plus diﬃcile. Toutefois, nous
pouvons constater que notre mod`ele est bien plus robuste `a cette augmentation de la
complexit´e : ses performances diminuent moins vite que celles des mod`eles it´eratifs.

126

Chapitre 6. Mod´elisation par diﬀusion de chaleur

Nous constatons ´egalement que la prise en compte du contenu, qu’il s’agisse de la version
HDK-T ou HDK-M, permet `a notre mod`ele d’obtenir de meilleurs r´esultats et de gagner
encore en robustesse. Le mod`ele HDK-M est bien meilleur que tous les autres, car la fa¸con
dont il prend en compte le contenu mod´elise bien la fa¸con dont les donn´ees artiﬁcielles
ont ´et´e g´en´er´ees.

De plus, nous remarquons dans ce tableau que la version asym´etrique permet d’obtenir de
meilleurs r´esultats, les donn´ees ´etant g´en´er´ees par un mod`ele IC asym´etrique (pi,j (cid:54)= pj,i).
Pour d ﬁx´e, la version asym´etrique des diﬀ´erentes versions de HDK dispose certes de plus
de param`etres, mais ce surplus n’explique pas tous les gains en performances, comme nous
pouvons le v´eriﬁer en comparant les r´esultats des mod`eles sym´etriques pour d = 80 `a ceux
des mod`eles asym´etriques pour d = 40.

Enﬁn, nous pouvons voir que d’une fa¸con g´en´erale, augmenter le nombre de dimensions de
l’espace de repr´esentation permet d’am´eliorer les performances de notre approche. Cepen-
dant, dans certains cas, celles-ci stagnent ou diminuent l´eg`erement lors du passage d’un
mˆeme mod`ele de 40 `a 80 dimensions, en particulier sur les valeurs de Q plus faibles, c’est
`a dire quand d devient trop ´elev´e par rapport `a la complexit´e du probl`eme. Il s’agit d’un
ph´enom`ene de surapprentissage (nous n’avons pas observ´e de stagnation des performances
sur les donn´ees d’apprentissage).

6.3.2 Donn´ees r´eelles

Nous ´evaluons a pr´esent notre approche sur les corpus Digg, Twitter et ICWSM pr´esen-
t´es dans les chapitres pr´ec´edents (page 83). Pour chaque ´episode de diﬀusion D, nous
extrayons une repr´esentation wD du contenu de la fa¸con suivante :

Digg :

le contenu wD est donn´e par la « cat´egorie » `a laquelle appartient l’informa-
tion se diﬀusant. Cette information est fournie directement par l’API utilis´ee pour
r´ecup´erer les donn´ees. Dix cat´egories existent : technologies, business, politique,
international, “lifestyle”, sciences, divertissements, insolite, jeux vid´eo et sports. Le
vecteur wD ∈ R10 a donc une seule composante `a 1, les autres ´etant `a 0, de la
mˆeme fa¸con que sur les donn´ees artiﬁcielles.

Twitter et ICWSM :

le vecteur wD est obtenu au moyen d’une repr´esentation en

sac de mots des messages faisant partie de D, sur un dictionnaire de 2000 mots.

La table 6.2 pr´esente les statistiques des corpus.

Digg

|U|
6424
ICWSM 2270
Twitter
4088

|D|
31861
19027
18636

Densit´e Longueur moyenne

0.04
0.001
0.08

9.57
2.22
7.8

Table 6.2 – Statistiques de jeux de donn´ees.

6.3. Exp´eriences

127

Mod`ele \ Corpus

DAIC
IC proj.

Version

Sym´etrie

HDK

HDK-T

HDK-M

Sym´etrique

Asym´etrique

Sym´etrique

Asym´etrique

Sym´etrique

Asym´etrique

Twitter Digg
0,527
0,545

0,105
0,111

ICWSM
0,785
0,785

0,054
0,083
0,087
0,065
0,092
0,096
0,053
0,090
0,101
0,057
0,093
0,101
0,061
0,080
0,088
0,065
0,092
0,093

0,373
0,510
0,507
0,457
0,535
0,530
0,488
0,539
0,530
0,487
0,551
0,546
0,371
0,509
0,511
0,460
0,537
0,520

0,766
0,780
0,775
0,780
0,776
0,771
0,744
0,773
0,785
0,735
0,768
0,785
0,760
0,782
0,783
0,768
0,782
0,781

d
10
50
100
10
50
100
10
50
100
10
50
100
10
50
100
10
50
100

Table 6.3 – Valeurs de MAP obtenues sur les corpus r´eels. Les valeurs en gras indiquent
les meilleures MAP obtenues par les mod`eles it´eratifs d’une part et par notre approche
d’autre part.

Les r´esultats sont donn´es en table 6.3. Nous pouvons voir que d’une fa¸con g´en´erale, les
mod`eles HDK obtiennent des r´esultats tr`es proches de ceux des mod`eles it´eratifs, et mˆeme
l´eg`erement sup´erieurs sur le corpus Digg. L’approche pr´edictive pr´esent´ee dans ce chapitre
est toutefois bien plus rapide que les mod`eles it´eratifs, puisque la pr´ediction se r´ealise en
calculant simplement des distances entre les utilisateurs, l`a o`u les mod`eles it´eratifs utilisent
une m´ethode d’estimation de type Monte-Carlo. `A titre d’exemple, HDK met quelques
minutes `a inf´erer tous les scores sur les ´episodes de test du corpus Digg, alors que les
mod`eles it´eratifs mettent pr`es d’une heure pour traiter le mˆeme volume de donn´ees 7.
Cette vitesse d’inf´erence peut ˆetre importante pour certaines applications « en ligne »,
c’est `a dire quand la pr´ediction doit ˆetre r´ealis´ee en temps r´eel.

De toutes les versions d’HDK que nous testons, une semble se d´egager : le mod`ele HDK-T
en version asym´etrique. En comparant plus pr´ecis´ement les diﬀ´erentes versions du mod`ele

7. Les exp´erimentations report´ees ici ont ´et´e eﬀectu´ees sur un processeur Intel Core i7 CPU

950@3.07GHz avec 16 gigas de m´emoire RAM.

128

Chapitre 6. Mod´elisation par diﬀusion de chaleur

HDK, nous arrivons globalement `a des conclusions similaires `a celles des corpus artiﬁ-
ciels :

1. L’augmentation du nombre de dimensions de l’espace de repr´esentation permet
d’am´eliorer les performances jusqu’`a un certain point. Ainsi, dans certains cas, les
performances diminuent l´eg`erement entre d = 50 et d = 100. C’est assez souvent
le cas sur Digg.

2. L’apprentissage de deux repr´esentations par utilisateur (versions asym´etriques des
mod`eles) donne de meilleurs r´esultats. Comme sur les donn´ees artiﬁcielles, cela
peut ˆetre partiellement expliqu´e par l’augmentation du nombre de param`etres al-
lou´es `a la mod´elisation de chaque utilisateur. Cependant, dans la plupart des cas,
les r´esultats des versions sym´etriques pour d = 100 restent moins bons que ceux
des versions asym´etriques pour d = 50. Cela conﬁrme l’id´ee selon laquelle la mod´e-
lisation de deux comportements par utilisateur est importante pour la pr´ediction
de la diﬀusion.

3. L’int´egration du contenu permet d’am´eliorer les r´esultats du mod`ele HDK. Cette
am´elioration est plus ou moins importante selon le corpus. Sur Digg, le contenu
est une cat´egorie parmi dix, indiqu´ee sur le site. Ce contenu n’est donc pas bruit´e
et est n´ecessairement pertinent et informatif. C’est donc sur ce corpus que nous
observons la meilleure am´elioration li´ee `a la prise en compte du contenu. Sur Twit-
ter et ICWSM, le contenu est beaucoup plus bruit´e, et il est bien plus diﬃcile
d’en extraire des informations pertinentes avec une repr´esentation en sac-de-mots.
L’am´elioration des performances est donc plus limit´ee sur ces corpus.

6.3.3 R´esultats empiriques

Aﬁn de mieux ´etudier le comportement de notre mod`ele HDK, nous r´ealisons dans cette
sous-section quelques ´evaluations empiriques.

6.3.3.1 Visualisation des projections

La ﬁgure 6.4 montre les repr´esentations des utilisateurs des trois corpus apprises dans
des espaces `a deux dimensions. Nous pouvons voir que notre mod`ele a tendance `a former
des groupes d’utilisateurs similaires. De plus, ces regroupements semblent d’autant plus
marqu´es que les r´esultats obtenus sur le corpus correspondant sont bons.

Ainsi, ce ph´enom`ene est particuli`erement fort sur le corpus ICWSM, avec des groupes
de points entour´es par des grandes marges circulaires pratiquement vides. Ces points
correspondent `a des groupes de sites interagissant quasi-exclusivement entre eux, qui se
retrouvent donc isol´es des autres dans l’espace de repr´esentation. Vers le centre de la ﬁgure
se trouvent d’autres groupes de points moins marqu´es. `A la p´eriph´erie de l’espace, nous
retrouvons des utilisateurs participant `a tr`es peu d’´episodes et qui sont donc ´eloign´es des

6.3. Exp´eriences

129

(a) Twitter

(b) Digg

Figure 6.4 – Repr´esentations des utilisateurs apprises par HDK dans des espaces `a deux
dimensions.

(c) ICWSM

130

Chapitre 6. Mod´elisation par diﬀusion de chaleur

autres jusqu’`a saturation. Sur le corpus Digg, nous n’observons pas ce type de structures.
En revanche, nous pouvons rep´erer divers regroupements assez marqu´es. Enﬁn, sur le
corpus Twitter (o`u nous obtenons les moins bons r´esultats en MAP), les groupements
d’utilisateurs sont peu nombreux et tr`es peu marqu´es.

Ces observations permettent d’envisager d’autres utilisations de notre approche, puisque
l’espace de repr´esentation semble pouvoir servir de base `a plusieurs applications, en par-
ticulier la d´etection de communaut´es d’utilisateurs.

6.3.3.2 Impact du contenu

Ce type de visualisation nous permet ´egalement d’´etudier l’impact du contenu sur le
corpus Digg, o`u la repr´esentation de ce contenu est assez simple (une cat´egorie parmi
dix). Rappelons que les mod`eles HDK-T et HDK-M apprennent les param`etres θ d’une
fonction lin´eaire fθ(wD) = wD.θ permettant d’obtenir une repr´esentation du contenu dans
Rd. Les param`etres θ correspondent donc `a une matrice de taille Q× d, o`u chaque ligne θi
peut ˆetre interpr´et´ee comme une repr´esentation d’un mot du corpus (ou d’une cat´egorie
dans le cas de Digg) dans Rd

La ﬁgure 6.5 montre les repr´esentations des utilisateurs dans un espace `a deux dimensions
apprises par le mod`ele HDK-M sym´etrique, ainsi que les valeurs du changement d’´echelle
θi appris pour chacune des dix cat´egories du corpus Digg. Quelques exemples de l’eﬀet du
changement d’´echelle sont donn´es en bas de la ﬁgure Nous pouvons voir que la plupart
des cat´egories ont pour eﬀet une d´eformation assez importante. De plus, ces cat´egories
peuvent ˆetre s´epar´ees en deux groupes suivant l’orientation de leurs d´eformations :

— international, business, politique, technologies, lifestyle et sciences d´eforment l’es-

pace horizontalement ;

— sports, jeux vid´eo, insolite et divertissement d´eforment l’espace verticalement.

Nous pouvons remarquer que ces deux groupes correspondent `a une division entre d’une
part les sujets plus « s´erieux », et d’autre part des sujets plus l´egers.

Sur le corpus Twitter, nous ne pouvons pas visualiser le contenu ainsi. Toutefois, en nous
int´eressant `a la version HDK-T apprise avec d = 100, nous pouvons calculer la liste
des mots dont les repr´esentations θi ont les normes ||θi||2 les plus ´elev´ees. Dans le cadre
du mod`ele HDK-T, il s’agit des mots ayant l’impact le plus important sur la diﬀusion,
car ils tendent `a d´eplacer la repr´esentation de la source bien plus loin. La liste de ces
mots est donn´ee en table 6.4. Nous pouvons constater qu’il s’agit exclusivement de mots
appartenant au champ lexical de la politique, ce qui n’est pas surprenant ´etant donn´e que
nous avons collect´e ce corpus pendant la campagne pr´esidentielle am´ericaine de 2012. La
politique n’est pas l’unique sujet discut´e au sein de ce corpus, mais ces r´esultats laissent
penser qu’il s’agit de celui impactant le plus la diﬀusion, de la mˆeme fa¸con que sur le corpus
Digg, o`u la cat´egorie politique est l’une de celles appliquant la plus forte d´eformation de
l’espace.

6.4. Conclusion

131

Cat´egorie

D´eformation

x

y

Technologies

Divertissements

Insolite

Jeux Vid´eo

Sports

International

Lifestyle
Sciences

Business
Politique

0,19
0,09
0,01
0,21
0,21
0,01
2,03
0,33
9,99
9,99
(b) D´eformations des cat´egories

0,26
0,43
10,0
2,41
0,26
0,59
0,01
0,1
0,01
0,02

(a) Positions normales des utilisateurs

(c) Technologies

(d) Business

(e) Insolite

Figure 6.5 – Mod`ele HDK-M sym´etrique en deux dimensions sur Digg. Les projections
normales des utilisateurs sont d´eform´ees selon un vecteur correspondant au contenu asso-
ci´e. Quelques exemples de d´eformations sont donn´es.

6.4 Conclusion

Dans ce chapitre, nous avons propos´e une approche pr´edictive du probl`eme de pr´edic-
tion de diﬀusion. Au lieu de baser notre mod`ele sur l’inf´erence, durant l’apprentissage,
d’une information manquante (les probabilit´es de transmission), nous avons propos´e un
algorithme visant `a reproduire uniquement l’ordre dans lesquels les utilisateurs ´etaient
infect´es. Cet algorithme est bas´e sur l’apprentissage d’un ensemble de repr´esentations des
utilisateurs et le calcul des distances les s´eparant, ce qui permet d’obtenir un mod`ele
beaucoup plus rapide en inf´erence, en plus de r´egulariser les relations entres eux comme
dans le chapitre 5. De plus, nous avons propos´e des extensions permettant de prendre
facilement en compte le contenu de l’information diﬀus´ee.

Les r´esultats sur des donn´ees r´eelles et synth´etiques nous ont montr´e que cette approche
obtenait des r´esultats comparables `a ceux des mod`eles it´eratifs. De plus, nous avons vu
que l’int´egration du contenu permettait d’am´eliorer les performances, lorsque celui-ci ´etait
assez pertinent.

-10-5 0 5 10-10-5 0 5 10-3-2-1 0 1 2 3-3-2-1 0 1 2 3-3-2-1 0 1 2 3-3-2-1 0 1 2 3-3-2-1 0 1 2 3-3-2-1 0 1 2 3132

Chapitre 6. Mod´elisation par diﬀusion de chaleur

Norme

252
250
229
222
221
217
196
192
187
186

Mot
Ohio
GOP

Romney

Poll

TeaParty

Obama2012

Sandy
Voter
Obama

Vote

Table 6.4 – Liste des mots ayant les repr´esentations θi les plus grandes, sur le corpus
Twitter.

Bien que les r´esultats ﬁnaux soient proches de ceux obtenus dans le chapitre 5, le gain
en complexit´e temporelle de l’inf´erence peut s’av´erer tr`es important pour certaines appli-
cations. Cette propri´et´e nous a notamment encourag´e `a ´etudier la tˆache de d´etection de
source avec le mˆeme type de mod`ele, qui fait l’objet du chapitre suivant.

Chapitre 7

D´etection de source

R´esum´e Ce chapitre d´etaille notre derni`ere contribution [Bourigault et al., 2016a], qui
concerne le probl`eme de la d´etection de source. Nous apprenons des repr´esentations des
utilisateurs dans Rd de fa¸con `a ce que la repr´esentation de la source d’un ´episode de
diﬀusion soit proche de la repr´esentation de l’´episode lui-mˆeme. Des exp´eriences sur des
donn´ees r´eelles montrent que le mod`ele obtenu est `a la fois meilleur et plus rapide que ceux
pr´esent´es dans le chapitre 2, bas´es sur le graphe. Nous pr´esentons ´egalement une extension
permettant de prendre en compte le contenu de l’information se diﬀusant, ainsi qu’une
extension permettant d’apprendre l’importance de chaque utilisateur dans la d´etection.

7.1 Introduction

7.1.1 Probl`eme

Dans ce chapitre, nous nous int´eressons `a la tˆache de d´etection de source, qui est la tˆache
inverse de celle de pr´ediction de diﬀusion. Le but est de retrouver, `a partir du r´esultat
de la diﬀusion, l’utilisateur ayant cr´e´e une information donn´ee. La principale application
concr`ete de ce probl`eme est de rep´erer la source d’une fausse information ou d’une fuite.
En eﬀet, sur beaucoup de r´eseaux sociaux en ligne, les contenus ne sont pas mod´er´es
a priori. De nombreuses rumeurs ou fausses informations se propagent donc facilement
[S´en´ecat, 2016]. De plus, les r´eseaux sociaux sont en g´en´eral le premier lieu o`u les fuites
ont lieux. Par exemple, il arrive qu’un ﬁlm ou un ´episode de s´erie t´el´evis´ee soit diﬀus´e
sur internet avant sa date de sortie oﬃcielle, en g´en´eral par un utilisateur ayant acc`es `a
une version presse. Dans ce genre de situation, les producteurs chercheront `a savoir d’o`u
provient la fuite aﬁn de ne plus lui fournir de version presse `a l’avenir [Hooton, 2015]. Tous
ces ph´enom`enes ont motiv´e un certain nombre de travaux sur le sujet, pr´esent´es dans le
chapitre 2, section 2.8.

133

134

Chapitre 7. D´etection de source

7.1.2 Limites des approches existantes

Pratiquement tous les mod`eles d´ecrits dans l’´etat de l’art partagent les mˆemes principes
g´en´eraux.

1. Ils consid`erent que le graphe du r´eseau social est connu ;

2. Ils font l’hypoth`ese que la diﬀusion d’information suit un mod`ele de diﬀusion ﬁx´e,
au sein de ce graphe. Il peut s’agir d’un mod`ele SI, d’une extension temporelle du
mod`ele SI [Shah and Zaman, 2010], d’un mod`ele IC [Lappas et al., 2010], ou d’un
mod`ele continu comme NetRate ou CTIC [Farajtabar et al., 2015, Pinto et al.,
2012].

3. Ils utilisent un estimateur de type maximum de vraisemblance : quand ils observent
le r´esultat d’une diﬀusion, ils cherchent l’utilisateur source maximisant la vraisem-
blance de l’observation, sous l’hypoth`ese du mod`ele de diﬀusion consid´er´e.

En d’autres termes, ces approches inversent des mod`eles de diﬀusion classiques. Cela pose
plusieurs probl`emes :

1. La qualit´e de la pr´ediction d´epend enti`erement de la pertinence du mod`ele de
diﬀusion consid´er´e, et du graphe utilis´e. Nous avons d´ej`a parl´e dans les chapitres
pr´ec´edents des probl`emes li´es `a l’utilisation d’un graphe ﬁx´e a priori : donn´ees
manquantes, non-pertinence des liens explicites, etc...

2. L’estimation de la source la plus probable ˆs est coˆuteuse en calcul. Il est souvent
n´ecessaire, pour trouver ˆs, de calculer la longueur des plus courts chemins entre
toutes les paires d’utilisateurs du graphe.

De plus, les mod`eles de d´etection de source d´ecrits dans le chapitre 2 sont la plupart
du temps test´es sur des donn´ees synth´etiques, i.e. des ´episodes de diﬀusion g´en´er´es par
le mod`ele de diﬀusion utilis´e en pr´ediction. Bien que les r´esultats ainsi obtenus soient
int´eressants, seules des exp´eriences sur des ´episodes de diﬀusion r´eels permettraient de
vraiment rendre compte des capacit´es de ces mod`eles. Or, seuls de rares travaux [Pinto
et al., 2012, Farajtabar et al., 2015] s’´evaluent sur des ´episodes de diﬀusion r´eels, et les
r´esultats obtenus sont largement inf´erieurs `a ceux obtenus sur des donn´ees synth´etiques.
En particulier, dans [Farajtabar et al., 2015], certains mod`eles bas´es sur les graphes ob-
tiennent des r´esultats nuls sur des ´episodes de diﬀusion r´eels, et ne parviennent `a identiﬁer
la source qu’en observant plusieurs ´episodes de diﬀusion commen¸cant par le mˆeme utili-
sateur.

Nous proposons donc dans ce chapitre d’appliquer l’apprentissage de repr´esentations `a
ce probl`eme. Cela nous permet, comme dans les chapitres pr´ec´edents, d’obtenir un mo-
d`ele plus compact, bien plus rapide, et de r´egulariser les relations entre utilisateurs sans
nous limiter `a un graphe ﬁx´e. De plus, nous proposons plusieurs extensions permettant de
prendre en compte l’importance des utilisateurs et le contenu de l’information se propa-
geant. Cette approche est test´ee sur des ´episodes de diﬀusion r´eelles et artiﬁcielles.

7.2. Apprentissage de repr´esentations pour la d´etection de source.

135

7.2 Apprentissage de repr´esentations pour la d´etec-

tion de source.

7.2.1 Mod`ele

Soit D un ´episode de diﬀusion. Le premier utilisateur infect´e dans celui-ci est not´e sD,
et correspond `a la source de l’information consid´er´ee. Nous notons ˆU D = U D∞ \ {sD}
l’ensemble des utilisateurs infect´es dans D priv´e de la source. Notre but dans ce chapitre
est donc de retrouver sD `a partir de ˆU D.

Pour cela, nous apprenons deux projections zi et ωi pour chaque utilisateur ui, mod´elisant
respectivement son comportement en tant que source et son comportement en tant que
r´ecepteur de contenu. Ces projections sont apprises en suivant le principe suivant :

La repr´esentation zsD de l’utilisateur sD devrait ˆetre situ´ee au point zD =
φ( ˆU D), qui correspond `a une repr´esentation de l’´episode de diﬀusion D, cal-
cul´ee `a partir des projections ωi des utilisateurs de ˆU D.

Plusieurs d´eﬁnitions de φ : 2U → Rd sont possibles 8. Nous choisissons d’utiliser une
moyenne, qui a l’avantage d’ˆetre rapide `a calculer :

(cid:88)

ui∈ ˆU D

zD = φ( ˆU D) =

1
| ˆU D|

ωi

(7.1)

Cette d´eﬁnition pr´esente ´egalement l’avantage d’ˆetre relativement stable par rapport aux
utilisateurs manquants : en eﬀet, pour | ˆU D| suﬃsamment grand, ∀ui ∈ U : φ( ˆU D∪{ui}) ≈
φ( ˆU D). Cela permet `a la repr´esentation de rester pertinente dans le cas o`u le mod`ele
manipule des ´episodes de diﬀusion incomplets. Une illustration de ce principe (avec une
seule projection par utilisateur) est donn´ee en ﬁgure 7.1, o`u la source de l’´episode D est
projet´ee pr`es du centre des utilisateurs ˆU D. Cette repr´esentation zD peut, d’une certaine
fa¸con, ˆetre vue comme la source de l’information dans l’espace de repr´esentation, de la
mˆeme fa¸con que dans le chapitre 6. Les deux mod`eles ne sont toutefois pas ´equivalents (cf
fonction objectif 7.3).

Pour retrouver la source d’un ´episode de diﬀusion D ´etant donn´e ˆU D, le mod`ele recherche
l’utilisateur ui dont la projection-source zi est la plus proche de la repr´esentation zD :

ˆs = arg min
ui∈U\ ˆU D

||zi − zD||2

(7.2)

o`u zD est calcul´ee selon la formule 7.1 appliqu´ee aux utilisateurs de ˆU D. Aﬁn d’apprendre
les ensembles de projections Z = (zi)ui∈U et Ω = (ωi)ui∈U de fa¸con `a ce que la formule

8. Rappelons que 2U d´esigne l’ensemble des parties de U

136

Chapitre 7. D´etection de source

Figure 7.1 – Les utilisateurs de l’´episode de diﬀusion D sont projet´es de fa¸con `a ce que
la source se trouve au centre des repr´esentations des utilisateurs infect´es.

.

7.2 soit valide, nous minimisons la fonction de coˆut suivante :

L(Z, Ω;D) = (cid:31)D∈D (cid:31)ui(cid:31)=sD
= (cid:31)D∈D (cid:31)ui /∈U D

ui /∈ ˆU D

h(cid:30)||zi − zD||2 − ||zsD − zD||2(cid:29)
h(cid:30)||zi − zD||2 − ||zsD − zD||2(cid:29)

(7.3)

o`u h est une fonction hingeloss : h(x) = max(1 − x, 0). L est donc une fonction de coˆut
d’ordonnancement « paire `a paire » exprimant le fait que la repr´esentation-source de sD,
not´ee zSD, doit ˆetre plus proche de la repr´esentation de D (second terme de la soustraction)
que les repr´esentations-sources des autres utilisateurs (premier terme de la soustraction)
de fa¸con `a ˆetre celle qui serait pr´edite par la fonction 7.2.

Ce coˆut peut ˆetre minimis´e en utilisant une descente de gradient stochastique proche
de celle du chapitre 6. Celle-ci est d´etaill´ee dans l’algorithme 4. Nous commen¸cons par
initialiser toutes les projections au hasard (lignes 2 et 3). Puis, `a chaque it´eration, nous
tirons un ´episode D (ligne 9) et un utilisateur « non-source » uj ne faisant pas partie de
U D
∞ (ligne 10). Si la projection zsD de la vraie source de D n’est pas plus proche de la
repr´esentation zD que zj avec une marge de 1 (ligne 15), toutes les projections concern´ees
(i.e les repr´esentation r´ecepteurs des utilisateur de ˆU D, ainsi que zj et zsD) sont mises `a jour
avec un pas de gradient (lignes 16 `a 19). Ce pas de gradient rapproche la repr´esentation
zD de zsD et l’´eloigne de zj. L’apprentissage continue jusqu’`a convergence, qui est test´ee
en observant l’´evolution de la valeur de L toutes les F it´erations (ligne 24).

De la mˆeme fa¸con que dans les chapitres pr´ec´edents, le tirage al´eatoire r´ealis´e en lignes 9
et 10 introduit un biais dans l’apprentissage, les utilisateurs n’apparaissant pas dans les
´episodes plus longs ´etant consid´er´es plus souvent. Chaque terme de la double somme 7.3
est tir´e avec une probabilit´e :

1

|D| × (N − |U D|)

7.2. Apprentissage de repr´esentations pour la d´etection de source.

137

Algorithme 4 : Apprentissage de repr´esentations pour la d´etection de source
Entr´ees :
U : Ensemble d’utilisateurs ;
D : Ensemble d’apprentissage ;
d : Nombre de dimensions
 : Pas de gradient ;
F : Fr´equence des tests de convergences ;
Sorties :
Z = {∀ui ∈ U : zi ∈ Rd} ; Ω = {∀ui ∈ U : ωi ∈ Rd} ;
1 pour ui ∈ U faire

2

Initialiser zi al´eatoirement, de fa¸con uniforme sur [−1, 1]d
Initialiser ωi al´eatoirement, de fa¸con uniforme sur [−1, 1]d

3
4 ﬁn
5 it ← 0 ;
6 oldL ← 0 ;

7 nbTermes ←(cid:80)

(cid:0)N − |U D|(cid:1)

D∈D
8 tant que true faire
Tirer un ´episode D ∈ D ;
9
Tirer uj (cid:54)∈ U D ;
Calculer zD suivant la formule 7.1 ;
ds ← ||zsD − zD||2 ;
dj ← ||zj − zD||2 ;
β ← |D|×(N−|U D|)
;
si dj − ds < 1 alors

nbTermes

10

11

12

13

14

15

zsD ← zsD −  × β × 2 (zsD − zD) ;
zj ← zj +  × β × 2 (zj − zD) ;
pour ux ∈ ˆU D faire

ωx ← ωx −  × β × 2

| ˆU D| (zj − zsD)

16

17

18

19

20

21

22

23

24

25

26

27

28

29
30 ﬁn

ﬁn

ﬁn
si it mod F = 0 alors
L ← L(Z, z)
si L ≥ oldL alors

retourner (Z, Ω);

ﬁn
oldL ← L;

ﬁn
it ← it + 1

138

Chapitre 7. D´etection de source

Pour ´eviter le biais, chaque terme de la double somme 7.3 devrait ˆetre tir´e avec la mˆeme
probabilit´e, c’est `a dire :

1(cid:80)

D∈D

N − |U D|

Nous calculons donc, en ligne 14, un poids β permettant de corriger ce biais :

|D| × (N − |U D|)
N − |U D|

β =

(cid:80)

D∈D

Ce poids est appliqu´e lors de la mise `a jour des param`etres (lignes 16 `a 19).

7.2.1.1 R´egularisation des projections

Dans le coˆut d´eﬁni au dessus, les deux repr´esentations des utilisateurs sont apprises in-
d´ependamment, pour mod´eliser son comportement en tant que source et en tant que
r´ecepteur. En pratique, bien que ces comportements puissent ˆetre assez diﬀ´erents, il est
raisonnable de penser qu’ils ne sont pas d´ecorr´el´es : ces deux comportements sont en eﬀet
des cons´equences des centres d’int´erˆet de l’utilisateur [Barbieri et al., 2013a]. Pour prendre
en compte cette propri´et´e, nous ajoutons un terme de r´egularisation au coˆut :
||zi − ωi||2

h(cid:0)||zi − zD||2 − ||zsD − zD||2(cid:1) + λ

Lλ(Z, Ω;D) =

(cid:88)

(cid:88)

(7.4)

(cid:88)

ui

D∈D

ui /∈U D

Le terme de r´egularisation favorise les projections telles que zi et ωi soient plus proches,
suivant un hyperparam`etre λ . Cette r´egularisation peut ´egalement am´eliorer les capacit´es
de g´en´eralisation de notre mod`ele : sans ce terme, aucune repr´esentation zi ne pourrait
ˆetre apprise pour un utilisateur n’apparaissant jamais en tant que source dans D. Avec ce
terme de r´egularisation liant les deux repr´esentations zi et ωi, une partie de l’information
apprise sur ωi peut ˆetre transf´er´ee sur zi.

7.2.2 Extensions

7.2.2.1 Mod´elisation de l’importance des utilisateurs

Nous pr´esentons maintenant une premi`ere extension possible de notre mod`ele, consistant
`a apprendre pour chaque utilisateur un poids αi pour red´eﬁnir zD ainsi :

(cid:88)

eS.αi(cid:80)

zD =

ωi

(7.5)

ui∈ ˆU D

(uj∈ ˆU D)

eS.αj

7.3. Exp´eriences

139

o`u S ∈ R est un param`etre et o`u la fraction correspond `a une fonction softmax permettant
de transformer un vecteur de k valeurs r´eelles en un vecteur de [0, 1]k sommant `a 1. Ainsi,
zD devient un barycentre des repr´esentations-r´ecepteurs des utilisateurs de ˆU D, pond´er´ees
par les valeurs α. Le poids de chaque utilisateur mod´elise donc son importance pour
la d´etection de source. Par exemple, sur Twitter, certains utilisateurs ne sont que des
robots, repostant automatiquement les hashtags et les tweets populaires dans le but de
gagner en visibilit´e aﬁn de poster des publicit´es. Dans ce cas, l’infection de cet utilisateur
donne tr`es peu d’information sur l’identit´e de la source, et le mod`ele pourra apprendre
un poids αi ≈ 0. De plus, autoriser le mod`ele `a se concentrer sur les utilisateurs les plus
discriminants peut aussi permettre de s´electionner les utilisateurs les plus importants
dans certains contextes applicatifs, o`u seul un nombre r´eduit d’entre eux peuvent ˆetre
monitor´es (comme dans [Seo et al., 2012], par exemple). La valeur de S, ﬁx´ee `a 1 dans
nos exp´eriences, permet de modiﬁer l’importance de l’utilisateur de poids maximum (plus
S est ´elev´e, plus le softmax se rapproche d’une fonction maximum).

7.2.2.2 Int´egration du contenu

De la mˆeme fa¸con que dans le chapitre 6, nous proposons une extension de notre mod`ele
permettant de prendre en compte le contenu d’une information pour la d´etection de source.
Pour cela, nous transformons la repr´esentation zD en fonction du contenu de l’information
consid´er´ee. Nous utilisons la mˆeme id´ee que celle du mod`ele HDK-T, qui a donn´e les
meilleurs r´esultats dans le chapitre 6 : le contenu d’un ´episode D est repr´esent´e par un
vecteur-ligne wD ∈ RQ, et nous apprenons les param`etres θ ∈ RQ×d d’une fonction lin´eaire
fθ permettant de projeter ce contenu dans Rd.

fθ(wD) = wD.θ

La repr´esentation de D est alors calcul´ee comme :

(7.6)

 1

| ˆU D|

zD =

 + fθ(wD)

ωi

(cid:88)

ui∈ ˆU D

Les param`etres θ sont appris en mˆeme temps que les projections des utilisateurs, avec
l’algorithme de descente de gradient appliqu´e `a cette d´eﬁnition de zD.

7.3 Exp´eriences

Nous pr´esentons dans cette section les r´esultats de plusieurs exp´eriences eﬀectu´ees sur des
donn´ees r´eelles et artiﬁcielles, et dans plusieurs contextes exp´erimentaux diﬀ´erents. Nous
´evaluons aussi l’impact des deux extensions pr´esent´ees dans la section pr´ec´edente.

140

Chapitre 7. D´etection de source

|U|
100
Artiﬁciel
Lastfm 1984
5000
Weibo
Twitter
4107

|E|
262

235011
20784
128855

|D|
10000
331829
44345
16824

Densit´e

2%
5%

0.08%

1%

Table 7.1 – Quelques statistiques sur les corpus : nombre d’utilisateurs |U|, de liens dans
le graphe |E|, d’´episodes de diﬀusion, et densit´e du graphe (voir section 7.3.1.2 pour la
d´eﬁnition du graphe utilis´e).

7.3.1 Param`etres

7.3.1.1 Corpus

Nous utilisons les corpus Lastfm et Twitter, ainsi qu’un corpus issus du site Weibo. Ce
site est un service de micro-blogging similaire `a Twitter, utilis´e essentiellement en Chine.
Le corpus est constitu´e de l’ensemble de l’activit´e du site sur une p´eriode d’un an [wa Fu
et al., 2013]. Les ´episodes de diﬀusion en sont extraits selon une m´ethode similaire `a celle
de [Gomez-Rodriguez et al., 2011].

1. Le corpus est vu comme un grand graphe h´et´erog`ene contenant deux types de

nœuds : les utilisateurs et les messages.

2. Chaque message est reli´e `a son auteur et aux messages qu’il r´ef´erence par le biais

de retweets ou de r´eponses.

3. Chaque composante connexe du sous-graphe des messages correspond ainsi `a un
ensembles de messages discutant d’un mˆeme sujet et s’inﬂuen¸cant les uns les autres.

4. Les auteurs des messages de chacune de ces composantes connexes, associ´es aux

temps auxquels ils ont post´e ces messages, forment un ´episode de diﬀusion.

Le corpus est ensuite ﬁltr´e pour ne garder que 5000 utilisateurs parmi les plus actifs. De
plus, nous eﬀectuons des exp´eriences sur un corpus artiﬁciel g´en´er´e comme suit. Nous
commen¸cons par construire un graphe al´eatoire invariant d’´echelle, en utilisant l’algo-
rithme de Barab´asi-Albert, contenant 100 utilisateurs. Nous tirons ensuite sur les liens de
ce graphe des probabilit´es de transmission, uniform´ement sur [0, 0.1], et utilisons celles-ci
pour g´en´erer des ´episodes de diﬀusion avec le mod`ele IC. Les propri´et´es de ces corpus sont
r´esum´ees dans la table 7.1.

7.3.1.2 Mod`eles de r´ef´erences

Nous comparons notre approche `a plusieurs heuristiques ou mod`eles issus de la litt´erature,
toutes bas´ees sur le graphe du r´eseau social.

7.3. Exp´eriences

141

OutDeg : cette heuristique simple a ´et´e propos´ee dans [Farajtabar et al., 2015]. `A
partir de de ˆU D, nous recherchons l’ensemble des « sources possibles » dans le
graphe, i.e tous les utilisateurs `a partir desquels il existe un chemin vers chaque
´el´ement de ˆU D dans le graphe. Ces diﬀ´erentes « sources possibles » sont ensuite
class´ees par degr´e sortant, le plus ´elev´e correspondant `a la source la plus vraisem-
blable.

Centre de Jordan :

l’utilisation du centre de Jordan comme estimateur de source
a ´et´e ´etudi´ee dans [Luo et al., 2015a]. Notre contexte exp´erimental n’´etant pas
exactement le mˆeme que dans [Luo et al., 2015a], nous en adaptons un peu la
formulation : la source pr´edite est celle minimisant la distance maximale `a tout
utilisateur infect´e ˆU D dans le graphe.

ˆs = arg min
ui /∈ ˆU D

max
uj∈ ˆU D

distG(ui, uj).

Pinto :

le mod`ele d´ecrit dans [Pinto et al., 2012]. Celui-ci est bas´e sur un mod`ele
de diﬀusion continu avec des d´elais de transmission suivant une loi gaussienne, et
utilise une heuristique bas´ee sur l’extraction d’un arbre couvrant (voir le chapitre
2).

Toutes ces m´ethodes sont bas´ees sur le graphe du r´eseau social. Comme dans les cha-
pitres pr´ec´edents, nous ne connaissons pas ce graphe dans nos corpus. Toutefois, nous ne
pouvons pas utiliser le graphe des « exemples positifs » comme dans le chapitre 3, c’est `a
dire cr´eer `a lien (ui, uj) `a chaque fois qu’un ´episode de diﬀusion d’apprentissage contient
l’utilisateur ui puis l’utilisateur uj. En eﬀet, plusieurs mod`eles de r´ef´erence utilisent les
longueurs des plus courts chemins dans le graphe. Ces longueurs auraient peu de sens dans
le graphe ainsi construit. Nous utilisons donc l’algorithme du chapitre 3 pour apprendre
les param`etres d’un mod`ele IC `a partir de l’ensemble d’apprentissage DAIC du chapitre
3. Puis, nous conservons dans le graphe les liens (ui, uj) tels que pi,j > S, o`u S est un seuil
ﬁx´e empiriquement `a partir des r´esultats obtenus sur un ensemble de validation. C’est la
densit´e de ce graphe qui est indiqu´ee dans la table 7.1. Rappelons bien que ce graphe n’est
utilis´e que par certains mod`eles de r´ef´erence, notre approche n’en ayant pas besoin.

7.3.1.3

´Evaluation

Les performances des diﬀ´erents mod`eles sont ´evalu´ees sur un ensemble de test D(cid:48) avec une
mesure de Top-K. Celle-ci est calcul´ee en classant les diﬀ´erents utilisateurs susceptibles
d’ˆetre sources suivant leurs scores (vraisemblance, degr´e ou distance `a zD, suivant le
mod`ele consid´er´e). Si la vraie source sD se trouve parmi les K utilisateurs les mieux
class´es, la valeur du Top-K est 1, sinon 0.

142

Chapitre 7. D´etection de source

Figure 7.2 – Dur´ee de l’apprentissage et performances obtenues (en Top-5) sur le corpus
Weibo.

7.3.2 R´esultats

7.3.2.1 Choix du nombre de dimensions

Nous commen¸cons par reproduire l’exp´erience du chapitre 5 pour s´electionner le nombre de
dimensions. Nous observons la dur´ee de l’apprentissage et les performances obtenues par
notre mod`ele pour diﬀ´erentes valeurs de d, sur le corpus Weibo. La ﬁgure 7.2 pr´esente les
r´esultats obtenus. Nous constatons que la dur´ee de l’apprentissage croit lin´eairement avec
d, mais que les performances du mod`ele stagnent `a partir d’une trentaine de dimensions.
Nous utiliserons donc une valeur de d = 30 dans toutes nos exp´eriences.

Nous testons maintenant notre mod`ele dans plusieurs contextes exp´erimentaux diﬀ´e-
rents.

7.3.2.2 D´etection de source classique

Il s’agit du contexte normal : notre but est de retrouver sD `a partir de ˆU D. Les r´esultats de
notre mod`ele (not´e RL, pour « representation learning ») sont donn´es pour une valeur du
param`etre de r´egularisation λ = 10−4, qui nous permettait d’obtenir les meilleurs r´esultats
sur un ensemble de validation. Les r´esultats sont pr´esent´es en ﬁgure 7.3.

Nous pouvons tout d’abord voir que sur le corpus artiﬁciel, notre mod`ele et celui des
centres de Jordan obtiennent de meilleurs r´esultats que les autres. Rappelons que sur ce
corpus, les ´episodes de diﬀusion sont g´en´er´es selon un mod`ele DAIC. Comme le corpus
est assez petit, la m´ethode d’extraction de graphe utilis´ee (bas´ee sur l’apprentissage des
param`etres d’un mod`ele IC) retrouve facilement les vrais liens du graphe `a partir de D.
Dans ce contexte, le mod`ele Jordan obtient d’excellentes performances car il est bas´e sur
le calcul exhaustif de toutes les distances dans le graphe. Notre approche est capable
d’obtenir des r´esultats proches de ceux-ci, sans faire l’hypoth`ese d’un mod`ele de diﬀusion
ﬁx´e et connu et sans utiliser ce graphe. Le mod`ele de Pinto, par contre, base sa pr´ediction

01020304050810121416182022dTime to converge (hours)010203040500.40.450.50.550.60.65dTop-5 precision7.3. Exp´eriences

143

Figure 7.3 – D´etection de source sur des ´episodes de diﬀusion complets.

sur un arbre extrait du graphe par un parcours en largeur d’abord, et ignore donc beaucoup
d’informations pertinentes, ce qui limite ses performances.

Sur le corpus Weibo, le mod`ele IC appris ne peut retrouver le vrai graphe de diﬀusion
(comme nous l’avons vu dans le chapitre 5). D`es lors, les r´esultats des mod`eles Pinto et
Jordan sont plus proches. En revanche, notre mod`ele bat tous les autres, car il ne repose
pas sur une connaissance a priori de ce graphe. Le fait que le mod`ele Pinto soit l´eg`erement
moins bon que le mod`ele Jordan peut s’expliquer par le fait que le premier fait l’hypoth`ese
que les d´elais de transmission suivent une loi Gaussienne, ce qui n’est pas r´ealiste dans
des corpus r´eels [Farajtabar et al., 2015].

Enﬁn, les corpus Twitter et Lastfm sont plus diﬃciles : le fait que deux utilisateurs aient
´ecout´e la mˆeme chanson ou utilis´e le mˆeme hashtag ne veut pas forc´ement dire qu’il y a eu
contamination de l’un par l’autre. Dans ce contexte, le graphe extrait de D devient moins
pertinent : il peut s’agir de liens de corr´elation et non de causalit´e. Tous les mod`eles de
r´ef´erence ´etant bas´es sur ce graphe, ils obtiennent des r´esultats moins bons que ceux de
notre mod`ele.

Notons que bien que les r´esultats de l’ensemble des mod`eles puissent sembler assez mau-
vais sur Twitter, ils peuvent tout de mˆeme ˆetre utilis´es dans certains contextes, comme
celui d´ecrit dans [Luo et al., 2015a] : quand l’administrateur d’un r´eseau doit d´ecider
quels utilisateurs inspecter pour retrouver la source d’une rumeur (avec un coˆut associ´e `a
cette inspection), tout mod`ele donnant des r´esultats meilleurs qu’un mod`ele al´eatoire est
susceptible d’ˆetre important.

135102000.20.40.60.81KTop-K precisionArtificialRL  Pinto  outDeg  Jordan  135102000.10.20.30.4KTop-K precisionLastfmRL  Pinto  outDeg  Jordan  135102000.20.40.60.8KTop-K precisionWeiboRL  Pinto  outDeg  Jordan  135102000.050.10.150.2KTop-K precisionTwitterRL  Pinto  outDeg  Jordan  144

Chapitre 7. D´etection de source

Figure 7.4 – D´etection de source sur des ´episodes de diﬀusion partiels (20%).

7.3.2.3 D´etection de source sur des cascades partielles

Dans certaines applications r´eelles, il est possible que les ´episodes de diﬀusion ne soient
que partiellement observ´es durant la d´etection de source. Pour ´etudier l’impact de ce
ph´enom`ene sur les performances, nous retirons au hasard des utilisateurs de ˆU D avant
de r´ealiser la pr´ediction, en ne gardant que 20% de ceux-ci. Les r´esultats se trouvent en
ﬁgure 7.4.

Sur le corpus artiﬁciel, les performances de tous les mod`eles chutent clairement. Notre
mod`ele se retrouve au mˆeme niveau que Pinto, et largement en dessous du mod`ele Jordan.
Ici, la sup´eriorit´e du mod`ele Jordan est due au fait qu’un faible nombre d’utilisateurs
observ´es suﬃse `a r´eduire grandement le nombre de sources possibles, le graphe ´etant
assez creux. De plus, le calcul des plus courts chemins dans le graphe traduit bien la fa¸con
dont l’information se diﬀuse dans un mod`ele IC (les plus courts chemins correspondant
souvent aux plus vraisemblables). En revanche, sur le corpus Weibo, les mod`eles restent
assez stables, et notre approche reste meilleure.

Il est int´eressant de remarquer ensuite que les r´esultats sur Lastfm et Twitter sont dif-
f´erents. Sur le corpus Lastfm, outDeg obtient de meilleurs r´esultats que les deux autres
mod`eles de r´ef´erence, alors que c’est le mod`ele des centres de Jordan qui bat les deux
autres sur Twitter. Une explication possible est que sur Lastfm, les longues chaˆınes de
diﬀusion sont rares, les chansons ´etant d’abord ´ecout´ees par des « early adopters », qui
sont responsables de la plupart des infections suivantes. Le degr´e sortant est donc dans ce

135102000.10.20.30.40.50.60.7KTop-K precisionArtificialRL  Pinto  outDeg  Jordan  135102000.050.10.150.20.250.30.35KTop-K precisionLastfmRL  Pinto  outDeg  Jordan  135102000.20.40.60.8KTop-K precisionWeiboRL  Pinto  outDeg  Jordan  135102000.020.040.060.080.10.120.140.16KTop-K precisionTwitterRL  Pinto  outDeg  Jordan  7.3. Exp´eriences

145

cas un bon indicateur de l’inﬂuence des utilisateurs. Sur Twitter, les longues chaˆınes de
diﬀusion sont plus courantes. Cela rend la mesure des centres de Jordan plus pertinente,
car elle revient `a rechercher la source minimisant le nombre de retweets n´ecessaires pour
atteindre tous les utilisateurs de ˆU D. De la mˆeme fa¸con que sur Weibo, les performances
du mod`ele Pinto sont faibles car ce mod`ele prend aussi en compte les d´elais de trans-
missions, qui sont compliqu´es `a extraire et tr`es bruit´es, comme nous l’avons vu dans le
chapitre 3. Sur ces deux corpus, Lastfm et Twitter, notre approche obtient de meilleurs
r´esultats.

D’une fa¸con g´en´erale, les r´esultats obtenus vont dans le mˆeme sens que ceux du chapitre
5 : certains corpus semblent plus « faciles » que d’autres, et les performances relatives des
mod`eles varient d’un corpus `a l’autre. Toutefois, notre approche obtient syst´ematiquement
de meilleurs r´esultats sur les corpus r´eels, grˆace `a l’utilisation d’un espace de repr´esentation
qui la rend plus robuste au bruit et `a la parcimonie des donn´ees.

7.3.2.4 Apprentissage sur des cascades partielles

Dans l’exp´erience pr´ec´edente, nous avons consid´er´e que nous avions acc`es `a des ´episodes
de diﬀusion d’apprentissage complets, et `a des ´episodes de test partiels. En pratique, il est
possible que les ´episodes d’apprentissage soient eux mˆeme partiellement observ´es. Pour
´etudier ce cas, nous ﬁltrons les ´episodes d’apprentissage de la mˆeme fa¸con que les ´episodes
de test, en gardant seulement 20% des utilisateurs, de fa¸con al´eatoire sur chaque ´episode
de d’apprentissage. Les r´esultats sont donn´es en ﬁgure 7.5

Sur la plupart des corpus, les performances relatives des mod`eles sont similaires `a celles
obtenues dans l’exp´erience pr´ec´edente, ce qui n’est pas surprenant puisque les ensembles
de test sont les mˆemes. En revanche, sur le corpus artiﬁciel, notre mod`ele bat largement
celui de Jordan, ce qui n’´etait pas le cas avant. Cela est dˆu au fait que le graphe appris est
cette fois-ci beaucoup moins pertinent, puisque les donn´ees d’apprentissage sont partielles.
Au ﬁnal, dans cette exp´erience, notre approche est meilleure que tous les mod`eles de
r´ef´erence.

7.3.3 Complexit´e

Pour l’apprentissage, notre mod`ele et l’extraction de graphe utilisent des algorithmes
it´eratifs prenant `a peu pr`es autant de temps `a converger. Notre mod`ele n´ecessite toutefois
de stocker beaucoup moins de param`etres. En revanche, de la mˆeme fa¸con que dans le
chapitre 6, inf´erer la source est beaucoup plus rapide avec notre mod`ele : cela prend
en g´en´eral moins d’une seconde par ´episode, alors que les mod`eles graphiques peuvent
prendre jusqu’`a quelques minutes, car le calcul des plus courts chemins dans le graphe est
bien plus lent que celui des distances dans l’espace de repr´esentation. Notre mod`ele est

146

Chapitre 7. D´etection de source

Figure 7.5 – D´etection de source sur des ´episodes de diﬀusion partiels (20%) avec ap-
prentissage sur des ´episodes ´egalement partiels (20%).

donc susceptible de mieux passer `a l’´echelle, ce qui est important lorsque l’on manipule
de grands r´eseaux sociaux en ligne.

7.3.4 Importances des utilisateurs

Nous testons maintenant l’extension d´ecrite en section 7.2.2.1. Nous comparons les r´esul-
tats obtenus par celle-ci `a ceux de la version de base, sur les corpus r´eels. Les r´esultats
sont pr´esent´es en table 7.2. Nous constatons que sur le corpus Twitter, l’utilisation de
poids utilisateurs am´eliore les r´esultats d’environ 10%. En eﬀet, Twitter est un r´eseau
social largement utilis´e et particuli`erement bruit´e. Apprendre des poids mod´elisant l’im-
portance des utilisateurs permet `a notre mod`ele de limiter l’impact des utilisateurs les
plus chaotiques. Nous observons un eﬀet similaire sur le corpus Lastfm. Sur le corpus
Weibo, en revanche, les r´esultats restent sensiblement ´egaux `a ceux du mod`ele normal, ce
qui pourrait indiquer que les utilisateurs sont beaucoup plus homog`enes dans ce corpus.
Nous pouvons le v´eriﬁer en calculant la variance des valeurs αi apprises sur chaque jeu de
donn´ees : celle-ci est de 0.12 sur Twitter et de 0.15 sur Lastfm, contre 0.08 sur Weibo. Ces
r´esultats pourraient permettre de s´electionner les M utilisateurs `a utiliser pour obtenir
la meilleure d´etection possible, dans le cadre d’un probl`eme de s´election de moniteurs
comme celui d´ecrit dans [Seo et al., 2012].

135102000.050.10.150.20.250.30.35KTop-K precisionArtificialRL  Pinto  outDeg  Jordan  135102000.050.10.150.20.25KTop-K precisionLastfmRL  Pinto  outDeg  Jordan  135102000.10.20.30.40.50.60.7KTop-K precisionWeiboRL  Pinto  outDeg  Jordan  135102000.020.040.060.08KTop-K precisionTwitterRL  Pinto  outDeg  Jordan  7.3. Exp´eriences

147

Top-K

1

3

5

10

20

RL

RL + poids

gain

RL

RL + poids

gain

RL

RL + poids

gain

0.020
0.021
3%

0.052
0.065
25%

Twitter
0.042
0.047
10%
Lastfm
0.12
0.1335
11%
Weibo
0.51
0.50

0.058
0.073
25%

0.166
0.175
5%

0.099
0.107
8%

0.2545
0.2605

2%

0.141
0.154
9%

0.374
0.378
1%

0.82
0.31
0.31
0.84
0% -2.3% +0% +4% +1%

0.72
0.75

0.59
0.60

Table 7.2 – D´etection de source avec prise en compte de l’importance des utilisateurs.
Les mod`eles sont test´es sur les ´episodes de longueur 3 ou plus. En eﬀet, sur les ´episodes
de longueur 2 (pour lesquels | ˆU D| = 1), l’utilisation d’une pond´eration ne change pas la
pr´ediction.

Top-K

1

3

5

10

20

RL

0.028
RL avec contenu 0.043

0.05
0.069

0.142
0.179
56% 38% 38% 26% 26%

0.102
0.128

0.072
0.099

gain

Table 7.3 – Int´egration du contenu sur le corpus Twitter

7.3.5 Int´egration du contenu

Enﬁn, nous testons la version avec contenu de notre mod`ele d´ecrite en section 7.2.2.2. Cette
version est test´ee sur le corpus Twitter. Nous extrayons de chaque ´episode de diﬀusion une
repr´esentation de son contenu sous la forme d’un sac de mots des tweets qu’il contient.
Le dictionnaire est ﬁltr´e pour ne garder que 2000 mots. La r´ecup´eration des donn´ees s’est
limit´ee aux tweets anglophones, mais l’approche reste valide pour d’autres langues. Les
r´esultats sont pr´esent´es en table 7.3. Nous pouvons voir que la prise en compte du contenu
augmente largement nos performances, en particulier en Top-1.

7.3.5.1

´Evaluation empirique

Comme nous l’avons vu dans le chapitre 6, section 6.3.3.2, les param`etres θ de la fonction
de projection du contenu forment une matrice de taille 2000 × d, dont chaque ligne θi
peut ˆetre vue comme une repr´esentation du i-`eme mot du dictionnaire dans Rd. La table
7.4 pr´esente la liste des dix mots dont les repr´esentations ont les normes les plus ´elev´ees,
c’est `a dire les mots ayant le plus grand impact sur la pr´ediction de la source selon notre
mod`ele. Nous pouvons voir qu’`a l’exception de « new » et « retweet », il s’agit de mots

148

Chapitre 7. D´etection de source

Mot
new

obama2012

music
2012

president

iran
nyc
game
ohio

retweet

Norme
9.9646
9.4358
9.2675
8.9344
8.1841
7.9415
7.2585
7.223
7.0147
6.8428

Table 7.4 – Liste des dix mots les plus impactants d’apr`es notre mod`ele

opesr
occupyhq
getaway
leisure
hipster
music
iran
iranian
masen mapoli

Table 7.5 – Paires de mots ayant les plus grandes similarit´es cosinus entre leurs repr´e-
sentations

assez informatifs, qui indiquent bien le sujet de l’information se diﬀusant.

De plus, dans notre mod`ele, deux mots ayant des repr´esentations similaires devraient avoir
le mˆeme eﬀet sur la diﬀusion. Pour v´eriﬁer cette propri´et´e, nous indiquons en table 7.5 les
paires de mots ayant les plus grandes similarit´es, en terme de similarit´e cosinus calcul´ee
sur leurs param`etres θi respectifs :

sim(x, y) =

θx.θy

||θx|| × ||θy||

Nous pouvons voir que ces paires correspondent eﬀectivement `a des mots ayant soit des
sens proches (leisure/getaway ou iran/iranian) soit `a des mots utilis´es dans des contextes
similaires. OpESR (Operation Empire State Rebellion) et OccupyHQ font r´ef´erence `a des
mouvements civiques am´ericains de la mouvance « Occupy Wall Street ». Masen et Mapoli
sont des abr´eviations de « Massachusetts Senate » et « Massachusetts Politics ».

7.4 Conclusion

Dans ce chapitre, nous avons appliqu´e notre m´ethode d’apprentissage de repr´esentations
au probl`eme de la pr´ediction de source. Notre id´ee consistait `a utiliser les repr´esentations

7.4. Conclusion

149

des utilisateurs infect´es dans un ´episode de diﬀusion pour calculer une repr´esentation de
celui-ci, aﬁn de trouver l’utilisateur le plus proche.

Contrairement aux mod`eles existants, notre approche ne repose pas sur la d´eﬁnition pr´ea-
lable d’un mod`ele de diﬀusion et n’utilise pas de graphe. Cela lui permet d’ˆetre beaucoup
plus rapide `a calculer en inf´erence.

Les r´esultats obtenus dans divers contextes exp´erimentaux ont montr´e la robustesse et la
sup´eriorit´e de notre mod`ele par rapport `a diﬀ´erentes approches graphiques, qui reposent
sur des hypoth`eses fortes et sont donc assez sensibles au bruit. Nous avons ´egalement pro-
pos´e plusieurs extensions de notre mod`ele permettant de mod´eliser d’autres param`etres.
Ces extensions nous ont permis d’am´eliorer nos r´esultats et ouvrent la voie `a d’autres
applications.

150

Chapitre 7. D´etection de source

Troisi`eme partie

Conclusion

151

Chapitre 8

Conclusions et perspectives

8.1 Conclusions et discussions

Au cours de ce travail de th`ese, nous avons explor´e divers aspects de la diﬀusion sur
les r´eseaux sociaux, en revisitant certaines hypoth`eses couramment admises et en nous
attachant `a la d´eﬁnition de mod`eles robustes adapt´es aux donn´ees bruit´ees telles que celles
issues de r´eseaux sociaux en ligne.

8.1.1 Utilisation du temps dans la diﬀusion

Dans une premi`ere contribution sur laquelle nous nous sommes appuy´es dans toute la
suite de cette th`ese, nous avons ´etudi´e une m´ethode d’apprentissage du mod`ele IC bas´ee
sur les ordres partiels d’infection plutˆot que sur les temps d’infection exacts. Nous avons
compar´e le mod`ele IC ainsi appris `a d’autres mod`eles explicatifs faisant des hypoth`ese plus
sophistiqu´ees sur les d´elais de transmission. Les r´esultats ont montr´e que notre m´ethode
obtenait de meilleurs r´esultats, ce qui a confort´e notre hypoth`ese selon laquelle les d´elais
de transmission sont d´elicats `a mod´eliser et gˆenent l’apprentissage. De plus notre but ´etait
uniquement de pr´edire les infections des utilisateurs, et non pas l’instant o`u ces infections
avait lieu. Toute la suite du manuscrit a donc suivi ce principe, et n’a pris en compte que
l’ordre d’infection des utilisateurs.

8.1.2 Apprentissage de repr´esentations

L’id´ee centrale de cette th`ese fut d’employer des techniques d’apprentissage de repr´e-
sentations, et d’´etudier de ce que cela pouvait apporter pour plusieurs tˆaches li´ees `a la
pr´ediction de diﬀusion.

153

154

Chapitre 8. Conclusions et perspectives

Complexit´e spatiale
Complexit´e inf´erence

Performances

IC

DAIC
´elev´ee
´elev´ee

HDK
´elev´ee
faible
´elev´ee
faible
faibles ´elev´ees ´elev´ees ´elev´ees

IC Proj.
faible
´elev´ee

Table 8.1 – R´esum´e des propri´et´es g´en´erales des mod`eles de pr´ediction de diﬀusion
´etudi´es dans ce manuscrit.

Nous avons ainsi propos´e d’utiliser une m´ethode d’apprentissage de repr´esentations pour
d´eﬁnir les probabilit´es de transmission du mod`ele IC, et avons adapt´e l’algorithme d’ap-
prentissage du mod`ele IC `a cette formulation. Nous avons obtenu un mod`ele plus compact,
avec une meilleure capacit´e de g´en´eralisation. Puis, en d´eﬁnissant la diﬀusion d’informa-
tion comme un ph´enom`ene de diﬀusion de chaleur continue, nous avons propos´e une
approche pr´edictive du probl`eme. Le mod`ele obtenu s’´etait beaucoup plus rapide qu’un
mod`ele g´en´eratif. Nous avons ´egalement d´eﬁni une extension de cette approche permettant
de prendre en compte le contenu de l’information se diﬀusant. Enﬁn, nous avons appli-
qu´e cette approche au probl`eme inverse de celui de pr´ediction de diﬀusion, la d´etection
de source. Notre mod`ele pr´edictif s’est r´ev´el´e meilleur et plus rapide que les approches
existantes bas´ees sur l’utilisation de graphes ﬁx´es.

La table 8.1 donne une rapide vue d’ensemble des diﬀ´erents mod`eles ´etudi´es pour la
pr´ediction de diﬀusion. Nous pouvons y voir que chaque mod`ele s’est montr´e meilleur que
le pr´ec´edent sur au moins un point.

Ces diﬀ´erents travaux nous ont permis d’identiﬁer plusieurs propri´et´es int´eressantes de
l’apprentissage de repr´esentations appliqu´e `a la diﬀusion dans les r´eseaux sociaux.

— Les mod`eles d´eﬁnis sont plus compacts, le nombre de param`etres appris pour

chaque utilisateur ´etant assez limit´e (au plus une centaine).

— Les propri´et´es intrins`eques des relations entre les utilisateurs sont naturellement
prises en compte par l’emploi d’un espace latent. Cela permet en particulier `a ces
mod`eles d’inf´erer des relations utilisateurs n’existant pas dans l’ensemble d’appren-
tissage, comme nous avons notamment pu le voir dans le chapitre 5 (page 113). Les
exp´eriences en visualisation du chapitre 6 (page 129) nous ont ´egalement permis
de voir que notre mod`ele identiﬁait des groupes d’utilisateurs aux comportements
similaires.

— Les mod`eles bas´es sur l’apprentissage de repr´esentations sont simples `a ´etendre.
Ainsi, dans les chapitres 6 et 7, nous avons pu d´eﬁnir des extensions permettant
notamment de prendre en compte le contenu de l’information diﬀus´ee, ce qui nous
a permis d’am´eliorer nos r´esultats.

— L’apprentissage de repr´esentations nous a ´egalement permis de d´eﬁnir des mod`eles
beaucoup plus rapides `a utiliser en inf´erence que les mod`eles it´eratifs dans les
chapitres 6 et 7.

8.2. Perspectives

8.2 Perspectives

155

Apr`es avoir ´etudi´e la pr´ediction de diﬀusion, nous avons dans le dernier chapitre de ce
manuscrit appliqu´e notre approche `a la tˆache de d´etection de source. D’autres perspectives
seraient aussi susceptibles d’ˆetre ´etudi´ees.

8.2.1 Extension des mod`eles d’apprentissage de repr´esentations

8.2.1.1 Ajout de connaissances suppl´ementaires

Les mod`eles d´eﬁnis dans les chapitres 6 et 7 peuvent ˆetre facilement ´etendus pour prendre
en compte d’autres connaissances. Par exemple, dans le cas o`u certaines propri´et´es des
utilisateurs sont connues (age, nationalit´e, langue), il est possible de calculer une similarit´e
entre deux utilisateurs s(ui, uj) bas´ee sur ces caract´eristiques, et d’ajouter dans la fonction
de coˆut un terme suppl´ementaire de la forme :

(cid:88)

λ

s(ui, uj)||zi − zj||2

(ui,uj )

Ce terme favorise, avec un poids λ, les projections telles que les utilisateurs similaires
soient plus proches. Cette m´ethode peut ´egalement servir `a prendre en compte d’autres
connaissances `a priori : existence de certains liens particuliers, appartenance des utilisa-
teurs `a des communaut´es, etc...

8.2.1.2 Mod´elisation de plusieurs types de diﬀusion

Nous avons vu dans le chapitre 4 des m´ethodes d’apprentissage de repr´esentations per-
mettant de mod´eliser diﬀ´erents types de relations entre les ´el´ements projet´es. Dans nos
mod`eles, nous en avons mod´elis´ee une seule. Il serait donc possible d’utiliser des m´e-
thodes de projections de donn´ees multi-relationnelles pour mod´eliser diﬀ´erents types de
diﬀusion `a partir d’une mˆeme repr´esentation des utilisateurs. Par exemple, sur Twitter,
les diﬀusions de hashtag et de retweets seraient susceptibles de r´epondre `a des dynamiques
diﬀ´erentes.

8.2.1.3 Communaut´es d’utilisateurs

Nous avons vu dans le chapitre 6 comment les utilisateurs, dans un espace de repr´esen-
tation `a deux dimensions, semblaient former des communaut´es, c’est `a dire des groupes
d’utilisateurs similaires.

156

Chapitre 8. Conclusions et perspectives

La d´etection de communaut´es dans les r´eseaux sociaux est un sujet vaste, que nous
n’avons pas abord´e dans ce manuscrit. Beaucoup de m´ethodes existantes mod´elisent la
tˆache comme un probl`eme de partition de graphe selon un certain crit`ere. Ces m´ethodes
sont donc coˆuteuses en calcul, le probl`eme ´etant souvent NP-diﬃcile. Tout notre discours
concernant les limitations des m´ethodes bas´ees sur des graphes est donc valable ´egalement
pour cette tˆache. Utiliser l’apprentissage de repr´esentations (en particulier l’algorithme
du chapitre 6) nous permettrait d’identiﬁer des communaut´es de diﬀusion possiblement
plus robustes que celles obtenues par des m´ethodes classiques.

Diverses pistes peuvent ˆetre envisag´ees pour la d´etection de communaut´es dans le cadre
de la diﬀusion d’information. Il serait par exemple possible de partitionner l’espace de
repr´esentation apr`es l’apprentissage aﬁn d’identiﬁer des groupes d’utilisateurs. Un autre
possibilit´e serait d’ajouter des contraintes de regroupement dans l’apprentissage des pro-
jections des utilisateurs.

Ce type de regroupement pourrait ensuite permettre d’´etudier des tˆaches de pr´ediction
de diﬀusion `a diﬀ´erents niveaux de granularit´e, c’est `a dire en ´etudiant les infections
de groupes d’utilisateurs plutˆot que celles des utilisateurs eux-mˆemes. Ces infections de
groupes seraient ´egalement susceptibles d’ˆetre plus r´eguli`eres et moins bruit´ees.

8.2.1.4 Compl´etion de cascades

Nous avons ´etudi´e dans ce manuscrit la tˆache de pr´ediction de diﬀusion et son inverse, la
tˆache de d´etection de source. Nous pouvons remarquer que ces deux tˆaches sont des cas
particuliers d’une probl´ematique plus g´en´erale, la « compl´etion de cascades » : comment
retrouver, `a partir d’une partie des utilisateurs infect´es, la liste de tous les utilisateurs
infect´es avant et apr`es ceux-ci ? Les mod`eles que nous avons d´eﬁnis peuvent s’appliquer
`a ce probl`eme moyennant quelques modiﬁcations. Des exp´eriences pr´eliminaires nous ont
donn´es des r´esultats encourageants, en particulier pour les ´episodes sur lesquels tr`es peu
d’utilisateurs sont observ´es.

Un mod`ele adapt´e `a cette tˆache permettrait de mieux comprendre les dynamiques de
la diﬀusion d’information dans leur globalit´e, et d’´etudier plus pr´ecis´ement les relations
existant entre la diﬀusion d’information et la recommandation.

Bibliographie

[Albert and Barab´asi, 2002] Albert, R. and Barab´asi, A.-L. (2002). Statistical mechanics

of complex networks. Rev. Mod. Phys., 74 :47–97.

[Anagnostopoulos et al., 2008] Anagnostopoulos, A., Kumar, R., and Mahdian, M.
(2008). Inﬂuence and correlation in social networks. In Proceedings of the 14th ACM
SIGKDD international conference on Knowledge discovery and data mining, pages 7–
15. ACM.

[Aral et al., 2009] Aral, S., Muchnik, L., and Sundararajan, A. (2009). Distinguishing
inﬂuence-based contagion from homophily-driven diﬀusion in dynamic networks. vo-
lume 106, pages 21544–21549. National Acad Sciences.

[Bakshy et al., 2011] Bakshy, E., Hofman, J. M., Mason, W. A., and Watts, D. J. (2011).
Everyone’s an inﬂuencer : quantifying inﬂuence on twitter. In Proceedings of the fourth
ACM international conference on Web search and data mining, pages 65–74. ACM.

[Barbieri et al., 2013a] Barbieri, N., Bonchi, F., and Manco, G. (2013a). Cascade-based
community detection. In Proceedings of the Sixth ACM International Conference on
Web Search and Data Mining, WSDM ’13, pages 33–42, New York, NY, USA. ACM.

[Barbieri et al., 2013b] Barbieri, N., Bonchi, F., and Manco, G. (2013b). Topic-aware
social inﬂuence propagation models. Knowledge and information systems, 37(3) :555–
584.

[Bass, 1969] Bass, F. M. (1969). A new product growth for model consumer durables.

Management Science, 15 :215–227.

[Bengio et al., 2013] Bengio, Y., Courville, A. C., and Vincent, P. (2013). Representation
learning : A review and new perspectives. IEEE Trans. Pattern Anal. Mach. Intell.,
35(8) :1798–1828.

[Bengio et al., 2006] Bengio, Y., Schwenk, H., Sen´ecal, J.-S., Morin, F., and Gauvain, J.-
L. (2006). Neural probabilistic language models. In Innovations in Machine Learning,
pages 137–186. Springer.

[Bharathi et al., 2007] Bharathi, S., Kempe, D., and Salek, M. (2007). Competitive in-
ﬂuence maximization in social networks. In Internet and Network Economics, pages
306–311. Springer.

157

158

Bibliographie

[Bordes et al., 2013] Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., and Yakh-
nenko, O. (2013). Translating embeddings for modeling multi-relational data. In Ad-
vances in Neural Information Processing Systems, pages 2787–2795.

[Bordes et al., 2011] Bordes, A., Weston, J., Collobert, R., and Bengio, Y. (2011). Lear-
ning structured embeddings of knowledge bases. In Conference on Artiﬁcial Intelligence,
number EPFL-CONF-192344.

[B´ota et al., 2013] B´ota, A., Kr´esz, M., and Pluh´ar, A. (2013). Approximations of the

generalized cascade model. Acta Cybern., 21(1) :37–51.

[Bourigault et al., 2014] Bourigault, S., Lagnier, C., Lamprier, S., Denoyer, L., and Gal-
linari, P. (2014). Learning social network embeddings for predicting information dif-
fusion. In Proceedings of the 7th ACM International Conference on Web Search and
Data Mining, WSDM ’14, pages 393–402, New York, NY, USA. ACM.

[Bourigault et al., 2016a] Bourigault, S., Lamprier, S., and Gallinari, P. (2016a). Lear-
ning distributed representations of users for source detection in online social networks.
In Proceedings of the 2016 European conference on Machine Learning and Knowledge
Discovery in Databases, ECML PKDD’16. Springer-Verlag.

[Bourigault et al., 2016b] Bourigault, S., Lamprier, S., and Gallinari, P. (2016b). Repre-
sentation learning for information diﬀusion through social networks : An embedded
cascade model.
In Proceedings of the Ninth ACM International Conference on Web
Search and Data Mining, WSDM ’16, pages 573–582, New York, NY, USA. ACM.

[Brauer et al., 2001] Brauer, F., Castillo-Chavez, C., and Castillo-Chavez, C. (2001). Ma-

thematical models in population biology and epidemiology, volume 40. Springer.

[Celma, 2010] Celma, O. (2010). Music Recommendation and Discovery. Springer.

[Cha et al., 2010] Cha, M., Haddadi, H., Benevenuto, F., and Gummadi, K. P. (2010).
Measuring User Inﬂuence in Twitter : The Million Follower Fallacy. In Proceedings of
the 4th International AAAI Conference on Weblogs and Social Media (ICWSM).

[Chen et al., 2013] Chen, G. H., Nikolov, S., and Shah, D. (2013). A latent source mo-
In Advances in Neural Information

del for nonparametric time series classiﬁcation.
Processing Systems, pages 1088–1096.

[Chen et al., 2007] Chen, M., Yang, Q., and Tang, X. (2007). Directed graph embedding.

In Proceedings of the 2007 International Joint Conference on Artiﬁcial Intelligence.

[Chen et al., 2012] Chen, S., Moore, J. L., Turnbull, D., and Joachims, T. (2012). Playlist
prediction via metric embedding. In Proceedings of the 18th ACM SIGKDD interna-
tional conference on Knowledge discovery and data mining, pages 714–722. ACM.

[Chen et al., 2011] Chen, W., Collins, A., Cummings, R., Ke, T., Liu, Z., Rincon, D., Sun,
X., Wang, Y., Wei, W., and Yuan, Y. (2011). Inﬂuence maximization in social networks
when negative opinions may emerge and propagate. In Proceedings of the 2011 SIAM
International Conference on Data Mining. SIAM.

159

[Chen et al., 2010] Chen, W., Wang, C., and Wang, Y. (2010). Scalable inﬂuence maxi-
In Proceedings
mization for prevalent viral marketing in large-scale social networks.
of the 16th ACM SIGKDD international conference on Knowledge discovery and data
mining, pages 1029–1038. ACM.

[Chen et al., 2009] Chen, W., Wang, Y., and Yang, S. (2009). Eﬃcient inﬂuence maxi-
mization in social networks. In Proceedings of the 15th ACM SIGKDD international
conference on Knowledge discovery and data mining, pages 199–208. ACM.

[Cheng et al., 2014] Cheng, J., Adamic, L., Dow, P. A., Kleinberg, J. M., and Leskovec, J.
(2014). Can cascades be predicted ? In Proceedings of the 23rd International Conference
on World Wide Web, WWW ’14, pages 925–936, New York, NY, USA. ACM.

[Cho et al., 2014] Cho, K., van Merrienboer, B., G¨ul¸cehre, ¸C., Bahdanau, D., Bougares,
F., Schwenk, H., and Bengio, Y. (2014). Learning phrase representations using RNN
encoder-decoder for statistical machine translation. In Proceedings of the 2014 Confe-
rence on Empirical Methods in Natural Language Processing, EMNLP 2014, October
25-29, 2014, Doha, Qatar.

[Daley et al., 2001] Daley, D. J., Gani, J., and Gani, J. M. (2001). Epidemic modelling :

an introduction, volume 15. Cambridge University Press.

[Daneshmand et al., 2014] Daneshmand, H., Gomez-Rodriguez, M., Song, L., and Schoel-
kopf, B. (2014). Estimating diﬀusion network structures : Recovery conditions, sample
complexity & soft-thresholding algorithm.
In Proceedings of the 31th International
Conference on Machine Learning.

[Dempster et al., 1977] Dempster, A. P., Laird, N. M., and Rubin, D. B. (1977). Maximum
likelihood from incomplete data via the em algorithm. Journal of the royal statistical
society. Series B (methodological), pages 1–38.

[Dong et al., 2013] Dong, W., Zhang, W., and Tan, C. W. (2013). Rooting out the rumor
culprit from suspects. In Proceedings of the 2013 IEEE International Symposium on
Information Theory (ISIT). IEEE.

[Du et al., 2012] Du, N., Song, L., Yuan, M., and Smola, A. J. (2012). Learning networks
of heterogeneous inﬂuence.
In Pereira, F., Burges, C., Bottou, L., and Weinberger,
K., editors, Advances in Neural Information Processing Systems 25, pages 2780–2788.
Curran Associates, Inc.

[Farajtabar et al., 2015] Farajtabar, M., Gomez-Rodriguez, M., Zamani, M., Du, N., Zha,
H., and Song, L. (2015). Back to the past : Source identiﬁcation in diﬀusion networks
from partially observed cascades. In Proceedings of the Eighteenth International Confe-
rence on Artiﬁcial Intelligence and Statistics (AISTATS).

[Freeman, 1978] Freeman, L. C. (1978). Centrality in social networks conceptual clariﬁ-

cation. Social networks, 1(3) :215–239.

[Fushimi et al., 2008] Fushimi, T., Kawazoe, T., Saito, K., Kimura, M., and Motoda, H.
(2008). What does an information diﬀusion model tell about social network structure ?
In Paciﬁc Rim Knowledge Acquisition Workshop, pages 122–136. Springer.

160

Bibliographie

[Goldenberg et al., 2001] Goldenberg, J., Libai, B., and Muller, E. (2001). Talk of the net-
work : A complex systems look at the underlying process of word-of-mouth. Marketing
letters, 12(3) :211–223.

[Gomez-Rodriguez et al., 2011] Gomez-Rodriguez, M., Balduzzi, D., and Sch¨olkopf, B.
In Proceedings of
(2011). Uncovering the temporal dynamics of diﬀusion networks.
the 28th International Conference on Machine Learning (ICML-11), ICML ’11, pages
561–568. ACM.

[Gomez Rodriguez et al., 2010] Gomez Rodriguez, M., Leskovec, J., and Krause, A.
(2010). Inferring networks of diﬀusion and inﬂuence. In Proceedings of the 16th ACM
SIGKDD international conference on Knowledge discovery and data mining, KDD ’10.
ACM.

[Gomez-Rodriguez et al., 2013] Gomez-Rodriguez, M., Leskovec, J., and Sch¨olkopf, B.
In Proceedings of

(2013). Modeling information propagation with survival theory.
the 30st International Conference on Machine Learning (ICML-10).

[Gomez Rodriguez et al., 2013] Gomez Rodriguez, M., Leskovec, J., and Sch¨olkopf, B.
(2013). Structure and dynamics of information pathways in online media. In Proceedings
of the sixth ACM international conference on Web search and data mining, pages 23–32.
ACM.

[Gomez Rodriguez et al., 2012] Gomez Rodriguez, M., Sch¨olkopf, B., Pineau, L. J., et al.

(2012). Inﬂuence maximization in continuous time diﬀusion networks. pages 1–8.

[Gong et al., 2014] Gong, Y., Ke, Q., Isard, M., and Lazebnik, S. (2014). A multi-view
embedding space for modeling internet images, tags, and their semantics. International
journal of computer vision, 106(2) :210–233.

[Goyal et al., 2010] Goyal, A., Bonchi, F., and Lakshmanan, L. V. (2010). Learning in-
ﬂuence probabilities in social networks. In Proceedings of the third ACM international
conference on Web search and data mining, pages 241–250. ACM.

[Granovetter, 1973] Granovetter, M. S. (1973). The strength of weak ties. American

journal of sociology, pages 1360–1380.

[Granovetter, 1978] Granovetter, M. S. (1978). Threshold Models of Collective Behavior.

American Journal of Sociology, 83(6) :1420–1143.

[Graves et al., 2013] Graves, A., Mohamed, A., and Hinton, G. E. (2013). Speech re-
cognition with deep recurrent neural networks. In IEEE International Conference on
Acoustics, Speech and Signal Processing, ICASSP 2013, Vancouver, BC, Canada, May
26-31, 2013, pages 6645–6649.

[Gruhl et al., 2004] Gruhl, D., Guha, R., Liben-Nowell, D., and Tomkins, A. (2004). Infor-
mation diﬀusion through blogspace. In Proceedings of the 13th International Conference
on World Wide Web, WWW ’04, pages 491–501, New York, NY, USA. ACM.

[Gu`ardia-Sebaoun et al., 2015] Gu`ardia-Sebaoun, E., Guigue, V., and Gallinari, P. (2015).
Latent trajectory modeling : A light and eﬃcient way to introduce time in recommender

161

systems. In Proceedings of the 9th ACM Conference on Recommender Systems, pages
281–284. ACM.

[Guille and Hacid, 2012] Guille, A. and Hacid, H. (2012). A predictive model for the tem-
poral dynamics of information diﬀusion in online social networks. In Proceedings of the
21st international conference companion on World Wide Web, WWW ’12 Companion.
ACM.

[Harko et al., 2014] Harko, T., Lobo, F. S., and Mak, M. (2014). Exact analytical solutions
of the susceptible-infected-recovered (sir) epidemic model and of the sir model with
equal death and birth rates. Applied Mathematics and Computation, 236 :184–194.

[Hethcote, 2000] Hethcote, H. W. (2000). The mathematics of infectious diseases. SIAM

review, 42(4) :599–653.

[Hooton, 2015] Hooton, C. (2015). Game of thrones season 5 : This is why episodes
1 to 4 leaked.
http://www.independent.co.uk/arts-entertainment/tv/news/
this-is-why-the-game-of-thrones-season-5-episodes-leaked-10175800.html.

[Huberman et al., 2008] Huberman, B., Romero, D., and Wu, F. (2008). Social networks

that matter : Twitter under the microscope. First Monday, 14(1).

[Jacob et al., 2014] Jacob, Y., Denoyer, L., and Gallinari, P. (2014). Learning latent
representations of nodes for classifying in heterogeneous social networks. In Proceedings
of the 7th ACM international conference on Web search and data mining, pages 373–
382. ACM.

[Jamali and Ester, 2010] Jamali, M. and Ester, M. (2010). A matrix factorization tech-
nique with trust propagation for recommendation in social networks. In Proceedings of
the fourth ACM conference on Recommender systems, pages 135–142. ACM.

[Keeling and Rohani, 2008] Keeling, M. J. and Rohani, P. (2008). Modeling infectious

diseases in humans and animals. Princeton University Press.

[Kempe et al., 2003] Kempe, D., Kleinberg, J., and Tardos, E. (2003). Maximizing the
spread of inﬂuence through a social network. In Proceedings of the ninth ACM SIGKDD
international conference on Knowledge discovery and data mining, KDD ’03, pages 137–
146. ACM.

[Kempe et al., 2005] Kempe, D., Kleinberg, J., and Tardos, ´E. (2005). Inﬂuential nodes
In Automata, languages and programming,

in a diﬀusion model for social networks.
pages 1127–1138. Springer.

[Kermack and McKendrick, 1927] Kermack, W. O. and McKendrick, A. G. (1927). A
contribution to the mathematical theory of epidemics. Proceedings of the Royal Society
of London A : Mathematical, Physical and Engineering Sciences, 115(772) :700–721.

[Kimura and Saito, 2006] Kimura, M. and Saito, K. (2006). Tractable models for infor-
mation diﬀusion in social networks. In Proceedings of the 10th European Conference on
Principle and Practice of Knowledge Discovery in Databases, PKDD’06, pages 259–271.

162

Bibliographie

[Kitsak et al., 2010] Kitsak, M., Gallos, L. K., Havlin, S., Liljeros, F., Muchnik, L., Stan-
ley, H. E., and Makse, H. A. (2010). Identiﬁcation of inﬂuential spreaders in complex
networks. Nature physics, 6(11) :888–893.

[Kleinberg, 1999] Kleinberg, J. M. (1999). Authoritative sources in a hyperlinked envi-

ronment. J. ACM, 46(5) :604–632.

[Klimt and Yang, 2004] Klimt, B. and Yang, Y. (2004). The enron corpus : A new dataset
In Proceedings of the 2004 European conference on

for email classiﬁcation research.
Machine Learning, pages 217–226. Springer.

[Kondor and Laﬀerty, 2002] Kondor, R. I. and Laﬀerty, J. (2002). Diﬀusion kernels on
graphs and other discrete structures. In Proceedings of the 19th international conference
on machine learning, pages 315–322.

[Koren et al., 2009] Koren, Y., Bell, R., and Volinsky, C. (2009). Matrix factorization

techniques for recommender systems. Computer, (8) :30–37.

[Kruskal, 1964] Kruskal, J. B. (1964). Multidimensional scaling by optimizing goodness

of ﬁt to a nonmetric hypothesis. Psychometrika, 29(1) :1–27.

[Kwak et al., 2010] Kwak, H., Lee, C., Park, H., and Moon, S. (2010). What is twitter, a
social network or a news media ? In Proceedings of the 19th International Conference
on World Wide Web, WWW ’10, pages 591–600, New York, NY, USA. ACM.

[Lagnier et al., 2013] Lagnier, C., Denoyer, L., Gaussier, E., and Gallinari, P. (2013).
Predicting information diﬀusion in social networks using content and user’s proﬁles.
In Advances in Information Retrieval, pages 74–85. Springer Berlin Heidelberg.

[Lamprier et al., 2015] Lamprier, S., Bourigault, S., and Gallinari, P. (2015). Extracting
diﬀusion channels from real-world social data : A delay-agnostic learning of transmis-
sion probabilities. In Proceedings of the 2015 IEEE/ACM International Conference on
Advances in Social Networks Analysis and Mining. ACM.

[Lappas et al., 2010] Lappas, T., Terzi, E., Gunopulos, D., and Mannila, H. (2010). Fin-
ding eﬀectors in social networks. In Proceedings of the 16th ACM SIGKDD international
conference on Knowledge discovery and data mining, pages 1059–1068. ACM.

[Lerman and Hogg, 2010] Lerman, K. and Hogg, T. (2010). Using a model of social dyna-
mics to predict popularity of news. In Proceedings of the 19th international conference
on World wide web, pages 621–630. ACM.

[Leskovec et al., 2009] Leskovec, J., Backstrom, L., and Kleinberg, J. (2009). Meme-
tracking and the dynamics of the news cycle. In Proceedings of the 15th ACM SIGKDD
international conference on Knowledge discovery and data mining, KDD ’09, pages
497–506, New York, NY, USA. ACM.

[Li et al., 2013] Li, Y., Chen, W., Wang, Y., and Zhang, Z.-L. (2013). Inﬂuence diﬀusion
dynamics and inﬂuence maximization in social networks with friend and foe relation-
ships. In Proceedings of the sixth ACM international conference on Web search and
data mining, pages 657–666. ACM.

163

[Lin et al., 2015a] Lin, Y., Liu, Z., Luan, H., Sun, M., Rao, S., and Liu, S. (2015a). Mo-
deling relation paths for representation learning of knowledge bases. In Proceedings of
the 2015 Conference on Empirical Methods in Natural Language Processing.

[Lin et al., 2015b] Lin, Y., Liu, Z., Sun, M., Liu, Y., and Zhu, X. (2015b). Learning entity
and relation embeddings for knowledge graph completion. In Proceedings of the 29th
Conference on Artiﬁcial Intelligence.

[Luo et al., 2015a] Luo, W., Tay, W. P., and Leng, M. (2015a). Rumor spreading maxi-
In Proceedings of the 2015
mization and source identiﬁcation in a social network.
IEEE/ACM International Conference on Advances in Social Networks Analysis and
Mining 2015, ASONAM ’15, pages 186–193, New York, NY, USA. ACM.

[Luo et al., 2015b] Luo, W., Tay, W. P., Leng, M., and Guevara, M. (2015b). On the
universality of the jordan center for estimating the rumor source in a social network.
In Digital Signal Processing (DSP), 2015 IEEE International Conference on, pages
760–764.

[Luu et al., 2012] Luu, D. M., Lim, E.-P., Hoang, T.-A., and Chua, F. C. T. (2012).
Modeling diﬀusion in social networks using network properties. In Sixth International
AAAI Conference on Weblogs and Social Media.

[Ma et al., 2008] Ma, H., Yang, H., Lyu, M. R., and King, I. (2008). Mining social net-
works using heat diﬀusion processes for marketing candidates selection. In Proceedings
of the 17th ACM conference on Information and knowledge management, CIKM ’08,
pages 233–242, New York, NY, USA. ACM.

[Ma et al., 2011] Ma, H., Zhou, T. C., Lyu, M. R., and King, I. (2011). Improving recom-
mender systems by incorporating social contextual information. ACM Transactions on
Information Systems (TOIS), 29(2) :9.

[Mahajan et al., 1995] Mahajan, V., Muller, E., and Bass, F. M. (1995). Diﬀusion of
new products : Empirical generalizations and managerial uses. Marketing Science,
14(3 supplement) :G79–G88.

[Mikolov et al., 2013a] Mikolov, T., Chen, K., Corrado, G., and Dean, J. (2013a). Eﬃcient

estimation of word representations in vector space. arXiv preprint arXiv :1301.3781.

[Mikolov et al., 2013b] Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., and Dean, J.
(2013b). Distributed representations of words and phrases and their compositionality.
In Burges, C., Bottou, L., Welling, M., Ghahramani, Z., and Weinberger, K., editors,
Advances in Neural Information Processing Systems 26, pages 3111–3119. Curran As-
sociates, Inc.

[Mislove et al., 2007] Mislove, A., Marcon, M., Gummadi, K. P., Druschel, P., and Bhat-
tacharjee, B. (2007). Measurement and analysis of online social networks. In Proceedings
of the 7th ACM SIGCOMM Conference on Internet Measurement, IMC ’07, pages 29–
42, New York, NY, USA. ACM.

[Morstatter et al., 2013] Morstatter, F., Pfeﬀer, J., Liu, H., and Carley, K. (2013).

Is
the sample good enough ? comparing data from twitter’s streaming api with twitter’s

164

Bibliographie

ﬁrehose. In Proceedgins of the 2013 International AAAI Conference on Web and Social
Media.

[Mosca, 2013] Mosca, M. (2013).

« nuit debout »,

loi travail... et leur cort`ege de
http://www.lemonde.fr/les-decodeurs/article/2016/04/11/

fausses photos.
nuit-debout-loi-travail-et-leur-cortege-de-fausses-photos_4899993_
4355770.html.

[Myers and Leskovec, 2012] Myers, S. A. and Leskovec, J. (2012). Clash of the contagions :
Cooperation and competition in information diﬀusion. In Proceedings of the IEEE 12th
International Conference onData Mining (ICDM), pages 539–548. IEEE.

[Najar et al., 2012] Najar, A., Denoyer, L., and Gallinari, P. (2012). Predicting infor-
mation diﬀusion on social networks with partial knowledge. In Proceedings of the 21st
international conference companion on World Wide Web, WWW ’12 Companion, pages
1197–1204, New York, NY, USA. ACM.

