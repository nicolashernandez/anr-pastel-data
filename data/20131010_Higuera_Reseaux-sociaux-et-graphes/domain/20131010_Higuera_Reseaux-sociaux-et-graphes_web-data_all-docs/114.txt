http://perso.ens-lyon.fr/eric.thierry/Graphes2007/thomas-braibant.pdf

Graphes alÃ©atoires

Thomas Braibant

Introduction

Si l'on se place dans la perspective de l'analyse d'un algorithme, la complexitÃ© dans le pire
cas est une mesure pessimiste de la qualitÃ© d'un algorithme. Tout comme certains problÃ¨mes
sont dans NP Ã  cause d'une petite famille d'instances dures, certains algorithmes peuvent Ãªtre
performants sur la plupart des instances, et Ãªtre moins ecaces sur des instances bizarres.

L'analyse probabiliste, qui consiste Ã  xer une distribution de probabilitÃ© sur les entrÃ©es,
et Ã©tudier l'espÃ©rance (ou valeur moyenne), du coÃ»t d'un algorithme en fonction de cette dis-
tribution donne une mesure plus acceptable. NÃ©anmoins, choisir une distribution de probabilitÃ©
rÃ©aliste peut s'avÃ©rer dicile. Dans ce rapport, on va donc Ã©tudier deux formalisations diÃ©rentes
de distributions de probabilitÃ©s sur les graphes ayant un nombre de sommets xÃ©s. Une fois le
formalisme Ã©tabli, on analysera ensuite :

 Quelques propriÃ©tÃ©s et leurs conditions d'apparition
 Un exemple d'algorithme polynomial qui permet de rÃ©pondre pour presque tous les couples

de graphes Ã  la question de savoir si ils sont isomorphes

 Des comparaisons entre les prÃ©dictions et les donnÃ©es expÃ©rimentales tirÃ©es des graphes

rÃ©els : Internet, rÃ©seaux divers, rÃ©seaux de collaboration (Acteurs -lms, scientique ...)

Les sources dont je me suis inspirÃ© pour la rÃ©daction de ce rapport sont les suivantes :
 [?] :)
 [?] : Un livre spÃ©cialement consacrÃ© aux graphes alÃ©atoires, contenant beaucoup de rÃ©sultats

complexes sur le modÃ¨le A.

 [?] : Un revue bibliographique sur le sujet des graphes alÃ©atoires, citÃ© environ 1200 fois1
 [?] : Un article prÃ©sentant le modÃ¨le B. Pour information, les auteurs ne sont pas infor-
maticiens, mais plutÃ´t issus des milieux des sciences sociales ou de la matiÃ¨re. Article citÃ©
250 fois environ2

1 ModÃ©lisations

J'ai regroupÃ© quelques informations utiles en annexe, sur les probabilitÃ©s, et quelques thÃ©o-

rÃ¨mes. Le lecteur peu familier (comme moi) avec les notions de probabilitÃ©s peut s'y rÃ©fÃ©rer.

1.1 ModÃ¨le A
ModÃ¨le A : ErdÃ¶s-Renyi Soit un ensemble V = {1, . . . n} de sommets. Soit un paramÃ¨tre
p, 0 < p < 1. Pour toute paire de sommets, il existe une arÃªte avec probabilitÃ© p, les arÃªtes Ã©tant
dÃ©terminÃ©es indÃ©pendamment les unes des autres. La variable alÃ©atoire Gp dÃ©note un graphe
issu de cet espace de probabilitÃ©s.

1information basÃ©e sur le site www.citebase.org
2idem

1

Fig. 1  Distribution des degrÃ©s , gure extraite de [?], page 12

Lemme 1.1 (DegrÃ© d'un sommet) Le degrÃ© d'un sommet est dÃ©ni par la loi de probabilitÃ©
(oÃ¹ on reconnait une loi de Poisson) :

(cid:18)n

(cid:19)

k

pk =

pk(1 âˆ’ p)nâˆ’k

Le degrÃ© moyen d'un sommet est donc :

z = E(k) = p âˆ— (n âˆ’ 1)

La gure ?? indique les prÃ©visions du modÃ¨le thÃ©orique correspondent Ã  ce que l'on observe
si l'on gÃ©nÃ¨re un graphe suivant cette modÃ©lisation. J'ai personnellement rÃ©alisÃ© des tests sur un
graphe alÃ©atoire avec 5000 noeuds, et trouvÃ© une distribution des degrÃ©s correspondant Ã©galement
Ã  ces prÃ©visions, aux erreurs expÃ©rimentales prÃ¨s.

Autre formalisation Soit n et m = m(n). On dÃ©nit la variable alÃ©atoire Gm comme Ã©tant un

graphe Ã  n sommets et m arrÃªtes, apparaissant avec une probabilitÃ©(cid:0)(n

La variable alÃ©atoire

(cid:1)âˆ’1

2)
m

Gm dÃ©note un graphe issu de cet espace de probabilitÃ©s.

Cette seconde dÃ©nition est plus commode dans de nombreux modÃ¨les Ã©tudiÃ©s, Ã©tant donnÃ©
qu'il est plus facile de se demander, Ã  n xÃ©, combien d'arÃªtes sont nÃ©cessaires pour avoir presque
toujours une propriÃ©tÃ© Q, plutÃ´t que de se demander quelle est la probabilitÃ© p nÃ©cessaire pour
avoir presque toujours Q

Ce second modÃ¨le est fort heureusement dÃ©crit par le modÃ¨le A, quand n est grand, et

p = m/(cid:0)n
(cid:1).

2

1.2 ModÃ¨le B

De nombreuses sources convergentes indiquent que la distribution des degrÃ©s dans les graphes
rÃ©els Ã©tudiÃ©s (systÃ¨mes biologiques, rÃ©seaux sociaux, rÃ©seaux mÃ©taboliques, . . .) ne suit pas la

2

Fig. 2  Distribution des degrÃ©s, expÃ©rience avec 5000 noeuds

loi de Poisson ci-dessus, et que de nombreuses propriÃ©tÃ©s sont mal approximÃ©es si on utilise le
modÃ¨le A. On verra dans la section ?? des donnÃ©es expÃ©rimentales, mais il convient de dire en
particulier que la rÃ©partition des degrÃ©s suit souvent une loi de puissance, qui n'est pas simulable
dans le modÃ¨le d'ErdÃ¶s-Renyi.

DÃ©nition On dÃ©nit la fonction gÃ©nÃ©ratrice G0(x) telle que

âˆX

G0(x) =

pkxk

k=0

avec pk la probabilitÃ© qu'un sommet choisi au hasard soit de degrÃ© k. On ne travaillera qu'avec
G0 normalisÃ©e telle que G0(1) = 1. La variable alÃ©atoire G(pk) dÃ©note un graphe issu de cet
espace de probabilitÃ©s.

Cette modÃ©lisation permet de calculer de faÃ§on simple certaines quantitÃ©s.

Lemme 1.2 (DegrÃ© moyen d'un sommet) Le degrÃ© moyen d'un sommet (ou espÃ©rance) est
donnÃ© par :

z =X

k âˆ— pk = G0

0(1)

k

Lemme 1.3 (Puissances) Si la loi de distribution d'une propriÃ©tÃ© X sur un objet est donnÃ©e
par une certaine fonction gÃ©nÃ©ratrice, alors la loi de distribution sur la somme de X sur m
Ã©lÃ©ments indÃ©pendants est donnÃ©e par la m-iÃ¨me puissance de cette fonction gÃ©nÃ©ratrice.

Somme des degrÃ©s de deux sommets pris au hasard

[G0(x)]2 =

#

pk âˆ— xk
pk âˆ— pj âˆ— xj+k

"X
= X

k

j,k

3

Les coecients de xn dans cette expression sont clairement les produits pj âˆ—pk tels que j +k = n,
et par consÃ©quent, on exprime bien ici la probabilitÃ© que la somme des degrÃ©s des deux sommets
soit n.

1.3 Relations entre ces modÃ¨les

Si il n'existe pas d'arÃªtes multiples entre un mÃªme couple de sommets, il est clair que le
modÃ¨le Gp recouvre le modÃ¨le Gm. Dans le cas contraire, il n'est pas facile de voir comment
simuler cette possibilitÃ©.

Le modÃ¨le B recouvre le modÃ¨le A, si on utilise comme probabilitÃ© pour le degrÃ© k : pk =

(cid:0)n
(cid:1)pk(1 âˆ’ p)nâˆ’k, la probabilitÃ© donnÃ©e en ??.

k

2 PropriÃ©tÃ©s

2.1 PropriÃ©tÃ©s pour presque tous les graphes
DÃ©nition Etant donnÃ©e une suite d'espaces de probabilitÃ©s â„¦n, soit qn la probabilitÃ© que la
propriÃ©tÃ© Q soit vraie dans l'espace â„¦n. On dit que la propriÃ©tÃ© Q est presque toujours vÃ©riÃ©e,
si limn7â†’âˆ qn = 1

2.2 DiamÃ¨tre

On rappelle que le diamÃ¨tre d'un graphe est dÃ©ni par : voir en annexe.

ThÃ©orÃ¨me 2.1 (DiamÃ¨tre) Si p est constant, alors presque tous les graphes Gp(on se place
ici dans le cas du ModÃ¨le A) ont pour diamÃ¨tre 2.

alors Gp est connectÃ©, et a pour diamÃ¨tre 2. On pose X =P
(1 âˆ’ p2)nâˆ’2. Donc E(X) =(cid:0)n

Preuve Soit X(Gp) le nombre de paires de sommets sans voisins communs. Si il n'y en a pas,
i,jâˆˆ[1...n]2 Xi,j avec Xi,j = 1 si et
seulement si vi, vj n'ont pas de voisins communs. Soient i0, j0 tels que Xi0,j0 = 1. Les sommets
n âˆ’ 2 autres sommets n'ont pas d'arÃªtes vers i0 et j0 Ã  la fois. On en dÃ©duit P [Xi,j = 1] =
Si p est xÃ©, alors E(X) 7â†’ 0. Par l'inÃ©galitÃ© de Markov, rappellÃ©e en annexe, cela implique

(cid:1) âˆ— (1 âˆ’ p2)nâˆ’2.

2

que P (X = 0) 7â†’ 1 et donc presque tous les graphes Gp ont pour diamÃ¨tre 2.
Fin de preuve

Contrairement Ã  ce qu'on peut penser, ce rÃ©sultat est en rÃ©alitÃ© assez faible. En eet, dans les
graphes usuels, p est une fonction dÃ©croissante du nombre de sommets3. On trouve donc souvent
dans la littÃ©rature des rÃ©sultats qui mettent en relation l'apparition d'une propriÃ©tÃ© avec un
comportement asymptotique de p, de la forme suivante.

ThÃ©orÃ¨me 2.2 (DiamÃ¨tre) Dans le cadre du modÃ¨le A, on a :

 Si la fonction M = M(n) <(cid:0)n

 Si p2 âˆ— n âˆ’ 2 âˆ— log n 7â†’ âˆ et n2(1 âˆ’ p) 7â†’ âˆ alors presque tous les graphes Gp ont pour
n3 âˆ’ log n 7â†’ âˆ alors presque tous les graphes

(cid:1) vÃ©rie 2 âˆ— M 2

diamÃ¨tre 2.

2

GM ont pour diamÃ¨tre 2

Preuve [?], page 263

Fin de preuve

3Soit X le nombre d'arÃªtes : E(X) =`n

Â´ âˆ— p(n)

2

4

2.3 Fonctions de seuils

Fonction de seuil On appelle fonction de seuil de probabilitÃ© pour une propriÃ©tÃ© monotone Q4
une fonction t(n) telle que p(n)/t(n) 7â†’ 0 implique que presque aucun Gp ne vÃ©rie la propriÃ©tÃ©
Q, et telle que p(n)/t(n) 7â†’ âˆ implique que presque tous les Gp vÃ©rient Q.

Cette formalisation de la notion prÃ©cÃ©dente nous amÃ¨ne Ã  rÃ©aliser des analyses plus nes
des propriÃ©tÃ©s des graphes alÃ©atoires. Par exemple, dans le modÃ¨le A, t : n 7â†’ ln(n)/n est une
fonction de seuil de probabilitÃ© pour la disparition des sommets isolÃ©s.

3 Variables alÃ©atoires

Dans cette section, je vais essayer de prÃ©senter des rÃ©sultats permettant de mettre en relation

des variables alÃ©atoires identiques dans les deux modÃ¨les de graphes.

3.1 Distance moyenne

Il est clair que dans les deux modÃ¨les, le nombre moyen de premiers voisins est Ã©gal au degrÃ©

moyen dans le graphe. Dans le modÃ¨le B, on a :

z1 =< k >=X

k

k âˆ— pk = G0

0(1)

(<k> dÃ©signant l'espÃ©rance du degrÃ©)
Si on part d'un noeud alÃ©atoire n, on s'intÃ©resse alors Ã  la distribution des degrÃ©s pour les
premiers voisins atteints. Une arrÃªte quelconque prise au hasard atteint un noeud n0 de degrÃ© k
avec une probabilitÃ© proportionelle Ã  k âˆ— pk. On a donc :

P
P
k k âˆ— pk âˆ— xkâˆ’1
k k âˆ— pk

G1(x) =

=

1

< k >

G0
0(x)

Le nombre moyen de voisins est z1 =< k >= G0
0.
Par extension, on appelle zm le nombre de m-iÃ¨mes voisins, et on a :

zm = [G0(1)]mâˆ’1G0

0(1) =

(cid:21)mâˆ’1

(cid:20) z2

z1

Si on suppose que tous les noeuds sont accessibles en D Ã©tapes, on a :

tX

1 +

zm = n

D'oÃ¹ on a :

m=1

l =

ln(n/z1)
ln(z2/z1)

+ 1

Dans le modÃ¨le A, on peut raisonablement penser que le nombre de sommets atteints Ã 
distance l en partant d'un noeud quelconque est de l'ordre de < k >l. En posant < k >l= n, il
vient :

l âˆ ln(n)

ln(< k >)

.

4voir en annexe ??

5

Fig. 3  Longueur moyenne de chemin,
comparaison entre modÃ©lisation et graphes
rÃ©els

Fig. 4  Une composante connexe peut
Ãªtre vue comme un sommet reliÃ© Ã  diÃ©-
rentes composantes connexes

3.2 Taille moyenne de composante connexe

Je vais ici dÃ©crire un rÃ©sultat gÃ©nÃ©ral pour le modÃ¨le B, et le raner ensuite pour le modÃ¨le

A.

Dans le modÃ¨le B, on s'intÃ©resse Ã  la fonction gÃ©nÃ©ratice H1(x) pour la taille des composantes
atteintes en suivant une arrÃªte jusqu'Ã  son bout, en excluant le cas oÃ¹ le graphe possÃ¨de une
composante gÃ©ante. La probabilitÃ© d'avoir un cycle Ã©tant en 1/N , on peut la nÃ©gliger pour N
grand.

Remarquons tout d'abord avec la loi de puissance5 que la fonction gÃ©nÃ©ratrice de la taille de
la composante formÃ©e de k sous composantes distinctes s'exprime comme la puissance k-iÃ¨me de
H1(x).

Donc, en s'appuyant sur le schÃ©ma gure ??, on remarque que H1(x) doit vÃ©rier l'Ã©quation

suivante, avec qi la probabilitÃ© que le sommet initial aie i arrÃªtes sortantes :
H1(x) = x âˆ— q0 + x âˆ— q1 âˆ— H1(x) + x âˆ— q2 âˆ— [H1(x)]2 + . . .

D'oÃ¹ il vient :

En partant d'un sommet plutÃ´t que d'une arrÃªte, il vient

H1(x) = xG1(H1(x))

H0(x) = xG0(H1(x))

De faÃ§on usuelle, on a alors :

< s >= H0

1(1)

0(1) âˆ— H0
0(1) = 1 + G0
= 1 + G0
0(1)
1 âˆ’ G0
= 1 + z2

1(1)

1

z1 âˆ’ z2

5(voir ??)

6

Notons d'ailleurs que cette Ã©quation peut diverger, et donne une condition pour l'apparition

d'une composante gÃ©ante, qui est : X

k âˆ— (k âˆ’ 2) âˆ— pk = 0

Pour le modÃ¨le A, on a G0(x) = G1(x) = exp (n âˆ’ 1) âˆ— p âˆ— (x âˆ’ 1), d'oÃ¹ < s >= 1+ (nâˆ’1)âˆ—p
1âˆ’(nâˆ’1)âˆ—p .

k

3.3 Coecient de clusterisation
Lemme 3.1 Dans un graphe alÃ©atoire Gp, Cp = p = <k>
nâˆ’1 .

En eet, dans le modÃ¨le A, la probabilitÃ© qu'il existe une arrÃªte entre deux voisins d'un mÃªme

noeud est la mÃªme que la probabilitÃ© d'existence d'une arrÃªte dans le cas gÃ©nÃ©ral.
Je reprends ici une explication que m'a donnÃ©e Eric Thierry sur le modÃ¨le B.
Soit Ax,y la variable alÃ©atoire entiÃ¨re valant 1 si il existe une arrÃªte entre x et y et 0 sinon. Le
modÃ¨le Ã©tant symÃ©trique par rapport aux sommets, P [Ax,y = 1] est identique pour tout couple
x, y âˆˆ V Ã— V, x 6= y. On la note p.

P
E(P

p =

x,y P [Ax,y = 1]

nombre de paires x,y

x,y Ax,y)
n âˆ— (n âˆ’ 1)/2

n âˆ— (n âˆ’ 1)/2

=
= E(nombre d'arÃªtes)
= E(somme des degrÃ©s)
= nâˆ— < k >
n âˆ— (n âˆ’ 1)

n âˆ— (n âˆ’ 1)

p = < k >
n âˆ’ 1

Comme toujours en Ã©tudiant des probabilitÃ©s, la solution est Ã©vidente, lorsqu'on l'a trouvÃ©e.
Ce rÃ©sultat implique cependant que le coecient de clusterisation est donnÃ© par la mÃªme ex-
pression dans les deux modÃ¨les, ce qui est intuitif. Attention, cependant, car il est possible de
construire presque arbitrairement une distribution de degrÃ© donnant une valeur donnÃ©e de ce
coecient p pour le modÃ¨le B, tout en n'ayant que deux types de sommets de degrÃ©s a et b, et
en choisissant judicieusement leurs probabilitÃ©s respectives.

4 Applications

Les propriÃ©tÃ©s des graphes alÃ©atoires peuvent permettre de trouver des algorithmes qui rÃ©-
solvent des problÃ¨mes diciles sur presque toutes les entrÃ©es. Le problÃ¨me de dÃ©cision de l'iso-
morphisme de deux graphes est dicile6. Cependant, il est possible de construire un algorithme
rapide qui permet de rÃ©soudre ce problÃ¨me sur presque tous les graphes.

L'idÃ©e de construction de cet algorithme repose sur certaines propriÃ©tÃ©s de la sÃ©quence des

degrÃ©s d'un graphe alÃ©atoire.

6On ne sait pas si il est NP-Complet ou non

7

ThÃ©orÃ¨me 4.1 (ErdÃµs-RÃ©nyi) Soient p = wn log(n)/n et  > 0 xÃ©s, avec n 7â†’ wn une fonc-
tion non bornÃ©e Ã  croissance arbitrairement lente. Alors presque tous les graphes Gp vÃ©rient :

(1 âˆ’ ) âˆ— p âˆ— n < Î´(Gp) â‰¤ âˆ†(Gp) â‰¤ (1 + ) âˆ— p âˆ— n

ThÃ©orÃ¨me 4.2 (BollobÃ¡s) Dans le modÃ¨le A, avec p xÃ©, et t(n) = Î¸((n/ log(n))1/4), les t(n)
sommets de plus haut degrÃ© sont de degrÃ©s diÃ©rents pour presque tout Gp.

Ce rÃ©sultat va nous permettre de construire un algorithme permettant de tester l'isomor-

phisme de deux graphes de faÃ§on rapide.

ThÃ©orÃ¨me 4.3 (Babai-ErdÃµs-Selkow) Il existe un algorithme quadratique qui teste l'isomor-
phisme de presque toute paire de graphes.
Preuve L'idÃ©e sous-jacente est la suivante : on construit un ensemble H qui contient presque
tous les graphes, et on montre que l'isomorphisme avec un graphe de H peut Ãªtre testÃ©e de faÃ§on
rapide.
Construction de H Soit un graphe G Ã  n sommets, codÃ© par matrices d'adjacence. Calculer
le degrÃ© de ses sommets, et les indicer par degrÃ© dÃ©croissant. On pose r = b3 âˆ— log(n)c. Si
d(vi) = d(vi+1) pour un i < r, on rejette G. Le thÃ©orÃ¨me ci dessus montre avec p = 1/2
que presque tous les graphes passent ce test.
On pose U = v1, . . . , vr. Il y de l'ordre de n3 diÃ©rents sous ensembles de U . On construit
H comme l'ensemble des graphes non rejettÃ©s, tels que les sommets de V âˆ’ U ont des
voisinages diÃ©rents dans U . Cela peut Ãªtre fait en Î˜(n2) Ã©tapes : pour tout x âˆˆ V âˆ’ U , on
encode N(X) âˆ© U comme un r-uplet binaire. On peut donc les trier comme des nombres
binaires en Î˜(n log n). On renomme les sommets restants dans l'ordre dÃ©croissant de ces
valeurs, en Ã©liminant le graphe si deux valeurs consÃ©cutives sont identiques.
Il faut encore montrer que pour presque tous les graphes Gp la probabilitÃ© pour les sommets
de V âˆ’ U d'avoir le mÃªme voisinage dans U tend vers 0. On peut montrer que le nombre
de paires de sommets en dehors de U avec des voisinages identiques dans U est bornÃ©e par

(cid:1)(1 âˆ’ p)r). Or cette quantitÃ© tend vers 0.

Utilisation de H Les graphes de H sont les graphes qu'il est facile d'Ã©tiquetter. Supposons
maintenant qu'on aie deux graphes Ã©tiquettÃ©s dans H, iomorphes au sens de l'Ã©tiquettage.
Il sut alors de comparer les matrices d'adjacences, dont les lignes et les colonnes sont
indicÃ©es par les Ã©tiquettes. Deux graphes sont isomorphes si et seulement si les matrices
sont identiques, ce qui se vÃ©rie en Î˜(n2) Ã©tapes.

O((cid:0)nâˆ’r

2

Fin de preuve

5 ExpÃ©riences

La gure ?? indique les caractÃ©ristiques gÃ©nÃ©rales de nombreux graphes. Pour chaque graphe,
certaines quantitÃ©s thÃ©oriques (longueur moyenne de chemin, coecient de clusterisation) sont
comparÃ©es aux prÃ©visions thÃ©oriques.

On remarque que la longueur moyenne de chemin est assez bien dÃ©crite par le modÃ¨le thÃ©o-
rique A. Par contre le coecient de clusterisation est beaucoup plus important que les prÃ©visions
thÃ©oriques du modÃ¨le A. [?], page 14 indique que mÃªme pour le modÃ¨le B, il existe parfois un
facteur 2 entre prÃ©vision et rÃ©alisation.

8

Fig. 5  Figure extraite de [?], page 8, comparant les donnÃ©es issues de graphes rÃ©els aux
prÃ©visions statistiques

Conclusion

En conclusion de ce rapport, je dois dire que le sujet des graphes alÃ©atoires est extrÃªmement
riche et intÃ©ressant. Les diÃ©rentes modÃ©lisations peuvent Ãªtre mises en examen en les comparant
aux donnÃ©es expÃ©rimentales, ce qui conduit actuellement Ã  un regain d'intÃ©rÃªt pour ce domaine.
Les modÃ©lisations prÃ©sentÃ©es ici sont des modÃ©lisations parmi d'autres, en particulier, elles
ne traitent pas des problÃ¨mes de graphes orientÃ©s, et pourraient Ãªtre ranÃ©es pour fournir des
rÃ©sultats plus intÃ©ressants sur des problÃ¨mes de graphes bipartis, petit-monde ou autres.

Un aspect que je n'ai pas du tout abordÃ©, mais qui est Ã©voquÃ© de faÃ§on importante dans
les sources que j'ai parcourues est l'Ã©volution temporelle des graphes auxquels on ajoute ou
retranche des arÃªtes. On s'aperÃ§oit que le comportement gÃ©nÃ©ral de cette Ã©volution peut varier
de faÃ§on extrÃªme pour des valeurs de p proches, par exemple, si l'on essaie de modÃ©liser les
propriÃ©tÃ©s d'un solide dont les liaisons entre les molÃ©cules sont dÃ©truites au hasard.

Il m'a Ã©tÃ© dicile de rÃ©aliser des expÃ©riences sur le modÃ¨le B, Ã©tant donnÃ© que je n'ai pas
trouvÃ© de construction associÃ©e Ã  la modÃ©lisation. En eet, Ã©tant donnÃ©e une distribution de
degrÃ©s, rien ne dit qu'il est possible de construire un graphe correspondant (cas Ã©vident oÃ¹ la
somme des degrÃ©s est impaire...), ni combien de graphes sont possibles. Ce dÃ©faut est nÃ©gligeable
dans le sens oÃ¹ ce qui intÃ©resse les auteurs de [?] est le rapport entre les prÃ©visions du modÃ¨le
et les donnÃ©es expÃ©rimentales Ã  leur disposition, sans qu'ils cherchent par exemple Ã  rÃ©aliser des
analyses d'algorithmes. Les informations de [?] et de l'ouvrage de rÃ©fÃ©rence [?] sont Ã  ce titre
prÃ©sentÃ©es de faÃ§on plus informaticienne.

9

Annexes

Formulaire de probabilitÃ©s

Espace de probabilitÃ©s On appelle espace de probabilitÃ©s S un ensemble dÃ©nombrable, tel
xâˆˆS wx = 1. On appelle Ã©vÃ©ne-
xâˆˆE wx.

qu'Ã  chaque Ã©lÃ©ment x de S on associe un poids wx, et tel queP
ment un sous ensemble E de S. On appelle probabilitÃ© d'un Ã©vÃ©nement E : P [E] =P
X la quantitÃ© E(X) =P

Variable alÃ©atoire On appelle variable alÃ©atoire une fonction X qui associe un rÃ©el Ã  tout
Ã©lÃ©ment de S. On note X = k pour e âˆˆ S|X(e) = k. On appelle espÃ©rance d'une variable alÃ©atoire

k k âˆ— P [X = k].

P (X â‰¥ t â‰¤ E(X)/t

Lemme 5.1 (InÃ©galitÃ© de Markov) Soit X une variable alÃ©atoire prenant uniquement des
valeurs non nulles. On a :

De plus, si X ne prends que des valeurs entiÃ¨res, on a : Si E(X) 7â†’ 0, alors P (X = 0) 7â†’ 1

Preuve E(X) =P

kâ‰¥0 k âˆ— pk â‰¥P

kâ‰¥t k âˆ— pk â‰¥ t âˆ— (P

kâ‰¥t pk) = t âˆ— P (X â‰¥ t)

Fin de preuve
Variance On appelle variance7 la quantitÃ© :V ar(X) = E((X âˆ’ E(X))2)

Le formalisme suivant permet d'exprimer de faÃ§on Ã©lÃ©gante certains rÃ©sultats sur le modÃ¨le

B.

Fonction gÃ©nÃ©ratrice d'une variable alÃ©atoire Soit X une variable alÃ©atoire Ã  valeurs en-
tiÃ¨res, non nÃ©gatives. La fonction gÃ©nÃ©ratrice de X est dÃ©nie par :

âˆX

G(x) =

P (X = n) âˆ— xn

On supposera par la suite que cette sÃ©rie converge absolument pour tout x â‰¤ 1.

n=0

Lemme 5.2 (PropriÃ©tÃ©s des fonctions gÃ©nÃ©ratrices) Quelques propriÃ©tÃ©s usuelles :

 P (X = k) = G(k)(0)
 E(X) = G0(1)
 V ar(X) = G00(1) + G0(1) âˆ’ [G0(1)]2

k!

DÃ©nitions
DiamÃ¨tre Le diamÃ¨tre d'un graphe G = (V, E) est dÃ©ni par :

maxu,vâˆˆV (d(u, v))

PropriÃ©tÃ© monotone Une propriÃ©tÃ© est qualiÃ© de monotone si elle est prÃ©servÃ©e par addition
d'arÃªtes.

Coecient de clusterisation Le coecient de clusterisation est dÃ©ni comme la probabilitÃ©
que, partant d'un sommet d'un graphe, et choisissant deux voisins, il existe une arrÃªte entre eux.
Avec Î»G(v) le nombre de triangles pour dans lesquels le sommet v appairait, et TG(v) le

nombre de triplets que l'on peut former avec deux voisins de v, on a :

âˆ—X

vâˆˆV

C =

1
n

Î»G(v)
TG(v)

7La variance reprÃ©sente la dispersion d'une variable alÃ©atoire autour de sa valeur moyenne

10

RÃ©fÃ©rences

[1] Reka Albert and Albert-Laszlo Barabasi. Statistical mechanics of complex networks. Reviews

of Modern Physics, 74 :47, 2002.

[2] B. Bollobas. Random Graphs. Cambridge University Press (2001), 2001.

[3] M. E. J. Newman, S. H. Strogatz, and D. J. Watts. Random graphs with arbitrary degree

distributions and their applications. Physical Review E, 64 :026118, 2001.

[4] D. B. West. Introduction to Graph Theory (2nd Edition). (Prenctice Hall, Upper Saddle

River), 2001.

11

