https://www.theses.fr/2017CERG0842.pdf

T H Ãˆ S E

pour obtenir le titre de

Docteur de

de l'UniversitÃ© de Cergy Pontoise

SpÃ©cialitÃ© : Sciences et Technologies de l'Information

et de la Communication STIC

prÃ©sentÃ©e et soutenue par

Jean-Philippe ATTAL

Nouveaux algorithmes pour la dÃ©tection de

communautÃ©s disjointes et chevauchantes

basÃ©s sur la propagation de labels et adaptÃ©s

aux grands graphes

date de soutenance 19 janvier 2017

Le jury est composÃ© de :

Rapporteur M. Arnaud MARTIN
Rapporteur M. Guy MELANÃ‡ON
Examinateur M. Henry SOLDANO
Directeur
Examinateur Mme. Maria MALEK
Examinateur M. Dominique Laurent

M. Marc ZOLGHADRI

1 RÃ©sumÃ©

Les graphes sont des structures mathÃ©matiques capables de modÃ©liser certains systÃ¨mes com-
plexes. Une des nombreuses problÃ©matiques liÃ©es aux graphes concerne la dÃ©tection de communau-
tÃ©s qui vise Ã  trouver une partition en sommet d'un graphe en vue d'en comprendre la structure.
A titre d'exemple, en reprÃ©sentant des contrats d'assurances par des nÃ·uds et leurs degrÃ©s de
similaritÃ© par une arÃªte, dÃ©tecter des groupes de nÃ·uds fortement connectÃ©s conduit Ã  dÃ©tecter
des prols similaires, et donc Ã  voir des prols Ã  risques. De nombreux algorithmes ont essayÃ©
de rÃ©pondre Ã  ce problÃ¨me. Une des mÃ©thodes est la propagation de labels qui consiste Ã  ce que
chaque nÃ·ud puisse recevoir un label par un vote majoritaire de ses voisins. Bien que cette mÃ©-
thode soit simple Ã  mettre en Ã·uvre, elle prÃ©sente une grande instabilitÃ© due au non dÃ©terminisme
de l'algorithme et peut dans certains cas ne pas dÃ©tecter de structures communautaires.

La premiÃ¨re contribution de cette thÃ¨se sera de i) proposer une mÃ©thode de stabilisation
de la propagation de labels tout en appliquant des barrages articiels pour limiter les possibles
mauvaises propagations. Les rÃ©seaux complexes ont Ã©galement comme caractÃ©ristique que certains
nÃ·uds puissent appartenir Ã  plusieurs communautÃ©s, on parle alors de recouvrements. C'est en ce
sens que la seconde contribution de cette thÃ¨se portera sur ii) la crÃ©ation d'un algorithme auquel
seront adjointes des fonctions d'appartenances pour dÃ©tecter de possibles recouvrements via des
nÃ·uds candidats au chevauchement. La taille des graphes est Ã©galement une notion Ã  considÃ©rer
dans la mesure oÃ¹ certains rÃ©seaux peuvent contenir plusieurs millions de nÃ·uds et d'arÃªtes. Nous
proposons iii) une version parallÃ¨le et distribuÃ©e de la dÃ©tection de communautÃ©s en utilisant la
propagation de labels par cÃ·ur. Une Ã©tude comparative sera eectuÃ©e pour observer la qualitÃ© de
partitionnement et de recouvrement des algorithmes proposÃ©s.

Table des mati`eres

Introduction gÂ´enÂ´erale

0.1 Des rÂ´eseaux complexes aux structures communautaires . . . . . .
0.2 Objectif de la th`ese et plan du manuscrit
. . . . . . . . . . . . .
0.3 Graphes utilisÂ´es . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1 Etat de lâ€™art

disjointes

1.1
1.2 Notions et notations relatives `a la thÂ´eorie des graphes

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . .
1.2.1 ReprÂ´esentation dâ€™un graphe . . . . . . . . . . . . . . . . .
1.2.2 CentralitÂ´e dans un graphe . . . . . . . . . . . . . . . . . .
1.2.3 Analyse des rÂ´eseaux sociaux et graphes de terrains . . . .
1.3 DÂ´etection de communautÂ´es disjointes . . . . . . . . . . . . . . . .
1.3.1 Formulation du probl`eme de dÂ´etections de communautÂ´es
. . . . . . . . . . . . . . . . . . . . . . . . . . .
1.3.2 Approches divisives
. . . . . . . . . . . . . . . . . . . . .
1.3.3 Approches agglomÂ´eratives et multi-niveaux . . . . . . . .
1.3.4 Approches fondÂ´ees sur la dÂ´etection de leaders . . . . . . .
1.3.5 Approches fondÂ´ees sur la perturbation du rÂ´eseau . . . . .
1.3.6 Approche par propagation de labels
. . . . . . . . . . . .
1.3.7 Autres mÂ´ethodes . . . . . . . . . . . . . . . . . . . . . . .
1.3.8 Tableau rÂ´ecapitulatif des mÂ´ethodes disjointes . . . . . . .
1.3.9 Mesures supervisÂ´ees et non supervisÂ´ees pour la dÂ´etection
. . . . . . . . . . . . . . . . .
1.3.10 Synth`ese et discussion . . . . . . . . . . . . . . . . . . . .
1.4 DÂ´etection de communautÂ´es chevauchantes . . . . . . . . . . . . .
1.4.1 Formulation du probl`eme de dÂ´etection de communautÂ´es
chevauchantes . . . . . . . . . . . . . . . . . . . . . . . . .
1.4.2 DÂ´etection de communautÂ´es chevauchantes `a base de pro-
. . . . . . . . . . . . . . . . . . . . . .
1.4.3 Autres mÂ´ethodes pour la dÂ´etection de communautÂ´es che-
. . . . . . . . . . . . . . . . . . . . . . . . . .
1.4.4 Tableau rÂ´ecapitulatif des mÂ´ethodes chevauchantes
. . . .
1.4.5 Mesures supervisÂ´ees et non supervisÂ´ees pour la dÂ´etection
de communautÂ´es chevauchantes . . . . . . . . . . . . . . .

de communautÂ´es disjointes

pagation de labels

vauchantes

1

7
8
11
12

15
16
16
18
18
20
23

24
26
30
33
34
36
43
46

49
56
58

58

59

61
64

65

2

TABLE DES MATI `ERES

1.4.6

Synth`ese et discussion . . . . . . . . . . . . . . . . . . . .

70

2 ParallÂ´elisme et distribution

graphes

2.2 Plateformes parall`eles et distribuÂ´ees

2.1 ProblÂ´ematique de la dÂ´etection de communautÂ´es dans de grands
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . .
2.2.1 Hadoop . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.2 Apache Spark . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.3
Syst`eme de traitement de graphes parall`eles . . . . . . . .
2.3 DÂ´etection de communautÂ´es dans un environnement parall`ele et
distribuÂ´e . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.4 Tableau rÂ´ecapitulatif des mÂ´ethodes parall`eles et distribuÂ´ees
. . .
2.5 Synth`ese et discussion . . . . . . . . . . . . . . . . . . . . . . . .

3 Propositions algorithmiques

3.1 LPA avec barrages et dendrogrammes

. . . . . . . . . . . . . . .
3.1.1 Propagation de labels asynchrone avec barrages . . . . . .
3.1.2 Propagation de labels asynchrone avec barrages et dÂ´etection
. . . . . . . . . . . . . . . . . . . . . . . . . . .
3.1.3 ExpÂ´erimentations portant sur les propositions algorith-
miques pour la dÂ´etection de communautÂ´es disjointes . . .
3.1.4 Conclusion sur les algorithmes de propagation de labels

de cÅ“urs

73

73
74
74
75
77

80
85
86

87
88
89

91

98

. . . . . . . . . . . . 121
3.2 LPA avec coloration . . . . . . . . . . . . . . . . . . . . . . . . . 123

avec barrages et dÂ´etection de cÅ“urs

3.2.1 Propagation de labels asynchrone avec dÂ´etection de cÅ“urs

et coloration . . . . . . . . . . . . . . . . . . . . . . . . . 123
3.2.2 ExpÂ´erimentation sur R-POP, POP-UP et POP-DOWN . 125
3.2.3 Conclusion sur les propositions algorithmiques `a base de

3.3 Analyse comparative des mÂ´ethodes disjointes
3.4 Propositions sur le chevauchement

coloration . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
. . . . . . . . . . . 137
. . . . . . . . . . . . . . . . . 141

3.4.1 De la propagation de labels avec dÂ´etection de cÅ“urs au

chevauchement . . . . . . . . . . . . . . . . . . . . . . . . 141
3.4.2 Fonction dâ€™appartenance . . . . . . . . . . . . . . . . . . . 142
3.4.3 Propositions algorithmiques . . . . . . . . . . . . . . . . . 145
3.4.4 ExpÂ´erimentations sur CDLPOV . . . . . . . . . . . . . . . 147
3.4.5 Etude portant sur le temps dâ€™exÂ´ecution . . . . . . . . . . 155
3.4.6 Analyse comparative . . . . . . . . . . . . . . . . . . . . . 156
3.4.7 Conclusion sur les propositions algorithmiques chevau-

chantes

. . . . . . . . . . . . . . . . . . . . . . . . . . . . 158

4 Propositions sur le parallÂ´elisme et la distribution

159
4.1 Propagation de labels avec dÂ´etection de cÅ“urs avec Apache Hadoop160

4.1.1 Proposition algorithmique pour la propagation de labels

parall`ele et distribuÂ´ee avec dÂ´etection de cÅ“urs . . . . . . . 161
4.1.2 ModÂ´elisation MapReduce de PAR-CDLP . . . . . . . . . 161

TABLE DES MATI `ERES

3

4.1.3 CrÂ´eation dâ€™un dendrogramme . . . . . . . . . . . . . . . . 171
4.2 ExpÂ´erimentations . . . . . . . . . . . . . . . . . . . . . . . . . . . 173
4.2.1 Etude de la stabilisation . . . . . . . . . . . . . . . . . . . 173
4.2.2 Etude sur de grands graphes de terrains . . . . . . . . . . 174
4.2.3 Etude volumÂ´etrique traitÂ´ee par le HDFS . . . . . . . . . . 183

4.3 Conclusion portant sur les propositions liÂ´ees au parallÂ´elisme et la

distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186

5 Conclusion

187
5.1 Contributions algorithmiques . . . . . . . . . . . . . . . . . . . . 188
5.2 Perspectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189

6 Glossaire

6.1 DÂ´eï¬nitions relatives aux graphes

191
. . . . . . . . . . . . . . . . . . 191

Bibliographie

195

Remerciements

Cette th`ese mâ€™a permis dâ€™acquÂ´erir une tr`es grande ouverture dâ€™esprit dans

le monde de la recherche.

Je remercie Madame Maria Malek, qui mâ€™a toujours soutenu, aidÂ´e, conseillÂ´e
et protÂ´egÂ´e au cours de cette th`ese. Madame Maria Malek mâ€™a transmis son sa-
voir et mâ€™a initiÂ´e `a la recherche scientiï¬que. Madame Maria Malek a toujours
fait preuve dâ€™une grande gentillesse `a mon Â´egard. Je nâ€™aurais jamais pu rÂ´eussir
cette th`ese sans elle.

Je remercie Monsieur Dominique Laurent, qui a toujours Â´etÂ´e `a mon Â´ecoute et
mâ€™a soutenu. Ses conseils et sa tr`es grande gentillesse mâ€™ont permis dâ€™accomplir
ce travail de doctorat.

Je remercie Monsieur Marc Zolghadri pour avoir acceptÂ´e de diriger cette
th`ese. Par ses conseils, sa grande gentillesse, et son enthousiasme, Monsieur
Marc Zolghadri mâ€™a aidÂ´e `a toujours amÂ´eliorer mon travail scientiï¬que.

Je remercie Monsieur Arnaud Martin dâ€™avoir acceptÂ´e dâ€™Ë†etre rapporteur de
cette th`ese. Monsieur Arnaud Martin mâ€™a beaucoup aidÂ´e `a amÂ´eliorer mon travail
scientiï¬que au cours des diï¬€Â´erentes confÂ´erences auxquelles nous avons assistÂ´e en-
semble. Ses remarques et observations sur le manuscrit mâ€™ont beaucoup aidÂ´e.

Je remercie Monsieur Guy MelanÂ¸con dâ€™avoir acceptÂ´e dâ€™Ë†etre rapporteur de
cette th`ese. Ses analyses critiques et son expÂ´erience mâ€™ont permis dâ€™amÂ´eliorer
ce travail doctoral.

Je remercie Monsieur Henry Soldano dâ€™avoir acceptÂ´e dâ€™Ë†etre examinateur de
cette th`ese. Les questions que Monsieur Henry Soldano a posÂ´ees durant les
diï¬€Â´erentes confÂ´erences auxquelles nous assistions mâ€™ont permis de faire Â´evoluer
mon travail, de lâ€™amÂ´eliorer, et dâ€™ouvrir de nouvelles perspectives scientiï¬ques.

Je remercie Monsieur Chrysostome Baskiotis qui mâ€™a enseignÂ´e, lorsque jâ€™Â´etais
Â´etudiant, le langage Python qui me fut tr`es utile dans la rÂ´ealisation du travail
doctoral.

5

6

TABLE DES MATI `ERES

Je remercie Monsieur Nesim Fintz pour mâ€™avoir aidÂ´e ï¬nanci`erement durant

cette th`ese et de sa grande gentillesse.

Je remercie tous mes coll`egues de lâ€™EISTI qui mâ€™ont toujours aidÂ´e et soutenu

durant mon travail doctoral.

Je remercie tous mes amis de mâ€™avoir aidÂ´e et soutenu.

Je remercie ma famille et mes parents, qui mâ€™ont toujours soutenu et aidÂ´e au
cours de ma vie et durant ce travail doctoral. Câ€™est `a eux que je dÂ´edie ma th`ese.
Je nâ€™aurais jamais rÂ´eussi sans leur soutien. Jâ€™ai une pensÂ´ee pour mes grands-
parents, qui ont contribuÂ´e `a mon Â´education et qui mâ€™ont guidÂ´e dans ma vie.

Introduction

De nombreux syst`emes rÂ´eels sont reprÂ´esentÂ´es `a lâ€™aide de graphes. Des entitÂ´es
peuvent Ë†etre modÂ´elisÂ´ees par des sommets et leurs relations par des arË†etes. Il
existe de nombreux domaines et champs dâ€™application utilisant la structure de
graphe (graphes sociologiques, graphes de collaborations, rÂ´eseaux biologiques
(interactions protÂ´eine-protÂ´eine, rÂ´eseaux de neurones, rÂ´eseaux de g`enes), rÂ´eseaux
sportifs, rÂ´eseaux du web (graphes de pages web connectÂ´ees), rÂ´eseaux de trans-
ports, rÂ´eseaux de co-achats,etc). Ces graphes portent le nom de graphes de
terrains ou de rÂ´eseaux complexes.

Lâ€™Â´etude et lâ€™analyse de ce genre de graphes rÂ´evÂ´elent des informations sur les
acteurs et expliquent la structure mË†eme du rÂ´eseau. Parmi les nombreuses appli-
cations liÂ´ees aux graphes, on peut citer la dÂ´etection de communautÂ´es qui vise `a
trouver au sein dâ€™un graphe des groupes de noeuds fortement connectÂ´es entre
eux et faiblement avec le reste du graphe. La dÂ´etection de communautÂ´es per-
met de trouver les individus dâ€™une population les plus similaires en fonction
de leurs relations. Par exemple, dans le domaine des assurances, considÂ´erer les
contrats dâ€™assurances comme des noeuds et leurs relations comme leurs degrÂ´es
de similaritÂ´e permet de trouver des groupes de contrats similaires, dâ€™oï¬€rir des
communautÂ´es `a Â´etudier pour en comprendre les relations, et de crÂ´eer un mod`ele
de score pour les nouveaux clients. Dans le rÂ´eseau web, o`u les sommets sont
des pages web et les arË†etes des hyperliens, des groupes de pages ou de sites
fortement connectÂ´es traitent souvent de th`emes apparentÂ´es et la dÂ´etection de
communautÂ´es permet lâ€™amÂ´elioration des moteurs de recherche. En considÂ´erant
le rÂ´eseau de neurones du ver Caenorhabditis elegans, Â´etudier lâ€™organisation des
liaisons et lâ€™existence de structures communautaires peut permettre de com-
prendre si la formation des synapses entre neurones se fait de mani`ere alÂ´eatoire
ou non, ce qui peut avoir en biologie et en mÂ´edecine de grandes rÂ´epercussions,
notamment en neurochirurgie. En marketing, grË†ace `a un graphe de co-achats o`u
les sommets reprÂ´esentent les produits et les arË†etes le fait que les produits ont
Â´etÂ´e achetÂ´es ensemble, un algorithme de dÂ´etection de communautÂ´es permettra
de trouver les proï¬ls des produits les plus co-achetÂ´es pour les analyser, en vue
de proposer un syst`eme de recommandation (utilisÂ´e par exemple par la sociÂ´etÂ´e
Amazon).

La dÂ´etection de communautÂ´es prÂ´esente trois challenges :

7

8

INTRODUCTION

Le premier est que les tailles des communautÂ´es peuvent Ë†etre diï¬€Â´erentes au sein
dâ€™un mË†eme graphe selon la nature des objets Â´etudiÂ´es. Par exemple, dans la sec-
tion livres dâ€™Amazon, les tailles des communautÂ´es seront plus grandes pour les
livres dont le th`eme est fantastique que pour ceux dont le th`eme est historique.
On peut observer ce phÂ´enom`ene en utilisant le site http : //www.yasiv.com/.
Le second est que certains nÅ“uds du graphe peuvent appartenir `a plusieurs com-
munautÂ´es. Par exemple, dans un rÂ´eseau de collaboration scientiï¬que, un auteur
peut publier dans diï¬€Â´erents domaines et champs scientiï¬ques.
Le troisi`eme challenge concerne la taille des graphes. Si lâ€™on consid`ere de nou-
veau le graphe Amazon, qui poss`ede plusieurs millions de nÅ“uds et plusieurs
centaines de millions dâ€™arË†etes, appliquer un algorithme de dÂ´etection de commu-
nautÂ´es sur une seule machine peut dans le meilleur des cas prendre plusieurs
heures, au pire, une erreur mÂ´emoire peut survenir due `a la quantitÂ´e de donnÂ´ees
traË†Ä±tÂ´ees.

0.1 Des rÂ´eseaux complexes aux structures com-

munautaires

Un graphe de terrain (ou rÂ´eseau complexe) est un rÂ´eseau constituÂ´e de donnÂ´ees
collectÂ´ees correspondant `a une vÂ´eritÂ´e de terrain. Il est rÂ´ealisÂ´e par des experts.
Un graphe de terrain a des caractÂ´eristiques topologiques non triviales. Ces
caractÂ´eristiques, qui nâ€™apparaissent pas dans les graphes simples ou graphes
alÂ´eatoires, Â´emergent lors de la modÂ´elisation de syst`emes rÂ´eels. Ces rÂ´eseaux
mettent en exergue un ensemble dâ€™individus, dâ€™organisations ou dâ€™objets reliÂ´es
par des interactions sociales rÂ´eguli`eres ou incontestables. Lâ€™un des premiers ayant
travaillÂ´e sur les relations humaines `a travers les graphes fut Moreno (1934) qui
publia â€Who shall survive ?â€. Il Â´etudie les aï¬ƒnitÂ´es entre Â´el`eves de classes de
divers degrÂ´es, reprÂ´esentÂ´es sous forme de sociogramme, posant ainsi les bases de
la sociomÂ´etrie. Lâ€™auteur explique par la suite lâ€™importance de lâ€™utilisation des
graphes comme outils dâ€™analyse sociologique, Moreno (1951).

Câ€™est `a Barnes (1954) que lâ€™on doit le terme analyse des rÂ´eseaux sociaux.
Il porta son analyse sur un cas particulier de rÂ´eseaux de terrains, les rÂ´eseaux
sociologiques. Wasserman et Faust (1994) Â´ecrivirent un livre sur les mÂ´ethodes
appliquÂ´ees aux rÂ´eseaux sociaux qui allaient ouvrir de tr`es nombreuses portes
comme celles du partitionnement de graphe et plus tard, la dÂ´etection de com-
munautÂ´es. Wasserman dÂ´ecrit un rÂ´eseau social comme Â´etant un ensemble ï¬ni
dâ€™acteurs avec des relations dÂ´eï¬nies entre eux. La notion de graphes de terrains
sâ€™est construite au fur et `a mesure dâ€™analyses concernant des syst`emes rÂ´eels, en
liaison avec les rÂ´eseaux sociaux.

Les premi`eres Â´etudes utilisant les rÂ´eseaux sociaux port`erent sur lâ€™aspect relation-
nel entre personnes, Murdock (1949) et Lowie (1950). A travers un graphe social,
lâ€™objectif Â´etait dâ€™expliquer les relations entre individus et comment les liens pou-

0.1. DES R Â´ESEAUX COMPLEXES AUX STRUCTURES COMMUNAUTAIRES9

vaient se former. Elles suivent les Â´etudes de Davis et al. (2009) sur lâ€™aspect com-
portemental et relationnel entre individus en fonction de certains Â´ev`enements.
Les Â´etudes portaient sur le fait de savoir si des personnes de mË†eme catÂ´egorie
sociale allaient entrer en relation ou non. Câ€™est en 1950 que les premi`eres Â´etudes
portant sur les questions de groupes dâ€™individus furent lancÂ´ees par Homans
(1950). Il exposa des exemples de groupes au sein de graphes sociaux. Ses tra-
vaux furent continuÂ´es par Nadel (1957) qui montra lâ€™existence de structures
sociales intrins`eques aux rÂ´eseaux rÂ´eels. Les premi`eres Â´etudes des structures de
groupes au sein du graphe furent proposÂ´ees par Glanzer et Glaser (1961). Les
mÂ´ethodes Â´etaient basÂ´ees sur des graphes de communication. Les premiers tra-
vaux concernant la possibilitÂ´e quâ€™un noeud dâ€™un graphe social puisse apparte-
nir `a plusieurs groupes de noeuds furent introduits par Bonacich (1972) qui
utilisa la topologique des graphes pour en exposer lâ€™existence. Breiger (1974)
proposa de dissocier les arË†etes dans un groupe de noeuds tr`es connectÂ´es de
celles sortant de ces structures. Lâ€™idÂ´ee fut dâ€™expliquer les groupes de noeuds
`a travers les arË†etes et de mettre une voix `a la dÂ´etection de telles structures.
Lâ€™existence de structures de noeuds densÂ´ement connectÂ´es entre eux et faible-
ment avec le reste du graphe fut exposÂ´ee par Newman, qui employa le terme de
communautÂ´es pour dÂ´eï¬nir ces groupes de noeuds. Il montra que la prÂ´esence de
structures communautaires Â´etait une caractÂ´eristique des rÂ´eseaux complexes. Des
Â´etudes menÂ´ees notamment par BarabÂ´asi et Bonabeau (2003), Newman (2003)
et Clauset et al. (2009a) ont essayÂ´e de recenser les caractÂ´eristiques communes
des rÂ´eseaux complexes. Les caractÂ´eristiques portent sur lâ€™eï¬€et â€petit mondeâ€ (le
fait que chaque individu puisse Ë†etre reliÂ´e `a nâ€™importe quel autre par une courte
chaË†Ä±ne de relations sociales), un fort nombre de triangles entre groupes de noeuds
fortement connectÂ´es et une distribution des degrÂ´es suivant une loi faible. Une
Â´etude portant sur les mÂ´ethodes de dÂ´etections de communautÂ´es fut proposÂ´ee par
Fortunato (2010). Il y rÂ´efÂ´erence plus dâ€™une cinquantaine de mÂ´ethodes (la liste
nâ€™est pas exhaustive) quâ€™il classiï¬e selon leurs techniques de partitionnement.
Ainsi, lâ€™auteur montre les algorithmes spectraux, les mÂ´ethodes hiÂ´erarchiques, les
mÂ´ethodes dâ€™optimisation dâ€™une fonction de qualitÂ´e appelÂ´ee la modularitÂ´e et les
autres mÂ´ethodes, notamment celles concernant le recouvrement, o`u un noeud
peut appartenir `a plusieurs communautÂ´es. Le choix de cette classiï¬cation nâ€™est
pas absolu. Lâ€™Â´etude nous oï¬€re plusieurs conclusions `a retenir. Tout dâ€™abord,
beaucoup de mÂ´ethodes issues du partitionnement de graphes (dÂ´ecoupage du
graphe en groupes de noeuds de mË†eme taille dont le nombre est donnÂ´e par lâ€™utili-
sateur, chaque noeud appartenant `a un et un seul groupe) avaient Â´etÂ´e appliquÂ´ees
ou transformÂ´ees pour la dÂ´etection de communautÂ´es. Parmi ces mÂ´ethodes, citons
celles portant sur lâ€™optimisation dâ€™une mesure de qualitÂ´e qui est la modularitÂ´e.
Une Â´etude menÂ´ee par Brandes et al. (2008) montre que lâ€™optimisation de la
modularitÂ´e est NP-diï¬ƒcile. D`es lors, les mÂ´ethodes dâ€™optimisation de la modu-
laritÂ´e ne peuvent sâ€™eï¬€ectuer quâ€™`a une Â´echelle locale si lâ€™on veut pouvoir traiter
des graphes de plusieurs millions de noeuds et dâ€™arË†etes. Lâ€™Â´etude de Fortunato
montre bien que les heuristiques les plus utilisÂ´ees reposent sur les principes de
classiï¬cation hiÂ´erarchique, qui est subdivisÂ´ee en deux catÂ´egories :

â€” les mÂ´ethodes ascendantes (agglomÂ´eratives) : partant des noeuds du graphe

10

INTRODUCTION

(ensembles de singletons), o`u les algorithmes fusionnent deux classes `a
chaque itÂ´eration en optimisant une certaine fonction de qualitÂ´e.

â€” les mÂ´ethodes descendantes (de subdivision), dans lesquelles on consid`ere
la topologie du graphe dans son entier pour y appliquer une coupe. A
chaque itÂ´eration, le graphe est scindÂ´e en deux, donnant deux sous-classes
disjointes dont la coupe donne le score le plus Â´elevÂ´e `a une certaine fonction
de qualitÂ´e.

Ces deux familles de mÂ´ethodes produisent une hiÂ´erarchie de communautÂ´es,
que lâ€™on appelle dendrogramme 6.1. Cependant, Fortunato (2010) a montrÂ´e que
ces mÂ´ethodes nâ€™avaient pas le mË†eme ordre de grandeur en termes de complexitÂ´e.
Les mÂ´ethodes descendantes ont une complexitÂ´e bien plus Â´elevÂ´ee que les mÂ´ethodes
ascendantes car elles consid`erent le graphe dans son entier pour faire la coupe.
La coupe optimale nÂ´ecessite de tester plusieurs possibilitÂ´es, parfois de migrer
certains noeuds dans dâ€™autres communautÂ´es comme le fait le recuit-simulÂ´e (Gui-
mera et Amaral (2005)) maximisant la modularitÂ´e, mais ne permettant lâ€™appli-
cation quâ€™`a des graphes de quelques dizaines de milliers de noeuds en un temps
raisonnable. Ces mÂ´ethodes sont dÂ´eterministes.

Les mÂ´ethodes ascendantes, dont les calculs sont basÂ´es sur le voisinage des
noeuds, demandent beaucoup moins de calculs, et permettent de traiter des
graphes de plus grandes tailles. Les mÂ´ethodes ascendantes sont non-dÂ´eterministes
alors que les mÂ´ethodes descendantes le sont. Ces conclusions se retrouvent dans
dâ€™autres Â´etudes comparatives telles que PlantiÂ´e et Crampes (2013), Papado-
poulos et al. (2012) ou Yang et Leskovec (2012). Les mÂ´ethodes prÂ´ecÂ´edemment
citÂ´ees oï¬€rent la possibilitÂ´e de partitionner un graphe en sous-groupes de noeuds
disjoints, cependant, elles ne permettent pas de crÂ´eer de recouvrements, o`u
des noeuds peuvent appartenir `a plusieurs communautÂ´es. Câ€™est pourtant une
caractÂ´eristique qui fut remarquÂ´ee pour les graphes de terrain. Par exemple,
en biologie, des recherches actuelles sâ€™eï¬€ectuent sur des rÂ´eseaux dâ€™interactions
protÂ´eine-protÂ´eine pour permettre, entre autres, de prÂ´edire leurs fonctions. Ce-
pendant, des protÂ´eines peuvent possÂ´eder plusieurs fonctions, il est ainsi utile de
construire des recouvrements, câ€™est `a dire un syst`eme de classes chevauchantes,
pour connaË†Ä±tre les fonctions des protÂ´eines suivant les diï¬€Â´erents tissus.

Parmi les nombreuses mÂ´ethodes de dÂ´etection de communautÂ´es, la propaga-
tion de labels (Raghavan et al. (2007)) est celle qui est la plus rapide et celle
permettant de traiter les plus grands graphes. Elle prÂ´esente cependant certains
inconvÂ´enients. Câ€™est une mÂ´ethode basÂ´ee sur le vote majoritaire des voisins dâ€™un
noeud pour la propagation de labels, ainsi, en cas dâ€™Â´equidistribution des labels
majoritaires, la mÂ´ethode est sujette au non dÂ´eterminisme. Il a Â´etÂ´e Â´egalement
notÂ´e que certaines mauvaises propagations pouvaient donner des communautÂ´es
ayant le mË†eme label. Enï¬n, lâ€™aspect asynchrone de la mÂ´ethode, câ€™est `a dire le
fait que chaque noeud du graphe doive connaË†Ä±tre le label courant de ses voisins
en fait une mÂ´ethode diï¬ƒcile `a parallÂ´eliser. La propagation de labels constituera
le socle algorithmique de nos contributions scientiï¬ques.

0.2. OBJECTIF DE LA TH `ESE ET PLAN DU MANUSCRIT

11

0.2 Objectif de la th`ese et plan du manuscrit

Les Â´etudes comparatives menÂ´ees par Fortunato ont montrÂ´e lâ€™existence de
nombreuses mÂ´ethodes dont les principales sont soit divisives, soit agglomÂ´eratives.
Il a Â´etÂ´e observÂ´e que les mÂ´ethodes locales, câ€™est-`a-dire dont le point de dÂ´epart
est atomique (par le noeud), permettaient de traË†Ä±ter de plus grands graphes que
les mÂ´ethodes divisives. La propagation de labels est une mÂ´ethode locale, qui
prÂ´esente lâ€™avantage dâ€™Ë†etre rapide et applicable `a des graphes de plusieurs mil-
lions de noeuds et dâ€™arË†etes mais elle a certains inconvÂ´enients. Câ€™est en ce sens
que notre premi`ere contribution sera i) de proposer une version amÂ´eliorÂ´ee de la
propagation de labels en y incluant une stabilisation par recherche de coeurs et
mise en place de barrages artiï¬ciels pour Â´eviter de mauvaises propagations. La
seconde contribution ii) sera dâ€™amÂ´eliorer la mÂ´ethode prÂ´ecÂ´edente pour le chevau-
chement en y incluant une fonction dâ€™appartenance permettant de dÂ´etecter des
noeuds pouvant appartenir `a plusieurs communautÂ´es. Plusieurs fonctions dâ€™ap-
partenance basÂ´ees sur la densitÂ´e et le coeï¬ƒcient de clustering seront proposÂ´ees en
vue dâ€™une Â´etude comparative. Enï¬n, nous proposerons iii) une implÂ´ementation
MapReduce de notre propagation de labels pour travailler sur de plus grands
graphes ayant au moins plusieurs millions de noeuds et dâ€™arË†etes. La propagation
de labels dans sa forme asynchrone prÂ´esente une diï¬ƒcultÂ´e pour le parallÂ´elisme
`a laquelle nous rÂ´epondrons.

Dans la suite du manuscrit, nous prÂ´esenterons au chapitre 1 la problÂ´ematique
de la dÂ´etection de communautÂ´es disjointes et chevauchantes, les mÂ´ethodes exis-
tantes pour la rÂ´esolution de ces probl`emes et les mesures sur la qualitÂ´e de parti-
tionnement qui y sont associÂ´ees. Le chapitre 2 traitera des mÂ´ethodes parall`eles
et distribuÂ´ees de la littÂ´erature avec les plateformes destinÂ´ees au traitement de
grands graphes. Le chapitre 3 prÂ´esentera notre contribution `a la dÂ´etection de
communautÂ´es disjointes et chevauchantes.
Le chapitre 4 donnera une implÂ´ementation Hadoop parall`ele et distribuÂ´ee dâ€™un
de nos algorithmes pour la dÂ´etection de communautÂ´es disjointes, ouvrant la
voie `a lâ€™Â´elaboration dâ€™une implÂ´ementation pour le chevauchement. Enï¬n, nous
prÂ´esenterons nos conclusions au chapitre 5, nos travaux de recherches actuels et
nos perspectives.

12

INTRODUCTION

0.3 Graphes utilisÂ´es

Pour tester la qualitÂ´e de nos algorithmes, et dans la mesure o`u nous voulons
que nos algorithmes soient Â´echelonnables selon lâ€™ordre et la taille du graphe, le
tout en rÂ´epondant aux problÂ´ematiques des grands graphes, nous proposons de
travailler sur les rÂ´eseaux rÂ´eels, plus exactement sociaux.

Nous utilisons des graphes issus de la littÂ´erature dont nous connaissons par
avance les communautÂ´es pour tester nos propositions algorithmiques et Â´etudier
leur comportement. Nous pouvons les retrouver sur le site
https : //snap.stanf ord.edu/snap/. Une Â´etude comparative pourra ensuite Ë†etre
proposÂ´ee avec les algorithmes les plus connus de la littÂ´erature. Les rÂ´eseaux pour
notre Â´etude concernent :

Le club de karatÂ´e de Zachary, Zachary (1977) (Zac) : un rÂ´eseau de membres
dâ€™un club chez lesquels une dispute entraine la formation de deux communautÂ´es
autour du manager et de lâ€™entraË†Ä±neur.
Un rÂ´eseau de dauphins, Lusseau et al. (2003) (Dol) : un graphe de dauphins
Â´etudiÂ´e `a Doubtful Sound, en Nouvelle ZÂ´elande. Le graphe comprend 62 dauphins
reprÂ´esentÂ´es en deux communautÂ´es, mË†ales et femelles.
Un rÂ´eseau footballistique, Girvan et Newman (2002a) (Foot) un graphe ex-
posant 11 diï¬€Â´erentes compÂ´etitions entre clubs de football amÂ´ericain.
Un rÂ´eseau de livres politiques amÂ´ericains, Krebs (2004) (pol) un graphe de
co-achat exposant les livres politiques Â´editÂ´es en 2004 et vendus sur Amazon.com.
Le graphe comprend 3 communautÂ´es, les DÂ´emocrates, les RÂ´epublicains et les
neutres.
Un rÂ´eseau de musiciens de jazz, Gleiser et Danon (2003), o`u chaque noeud
reprÂ´esente un musicien, une arË†ete dÂ´enotant que deux musiciens ont jouÂ´e en-
semble dans un groupe.
Le rÂ´eseau aÂ´eroportuaire amÂ´ericain de 1997, Batagelj et Mrvar (2006), o`u
les noeuds sont des aÂ´eroports et les liens sont des lignes directes .
Le rÂ´eseau dâ€™Amazon, Yang et Leskovec (2015), qui est un graphe de co-achat
o`u les noeuds sont des produits (livres, vidÂ´eos, CD de musique,etc). Un lien est
mis entre le produit i et le produit j si les deux produits sont frÂ´equemment
achetÂ´es ensemble.
Le rÂ´eseau de collaborations scientiï¬ques DBLP, Yang et Leskovec (2015),
o`u les auteurs de publications scientiï¬ques sont liÂ´es sâ€™ils sont co-auteurs.
Le rÂ´eseau de vidÂ´eos You tube, Yang et Leskovec (2015), o`u les noeuds
sont des utilisateurs qui peuvent former des groupes auxquels sâ€™agglom`erent de
nouveaux utilisateurs. Les groupes de noeuds sont caractÂ´erisÂ´es par des th`emes
sociaux.
Le rÂ´eseau social LiveJournal, Yang et Leskovec (2015) est une communautÂ´e
de blogs en ligne gratuite, o`u les utilisateurs se dÂ´eclarent leur amitiÂ´e, formant
ainsi des liens. Les utilisateurs penvent Â´egalement former des groupes sur des
th`emes auxquels dâ€™autres utilisateurs peuvent se joindre.
Les caractÂ´eristiques des graphes sont exposÂ´ees sur le tableau 1.

0.3. GRAPHES UTILIS Â´ES

13

CaractÂ´eristiques de certains rÂ´eseaux rÂ´eels

densitÂ´e
0,139
0,0938
0,0841
0,0808
0,281
0.038
0,0021
1,65e âˆ’ 05
2,08e âˆ’ 05
4,3e âˆ’ 06
4,3e âˆ’ 06

diam`etre

5
4
8
7
6
6
17
44
21
20
17

AT

0,2557
0,4072
0,3088
0,3484
0,52
0.0

0,6934
0,3967
0,6324
0,0808
0,2843

rÂ´eseaux
Zachary
Football
Dauphins
Politique
Jazz
US-Air 97
Netscience
Amazon
DBLP
You tube
LiveJournal

|V | et |E|
34 \ 78
115 \ 615
62 \ 159
105 \ 441
198 \ 5 484
332 \ 2126
1 589 \ 2 742

334 863 \ 925 872
317 080 \ 1 049 866
1 134 890 \ 2 987 624
3 997 962 \ 34 681 189

Tableau 1 â€“ CaractÂ´eristiques des rÂ´eseaux utilisÂ´es frÂ´equemment pour les Â´etudes algo-
rithmiques avec AT, pour la transitivitÂ´e moyenne. |V | est le nombre de noeuds du
graphe et |E|, le nombre dâ€™arË†etes.

14

INTRODUCTION

Chapitre 1

Etat de lâ€™art

Introduction . . . . . . . . . . . . . . . . . . . . . .

Sommaire
16
1.1
1.2 Notions et notations relatives `a la thÂ´eorie des graphes 16
18
18
20
23

1.2.1 ReprÂ´esentation dâ€™un graphe . . . . . . . . . . . . . .
1.2.2 CentralitÂ´e dans un graphe . . . . . . . . . . . . . . .
1.2.3 Analyse des rÂ´eseaux sociaux et graphes de terrains .

1.3 DÂ´etection de communautÂ´es disjointes . . . . . . .
1.3.1 Formulation du probl`eme de dÂ´etections de commu-

nautÂ´es disjointes . . . . . . . . . . . . . . . . . . . .
1.3.2 Approches divisives
. . . . . . . . . . . . . . . . . .
1.3.3 Approches agglomÂ´eratives et multi-niveaux . . . . .
1.3.4 Approches fondÂ´ees sur la dÂ´etection de leaders . . . .
1.3.5 Approches fondÂ´ees sur la perturbation du rÂ´eseau . .
1.3.6 Approche par propagation de labels
. . . . . . . . .
1.3.7 Autres mÂ´ethodes . . . . . . . . . . . . . . . . . . . .
1.3.8 Tableau rÂ´ecapitulatif des mÂ´ethodes disjointes . . . .
1.3.9 Mesures supervisÂ´ees et non supervisÂ´ees pour la dÂ´etection

24
26
30
33
34
36
43
46

de communautÂ´es disjointes

. . . . . . . . . . . . . .
1.3.10 Synth`ese et discussion . . . . . . . . . . . . . . . . .

1.4 DÂ´etection de communautÂ´es chevauchantes

. . . .
1.4.1 Formulation du probl`eme de dÂ´etection de commu-

49
56
58

nautÂ´es chevauchantes

. . . . . . . . . . . . . . . . .

58

1.4.2 DÂ´etection de communautÂ´es chevauchantes `a base de

propagation de labels

. . . . . . . . . . . . . . . . .

59

1.4.3 Autres mÂ´ethodes pour la dÂ´etection de communautÂ´es

chevauchantes . . . . . . . . . . . . . . . . . . . . . .
.

1.4.4 Tableau rÂ´ecapitulatif des mÂ´ethodes chevauchantes
1.4.5 Mesures supervisÂ´ees et non supervisÂ´ees pour la dÂ´etection

61
64

de communautÂ´es chevauchantes . . . . . . . . . . . .
Synth`ese et discussion . . . . . . . . . . . . . . . . .

65
70

1.4.6

15

16

CHAPITRE 1. ETAT DE Lâ€™ART

1.1

Introduction

La dÂ´etection de communautÂ´es est un domaine de recherche actif depuis
ces vingt derni`eres annÂ´ees. De tr`es nombreuses approches ont Â´etÂ´e mises en
Å“uvre pour la dÂ´etection de structures communautaires. Certaines mÂ´ethodes
consid`erent le graphe dans son ensemble et eï¬€ectuent une coupe pour trouver
des communautÂ´es alors que dâ€™autres privilÂ´egieront une approche nodale (câ€™est-
`a-dire, un partitionnement fondÂ´e sur les propriÂ´etÂ´es de nÅ“uds voisins). Lâ€™`ere du
traitement de donnÂ´ees massives, a Â´egalement vu la naissance dâ€™architectures pa-
rall`eles et distribuÂ´ees sur lesquelles se sont agrÂ´egÂ´es de nombreux algorithmes et
des solutions `a des probl`emes multidisciplinaires.

Ce chapitre vise `a prÂ´esenter les principales mÂ´ethodes de dÂ´etection de commu-
nautÂ´es disjointes et chevauchantes. Nous prÂ´esenterons dans un premier temps la
notion de rÂ´eseaux complexes avec les caractÂ´eristiques communes qui leur sont
associÂ´ees. Nous donnerons une formulation `a la dÂ´etection de communautÂ´es dis-
jointes et chevauchantes, ainsi que les mÂ´ethodes respectives pour rÂ´esoudre ces
probl`emes. A la ï¬n de chaque section dÂ´ecrivant les mÂ´ethodes pour un probl`eme
donnÂ´e, un tableau rÂ´ecapitulatif suivi dâ€™une discussion sera prÂ´esentÂ´e pour expli-
quer les choix et les dÂ´ecisions que nous avons pris au cours de cette th`ese. Nous
exposerons les mesures supervisÂ´ees et non supervisÂ´ees relatives `a chaque type
de probl`eme avec des tableaux rÂ´ecapitulatifs et une discussion sur le choix des
mesures que nous avons sÂ´electionnÂ´ees. A partir de lâ€™Â´etat de lâ€™art que nous aurons
prÂ´esentÂ´e, nous tirerons les conclusions nÂ´ecessaires pour le dÂ´eveloppement de nos
solutions de dÂ´etection de communautÂ´es disjointes, chevauchantes, parall`eles et
distribuÂ´ees.

1.2 Notions et notations relatives `a la thÂ´eorie

des graphes

Nous utilisons dans la suite de ce manuscrit de nombreuses notations qui

illustreront lâ€™Â´etat de lâ€™art, nos propositions algorithmiques et nos expÂ´erimentations.
Nous proposons dans cette section de donner les dÂ´eï¬nitions gÂ´enÂ´erales relatives
aux graphes.

Un graphe G est une structure mathÂ´ematique, plus exactement un couple
(V, E), o`u V = {v1, ..., vn} est lâ€™ensemble des sommets (ou nÅ“uds) et E est lâ€™en-
semble des arË†etes (ou liens) E = {e1, ..., em}. Une arË†ete ek âˆˆ E est un couple de
sommets (vi, vj) reliant les sommets vi `a vj. La notation usuelle pour dÂ´eï¬nir un
graphe G est G = (V, E). Nous notons |V | = n lâ€™ordre du graphe, câ€™est-`a-dire le
nombre de sommets du graphe et |E| = m le nombre dâ€™arË†etes. Deux sommets
u, v âˆˆ V sont dit voisins (ou adjacents) si une arË†ete les relie, câ€™est-`a-dire sâ€™il
existe une arË†ete e âˆˆ E telle que e = {u, v}. On dit Â´egalement quâ€™une paire de
sommets est adjacente si les deux sommets qui la composent sont adjacents.

1.2. NOTIONS ET NOTATIONS RELATIVES `A LA TH Â´EORIE DES GRAPHES17

Il existe des graphes orientÂ´es (ou dirigÂ´es) et non orientÂ´es (non dirigÂ´es). Un
graphe orientÂ´e est un graphe pour lequel les arË†etes sont orientÂ´ees, ce qui nâ€™est
pas le cas pour un graphe non orientÂ´e. Un graphe peut Â´egalement Ë†etre pondÂ´erÂ´e
ou valuÂ´e, câ€™est-`a-dire lorsquâ€™il existe une fonction W : e âˆˆ E â†’ R qui `a chaque
lien associe une valeur rÂ´eelle. On note G = (V, E, W ) un graphe pondÂ´erÂ´e.

Un graphe a certaines caractÂ´eristiques propres. Nous donnons les principales

dÂ´eï¬nitions.

On note N (u) le voisinage du nÅ“ud u , o`u N (u) = {u âˆˆ V, (u, v) âˆˆ E}. Le
cardinal du voisinage dâ€™un sommet est son degrÂ´e (ou degrÂ´e dâ€™incidence) que lâ€™on
note d(u) o`u ku (Freeman (1978)) qui est le nombre de liens qui lui sont incidents.

(cid:80)

Le degrÂ´e moyen dâ€™un graphe notÂ´e Î»G pour un graphe G est la moyenne des

degrÂ´es des nÅ“uds du graphe : Î»G = 1
n

uâˆˆV d(u).

Un graphe G(cid:48) = (V (cid:48), E(cid:48)) est un sous-graphe de G = (V, E) si V (cid:48) âŠ† V
et E(cid:48) âŠ† E, et toute arË†ete de E(cid:48) a ses extrÂ´emitÂ´es dans V (cid:48). Etant donnÂ´e un
ensemble V (cid:48) âŠ† V , le sous-graphe de G engendrÂ´e (ou induit) par S(cid:48) est le graphe
G(cid:48) = (V (cid:48), E(cid:48)), o`u E(cid:48) = {(u, v) âˆˆ E : u, v âˆˆ S(cid:48)}

Un graphe partiel de G est un graphe G(cid:48) = (V (cid:48), E(cid:48)) qui a le mË†eme nombre de
sommets mais pour lequel certains arcs ou arË†etes ont Â´etÂ´e Â´eliminÂ´es, câ€™est-`a-dire
avec V (cid:48) = V et E(cid:48) âŠ‚ E.

On appelle graphe complet, un graphe o`u tous les sommets sont adjacents,
câ€™est-`a-dire si tout couple de sommets distincts est liÂ´e par une arË†ete. Pour tout
entier naturel n, on note Kn le graphe complet dâ€™ordre n. Le nombre dâ€™arË†etes du
graphe complet Kn est Â´egal `a n(nâˆ’1)
. On appelle clique un sous-graphe complet
de G.

2

Un chemin du sommet s vers le sommet t dans un graphe orientÂ´e est une
suite v0, v1, ..., vk de sommets telle que v0 = s, vk = t, (viâˆ’1, vi) âˆˆ E, pour tout
1 â‰¤ i â‰¤ k. Le terme k est appelÂ´e la longueur du chemin, et on dit que le sommet
t est joignable `a partir du sommet s. Le chemin est dit simple (ou Â´elÂ´ementaire)
si les vi sont distinctes deux-`a-deux (arË†etes incidentes deux-`a-deux). La notion
correspondante dans les graphes non orientÂ´es est celle de chaË†Ä±ne. Dans un graphe
non orientÂ´e, un cycle est une suite dâ€™arË†etes consÂ´ecutives (chaine) dont les deux
sommets extrÂ´emitÂ´es sont identiques, câ€™est-`a-dire tel que v0 = vk.

La distance gÂ´eodÂ´esique entre deux sommets dans un graphe est dÂ´eï¬nie par

la longueur dâ€™un plus court chemin entre ces deux sommets.

Un graphe est dit connexe si deux sommets quelconques peuvent Ë†etre reliÂ´es

par un chemin.

18

CHAPITRE 1. ETAT DE Lâ€™ART

La densitÂ´e dâ€™un graphe, notÂ´e ÏG, est le rapport entre le nombre dâ€™arË†etes (ou
dâ€™arcs) et le nombre dâ€™arË†etes (ou dâ€™arcs) possibles. ÏG = 2m
n(nâˆ’1) . Un graphe
dont la densitÂ´e est de 1 est un graphe complet, câ€™est-`a-dire o`u chaque sommet
est reliÂ´e `a tout autre sommet par une arË†ete. Un graphe avec une densitÂ´e nulle
signiï¬e quâ€™aucun sommet nâ€™est connectÂ´e `a un autre.

Lâ€™excentricitÂ´e dâ€™un sommet est sa distance maximale `a tous les autres som-
mets. Le diam`etre dâ€™un graphe est la plus longue des distances entre deux som-
mets du graphe considÂ´erÂ´e. Câ€™est lâ€™excentricitÂ´e maximale.

Il existe de tr`es nombreux types de graphes dans la littÂ´erature. Nous nous
focaliserons dans notre Â´etude sur des graphes simples, câ€™est-`a-dire ne contenant
ni boucle (un lien reliant un sommet `a lui mË†eme) et ni plus dâ€™un lien entre deux
mË†emes sommets. Nous porterons notre attention aux rÂ´eseaux complexes dont
nous donnerons les caractÂ´eristiques gÂ´enÂ´erales dans cette section.

1.2.1 ReprÂ´esentation dâ€™un graphe

Il existe plusieurs structures permettant de reprÂ´esenter un graphe. Lâ€™une des
structures les plus intuitives concerne la reprÂ´esentation matricielle. Un graphe
peut Ë†etre reprÂ´esentÂ´e par une matrice dâ€™adjacence de taille |V |Ã—|V | dont lâ€™Â´elÂ´ement
non-diagonal notÂ´e Aij reprÂ´esente le nombre dâ€™arË†etes liant le nÅ“ud i au nÅ“ud
j. La matrice dâ€™adjacence est notÂ´ee A. Dans un graphe simple (sans boucle), la
diagonale de la matrice ne comprend que des zÂ´eros. Cette reprÂ´esentation per-
met dâ€™avoir des informations sur la topologie du graphe et sur les relations entre
paires de sommets. On peut par exemple, connaË†Ä±tre le nombre de chemins de
longueur k entre deux nÅ“uds i et j en Â´elevant la matrice `a la puissance k et
en observant les Â´elÂ´ements de la ieme ligne et de la jeme colonne de la matrice
rÂ´esultante.

Bien que la structure de matrice soit sÂ´eduisante `a utiliser, elle nâ€™est pas pra-
tique en programmation dans la mesure o`u elle demande un espace mÂ´emoire
important mË†eme pour des machines modernes. Une reprÂ´esentation moins gour-
mande consiste `a considÂ´erer une liste de voisins, nommÂ´ee liste dâ€™adjacence, notÂ´ee
LA = (lvi)n

i=1 o`u lâ€™Â´elÂ´ement lvi est la liste des voisins du sommet vi.

1.2.2 CentralitÂ´e dans un graphe

Il existe plusieurs mesures pour `a la fois caractÂ´eriser la topologie dâ€™un graphe
et rÂ´evÂ´eler lâ€™importance dâ€™un nÅ“ud au sein du rÂ´eseau. Nous proposons dâ€™exposer
les mesures les plus utilisÂ´ees en analyse des rÂ´eseaux sociaux.

Nous avons vu que le degrÂ´e dâ€™un nÅ“ud Â´etait le nombre de liens qui lui Â´etait
incident. Cependant, cela ne donne aucune information sur son importance au

1.2. NOTIONS ET NOTATIONS RELATIVES `A LA TH Â´EORIE DES GRAPHES19

sein du graphe. Lâ€™une des premi`eres mesures pour connaË†Ä±tre lâ€™importance dâ€™un
nÅ“ud dans un rÂ´eseau est sa centralitÂ´e de degrÂ´e normalisÂ´ee. Pour un nÅ“ud u,
la centralitÂ´e de degrÂ´e normalisÂ´ee consiste en Â¯du = d(u)
nâˆ’1 . Un nÅ“ud peut Ë†etre
connectÂ´e au plus `a tous les autres nÅ“uds du graphe, soit aux n âˆ’ 1 autres
nÅ“uds constituant le graphe. Ainsi, eï¬€ectuer le rapport du degrÂ´e du nÅ“ud u sur
les n âˆ’ 1 autres nÅ“uds permet de voir lâ€™importance quâ€™a le nÅ“ud u vis-`a-vis de
son degrÂ´e au sein du graphe. Lâ€™objectif Â´egalement est de ramener la centralitÂ´e
dans lâ€™intervalle [0, 1]. Pour un nÅ“ud u, plus sa centralitÂ´e de degrÂ´e normalisÂ´ee
est proche de 1, plus ce nÅ“ud sera connectÂ´e aux autres nÅ“uds du graphes.

(cid:80)n
i=1[d(uâˆ—)âˆ’d(i)]
[(nâˆ’1)(nâˆ’2)]

Cependant, il est intÂ´eressant dâ€™examiner la variation de la centralitÂ´e de
degrÂ´e des nÅ“uds du graphe pour en Â´etudier la distribution. En 1978, Free-
man (1978) a ainsi proposÂ´e le degrÂ´e de centralisation du graphe G comme Â´etant
o`u d(uâˆ—) est le degrÂ´e du nÅ“ud maximal du rÂ´eseau. Ce
CD =
nombre varie entre 0 et 1. La valeur 1 est atteinte pour le graphe en forme
dâ€™Â´etoile, câ€™est-`a-dire un nÅ“ud connectÂ´e `a tous les autres, tous de degrÂ´e 1. La
valeur 0 est atteinte avec une clique.

Il est Â´egalement intÂ´eressant de comprendre lâ€™organisation topologique du
graphe et comment sont liÂ´es certains nÅ“uds. Le cÅ“ï¬ƒcient de clustering (CC)
est une mesure dâ€™analyse des rÂ´eseaux sociaux et de regroupement des nÅ“uds
dans un rÂ´eseau. Il mesure `a quel point le voisinage dâ€™un sommet est connectÂ´e,
et calcule plus exactement la probabilitÂ´e que deux nÅ“uds liÂ´es `a un autre nÅ“ud
soient Â´egalement liÂ´es. Le CC a une forme globale et une forme locale. La premi`ere
(globale) concerne le graphe dans son ensemble alors que la seconde (locale) ne
concerne que le nÅ“ud. Pour un nÅ“ud u âˆˆ G, le CC est dÂ´eï¬ni par :

CCu =

nombre de triangles contenant le nÅ“ud u
nombre de triplets contenant le nÅ“ud u

(1.1)

o`u le triplet contenant le nÅ“ud u correspond au nombre de paires de voisins
du sommet u. Par dÂ´efaut, si le degrÂ´e du nÅ“ud u est de 1 ou de 0, nous posons
CCu = 0. Le cÅ“ï¬ƒcient de clustering global pour le graphe G est calculÂ´e en
utilisant la valeur locale CCu,âˆ€u âˆˆ G

(cid:88)

uâˆˆG

CC(G) =

1
n

CCu

(1.2)

Par dÂ´eï¬nition, nous avons 0 â‰¤ CCu â‰¤ 1,âˆ€u âˆˆ G et 0 â‰¤ CC(G) â‰¤ 1. Pour un
nÅ“ud u, plus grand est son coeï¬ƒcient de clustering, plus la probabilitÂ´e que ses
voisins soient liÂ´es est forte.

Il existe Â´egalement des mesures pour connaË†Ä±tre le degrÂ´e avec lequel un nÅ“ud
est directement connectÂ´e aux autres nÅ“uds qui ne sont pas nÂ´ecessairement di-
rectement connectÂ´es les uns avec les autres. La centralitÂ´e dâ€™intermÂ´ediaritÂ´e (node
betweenness centrality) correspond au nombre de plus courts chemins du graphe

20

CHAPITRE 1. ETAT DE Lâ€™ART

passant par chaque sommet. Pour toutes paires de nÅ“uds s et t dâ€™un graphe G,
la centralitÂ´e dâ€™intermÂ´ediaritÂ´e est dÂ´eï¬nie par :

CI(v) =

s(cid:54)=v,t(cid:54)=v,s(cid:54)=t

Ïƒst(v)

Ïƒst

(1.3)

(cid:88)

(cid:88)

avec Ïƒst le nombre de plus courts chemins entre s et t et Ïƒst(v) le nombre de
plus courts chemins entre s et t passant par v. Un niveau Â´elevÂ´e de centralitÂ´e
dâ€™intermÂ´ediaritÂ´e nâ€™est pas toujours corrÂ´elÂ´e avec un degrÂ´e important du sommet.
En eï¬€et, un nÅ“ud avec un faible degrÂ´e faisant le lien entre deux groupes de som-
mets aura une centralitÂ´e dâ€™intermÂ´ediaritÂ´e Â´elevÂ´ee. Dans sa conception, les nÅ“uds
qui ont une forte probabilitÂ´e dâ€™apparaË†Ä±tre sur un court chemin choisi au hasard
entre deux nÅ“uds choisis Â´egalement au hasard ont une haute intermÂ´ediaritÂ´e.

Il existe Â´egalement une centralitÂ´e dâ€™intermÂ´ediaritÂ´e pour les arË†etes. Soit w :
E (cid:55)âˆ’â†’ R la fonction de pondÂ´eration sur les arË†etes de G, avec E, ensemble
dâ€™arË†etes du graphe G. Pour un graphe non pondÂ´erÂ´e, nous avons w(e) = 1 âˆ€e âˆˆ E.
Soit un chemin entre deux sommets commenÂ¸cant en s âˆˆ V et se terminant `a
t âˆˆ V . Notons Ïƒst le nombre de plus courts chemins entre les sommets s et t. La
notion dâ€™intermÂ´ediaritÂ´e dâ€™une arË†ete repose sur le nombre de plus courts chemins
qui passent `a travers une certaine arË†ete. La centralitÂ´e dâ€™intermÂ´ediaritÂ´e pour les
arË†etes, que lâ€™on note CI(e) pour un lien e est donnÂ´ee par :

CI(e) =

s,tâˆˆV,s(cid:54)=t

Ïƒst(e)

Ïƒst

(1.4)

Ïƒst(e) reprÂ´esentant le nombre de plus courts chemins allant de s `a t passant
par e. La complexitÂ´e pour calculer la centralitÂ´e dâ€™intermÂ´ediaritÂ´e est en O(n3)
(Brandes (2001)). Cependant, des recherches Brandes (2001), Bader et al. (2007)
et Geisberger et al. (2008) portant sur lâ€™approximation de cette mesure ont pu
rÂ´eduire la complexitÂ´e en O(nm) sur des graphes complexes.

Il existe dâ€™autres centralitÂ´es en analyse des rÂ´eseaux sociaux, nous invitons le

lecteur `a se reporter au glossaire du manuscrit.

1.2.3 Analyse des rÂ´eseaux sociaux et graphes de terrains

La topologie des graphes dÂ´epend des syst`emes complexes Â´etudiÂ´es. Un rÂ´eseau
de collaboration scientiï¬que nâ€™aura pas exactement les mË†emes caractÂ´eristiques
quâ€™un rÂ´eseau social liÂ´e `a la musique ou au cinÂ´ema. Cependant, les graphes
sociologiques ont des caractÂ´eristiques communes que nous allons dÂ´evelopper.
Dans notre Â´etude, nous nous focaliserons sur des rÂ´eseaux complexes (qualiï¬Â´es
de graphes de terrain). De nombreuses Â´etudes, notamment celles de BarabÂ´asi
et Albert (1999), de Newman (2003) et de Clauset et al. (2009a) ont essayÂ´e de
trouver toutes les caractÂ´eristiques liÂ´ees aux rÂ´eseaux complexes. Elles ont montrÂ´e
des caractÂ´eristiques communes concernant la distribution des degrÂ´es des nÅ“uds,

1.2. NOTIONS ET NOTATIONS RELATIVES `A LA TH Â´EORIE DES GRAPHES21

un faible nombre de nÅ“uds ayant une forte centralitÂ´e (les hubs), un nombre
de triangles important, une distance moyenne entre chaque paire de sommets
assez faible et lâ€™existence de groupes de nÅ“uds fortement connectÂ´es ensemble
et faiblement avec le reste du graphe, les communautÂ´es. Nous dÂ´eveloppons cha-
cune des caractÂ´eristiques des rÂ´eseaux complexes pour en venir aux structures
communautaires et `a la problÂ´ematique de leur dÂ´etection.

Distribution des degrÂ´es

De nombreuses Â´etudes telles que BarabÂ´asi et Albert (1999); Albert et al.
(1999) et Clauset et al. (2009b) ont constatÂ´e que la majoritÂ´e des graphes de
terrain poss`edent une distribution des degrÂ´es non uniforme, qui est approximÂ´ee
par une distribution en loi de puissance de type P (k) = Ckâˆ’Î³, avec P (k) la
proportion de nÅ“uds de degrÂ´e k et Î³, appelÂ´e exposant dâ€™invariance dâ€™Â´echelle,
un rÂ´eel strictement positif. Nous avons de mani`ere gÂ´enÂ´erale 2 â‰¤ Î³ â‰¤ 3. Ce type
de graphe est qualiï¬Â´e de rÂ´eseau invariant dâ€™Â´echelle (scale-free network). Lors
de la crÂ´eation dâ€™un graphe de terrain, les nÅ“uds se connectent de mani`ere non
uniforme. Certains nÅ“uds attirent les nouveaux nÅ“uds en formant de nouvelles
connexions. Ces nÅ“uds que lâ€™on pourrait qualiï¬er dâ€™attracteurs, caractÂ´erisÂ´es par
une forte centralitÂ´e, sont appelÂ´es hubs et sont typiques des graphes de terrains.

Eï¬€et petit-monde

Lâ€™eï¬€et du petit monde est une expÂ´erience menÂ´ee en 1967 par les psychologues
Travers et Milgram (1969) qui met en exergue lâ€™hypoth`ese que la longueur de la
chaË†Ä±ne des connaissances sociales requise pour lier une personne arbitrairement
choisie `a nâ€™importe quelle autre sur terre est gÂ´enÂ´eralement courte. Le concept
a engendrÂ´e lâ€™expression cÂ´el`ebre â€le monde est petit (Itâ€™s a small world )â€. Dans
cette expÂ´erience, Stanley Milgram a mis en Â´evidence des chaË†Ä±nes tr`es courtes
reliant deux citoyens alÂ´eatoirement choisis aux Â´Etats-Unis (les chaË†Ä±nes obte-
nues avaient une longueur moyenne de six personnes, dâ€™o`u lâ€™expression qui
en a dÂ´ecoulÂ´e). En 2011, le site social Facebook publie une analyse de sa to-
pologie et indique quâ€™il y a en moyenne cinq degrÂ´es de sÂ´eparation entre ses
membres (quatre, si lâ€™on se rÂ´ef`ere uniquement aux Â´Etats-Unis). Ces expÂ´eriences
conï¬rment quâ€™un petit nombre dâ€™intermÂ´ediaires est suï¬ƒsant pour connecter
nâ€™importe quelle personne `a une autre en ce qui concerne les graphes socio-
logiques.

Variations de densitÂ´e et de taille des structures communautaires et
fort cÅ“ï¬ƒcient de clustering

Dans un rÂ´eseau social, chaque nÅ“ud est connectÂ´e `a un certain nombre de
sommets mais rarement `a tous les sommets. Le degrÂ´e moyen des graphes de
terrains est tr`es faible et indÂ´ependant du nombre de sommets du graphe (Al-
bert et al. (1999)). Les graphes de terrain ont un cÅ“ï¬ƒcient de clustering Â´elevÂ´e.

22

CHAPITRE 1. ETAT DE Lâ€™ART

Câ€™est-`a-dire que deux sommets voisins dâ€™un nÅ“ud auront tendance `a se connaË†Ä±tre
et donc `a Ë†etre liÂ´es. Ainsi, des nÅ“uds dans certaines rÂ´egions denses du graphe
seront connectÂ´es `a de nombreux triangles. On peut citer comme exemples des
rÂ´eseaux de collaborations avec un fort coeï¬ƒcient de clustering (Newman (2006)).
Pour Â´etudier les graphes de terrains, il faut donc considÂ´erer deux niveaux, celui
concernant le nÅ“ud avec une densitÂ´e Â´elevÂ´ee et celui de la topologie du graphe, de
densitÂ´e faible. Cependant, Melancon (2006) montre que la densitÂ´e dâ€™un graphe
varie en fonction du domaine dâ€™application en donnant des exemples rÂ´eels. Ainsi,
il nâ€™existe pas de seuil universel permettant de dire si nous avons un graphe de
terrain connaissant sa densitÂ´e.

Structures communautaires

En 2002, Girvan et Newman (2002b) ont montrÂ´e que la prÂ´esence au sein de
graphes sociaux de groupes de nÅ“uds fortement connectÂ´es entre eux et faible-
ment avec le reste du graphe est une caractÂ´erisque des rÂ´eseaux complexes, ils
donnent le nom de communautÂ´es `a ces groupes de nÅ“uds fortement connectÂ´es.
La diï¬ƒcultÂ´e de trouver des communautÂ´es est quâ€™elles peuvent avoir des ordres
et des tailles diï¬€Â´erents au sein dâ€™un mË†eme graphe. Câ€™est en ce sens que nous
allons dans la prochaine section formuler le probl`eme gÂ´enÂ´eral de dÂ´etection de
communautÂ´es et voir les diï¬€Â´erentes dÂ´eï¬nitions des communautÂ´es (il nâ€™existe pas
de dÂ´eï¬nition exacte).

Figure 1.1 â€“ Exemple dâ€™un graphe avec quatre communautÂ´es

La modularitÂ´e

La modularitÂ´e est une mesure de qualitÂ´e de partitionnement pour la dÂ´etection
de communautÂ´e crÂ´eÂ´ee par Newman et Girvan (2004). En considÂ´erant une par-
tition P de lâ€™ensemble des nÅ“uds dâ€™un graphe G = (V, E), la modularitÂ´e est
une fonction prenant une partition P = {c1, ..., ck} de communautÂ´es, Q : P â†’

1.3. D Â´ETECTION DE COMMUNAUT Â´ES DISJOINTES

23

(cid:80)

i(Aijâˆ’ kikj

2m

2m et la proportion de liens (soit ( kikj

[âˆ’1, 1], dÂ´eï¬nie par Q(P ) = 1
2m )Î´(li, lj), avec Aij la matrice dâ€™adja-
cence, ki le degrÂ´e du nÅ“ud i, m le nombre de liens dans le graphe, li lâ€™identidiant
de la communautÂ´es auquel appartient le nÅ“ud i, lj lâ€™identidiant de la commu-
nautÂ´es auquel appartient le nÅ“ud j, et Î´(li, lj) = 1 si les nÅ“uds i et j sont
dans la mË†eme communautÂ´e, 0 sinon. Cette mesure est la somme, sur toutes les
communautÂ´es des diï¬€Â´erences entre la proportion de liens `a lâ€™intÂ´erieur dâ€™une com-
munautÂ´e (ce qui Â´equivaut `a Aij
2m ) que devrait
avoir une communautÂ´e dans un graphe alÂ´eatoire dont la distribution de degrÂ´es
est la mË†eme que celui du graphe originel. Un tel graphe alÂ´eatoire est nommÂ´e
le mod`ele nul (cf. glossaire 6.1). Une partition sera jugÂ´ee correcte sâ€™il y a plus
de liens `a lâ€™intÂ´erieur de la communautÂ´e que ce `a quoi lâ€™on pourrait sâ€™attendre.
La modularitÂ´e prend une valeur entre 1 et âˆ’1. Une valeur Â´egale `a âˆ’1 signiï¬e
quâ€™il nâ€™existe aucun lien entre les nÅ“uds dâ€™une mË†eme communautÂ´e avec tous
les liens pointant vers dâ€™autres communautÂ´es. Une valeur de 1 signiï¬e un grand
nombre de liens dans les structures de communautÂ´es dÂ´etectÂ´ees. La valeur 0 de la
modularitÂ´e signiï¬e la partition triviale considÂ´erant le graphe comme une grande
communautÂ´e. Lâ€™inconvÂ´enient de la modularitÂ´e est sa limite de rÂ´esolution. En
eï¬€et, si lâ€™on est confrontÂ´e `a des communautÂ´es de tailles diï¬€Â´erentes `a lâ€™intÂ´erieur
dâ€™un mË†eme graphe, certaines communautÂ´es, mË†eme bien dÂ´eï¬nies, pourront ne
pas Ë†etre distinguÂ´ees dans la partition de modularitÂ´e optimale. On ne pourra
m, m Â´etant le nombre
dÂ´etecter des communautÂ´es ayant une taille infÂ´erieure `a
dâ€™arË†etes.

âˆš

De nombreux algorithmes de dÂ´etection de communautÂ´es que nous expose-

rons dans ce chapitre visent `a maximiser cette mÂ´etrique.

Notations scientiï¬ques

Dans le cadre de ce travail doctoral, nous allons utiliser des notations scien-
tiï¬ques pour mieux expliquer certains algorithmes ou certaines mesures. Câ€™est
en ce sens que nous proposons le Tableau 1.1 de notation suivant :

1.3 DÂ´etection de communautÂ´es disjointes

Bien que la notion de communautÂ´e ne soit pas un objet mathÂ´ematique en-
core dÂ´eï¬ni, de nombreuses recherches ont essayÂ´e de trouver une formulation
pour la dÂ´eï¬nir. Nous allons voir que les dÂ´eï¬nitions proposÂ´ees par la littÂ´erature
concernent des graphes spÂ´eciï¬ques. Cette section vise `a retracer les principales
dÂ´eï¬nitions de ce que lâ€™on nomme communautÂ´e.

24

CHAPITRE 1. ETAT DE Lâ€™ART

Sigle
G = (V, E)
|V | = n
|E| = m
kS
in

kS
out

N (u)
P = {C1, ..., Cr}
(u, v) âˆˆ E
A

Signiï¬cation

Un graphe notÂ´e G, constituÂ´e dâ€™un ensemble

de sommets V et un ensemble dâ€™arË†etes E

Nombre de sommets

Nombre dâ€™arË†etes
Nombre de liens `a

lâ€™intÂ´erieur du sous-graphe S
Nombre de liens sortant de S
(liant les nÅ“uds de S `a V âˆ’ S),

câ€™est-`a-dire ayant le nombre de liens qui ont

une extrÂ´emitÂ´e `a lâ€™intÂ´erieur de S
`a lâ€™extÂ´erieur de S (soit V âˆ’ S)

et leurs autres extrÂ´emitÂ´es

Le voisinage dâ€™un nÅ“ud u

Une partition en r parties de sommets

Un lien liant u et v
Matrice dâ€™adjacence

Tableau 1.1 â€“ Notations scientiï¬ques

1.3.1 Formulation du probl`eme de dÂ´etections de commu-

nautÂ´es disjointes

ConsidÂ´erons un rÂ´eseau social reprÂ´esentÂ´e par un graphe G = (V, E). Le
probl`eme de dÂ´etection de communautÂ´e dans sa forme gÂ´enÂ´erale consiste `a trou-
ver une partition P = {C1, ..., Cr} de lâ€™ensemble des sommets V en r classes,

(cid:84) Cl = âˆ…, r â‰¥ k â‰¥ 1 et Ck (cid:54)= âˆ…,âˆ€k âˆˆ {1, ..., r}, de

avec(cid:83)

kâˆˆ{1,...,r} Ck = V , Ck

telle sorte que les sommets dans une communautÂ´e soient fortement connectÂ´es et
faiblement avec le reste du graphe.

Dans son livre sur la dÂ´etection de communautÂ´es, Fortunato (2010) donne
une formulation de la problÂ´ematique de la dÂ´etection de communautÂ´es fondÂ´ee
sur la mesure de Mancoridis et al. (1998), câ€™est-`a-dire sur la densitÂ´e intra-classe
et inter-classe. Câ€™est-`a-dire quâ€™une communautÂ´e doit Ë†etre caractÂ´erisÂ´ee par une
densitÂ´e forte et un nombre de liens liant les communautÂ´es (inter-classe) faible.
Ainsi, la problÂ´ematique de la dÂ´etection de communautÂ´es peut Ë†etre vue comme
une fonction `a optimiser. En considÂ´erant un partition C = {C1, ..., Ck} en k
parties de sommets disjoints, la mesure de Mancoridis se dÂ´eï¬nit comme suit :

M Q =

s(Ci, Ci) âˆ’

k(k âˆ’ 1)(cid:80)

1
i,j(cid:54)=i s(Ci, Cj)

(cid:88)

1
k

i
|E(Ci,Cj )|
|Ci||Cj|

avec s(Ci, Cj) =
dans la communautÂ´e Ci et Cj. En dÂ´eï¬nissant par âˆ†Int(C) = 1
k
et âˆ†Ext(C) =
Dans cette derni`ere Â´equation, âˆ†Int(C) reprÂ´esente la cohÂ´esion interne des groupes

avec E(Ci, Cj) lâ€™ensemble des liens Â´etant `a la fois
i s(Ci, Ci)
i,j(cid:54)=i s(Ci,Cj ) , nous obtenons M Q = âˆ†Int(C) âˆ’ âˆ†Ext(C).

k(kâˆ’1)(cid:80)

1

(1.5)

(cid:80)

1.3. D Â´ETECTION DE COMMUNAUT Â´ES DISJOINTES

25

C1, ..., Ck (ou intra-classe) alors que âˆ†Ext(C) reprÂ´esente la cohÂ´esion externe des
groupes (ou inter-classe). Il sâ€™agit de maximiser la somme de ratios sur lâ€™en-
semble des classes.

x (G(cid:48)) + kout

Le fait que les densitÂ´es soient diï¬€Â´erentes dâ€™un type de graphes `a lâ€™autre
rend diï¬ƒcile la formulation dâ€™une dÂ´eï¬nition rigoureuse. En 2004, Radicchi et al.
(2004) proposent de considÂ´erer deux types de communautÂ´es, les communautÂ´es
au sens faible et les communautÂ´es au sens fort. En considÂ´erant un sous graphe G(cid:48),
auquel le nÅ“ud x appartient, le degrÂ´e dâ€™un nÅ“ud peut Ë†etre coupÂ´e en deux parties,
kx(G(cid:48)) = kin
x (G(cid:48)) reprÂ´esente le nombre dâ€™arË†etes reliant le
x (G(cid:48)) , o`u kin
nÅ“ud x `a ses voisins dans G(cid:48), et kout
x (G(cid:48)) reprÂ´esente le nombre dâ€™arË†etes sortant
de G(cid:48). Ainsi, un sous-graphe G(cid:48) sera considÂ´erÂ´e comme une communautÂ´e au sens
x (G(cid:48)),âˆ€x âˆˆ G(cid:48). Dans cette dÂ´eï¬nition, chaque nÅ“ud a plus de
fort si kin
connexions `a lâ€™intÂ´erieur de sa communautÂ´e quâ€™`a lâ€™extÂ´erieur. Une communautÂ´e au
x (G(cid:48)).
Dans cette derni`ere dÂ´eï¬nition, la somme de tous les degrÂ´es `a lâ€™intÂ´erieur de G(cid:48)
est plus grande que la somme de tous les degrÂ´es vers le reste du rÂ´eseau.

sens faible doit vÂ´eriï¬er la condition suivante :(cid:80)

x (G(cid:48)) >(cid:80)

x (G(cid:48)) > kout

xâˆˆG(cid:48) kin

xâˆˆG(cid:48) kout

Les crit`eres dans lâ€™article de Fortunato (2010) `a la recherche de bonnes com-

munautÂ´es sâ€™articule autour de cinq grands axes :

â€” la rÂ´eciprocitÂ´e compl`ete (les voisins de deux nÅ“uds au sein dâ€™une mË†eme

communautÂ´e sont sensiblement les mË†emes ((Luce et Perry (1949)))

â€” la joignabilitÂ´e (deux nÅ“uds dâ€™une mË†eme communautÂ´e doivent pouvoir

Ë†etre proches topologiquement lâ€™un de lâ€™autre)

â€” le degrÂ´e de sommet (les communautÂ´es doivent contenir des nÅ“uds ayant

un degrÂ´e moyen important)

â€” un fort coeï¬ƒcient de clustering au sein des communautÂ´es (une commu-

nautÂ´e doit contenir des triangles et des triades)

â€” la comparaison de la cohÂ´esion interne et externe (nombre dâ€™acteurs mi-

nimal qui pourrait rendre un graphe non connexe si on les retirait)

Le nombre de partitions possibles en k groupes de nÅ“uds dâ€™un graphe com-
prenant n sommets est le nombre de Sterling de seconde esp`ece S(n, k) (An-
drews (1976)). Le nombre total de partitions possibles est le nieme nombre de
k=0 S(n, k) (Andrews (1976)). LovÂ´asz (1993) montre que pour n

Bell, Bn =(cid:80)n

tendant vers lâ€™inï¬ni, Bn a une forme asymptotique.

Bn âˆ¼ 1âˆš
n

[Î»(n)]n+1/2eÎ»(n)âˆ’nâˆ’1

(1.6)

o`u Î»(n) = eW (n) = n/W (n), W (n) Â´etant la fonction de Lambert (PÂ´olya et
SzegÂ¨o (1997)). Le probl`eme de dÂ´etection de communautÂ´es est donc un probl`eme
dâ€™analyse combinatoire discret, o`u lâ€™objectif est de trouver une partition avec
des structures fortement denses et faiblement connectÂ´ees avec le reste du graphe.

26

CHAPITRE 1. ETAT DE Lâ€™ART

1.3.2 Approches divisives

Les approches divisives consistent `a considÂ´erer la topologie enti`ere du graphe
et `a eï¬€ectuer une coupe pour obtenir un partitionnement. Une coupe dâ€™un
graphe est une partition des sommets en deux sous-ensembles. Les coupes ont
lieu sur des liens connectant des rÂ´egions denses du graphe. La mÂ´ethode la plus
connue est celle de la bissection (Fiedler (1973) et Pothen et al. (1990)) qui
coupe le graphe en deux, puis op`ere de mani`ere itÂ´erative sur les sous-graphes
rÂ´esultants. Il existe cependant dâ€™autres mÂ´ethodes que nous allons dÂ´etailler dans
cette section.

Approche spectrale

La mÂ´ethode spectrale, issue de lâ€™alg`ebre linÂ´eaire, Â´etablit notamment lâ€™exis-
tence dâ€™une base orthonormale de vecteurs propres pour tout endomorphisme
symÂ´etrique sur un espace vectoriel complexe de dimension ï¬nie. Elle consiste en
lâ€™Â´etude de matrices particuli`eres, portant notamment sur les vecteurs propres de
(cid:80)n
matrices dÂ´eï¬nies positives. Une matrice dÂ´eï¬nie positive est une matrice positive
inversible et telle que pour tout vecteur f âˆˆ R, avec f(cid:48) la transposÂ´ee de f , nous
i,j wij(fi âˆ’ fj)2. Cela induit certaines propriÂ´etÂ´es comme la
avons f(cid:48)Lf = 1
positivitÂ´e des valeurs propres, que lâ€™on peut ordonner de la mani`ere suivante
Î»1 = 0 â‰¤ Î»2 â‰¤ ... â‰¤ Î»n. On peut Â´egalement par des mÂ´ethodes algÂ´ebriques
ou numÂ´eriques, calculer les valeurs et les vecteurs propres (Lanczos (1950)).
Une Â´etude thÂ´eorique de la mÂ´ethode spectrale a Â´etÂ´e traitÂ´ee par Chung (1996) et
Von Luxburg (2007).

2

Dans lâ€™analyse spectrale des rÂ´eseaux, la matrice Laplacienne a une place

centrale :

L = D âˆ’ A

(1.7)

o`u D est la matrice diagonale des degrÂ´es et A est la matrice dâ€™adjacence.

ConsidÂ´erons la matrice Laplacienne L, les propriÂ´etÂ´es suivantes ont Â´etÂ´e Â´etablies

(Von Luxburg (2007)) :

â€” L est une matrice symÂ´etrique et dÂ´eï¬nie positive
â€” La plus petite valeur propre de L est 0, avec comme Â´elÂ´ement propre 1
â€” Les Â´elÂ´ements proposÂ´es de L sont rÂ´eels et non nÂ´egatifs 0 = Î»1 â‰¤ Î»2 â‰¤ ... â‰¤

(soit le graphe comme Â´etant une communautÂ´e)

Î»n

La matrice Laplacienne permet Â´egalement lâ€™obtention dâ€™information sur la
topologie du graphe. Par exemple, lâ€™ordre de multiplicitÂ´e de la valeur propre 0
est Â´egale au nombre de composantes connexes du graphe. Si G est un graphe
connexe, la seconde plus petite valeur propre Î»2 est positive. Le vecteur propre
associÂ´e `a Î»2, appelÂ´ee vecteur de Fiedler, fut Â´etudiÂ´e par Fiedler (1973) et Fiedler
(1975). Une des applications est dâ€™ordonner les sommets de G sur la droite des
rÂ´eels en associant chaque sommet vi une composante xi correspondante `a sa

1.3. D Â´ETECTION DE COMMUNAUT Â´ES DISJOINTES

27

iieme composante du vecteur de Fiedler. En 1970, Hall (1970) a montrÂ´e que si
deux sommets vi et vj sont connectÂ´es, alors la distance |xi âˆ’ xj| dans le vecteur
de Fiedler est petite. Ainsi, les sommets fortement connectÂ´es sont donc proches
dans lâ€™ordonnancement des sommets du vecteur de Fiedler. Il est ainsi possible
dâ€™eï¬€ectuer une partition P = {P1, P2} du graphe G en choisissant un rÂ´eel r en
posant P1 = {vi|xi â‰¤ r} et P2 = {vi|xi > r}. Lâ€™une des premi`eres mÂ´ethodes
exploitant ce champ fut la mÂ´ethode de Barnes et Hoï¬€man (1981), dans laquelle
la recherche considÂ´era le vecteur de Fiedler et eï¬€ectua une bissection entre
les Â´elÂ´ements positifs et nÂ´egatifs du vecteur. Cette mÂ´ethode permit de couper le
graphe en deux. En 1990, Pothen et al. (1990) utilis`erent la mÂ´ediane des Â´elÂ´ements
du vecteur de Fiedler pour la valeur de r pour eï¬€ectuer une bissection rÂ´ecursive
du graphe. De 1993 `a 1995, Barnard et Simon (1994) propos`erent la bissection
spectrale rÂ´ecursive et multi-niveaux. Cela consiste `a eï¬€ectuer une bissection en
se fondant sur le vecteur de Fiedler et `a rÂ´eduire ce vecteur en minimisant la
distance entre certains points. Le processus Â´etant itÂ´eratif, la mÂ´ethode permit de
couper le graphe de mani`ere rÂ´ecursive. Une version parall`ele fut dÂ´eveloppÂ´ee par
Barnard (1995). Mais ces deux mÂ´ethodes nâ€™utilisent quâ€™un seul vecteur propre,
et donc une seule source dâ€™information.
Shi et Malik (2000), ainsi Ng et al. (2001) eurent lâ€™idÂ´ee dâ€™utiliser lâ€™information
stockÂ´ee dans dâ€™autres vecteurs propres pour amÂ´eliorer la qualitÂ´e de partitionne-
ment. Lâ€™idÂ´ee consistait `a utiliser lâ€™algorithme k-means dans lâ€™espace propre aï¬n
de trouver k clusters et par transposition sur le graphe, k communautÂ´es. Les
auteurs lâ€™ont appliquÂ´e `a diï¬€Â´erentes matrices Laplaciennes normalisÂ´ees :

LN = I âˆ’ D

1

2 ADâˆ’ 1

2

et

LN = I âˆ’ Aâˆ’1Dâˆ’ 1

2

(1.8)

(1.9)

o`u I est la matrice dâ€™identitÂ´e de la matrice dâ€™adjacence A. Les rÂ´esultats en termes
de qualitÂ´e de partitionnement sont meilleurs que ceux de la matrice Laplacienne
non normalisÂ´ee. Malheureusement cette mÂ´ethode nÂ´ecessite de connaË†Ä±tre la va-
leur k. Aï¬n de remÂ´edier `a ce probl`eme, certaines recherches ont privilÂ´egiÂ´e le
nombre de vecteurs propres qui optimise le mieux une fonction de qualitÂ´e de
partitionnement pour la dÂ´etection de communautÂ´es, comme la modularitÂ´e.

Donetti et MuËœnoz (2004) propos`erent dâ€™utiliser les vecteurs propres associÂ´es
aux K plus petites valeurs propres non-nulles (au lieu simplement du vecteur
de Fiedler), K Â´etant un entier ne pouvant excÂ´eder le nombre de valeurs propres.
Lâ€™idÂ´ee est quâ€™un sommet est reprÂ´esentÂ´e dans un espace de dimension K constituÂ´e
des composantes qui lui correspondent dans les K vecteurs propres. A chaque
itÂ´eration de lâ€™algorithme, K est incrÂ´ementÂ´e de un et un algorithime de clustering
hiÂ´erarchique est appliquÂ´e comme le single-linkage clustering ou complete-linkage
clustering, fondÂ´e sur la distance angulaire entre les nÅ“uds dans cet espace. Le
meilleur partitionnement du dendrogramme est celui qui a la plus grande mo-
dularitÂ´e. La conï¬guration donnant la modularitÂ´e maximale est alors conservÂ´ee

28

CHAPITRE 1. ETAT DE Lâ€™ART

pour retourner la partition en question parmi tous les dendrogrammes. La Fi-
gure 1.2 montre les rÂ´esultats de lâ€™algorithme appliquÂ´e `a un graphe synthÂ´etique
(Girvan et Newman (2002a)) de 128 nÅ“uds, constituÂ´e de 4 communautÂ´es de 32
nÅ“uds chacune, bien visibles.

Figure 1.2 â€“ a) Composante du premier vecteur propre non trivial (deux communautÂ´es
sont clairement identiï¬Â´ees) b) Toutes les communautÂ´es peuvent Ë†etre clairement iden-
tiï¬Â´ees lorsque les composantes du deuxi`eme vecteur propre sont tracÂ´ees par rapport `a
celles du premier (Extrait de Donetti et MuËœnoz (2004)).

Newman (2006) et Newman (2013) ont poussÂ´e lâ€™Â´etude en considÂ´erant la ma-
trice de modularitÂ´e pour y appliquer la mÂ´ethode spectrale, tout en eï¬€ectuant
des mÂ´ethodes de raï¬ƒnage (o`u des nÅ“uds changent dynamiquement de commu-
nautÂ´es).

Les mÂ´ethodes pour calculer les vecteurs propres comme la mÂ´ethode QR
(Horn et Johnson (1985)) ou la mÂ´ethode de Golub (1996) ont une tr`es forte com-
plexitÂ´e, de lâ€™ordre de O(n3). Cela a pour consÂ´equence que la mÂ´ethode spectrale
ne peut pas Ë†etre appliquÂ´ee `a de grands graphes, tout au plus `a des graphes de
quelques milliers de nÅ“uds. Des mÂ´ethodes dâ€™approximations existent cependant
comme Koren et al. (2002) pour le calcul sur des matrices de taille relativement
grande (leur plus grand graphe comprenant 7 533 224 sommets et 14 991 280
arË†etes). La mÂ´ethode spectrale est sujette `a la propagation dâ€™erreurs qui dÂ´erivent
du calcul des composantes propres. A chaque calcul dâ€™une composante propre,

1.3. D Â´ETECTION DE COMMUNAUT Â´ES DISJOINTES

29

une erreur de troncature est prise en compte pour le calcul du prochain vec-
teur propre. Parmi les matrices utilisÂ´ees dans le domaine de la thÂ´eorie spectrale,
Newman (2006) a dÂ´emontrÂ´e que la modularitÂ´e peut Ë†etre exprimÂ´ee en termes de
valeurs propres et de vecteurs propres dâ€™une matrice appelÂ´ee matrice de mo-
dularitÂ´e. En 2010, Shen et Cheng (2010) a eï¬€ectuÂ´e une Â´etude comparative en
utilisant diï¬€Â´erentes matrices utilisÂ´ees en thÂ´eorie spectrale.

La centralitÂ´e dâ€™intermÂ´ediaritÂ´e

Lâ€™un des premiers algorithmes modernes pour la dÂ´etection de communautÂ´es
fut proposÂ´e par Girvan et Newman (2002b) avec la crÂ´eation dâ€™une mesure dâ€™im-
portance fondÂ´ee sur les arË†etes, la centralitÂ´e dâ€™intermÂ´ediaritÂ´e.

Girvan et Newman Â´etendent le calcul de la centralitÂ´e (pondÂ´erÂ´e) aux arË†etes
dâ€™un graphe. Leur heuristique repose ensuite sur lâ€™hypoth`ese que la suppression
dâ€™une arË†ete de plus forte centralitÂ´e est susceptible de rompre la connexitÂ´e du
graphe (ou plus exactement de la composante dans laquelle elle se trouve). On
obtient une mÂ´ethode hiÂ´erarchique divisive de clustering du graphe en supprimant
tour `a tour les arË†etes de plus forte centralitÂ´e (en prenant soin de mettre `a jour la
centralitÂ´e apr`es chaque suppression). Cependant, des recherches Brandes (2001);
Bader et al. (2007); Geisberger et al. (2008) portant sur lâ€™approximation de cette
mesure ont pu rÂ´eduire la complexitÂ´e en O(n2) sur des graphes complexes. Bien
que ne pouvant pas Ë†etre appliquÂ´ee `a de grands graphes, la mÂ´ethode permet de
classer les arË†etes selon leur capacitÂ´e `a relier des communautÂ´es, ce qui a donnÂ´e `a
cette mÂ´ethode une forte notoriÂ´etÂ´e.

Optimisation extrÂ´emale de la modularitÂ´e

En 2005, Duch et Arenas (2005) proposent lâ€™optimisation extrÂ´emale liÂ´ee `a
la modularitÂ´e. Lâ€™algorithme fonctionne `a une Â´echelle locale pour chaque nÅ“ud
en optimisant la modularitÂ´e. Initialement, une partition en deux groupes de
nÅ“uds est eï¬€ectuÂ´ee alÂ´eatoirement. Pour chaque nÅ“ud, une optimisation de la
modularitÂ´e est calculÂ´ee en dÂ´eplaÂ¸cant le nÅ“ud considÂ´erÂ´e dans un des deux sous-
groupes. Le dÂ´eplacement dâ€™un sommet dâ€™un groupe `a un autre a une incidence
sur la modularitÂ´e. On dÂ´eplace, de mani`ere rÂ´epÂ´etÂ´ee, les sommets entre les deux
groupes jusquâ€™`a trouver un dÂ´ecoupage dont la modularitÂ´e approche un maxi-
mum. Lorsquâ€™un Â´etat stable est Â´etabli, les arË†etes liant les deux communautÂ´es
sont retirÂ´ees et le processus est rÂ´epÂ´etÂ´e de mani`ere rÂ´ecursive jusquâ€™`a ce que la
modularitÂ´e nâ€™augmente plus.
La mÂ´ethode prÂ´esente une complexitÂ´e algorithmique en O(n2log(n)). Elle
est cependant sujette au probl`eme de rÂ´esolution de limite (elle ne peut trou-
m (m Â´etant le nombre de
ver de communautÂ´es dont la taille est infÂ´erieure `a
liens dans le graphe)). Les rÂ´esultats sont encourageants mais le fait dâ€™eï¬€ectuer
une bissection rÂ´ecursive ne permet pas de trouver toutes les structures com-
munautaires. En 2006, Massen et Doye (2006) proposent deux modiï¬cations
de la version du recuit-simulÂ´e prÂ´ecÂ´edent. La premi`ere modiï¬cation consiste `a

âˆš

30

CHAPITRE 1. ETAT DE Lâ€™ART

stopper lâ€™algorithme de mani`ere pÂ´eriodique, `a essayer toutes les combinaisons
de mouvements possibles et `a prendre celle optimisant le plus la modularitÂ´e.
La deuxi`eme amÂ´elioration consiste en lâ€™utilisation de lâ€™approche dâ€™optimisation
globale de Basin-Hopping (Wales et Doye (1997)) qui dÂ´eplace des groupes de
nÅ“uds dâ€™une communautÂ´e `a une autre en optimisant toujours la modularitÂ´e. Les
rÂ´esultats en termes de qualitÂ´e sont meilleurs que ceux de Guimera et al. (2004),
mais lâ€™algorithme est plus lent. Ces algorithmes, utilisant toutes les combinai-
sons possibles, ne permettent pas de travailler sur de grands graphes.

1.3.3 Approches agglomÂ´eratives et multi-niveaux

Une mÂ´ethode hÂ´eritÂ´ee de celle du partitionnement est la mÂ´ethode multi-
niveau. Elle consiste `a fusionner des nÅ“uds pour produire de super-nÅ“uds. A
la ï¬n du processus, les super-nÅ“uds (qui agglom`erent des groupes de nÅ“uds
connectÂ´es) rÂ´eprÂ´esentent les communautÂ´es.

En 2004, Clauset et al. (2004) ont proposÂ´e une mÂ´ethode multi-niveau dont
le processus de fusion se fait sur une optimisation globale de la modularitÂ´e.
Câ€™est-`a-dire que pour chaque paire de nÅ“uds, toutes les fusions possibles entre
nÅ“uds voisins sont eï¬€ectuÂ´ees et lâ€™on consid`ere la fusion donnant la modula-
ritÂ´e maximale `a travers tout le graphe pour une paire de nÅ“uds voisins. Cette
mÂ´ethode donne des rÂ´esultats en termes de qualitÂ´e similaire `a la mÂ´ethode New-
man et Girvan (2004). Les auteurs ont crÂ´ee une structure de donnÂ´ees adaptÂ´ee
aï¬n dâ€™amÂ´eliorer la complexitÂ´e de la mÂ´ethode de Newman. Les auteurs ont en ef-
fet appliquÂ´ees leurs mÂ´ethodes sur un graphe de co-achat, celui dâ€™Amazon, ayant
409 687 nÅ“uds (reprÂ´esentant les items) et 2 464 630 arË†etes. La mÂ´ethode retourne
de bons rÂ´esultats en termes de partitionnement, avec une modularitÂ´e de 0.745,
qui rÂ´ev`ele lâ€™existence de structures communautaires.

En 2008, Blondel et al. (2008) fusionnent localement un nÅ“ud avec le voi-
sin dont le rÂ´esultat augmentera le plus une fonction de qualitÂ´e, en lâ€™occurence
la modularitÂ´e. Le processus (cf Algorithme 1) se poursuit de mani`ere rÂ´ecursive
sur le graphe rÂ´esultant `a chaque nouvelle fusion jusquâ€™`a ce quâ€™il nâ€™y ait plus
dâ€™augmentation de la modularitÂ´e. Il sâ€™agit de la version locale de la mÂ´ethode de
Clauset et al. (2004).

La mÂ´ethode permet de produire des communautÂ´es de bonne qualitÂ´e sur de
petits rÂ´eseaux et lâ€™obtention de dendrogrammes. Elle ne souï¬€re pas du probl`eme
frÂ´equent que lâ€™on peut trouver dans certains algorithmes optimisant la modu-
laritÂ´e, la rÂ´esolution de limite. Cependant, pour de grands graphes (de plusieurs
millions de nÅ“uds et dâ€™arË†etes), lâ€™optimisation dâ€™une mesure globale conduit `a
une propagation dâ€™erreur apr`es la virgule. De ce fait, la qualitÂ´e risque de se
dÂ´etÂ´eriorer en fonction de la taille des rÂ´eseaux. Lâ€™algorithme agissant localement,
la mÂ´ethode est instable, ne produisant jamais le mË†eme rÂ´esultat dâ€™un lancement

1.3. D Â´ETECTION DE COMMUNAUT Â´ES DISJOINTES

31

Algorithme 1 Lâ€™algorithme de Louvain
EntrÂ´ee : Un graphe G = (V, E)

1: A rÂ´epÂ´eter jusquâ€™`a lâ€™obtention dâ€™un score local optimal
2: Phase 1 : partitionner le rÂ´eseau de mani`ere gloutonne utilisant la modula-

ritÂ´e

3: 1) Assigner `a chaque nÅ“ud une communautÂ´e spÂ´eciï¬que
4: 2) Pour chaque nÅ“ud i du rÂ´eseau

â€” Pour chaque voisin j de i, choisir le voisin pour lequel lâ€™assignation du

nÅ“ud i dans une communautÂ´e augmenterait le plus la modularitÂ´e

â€” RÂ´epÂ´eter le processus jusquâ€™`a ce quâ€™il nâ€™y ait plus de changement

5: Phase 2 : AgglomÂ´erer les sous-graphes en nouveaux nÅ“uds
6: 1) Laissons chaque communautÂ´e Ci former un nouveau nÅ“ud i
7: 2) Laissons les arË†etes entre les nouveaux nÅ“uds i et j comme Â´etant la
rÂ´eunion des arË†etes entre les nÅ“uds qui Â´etaient dans Ci et Cj au sein du
graphe prÂ´ecÂ´edent

`a lâ€™autre. Il a Â´etÂ´e montrÂ´e que lâ€™ordre jouait un rË†ole important sur la qualitÂ´e des
communautÂ´es dÂ´etectÂ´ees. La ï¬gure 1.3 montre un exemple de fonctionnement de
la mÂ´ethode de Louvain.

Figure 1.3 â€“ Exemple dâ€™application de la mÂ´ethode de Louvain sur un graphe `a 16
sommets (Extrait de Blondel et al. (2008))

La mÂ´ethode de Louvain Â´etant instable, une des pistes de recherche fut de la
stabiliser. Une mÂ´ethode proposÂ´ee par Seiï¬ et al. (2013) consiste `a lancer plusieurs
fois lâ€™algorithme non dÂ´eterministe et `a considÂ´erer les nÅ“uds qui apparaissent le
plus souvent ensemble dans une mË†eme communautÂ´e. On appelle ces nÅ“uds dont
la frÂ´equence dâ€™apparition est tr`es forte, des cÅ“urs.

32

CHAPITRE 1. ETAT DE Lâ€™ART

DÂ´eï¬nition Un cÅ“ur de communautÂ´e est lâ€™ensemble des nÅ“uds se trouvant
frÂ´equemment ensemble dans une mË†eme communautÂ´e apr`es plusieurs lancements
dâ€™un algorithme non dÂ´eterministe (exemple de Louvain avec Seiï¬ et al. (2013)).

ij = [pij]N

Cette mÂ´ethode consiste `a utiliser une matrice de frÂ´equence, spÂ´eciï¬ant le
nombre de fois que chaque paire de nÅ“uds apparaË†Ä±t dans les mË†emes commu-
nautÂ´es. Les auteurs de cette mÂ´ethode lâ€™ont appliquÂ´ee en utilisant la mÂ´ethode
de Louvain (Blondel et al. (2008)). Soit N le nombre de fois que lâ€™algorithme
non dÂ´eterministe est lancÂ´e. A chaque essai, nous notons chaque paire de nÅ“uds
qui apparait dans une mË†eme communautÂ´e. Il est ainsi possible de dÂ´eï¬nir une
matrice P N
nÃ—n telle que pij reprÂ´esente la frÂ´equence dâ€™appartenance
des nÅ“uds i et j `a une mË†eme communautÂ´e apr`es les N essais. pij, Â´etant une
probabilitÂ´e,âˆ€(i, j) âˆˆ V Ã— V a une valeur comprise entre 0 et 1. Un nombre
proche de 1 signiï¬e que les nÅ“uds i etj sont souvent ensemble durant les N
essais. Pour trouver les cÅ“urs, on crÂ´ee un nouveau graphe G(cid:48) = (V, E(cid:48)) o`u E(cid:48)
reprÂ´esente lâ€™ensemble des arË†etes crÂ´eÂ´ees `a partir de la matrice de frÂ´equence en
utilisant un seuil Î± âˆˆ [0, 1] permettant de faire apparaË†Ä±tre des composantes
connexes. Le seuil Î± est un entier positif que lâ€™on utilise pour crÂ´eer le nouveau
graphe `a partir de la matrice de co-frÂ´equence. Pour toutes paires de sommets du
graphe, si la frÂ´equence dâ€™apparition dans la matrice est supÂ´erieure `a la valeur
Î±, on ajoute une arË†ete au nouveau graphe G(cid:48) reliant les nÅ“uds en question.
Par construction, les composantes connexes dans le graphe G(cid:48) apparaissent.
Les composantes connexes sont ici les cÅ“urs, qui correspondent `a nos commu-
nautÂ´es. G(cid:48) est appelÂ´e le graphe Î±-seuillÂ´e. Î± est un param`etre qui inï¬‚uence des
connexions dans le nouveau graphe G(cid:48), et par consÂ´equence, le nombre de com-
posantes connexes. Dâ€™apr`es les Â´etudes menÂ´ees par Seiï¬ et al. (2013), de faibles
valeurs de Î± conduisent `a peu de composantes connexes alors que de fortes va-
leurs de Î± m`enent `a beaucoup de composantes connexes. Les auteurs ont montrÂ´e
quâ€™ils avaient rÂ´eussi `a stabiliser la mÂ´ethode de Louvain, et `a trouver des cÅ“urs
stables. La mÂ´ethode prÂ´esente lâ€™avantage de pouvoir crÂ´eer un dendrogramme en
faisant varier Î± sur un intervalle.

Pons et Latapy (2006) ont proposÂ´e WalkTrap , un algorithme se fondant sur
le fait quâ€™un marcheur alÂ´eatoire se promenant sur le graphe aura tendance `a
circuler dans des zones denses (ou `a y rester plus longtemps) plutË†ot que dans
des rÂ´egions faiblement denses. Il sâ€™agit dâ€™un algorithme agglomÂ´eratif permet-
tant lâ€™Â´elaboration dâ€™un dendrogramme. ConsidÂ´erons un nÅ“ud u et son voisinage
N (u). La probabilitÂ´e que le marcheur alÂ´eatoire aille du nÅ“ud u vers un de ses
deg(u) . Câ€™est ainsi que lâ€™on peut calculer la probabilitÂ´e que le
voisins est de
marcheur alÂ´eatoire puisse, `a partir de k pas, aller du nÅ“ud u `a un autre nÅ“ud
v du graphe. Les probabilitÂ´es calculÂ´ees entre chaque paire de nÅ“uds vont Ë†etre
utilisÂ´ees pour calculer les similaritÂ´es entre chaque paire de sommets du graphe.
WalkTrap dÂ´emarre en considÂ´erant chaque nÅ“ud comme une communautÂ´e. Lâ€™al-
gorithme calcule pour chaque nÅ“ud dans le graphe un vecteur qui donne la
probabilitÂ´e quâ€™un marcheur alÂ´eatoire arrive aux autres nÅ“uds du rÂ´eseau en k
pas de temps. Ainsi, deux sommets u et v sont proches si leur vecteurs de proba-

1

1.3. D Â´ETECTION DE COMMUNAUT Â´ES DISJOINTES

33

bilitÂ´e dâ€™atteindre les autres sommets sont similaires. Les paires de nÅ“uds ayant
la plus grande similaritÂ´e entre eux fusionnent pour former une nouvelle com-
munautÂ´e. Un nouveau graphe est ainsi construit o`u les nÅ“uds reprÂ´esentent des
communautÂ´es. La mÂ´ethode continue de mani`ere rÂ´ecursive jusquâ€™`a obtenir une
communautÂ´e. A chaque dÂ´ecoupage intermÂ´ediaire, un calcul de la modularitÂ´e
est eï¬€ectuÂ´e qui permettra de retourner la partition optimisant ce score. Lâ€™algo-
rithme donne des rÂ´esultats satisfaisants mais ne permet pas dâ€™Ë†etre appliquÂ´e `a
de tr`es grands graphes dans la mesure o`u il faut calculer pour toutes paires de
nÅ“uds les distances. La complexitÂ´e de lâ€™algorithme est en O(n Ã— m Ã— H) o`u H
est la hauteur du dendrogramme.

1.3.4 Approches fondÂ´ees sur la dÂ´etection de leaders

Dans un rÂ´eseau, certains nÅ“uds peuvent Ë†etre plus importants que dâ€™autres.
Cela peut se traduire par une centralitÂ´e ou un cÅ“ï¬ƒcient de clustering plus
fort pour certains nÅ“uds du graphe par rapport `a dâ€™autres. Câ€™est une des ca-
ractÂ´eristiques des graphes de terrains avec des nÅ“uds situÂ´es au centre de struc-
tures communautaires et dâ€™autres nÅ“uds qui leur sont liÂ´es. Un graphe de terrain
poss`ede la caractÂ´eristique dâ€™avoir une distribution des degrÂ´es des nÅ“uds suivant
une loi faible (Loi de Zipf) (Newman (2005)). Des algorithmes, ces derni`eres
annÂ´ees, ont proposÂ´e de dÂ´etecter les nÅ“uds les plus importants que lâ€™on peut
qualiï¬er de leaders et dâ€™attribuer les autres nÅ“uds `a ces derniers pour former
des communautÂ´es.

Shah et Zaman (2010) ont proposÂ´e lâ€™algorithme â€Leaders-Suiveursâ€. Les au-
teurs dÂ´eï¬nissent deux types de nÅ“uds, les leaders (nÅ“uds qui connectent plu-
sieurs communautÂ´es) et les suiveurs loyaux (nÅ“uds dont le voisinage se situe
dans une structure communautaire et poss`ede un lien avec un leader). Lâ€™algo-
rithme se dÂ´ecompose en deux Â´etapes. La premi`ere Â´etape consiste `a rechercher
les leaders. Les auteurs dÂ´eï¬nissent une mesure de centralitÂ´e, pour un nÅ“ud u,
comme la somme des plus courtes distances de ce nÅ“ud `a tous les autres nÅ“uds
du graphe. Un tri est alors eï¬€ectuÂ´e sur les nÅ“uds, fondÂ´e sur cette mesure. Lâ€™en-
semble des leaders est ainsi constituÂ´e de telle sorte quâ€™il ne puisse pas y avoir
deux leaders voisins. La seconde Â´etape consiste `a assigner les autres nÅ“uds qua-
liï¬Â´es de suiveurs aux leaders. Les voisins directs des leaders leur sont assignÂ´es,
permettant la crÂ´eation des communautÂ´es. Lâ€™algorithme est en O(n Ã— m). Lâ€™al-
gorithme admet de meilleurs rÂ´esultats en termes de qualitÂ´e que les mÂ´ethodes
spectrales. Cependant, la mÂ´ethode ne peut pas Ë†etre appliquÂ´ee `a de tr`es grands
graphes dans la mesure o`u le calcul des plus courtes distances entre sommets
nÂ´ecessite un temps important. De plus, dans des zones fortement denses, lâ€™algo-
rithme peut dÂ´etecter plusieurs leaders alors que cela ne devrait pas Ë†etre le cas.
La consÂ´equence est la crÂ´eation de petites communautÂ´es qui auraient dË†u Ë†etre
fusionnÂ´ees.

34

CHAPITRE 1. ETAT DE Lâ€™ART

Kanawati (2011) a proposÂ´e LICOD (pour â€Leaderâˆ’driven algorithm for com-
munity detection in complex networksâ€). Il sâ€™agit dâ€™une version enrichie de la
mÂ´ethode prÂ´esentÂ´ee prÂ´ecÂ´edemment par Shah et Zaman. Les auteurs proposent
diï¬€Â´erentes mesures pour le calcul des leaders, `a savoir la centralitÂ´e de degrÂ´e
(mesure locale) et la centralitÂ´e dâ€™intermÂ´ediaritÂ´e des nÅ“uds (mesure globale).
Un nÅ“ud sera considÂ´erÂ´e comme leader si sa centralitÂ´e est supÂ´erieure ou Â´egale
`a Ïƒ âˆˆ [0, 1] pourcentage de voisins. Deux leaders sont considÂ´erÂ´es comme Â´etant
dans une mË†eme communautÂ´e si leur nombre de voisins communs est supÂ´erieur `a
un seuil Î´ âˆˆ [0, 1]. Concernant les nÅ“uds suiveurs, les auteurs proposent dâ€™utili-
ser lâ€™inverse du plus court chemin vis-`a-vis des communautÂ´es qui se constituent.
Les rÂ´esultats en termes de qualitÂ´e sont corrects et surpassent les autres algo-
rithmes sur des rÂ´eseaux dont la densitÂ´e est Â´elevÂ´ee. Lâ€™algorithme est cependant
sujet au choix de la paramÂ´etrisation de Ïƒ et Î´ qui ont une inï¬‚uence sur le nombre
de communautÂ´es trouvÂ´ees. Comme pour la mÂ´ethode de Shah et Zaman, lâ€™algo-
rithme est sujet au calcul des plus courts chemins dont le coË†ut computationnel
peut se rÂ´evÂ´eler important pour de grands graphes. On notera que des travaux
de recherches portant sur la centralitÂ´e dâ€™intermÂ´ediaritÂ´e pour traiter des graphes
relativement grands ont Â´etÂ´e eï¬€ectuÂ´es en utilisant le parallÂ´elisme par Kermarrec
et al. (2011).

1.3.5 Approches fondÂ´ees sur la perturbation du rÂ´eseau

Les mÂ´ethodes de perturbation des rÂ´eseaux ont Â´etÂ´e crÂ´eÂ´ees pour lâ€™amÂ´elioration
dâ€™algorithmes dÂ´eterministes. Lâ€™idÂ´ee est quâ€™en eï¬€ectuant une modiï¬cation to-
pologique du graphe, certaines structures communautaires puissent Ë†etre plus
facilement dÂ´etectÂ´ees.

Gfeller et al. (2005) proposent de construire une suite de graphes G1,G2,...,Gn
en modiï¬ant la pondÂ´eration des arË†etes pour chaque couple de nÅ“uds (x, y) via
une loi de distribution uniforme. Lâ€™idÂ´ee est que si des communautÂ´es existent au
sein dâ€™un graphe, une faible modiï¬cation topologique du graphe en utilisant une
nouvelle pondÂ´eration des arË†etes ne devrait pas modiï¬er la structure des commu-
nautÂ´es dÂ´etectÂ´ees. Les auteurs dÂ´eï¬nissent la probabilitÂ´e intra-cluster pij comme
Â´etant le nombre de fois que les nÅ“uds i et j se sont trouvÂ´es dans les mË†emes
communautÂ´es. Les liens ayant une pondÂ´eration pij â‰¤ Î¸ sont retirÂ´es du graphe.
Les composantes connexes rÂ´esultantes forment ainsi les communautÂ´es. Bien que
lâ€™idÂ´ee de perturbation des arË†etes semble Ë†etre un axe prometteur, lâ€™Â´evaluation
des param`etres Î¸ et Ïƒ handicape la mÂ´ethode fortement. Lâ€™algorithme nÂ´ecessite
plusieurs tests avant de retourner sa meilleure partition.

Karrer et al. (2008) ont proposÂ´e un algorithme perturbatif qui enl`eve une
certaine portion dâ€™arË†etes Î± et qui la remet entre certaines paires de sommets
(x, y) avec une probabilitÂ´e d(x)d(y)
2m , que lâ€™on retrouve dans le mod`ele nul. Lâ€™ob-
jectif est de conserver la distribution des degrÂ´es des nÅ“uds au sein du rÂ´eseau.

1.3. D Â´ETECTION DE COMMUNAUT Â´ES DISJOINTES

35

Lâ€™idÂ´ee de cette mÂ´ethode est dâ€™ajouter des liens dans des zones fortement denses
et dâ€™en retirer des zones faiblement denses. Lâ€™algorithme nÂ´ecessite de tester
cependant plusieurs valeurs de Î± avant lâ€™obtention dâ€™une partition de qualitÂ´e.
Cette mÂ´ethode dÂ´epend Â´egalement du mod`ele nul, qui parfois, ne met pas en
Â´evidence de structures communautaires ostensibles. Lâ€™algorithme prÂ´esente ce-
pendant lâ€™avantage de dÂ´etecter des structures communautaires au sens fort et
faible de Radicchi et al. (2004) et de tailles diï¬€Â´erentes.

Rosvall et Bergstrom (2007b) ont proposÂ´e Infomod. Il sâ€™agit dâ€™une mÂ´ethode
fondÂ´ee sur la thÂ´eorie de lâ€™information, plus exactement sur la quantitÂ´e dâ€™informa-
tion quâ€™une partition a vis-`a-vis du graphe originel. Lâ€™idÂ´ee consiste `a partir dâ€™une
partition Y de sommets dâ€™un graphe quâ€™un Â´emetteur envoie `a un receveur, de
deviner la structure topologique du graphe X. La meilleure partition du signal Y
contenant le plus dâ€™information au sujet de X sera considÂ´erÂ´ee. Chaque Â´elÂ´ement
de Y reprÂ´esente une structure communautaire. Lâ€™information entre les deux par-
titions peut-Ë†etre quantiï¬Â´ee par la minimisation de lâ€™information conditionnelle

de lâ€™entropie H(X|Y ) de X sachant Y . H(X|Y ) = log[(cid:81)q

lij
o`u q est le nombre initialement choisi de communautÂ´es par lâ€™utilisateur, ni le
nombre de sommets dans la communautÂ´e i et lij le nombre de liens entre les
communautÂ´es i et j. A chaque calcul de la quantitÂ´e dâ€™information entre les
deux partitions, des migrations de sommets sâ€™eï¬€ectuent entre communautÂ´es.
La mÂ´ethode donne des rÂ´esultats en termes de qualitÂ´e de partitionnement en-
courageants sur des graphes faiblement et fortement denses. Cependant, cette
mÂ´ethode ne peut pas Ë†etre appliquÂ´ee `a des graphes de plus de 105 nÅ“uds. La
mÂ´ethode nÂ´ecessite Â´egalement de donner un nombre de communautÂ´es initial. La
ï¬gure 1.4 donne une explication du fonctionnement de la mÂ´ethode Infomod.

(cid:0) ni(niâˆ’1)

(cid:1)(cid:81)

i>j

(cid:0)ninj

(cid:1)]

i=1

2
lii

Figure 1.4 â€“ Principe de base de la mÂ´ethode Infomod. Un codeur envoie `a un dÂ´ecodeur
une information compressÂ´ee sur la topologie du graphe `a gauche. Lâ€™information donne
une description grossi`ere du graphe, qui est utilisÂ´ee par le dÂ´ecodeur pour dÂ´eduire la
structure topologique originale. Extrait dâ€™origine de Rosvall et Bergstrom (2007b)

Rosvall et Bergstrom (2010) ont proposÂ´e Infomap. Il sâ€™agit dâ€™une mÂ´ethode
fondÂ´ee sur la thÂ´eorie de lâ€™information, un processus dâ€™encodage et sur la marche
alÂ´eatoire. Le procÂ´edÂ´e dâ€™Infomap consiste `a trouver des structures communau-
taires en Â´etudiant la marche alÂ´eatoire et la ressemblance de motifs. Pour situer
le marcheur alÂ´eatoire dans le graphe, on attribue aux sommets un identiï¬ant

36

CHAPITRE 1. ETAT DE Lâ€™ART

unique ainsi quâ€™un identiï¬ant `a la communautÂ´e `a laquelle ils appartiennent.
Pour dÂ´ecrire le dÂ´eplacement du marcheur alÂ´eatoire, on commence par donner
lâ€™identiï¬ant de la communautÂ´e, puis le label du nÅ“ud sur lequel il se trouve.
D`es que le marcheur alÂ´eatoire sort de la communautÂ´e il faut lui attribuer lâ€™iden-
tiï¬ant de la nouvelle communautÂ´e et le label du nouveau nÅ“ud. Lâ€™idÂ´ee est quâ€™il
peut y avoir des structures ressemblantes dans chacune des communautÂ´es. Il y a
par exemple, plusieurs â€rue des Abeillesâ€ en France, notamment `a Montpellier,
Mulhouse, Marseille, Toulouse ou `a L`ege-Cap-Ferret, dans des villes diï¬€Â´erentes.
Les chemins quâ€™emprunte le marcheur alÂ´eatoire sont ainsi encodÂ´es et lâ€™encodage
minimum permet de trouver les structures communautaires.
Cette mÂ´ethode fut testÂ´ee sur les graphes alÂ´eatoires gÂ´enÂ´erÂ´es par les benchmarks
de Lancichinetti et al. (2008) et surpassa les autres mÂ´ethodes en termes de
qualitÂ´e de partitionnement, ce qui fonda sa notoriÂ´etÂ´e. Lâ€™algorithme prÂ´esente
lâ€™avantage de pouvoir traiter de tr`es grands graphes. Il constitue `a ce jour lâ€™une
des meilleures mÂ´ethodes de partitionnement pour la dÂ´etection de communautÂ´es
disjointes.

De Meo et al. (2013) ont proposÂ´e CONCLUDE (pour Complex Network
Cluster Detection). Lâ€™algorithme utilise `a la fois lâ€™importance des arË†etes du
graphe et un algorithme de clustering qui fait suite `a une projection des nÅ“uds
dans un espace euclidien pour trouver les communautÂ´es. Lâ€™algorithme fonctionne
en deux Â´etapes. La premi`ere Â´etape consiste en lâ€™utilisation dâ€™un mod`ele de pro-
pagation de lâ€™information au sein du rÂ´eseau, fondÂ´e sur une marche alÂ´eatoire avec
non retour et de longueur ï¬xe. Cela permet dâ€™attribuer un score `a lâ€™importance
des arË†etes maintenant le graphe connectÂ´e. Les auteurs nomment cette mesure la
centralitÂ´e dâ€™arË†ete (Meo et al. (2011)). La centralitÂ´e dâ€™arË†ete est ensuite utilisÂ´ee
pour projeter les sommets du rÂ´eseau en points dans un espace euclidien et un
calcul de distance entre chaque paire de nÅ“uds est eï¬€ectuÂ´e. Un nouveau graphe
est crÂ´eÂ´e et la mÂ´ethode de Louvain est appliquÂ´ee.
Cette mÂ´ethode nÂ´ecessite cependant de paramÂ´etrer la longueur des marches
alÂ´eatoires k qui est un param`etre global. Les graphes de terrain peuvent conte-
nir des tailles de communautÂ´es diï¬€Â´erentes, ce qui pose un probl`eme `a la pa-
ramÂ´etrisation de k. Lâ€™algorithme a cependant une complexitÂ´e proche de la
linÂ´earitÂ´e en termes dâ€™arË†etes et produit, sous condition dâ€™une bonne paramÂ´etrisation,
de meilleurs rÂ´esultats que la mÂ´ethode de Louvain sur des graphes sociaux.

1.3.6 Approche par propagation de labels

La mÂ´ethode de propagation de labels (Raghavan et al. (2007)), notÂ´ee LPA,
est fondÂ´ee sur la transmission dâ€™un label dâ€™un nÅ“ud `a ses voisins. Un Â´etat
dâ€™Â´equilibre est atteint lorsque chaque nÅ“ud a son label Â´egal `a celui de la majo-
ritÂ´e de ses voisins. Soit un graphe G = (V, E), avec V lâ€™ensemble des sommets
(|V | = n) et E lâ€™ensemble des arË†etes (|E| = m).

A chaque Â´etape, chaque nÅ“ud met `a jour son label selon les labels de ses

1.3. D Â´ETECTION DE COMMUNAUT Â´ES DISJOINTES

37

voisins, en utilisant un vote. Le label du nÅ“ud u prendra le label majoritaire
de ses voisins. En notant cu le label du nÅ“ud u, et par N l(u) lâ€™ensemble du
voisinage du nÅ“ud u avec le label l, lâ€™aï¬€ectation dâ€™un label au nÅ“ud u est
donnÂ´ee par la formule suivante :

cu = arg max

l

|N l(u)|

(1.10)

A la ï¬n du processus, les nÅ“uds ayant le mË†eme label reprÂ´esentent une com-
munautÂ´e. Cette mÂ´ethode peut Ë†etre eï¬€ectuÂ´ee de mani`ere synchrone ou asyn-
chrone. La mÂ´ethode asynchrone signiï¬e que la mise `a jour dâ€™un label dâ€™un nÅ“ud
est connue par tous les autres nÅ“uds du graphe immÂ´ediatement. Son label est
transmis pour la mise `a jour des labels des autres nÅ“uds. Ce nâ€™est pas le cas
du mode synchrone, o`u la mise `a jour des labels utilise les labels des nÅ“uds
`a la prÂ´ecÂ´edente propagation. La complexitÂ´e de cet algorithme que cela soit en
mode synchrone ou asynchrone est en O(k Ã— (n + m)), o`u k âˆˆ N reprÂ´esente le
nombre dâ€™itÂ´erations de lâ€™algorithme, spÂ´eciï¬Â´e par lâ€™utilisateur. Dâ€™apr`es les Â´etudes
menÂ´ees par Raghavan et al. (2007), sur des graphes sociaux ayant moins de
1000 nÅ“uds, 5 itÂ´erations suï¬ƒsent pour obtenir une bonne classiï¬cation. Pour
des graphes ayant plus de nÅ“uds, les recherches menÂ´ees par lâ€™auteur ne purent
Â´etablir le nombre exact dâ€™itÂ´erations. Lâ€™auteur prÂ´econise de mettre un nombre
assez important dâ€™itÂ´erations et dâ€™observer itÂ´eration apr`es itÂ´eration si le nombre
de communautÂ´es Â´evolue. Cet algorithme prÂ´esente lâ€™avantage dâ€™avoir une com-
plexitÂ´e permettant de travailler sur de grands graphes.
Cependant, lâ€™algorithme de propagation de labels prÂ´esente lâ€™inconvÂ´enient dâ€™Ë†etre
instable, ne donnant que rarement le mË†eme rÂ´esultat apr`es plusieurs lancements.
Il est aussi caractÂ´erisÂ´e par un probl`eme intrins`eque conduisant dans certains
cas `a de tr`es grandes communautÂ´es (monstres). Ce probl`eme peut sâ€™expliquer
par deux raisons. La premi`ere est le choix parfois alÂ´eatoire du label que doit
prendre un nÅ“ud lorsquâ€™il y a plusieurs labels majoritaires dans son voisinage.
La seconde porte sur les tailles des structures. En eï¬€et, la propagation de labels
prendra moins de temps `a couvrir de petits rÂ´eseaux que de gros rÂ´eseaux. Pour
pallier ces deux derniers probl`emes, de nombreuses propositions algorithmiques
ont Â´etÂ´e publiÂ´ees depuis ces derni`eres annÂ´ees, que nous allons exposer.

Figure 1.5 â€“ Exemple de propagation de labels

38

CHAPITRE 1. ETAT DE Lâ€™ART

Sur la Figure 1.5, nous considÂ´erons un graphe G avec V = A, B, C, D, F .
Chaque nÅ“ud a initialement son propre label que nous avons modÂ´elisÂ´e par une
couleur. Ainsi, le nÅ“ud A a la couleur rose, le nÅ“ud B a la couleur orange, le
nÅ“ud C a la couleur bleue, le nÅ“ud D a la couleur violette et le nÅ“ud E a la
couleur beige. Un ordre Ïƒ est donnÂ´e sur les nÅ“uds et est suivi pour procÂ´eder
`a la propagation de labels. Le nÅ“ud A a le choix entre les couleurs de B,C,
D et E (cas de lâ€™Â´equidistribution des labels majoritaires), au hasard, le nÅ“ud
A prend le label du nÅ“ud B, soit la couleur du nÅ“ud B, lâ€™orange. La couleur
majoritaire dans le voisinage du nÅ“ud D est orange, le nÅ“ud D prend la couleur
orange. La couleur majoritaire dans le voisinage du nÅ“ud C est orange, le nÅ“ud
C prend la couleur orange. La couleur majoritaire dans le voisinage du nÅ“ud
B est orange, le nÅ“ud B prend la couleur orange. Enï¬n, la couleur majoritaire
dans le voisinage du nÅ“ud E est orange, le nÅ“ud E prend la couleur orange.
La premi`ere itÂ´eration de labels est eï¬€ectuÂ´ee. Chaque nÅ“ud poss`ede la couleur
majoritaire de son voisinage, le processus sâ€™arrË†ete. Sur dâ€™autres conï¬gurations
de graphe, nous serions passÂ´es `a la seconde itÂ´eration de labels jusquâ€™`a ce que
chaque nÅ“ud poss`ede la majoritÂ´e des couleurs des voisins.

En appliquant ce procÂ´edÂ´e au graphe de la Figure 1.6, les communautÂ´es ap-

paraissent.

Figure 1.6 â€“ Exemple de propagation de labels

Cependant, lâ€™algorithme souï¬€re de mauvaises propagations pouvant don-
ner le phÂ´enom`ene de communautÂ´es gÂ´eantes, câ€™est-`a-dire lâ€™incapacitÂ´e pour lâ€™algo-
rithme de dÂ´etecter de petites structures communautaires. Dans lâ€™exemple de la
Figure 1.7, une mauvaise propagation se fait lorsque le nÅ“ud B est visitÂ´e pour
la mise `a jour de son label. A cause de lâ€™Â´equidistribution des couleurs majori-
taires, le nÅ“ud B choisit au hasard une couleur, ce qui par la suite aura pour
consÂ´equence lâ€™obtention de la communautÂ´e gÂ´eante.

Lâ€™algorithme est non dÂ´eterministe et souï¬€re dâ€™une forte instabilitÂ´e. En considÂ´erant

lâ€™exemple du club de KaratÂ´e (Zachary (1977)), on peut sâ€™apercevoir sur la Figure
1.8 que le nombre de communautÂ´es change au cours des diï¬€Â´erentes propagations
de labels. Certains exemples donnent 2 ou 3 communautÂ´es alors que dâ€™autres ne
donnent quâ€™une grande communautÂ´e. Il sâ€™agit dâ€™un algorithme instable, câ€™est-`a-
dire ne donnant que rarement le mË†eme rÂ´esultat dâ€™un lancement `a lâ€™autre.
Leung et al. (2009) ont proposÂ´e un score pour chaque label qui diminue dâ€™un
certain pas Î´ âˆˆ [0, 1] quand la distance gÂ´eodÂ´esique de la source du nÅ“ud qui a
Â´emis le label devient trop Â´elevÂ´ee. Cette mÂ´ethode a Â´etÂ´e nommÂ´ee â€propagation de
labels par attÂ´enuationâ€. Cela a pour consÂ´equence dâ€™Â´eviter lâ€™obtention de trop
grandes communautÂ´es dans les graphes. Les expÂ´eriences ont montrÂ´e que cette

1.3. D Â´ETECTION DE COMMUNAUT Â´ES DISJOINTES

39

Figure 1.7 â€“ Exemple de propagation de labels donnant une communautÂ´e gÂ´eante

Figure 1.8 â€“ La propagation de labels est un algorithme non dÂ´eterministe et instable.
Application sur le graphe de KaratÂ´e (Zachary (1977))

mÂ´ethode permettait dâ€™Â´eviter de mauvaises propagations et donnait de meilleurs
rÂ´esultats que le LPA. Le probl`eme restant est de pouvoir paramÂ´etrer la distance
du nÅ“ud `a la source aï¬n de diminuer le score de la fonction dâ€™attÂ´enuation.
La solution nâ€™est pas stable et nÂ´ecessite plusieurs essais avant lâ€™obtention dâ€™un
rÂ´esultat concluant.

Ë‡Subelj et Bajec (2011) ont continuÂ´e les travaux de Leung en proposant une
propagation de labels oï¬€ensive, dÂ´efensive et hybride fondÂ´ee sur la modiï¬ca-

40

CHAPITRE 1. ETAT DE Lâ€™ART

tion du vote et du pas dâ€™attÂ´enuation. Cette modiï¬cation porte sur lâ€™application
dâ€™une propagation de labels par prÂ´efÂ´erence de nÅ“ud, qui consiste lors du vote,
`a prendre le label voisin dont le degrÂ´e de centralitÂ´e et la diï¬€usion en termes de
marche alÂ´eatoire sont les plus importants. Le facteur de prÂ´efÂ´erence est la diï¬€u-
sion du label divisÂ´ee par la centralitÂ´e du nÅ“ud Â´emetteur (mÂ´ethode dÂ´efensive pour
la dÂ´etection de cÅ“urs), et la mÂ´ethode oï¬€ensive (permettant de dÂ´eï¬nir les bor-
dures des communautÂ´es) dont la distance de propagation est plus grande. Une
hybridation des deux mÂ´ethodes a menÂ´e `a lâ€™algorithme Kâˆ’cÅ“urs, qui consiste
`a appliquer la mÂ´ethode dÂ´efensive pour trouver les cÅ“urs, puis `a appliquer la
mÂ´ethode oï¬€ensive pour trouver les fronti`eres des communautÂ´es. Les rÂ´esultats
on montrÂ´e de nettes diï¬€Â´erences entre les mÂ´ethodes avec une stabilitÂ´e plus forte
pour la mÂ´ethode dÂ´efensive. La mÂ´ethode dÂ´efensive trouve de petites commu-
nautÂ´es alors que la mÂ´ethode oï¬€ensive trouve de tr`es grandes communautÂ´es. Les
rÂ´esultats sont cependant Â´equivalents au LPA en termes de qualitÂ´e de partition-
nement. Les expÂ´erimentations ont montrÂ´e que la mÂ´ethode hybride Â´etait un bon
compromis dont le rÂ´esultat en termes de qualitÂ´e des communautÂ´es surpassait le
LPA. Lâ€™algorithme nÂ´ecessite cependant une paramÂ´etrisation importante, comme
le pas dâ€™attÂ´enuation et la puissance `a laquelle on lâ€™Â´el`eve. Lâ€™algorithme nâ€™est ce-
pendant pas dÂ´eterministe.

Zong-Wen et al. (2014) proposent une propagation de labels guidÂ´ee par
consensus. Les auteurs proposent de lancer plusieurs fois lâ€™algorithme de propa-
gation de labels pour obtenir diï¬€Â´erentes partitions. Un nouveau graphe pondÂ´erÂ´e
est alors crÂ´eÂ´e o`u la pondÂ´eration des arË†etes reprÂ´esente le nombre de fois que
chaque paire de nÅ“uds est dans une mË†eme communautÂ´e. Câ€™est alors quâ€™une
propagation de labels avec consensus fondÂ´ee `a la fois sur les poids des arË†etes et
la frÂ´equence des labels permet dâ€™assigner `a un nÅ“ud un nouveau label. Cette
mÂ´ethode produit de meilleurs rÂ´esultats que le LPA mais une Â´etude prÂ´ealable
pour chaque graphe doit Ë†etre faite pour la paramÂ´etrisation. Cette mÂ´ethode ne
permet pas lâ€™Â´elaboration de dendrogramme.

Pour rÂ´esoudre le probl`eme de lâ€™Â´equidistribution des labels majoritaires pour
le processus de vote, Xie et Szymanski (2013) proposent une propagation de
labels avec opÂ´erateurs aï¬n de stabiliser et de rendre dÂ´eterministe le LPA tout
en amÂ´eliorant la qualitÂ´e de partitionnement. Cela consiste `a stocker, propager
et trier les labels de chaque nÅ“ud en utilisant quatre opÂ´erateurs qui sont la
propagation, lâ€™inï¬‚ation, la coupure et une phase de mise `a jour de stabilisation
du LPA. Chaque nÅ“ud reÂ¸coit le label majoritaire de ses voisins en Â´eliminant les
choix alÂ´eatoires (câ€™est-`a-dire que sâ€™il y a plusieurs labels majoritaires dans son
voisinage, lâ€™algorithme les ajoute `a un vecteur et sÂ´electionne le label recouvrant
le groupe de nÅ“uds ayant la centralitÂ´e moyenne la plus Â´elevÂ´ee. Les communautÂ´es
se forment itÂ´eration apr`es itÂ´eration). La partition rÂ´esultante est dÂ´eterministe car
il nâ€™y a plus de choix alÂ´eatoires. Le labelrank a une complexitÂ´e algorithmique en
O(m).
Les auteurs ont proposÂ´e par la suite LabelRankT en y ajoutant une condition

1.3. D Â´ETECTION DE COMMUNAUT Â´ES DISJOINTES

41

supplÂ´ementaire sur la mise `a jour des labels, destinÂ´ee aux graphes dynamiques
(graphes o`u les sommets et les arË†etes sont ajoutÂ´es au cours du temps dans
leur cas). Lâ€™idÂ´ee est de considÂ´erer la partition actuelle pour infÂ´erer la partition
suivante. Cela maintient lâ€™ancienne partition tout en mettant `a jour les nÅ“uds
seulement aï¬€ectÂ´es par lâ€™ajout dâ€™arË†etes. Lorsquâ€™une nouvelle arË†ete se greï¬€e dans le
graphe, LabelRankT met `a jour les nÅ“uds qui sont sur ses extrÂ´emitÂ´es. La qualitÂ´e
de partionnement est similaire `a MCL et Informap sur des graphes sociaux, mais
avec une complexitÂ´e algorithmique moins Â´elevÂ´ee. Il est cependant plus rapide
que certains algorithmes pour la dÂ´etection de communautÂ´es dynamiques comme
facetNet et iLCD. La complexitÂ´e globale de cet algorithme entre deux images
consÂ´ecutives dâ€™un mË†eme rÂ´eseau est en O(kÃ— m), o`u k est le nombre dâ€™itÂ´erations.
LabelRankT peut Ë†etre Â´etendu `a la dÂ´etection de communautÂ´es chevauchantes
en lui intÂ´egrant le SLPA (â€Speakerlistener Label Propagation Algorithmâ€) (Xie
et al. (2011)) dont nous donnerons la dÂ´eï¬nition en section 1.4.

Lou et al. (2013), arguent quâ€™une limitation du LPA est due `a son processus
de vote. En adoptant le label majoritaire de ses voisins lâ€™information topologique
est perdue et cela a pour eï¬€et lâ€™instabilitÂ´e du LPA et sa pauvre performance en
termes de qualitÂ´e dans certains cas. Câ€™est en ce sens que les auteurs font interve-
nir une mesure nommÂ´ee â€cohÂ´erence de proximitÂ´e du voisinageâ€ (W-CNN) dont
lâ€™objectif est de calculer la probabilitÂ´e quâ€™une paire de nÅ“uds soit dans la mË†eme
communautÂ´e. Elle est fondÂ´ee sur un voisinage plus large des nÅ“uds considÂ´erÂ´es
lors du vote. Un label aura plus dâ€™importance si sa source est issue dâ€™un milieu
fortement dense. Dans la phase de mise `a jour des labels, un nÅ“ud adoptera le
label ayant la plus forte valeur de W-CNN au lieu du vote majoritaire tradi-
tionnel.
Les auteurs montrent que pour de petits rÂ´eseaux, les rÂ´esultats sont Â´equivalents
au LPA sans toujours stabiliser la solution. Lâ€™algorithme toutefois montre de
meilleurs rÂ´esultats que le LPA pour de grands graphes de terrain, avec une
meilleure stabilisation.

Xing et al. (2014) proposent une propagation de labels par nÅ“uds inï¬‚uents.

Cette mÂ´ethode est fondÂ´ee sur un ordre de mise `a jour des labels et sur lâ€™amÂ´elioration
du vote lorsquâ€™il y a Â´equidistribution des labels majoritaires. Cette mÂ´ethode se
fonde sur le (k)-shell dâ€™un nÅ“ud et de son voisinage. Un k-shell est un sous
graphe connexe maximum o`u chaque nÅ“ud a un degrÂ´e au moins de k. Un k-shell
est formÂ´e des sommets qui sont du k-core mais qui ne sont pas du k + 1-core.
La valeur du k-shell dâ€™un nÅ“ud est k. Pour un nÅ“ud u, les auteurs notent
Ks(u) la valeur du k-shell du nÅ“ud u, N (u) lâ€™ensemble des voisins du nÅ“ud u
et dÂ´eï¬nissent lâ€™inï¬‚uence du nÅ“ud par :

N I(u) = Ks(u) + Î± Ã— (cid:88)

Ks(u)
d(v)

(1.11)

vâˆˆN (u)

o`u d(v), le degrÂ´e du nÅ“ud u, Î± âˆˆ [0, 1] Â´etant un param`etre global (utilisÂ´e pour

42

CHAPITRE 1. ETAT DE Lâ€™ART

ajuster lâ€™eï¬€et des voisins sur la centralitÂ´e dâ€™un nÅ“ud u). Les auteurs ï¬xent lâ€™ordre
de mise `a jour des labels de mani`ere dÂ´ecroissante selon les scores des inï¬‚uences
des nÅ“uds. Ils dÂ´eï¬nissent Â´egalement lâ€™inï¬‚uence du label fondÂ´ee sur lâ€™inï¬‚uence du
nÅ“ud pour choisir un label lorsquâ€™il y a plusieurs labels majoritaires au sein dâ€™un
voisinage dâ€™un nÅ“ud. De par leurs expÂ´erimentations, notamment sur des graphes
rÂ´eels comme le club de karatÂ´e, le rÂ´eseau de dauphins, le rÂ´eseau footballistique,
celui des livres politiques et celui portant sur des collaborations scientiï¬ques,
les auteurs montrent quâ€™eï¬€ectuer la mise `a jour des labels des nÅ“uds ayant un
fort (k)-shell permet de mieux stabiliser la propagation de labels mais que les
rÂ´esultats en termes de qualitÂ´e de partitionnement ne sont toujours satisfaisants.
En eï¬€et, le NMI sur les dauphins nâ€™est que de 0.65, celui du rÂ´eseau footballis-
tique nâ€™est que de 0.87 et celui des livres politiques, de 0.656. Ce qui, par rapport
`a dâ€™autres algorithmes notamment celui de Louvain montre que la mÂ´ethode est
moins performante. Les rÂ´esultats sur les graphes alÂ´eatoires conduise a la mË†eme
analyse.
Cette mÂ´ethode est Â´egalement sujette au choix de la valeur Î± qui reste un sujet
de recherche ouvert. Par consÂ´equent, cette mÂ´ethode ne peut pas Ë†etre appliquÂ´ee
sur des graphes rÂ´eels sans faire une Â´etude prÂ´ealable. Une autre contrainte est le
temps dâ€™exÂ´ecution nÂ´ecessaire `a la mise `a jour de la fonction dâ€™inï¬‚uence qui peut
devenir tr`es important pour de grands graphes.

Zhang et al. (2014) ont proposÂ´e une version modiï¬Â´ee du LPA avec la capacitÂ´e
`a la prÂ´ediction de transition de percolation (LPAp). Les eï¬€ets de la phase de
prÂ´ediction au sein du LPA permettent de retarder la formation de communautÂ´es
gÂ´eantes. Les auteurs implÂ´ementent une condition de mise `a jour dans le but de
rÂ´eduire le temps dâ€™Â´exÂ´ecution du LPAp.
Les expÂ´erimentations ont montrÂ´e que LPAp permettait de trouver des commu-
nautÂ´es de petites tailles, Â´etait plus stable que le LPA et donnait de meilleurs
rÂ´esultats. Cependant, la mise `a lâ€™Â´echelle pour de grands graphes semble Ë†etre la
faiblesse de la proposition algorithmique.

Cordasco et Gargano (2012) ont Â´etudiÂ´e le comportement de la propagation
de labels synchrone et asynchrone. Dans le but de rÂ´esoudre le probl`eme dâ€™une
implÂ´ementation parallÂ´elisÂ´ee de la propagation de labels (o`u la propagation se
fait de mani`ere sÂ´equentielle dâ€™ordinaire), les auteurs proposent la propagation de
labels semi-synchrone. Un algorithme de coloration est lancÂ´e permettant dâ€™obte-
nir une partition D = {D1, D2, ..., Dk} (en k parties) de telle mani`ere que deux
nÅ“uds adjacents nâ€™aient pas la mË†eme couleur. Les couleurs obtenues serviront
dâ€™ordre de visite pour la mise `a jour des labels. Tous les nÅ“uds avec les mË†emes
couleurs eï¬€ectueront en mË†eme temps la mise `a jour de leurs labels selon le vote
majoritaire classique du LPA. Durant cette mise `a jour, les autres nÅ“uds, dont
la coloration est diï¬€Â´erente, sont bloquÂ´es, leur imposant lâ€™impossibilitÂ´e de mettre
`a jour leurs labels. Cela permet dâ€™Â´eviter de rendre lâ€™algorithme synchrone et
de perdre en qualitÂ´e de partitionnement. Apr`es que cette phase de mise `a jour
est eï¬€ectuÂ´ee, les nÅ“uds qui Â´etaient bloquÂ´es connaissent les nouveaux labels, no-

1.3. D Â´ETECTION DE COMMUNAUT Â´ES DISJOINTES

43

tamment sâ€™il y a eu des modiï¬cations de labels dans leur voisinage. Une autre
couleur est alors considÂ´erÂ´ee et le processus continue. Lorsque toutes les couleurs
ont Â´etÂ´e traË†Ä±tÂ´ees, une propagation de labels globale a Â´etÂ´e eï¬€ectuÂ´ee. On rÂ´ep`ete le
processus un nombre de fois dÂ´eterminÂ´e par lâ€™utilisateur ou jusquâ€™`a stabilisation
en termes de vote.

Les auteurs ont montrÂ´e que la mÂ´ethode semi-synchrone Â´etait plus eï¬ƒcace en
termes de stabilitÂ´e que le LPA (sans la rendre pour autant dÂ´eterministe), et
parallÂ´elisable. Les rÂ´esultats sont cependant Â´equivalents au LPA en termes de
qualitÂ´e de partitionnement.

1.3.7 Autres mÂ´ethodes

MÂ´ethodes de modularitÂ´e extrÂ´emale

Guimera et al. (2004) propos`erent le recuit-simulÂ´e fondÂ´e sur lâ€™optimisation
de la modularitÂ´e pour former les communautÂ´es. Une partition alÂ´eatoire est ef-
fectuÂ´ee sur le rÂ´eseau. Un nÅ“ud se dÂ´eplacera dans une autre communautÂ´e si la
modularitÂ´e augmente ou avec une certaine probabilitÂ´e. Lâ€™algorithme est itÂ´eratif
jusquâ€™`a ce que la modularitÂ´e nâ€™augmente plus. Bien que lâ€™algorithme donne des
rÂ´esultats satisfaisants, la mÂ´ethode nÂ´ecessite de paramÂ´etrer le recuit-simulÂ´e, et
nâ€™est pas exempte de tomber dans un optimum local duquel on ne puisse plus
sortir. La complexitÂ´e est diï¬ƒcile `a estimer et dÂ´epend de la paramÂ´etrisation. De
nombreuses combinaisons doivent Ë†etre testÂ´ees pour faire migrer un nÅ“ud dâ€™une
communautÂ´e `a une autre, ce qui nÂ´ecessite un certains de traitement. La mÂ´ethode
a Â´etÂ´e appliquÂ´ee `a des graphes ayant environ 200 nÅ“uds.

Massen et Doye (2006) ont apportÂ´e deux amÂ´eliorations majeures. La premi`ere
est que lâ€™algorithme sâ€™arrË†ete de mani`ere pÂ´eriodique, Â´evalue les communautÂ´es et
teste toutes les possibilitÂ´es de mouvement de certains nÅ“uds qui optimisent
le plus la modularitÂ´e. La seconde rÂ´eside en lâ€™utilisation de lâ€™approche Basin-
Hopping (Wales et Doye (1997)), `a savoir que des groupes de nÅ“uds puissent
changer de communautÂ´e dâ€™un bloc. Cela permet dâ€™Â´eviter de tomber dans un op-
timum local concernant la modularitÂ´e. Lâ€™algorithme donne de meilleurs rÂ´esultats
que celui de Guimera et al. (2004), mais est plus lent.

Mod`ele de Potts

Le mod`ele dâ€™Ising (aussi appelÂ´e mod`ele de Lenz-Ising), est un mod`ele de
physique statistique. Il reprÂ´esente un syst`eme de particules, chacune possÂ´edant
deux niveaux dâ€™Â´energie (on parle de spins). Le spin est le moment cinÂ´etique in-
trins`eque des particules quantiques. Il sâ€™agit, pour simpliï¬er, du sens de rotation
de lâ€™Â´electron considÂ´erÂ´e. La spintronique (Â´electronique de spin) permet de mettre

44

CHAPITRE 1. ETAT DE Lâ€™ART

la forme gÂ´enÂ´erale de lâ€™hamiltonien comme Â´etant H(x) = âˆ’(cid:80)

en Â´evidence des phÂ´enom`enes de transition de phase, câ€™est-`a-dire une transfor-
mation du syst`eme Â´etudiÂ´e provoquÂ´ee par la variation dâ€™un param`etre extÂ´erieur
particulier (tempÂ´erature, champ magnÂ´etique...). En consid`erant un syst`eme isolÂ´e
de n particules auxquelles est associÂ´e un Â´etat (ou spin) âˆ’1 ou +1, on peut
dÂ´eï¬nir la conï¬guration du syst`eme, qui est la donnÂ´ee de chacun des spins du
syst`eme. Lâ€™information peut donc Ë†etre contenue dans un vecteur x âˆˆ {+1,âˆ’1}n
En notant par xi la ieme particule tel que x = {xi, 1 â‰¤ i â‰¤ n}, on dÂ´eï¬nit
1â‰¤i,jâ‰¤n Jijxixj,
o`u les Jij sont les couplages entre les particules i et j (rÂ´eels positifs ou nuls)
et xixj est un produit scalaire. Suivant une certaine conï¬guration du mod`ele,
lâ€™hamiltonien nous donne lâ€™Â´energie du syst`eme de particules Â´etudiÂ´ees selon la
conï¬guration x. Lâ€™hamiltonien est une fonction `a optimiser. Plus lâ€™Â´energie dâ€™un
syst`eme est Â´elevÂ´ee, moins le syst`eme est stable. Un syst`eme physique a tendance
`a se trouver dans un Â´etat dâ€™Â´energie minimale. Le mod`ele de Potts consiste en
une gÂ´enÂ´eralisation du mod`ele dâ€™Ising o`u le syst`eme de spins peut Ë†etre dans q
Â´etats diï¬€Â´erents (x âˆˆ {1, ..., q}n).

Câ€™est Fu et Anderson (1986) qui ont dÂ´emontrÂ´e par analogie quâ€™il existe une
relation entre lâ€™Â´energie des syst`emes physiques (reprÂ´esentÂ´ee par lâ€™Hamiltonien)
et la fonction de coË†ut dans un probl`eme dâ€™optimisation discr`ete (probl`eme com-
binatoire). Blatt et al. (1996) ont construit le mod`ele de clustering de Potts.
Câ€™est Reichardt et Bornholdt (2006) qui lâ€™ont retranscrit au probl`eme de la
dÂ´etection de communautÂ´es, avec lâ€™Â´energie du syst`eme de spin (soit lâ€™hamilto-
nien) Â´equivalente `a la fonction de qualitÂ´e du regroupement `a optimiser, les Â´etats
de spins Â´etant les indices communautaires. Le lien entre le mod`ele de Potts et
la dÂ´etection de communautÂ´es se fait en considÂ´erant les Jij (couplages entre les
particules i et j) comme Â´etant la matrice dâ€™adjacence Aij (lien entre les nÅ“uds
i et j).

Reichardt et Bornholdt (2006) dÂ´eï¬nissent lâ€™hamiltonien comme Â´etant :

(1.12)

(1.13)

H({Ïƒ}) = âˆ’(cid:88)
(cid:88)

i(cid:54)=j

(cid:88)
cijAij(1 âˆ’ Î´(Ïƒi, Ïƒj)) âˆ’(cid:88)

aijAijÎ´(Ïƒi, Ïƒj) +

i(cid:54)=j

+

i(cid:54)=j

bij(1 âˆ’ Aij)(1 âˆ’ Î´(Ïƒi, Ïƒj))

dijAij(1 âˆ’ Î´(Ïƒi, Ïƒj))

i(cid:54)=j

o`u les Aij sont les Â´elÂ´ements de la matrice dâ€™adjacence, Ïƒ = {Ïƒ1, ..., Ïƒn} est le
vecteur reprÂ´esentant la partition du graphe, Ïƒi est le label de la communautÂ´e
du nÅ“ud i et aij, bij, cij, dij sont des pondÂ´erations sur les liens entre i et j.
Î´(Ïƒi, Ïƒj) = 1 si les nÅ“uds i et j sont dans la mË†eme communautÂ´e, 0 sinon. JÅ“rg
Reichardt et Stefan Bornholdt ont voulu un algorithme permettant dâ€™encourager
la crÂ´eation de communautÂ´es `a la fois avec une forte proportion de liens dans ces
derni`eres et une faible proportion de liens en ressortant. Ainsi, peut-on expliquer
la formule prÂ´ecÂ´edemment exposÂ´ee comme suit :

1. aijAijÎ´(Ïƒi, Ïƒj) reprÂ´esente les liens internes
2. bij(1 âˆ’ Aij)(1 âˆ’ Î´(Ïƒi, Ïƒj)) reprÂ´esente les liens internes nâ€™existant pas

1.3. D Â´ETECTION DE COMMUNAUT Â´ES DISJOINTES

45

3. cijAij(1 âˆ’ Î´(Ïƒi, Ïƒj)) reprÂ´esente les liens externes
4. dijAijÎ´(1 âˆ’ Ïƒi, Ïƒj) reprÂ´esente les liens externes nâ€™existant pas

Pour les liens nâ€™existant pas, le mod`ele de JÅ“rg Reichardt et Stefan Bornholdt
utilise un graphe complet avec un poids (1 si le lien existe et 0 dans le cas
contraire). Les auteurs ont rÂ´eÂ´ecrit la formule sous une autre forme :

H({Ïƒ}) = âˆ’(cid:88)

i(cid:54)=j

(Aij âˆ’ Î³pij)Î´(Ïƒi, Ïƒj))

(1.14)

o`u pij est la probabilitÂ´e quâ€™il existe un lien entre les nÅ“uds i et j dans le
graphe nul (un graphe respectant la distribution des degrÂ´es des nÅ“uds du rÂ´eseau
initial mais o`u les arË†etes ont Â´etÂ´e mises de mani`ere alÂ´eatoire). En considÂ´erant la
derni`ere formule citÂ´ee, supposons que le facteur Î³ nâ€™apparaisse pas, nous obte-
nons alors la formule de la modularitÂ´e. La modularitÂ´e est une mesure de par-
titionnement souï¬€rant dâ€™une limite de rÂ´esolution. Si des communautÂ´es sont de
tailles diï¬€Â´erentes `a lâ€™intÂ´erieur dâ€™un mË†eme graphe, certaines communautÂ´es, mË†eme
bien dÂ´eï¬nies, pourront ne pas Ë†etre distinguÂ´ees dans la partition de modularitÂ´e
optimale. Pour pallier ce probl`eme, les auteurs font intervenir un facteur Î³ qui a
une incidence sur lâ€™Â´echelonnabilitÂ´e des tailles des communautÂ´es dÂ´etectÂ´ees. Pour
Î³ â†’ 0, le graphe est considÂ´erÂ´e comme une seule communautÂ´e. Pour Î³ â†’ âˆ,
chaque nÅ“ud est considÂ´erÂ´e comme une communautÂ´e. On peut ainsi considÂ´erer
la fonction hamiltonienne comme une fonction objective `a optimiser, o`u les
Â´elÂ´ements `a rechercher sont ceux du vecteur Ïƒ = {Ïƒ1, ..., Ïƒn}. Les auteurs uti-
lisent une mÂ´ethode de recuit-simulÂ´e en partant dâ€™un Â´etat initial o`u les spins sont
assignÂ´es au hasard aux sommets, avec un nombre dâ€™Â´etats q Â´elevÂ´e. Les rÂ´esultats
expÂ´erimentaux en termes de qualitÂ´e sont bons, mais cependant sujets au choix
du paramË†etre Î³, `a la lenteur de lâ€™algorithme du recuit-simulÂ´e qui demande une
forte paramÂ´etrisation et `a sa complexitÂ´e qui ne lui permet pas dâ€™Ë†etre appliquÂ´e
`a de tr`es grands graphes.

âˆš

Ronhovde et Nussinov (2010) ont dans des travaux postÂ´erieurs proposÂ´e des
amÂ´eliorations et diverses fonctions hamiltoniennes, mais Â´egalement considÂ´erÂ´e
dâ€™autres algorithmes de dÂ´etection de communautÂ´es dont les complexitÂ´es sont
moins fortes que celle du recuit-simulÂ´e. Les auteurs ont montrÂ´e quâ€™en faisant in-
tervenir Î³, le probl`eme de rÂ´esolution de limite persistait dans des communautÂ´es
Î³ Ã— m. Ils introduisent le mod`ele absolu permettant de
de taille infÂ´erieure `a
crÂ´eer un mod`ele de Potts `a q Â´etats sans utiliser le mod`ele nul, en supprimant
par voie de consÂ´equence le probl`eme de rÂ´esolution de limite. Pour ce faire, les
auteurs proposent dâ€™utiliser la densitÂ´e comme probabilitÂ´e et de maximiser son
espÂ´erance sur toutes les communautÂ´es. Lâ€™algorithme utilisÂ´e est une mÂ´ethode
multi-niveau permettant la crÂ´eation dâ€™un dendrogramme. Le syst`eme donne
de meilleurs rÂ´esultats que le mod`ele originel, mais nÂ´ecessite deux grands pa-
ram`etres, le nombre de contractions et le nombre dâ€™Â´etats au dÂ´epart (un nombre
de communautÂ´es dont le nombre diminue au cours du temps). Les auteurs pro-
posent par la suite dâ€™autres fonctions hamiltoniennes comme pour des graphes

46

CHAPITRE 1. ETAT DE Lâ€™ART

pondÂ´erÂ´es, un mod`ele fondÂ´e sur les graphes alÂ´eatoires dâ€™Erdos-Renyi, et sa ver-
sion pondÂ´erÂ´ee. Les rÂ´esultats en termes de qualitÂ´e sont encourageants et tr`es
proches mais nÂ´ecessitent la paramÂ´etrisation de Î³ qui a un impact tr`es Â´elevÂ´e sur
la qualitÂ´e des communautÂ´es.

Prat-PÂ´erez et al. (2014) en 2014 ont proposÂ´e un algorithme de dÂ´etection
de communautÂ´es, SCD (pour Scalable Community Detection), fondÂ´e sur lâ€™idÂ´ee
que des communautÂ´es doivent avoir une fort coeï¬ƒcient de clustering dans les
rÂ´eseaux complexes. SCD comprend deux Â´etapes. La premi`ere consiste en lâ€™obten-
tion dâ€™une partition P par optimisation du cÅ“ï¬ƒcient de clustering. La deuxi`eme
Â´etape consiste en un raï¬ƒnage qui fait migrer certains nÅ“uds dans dâ€™autres com-
munautÂ´es en utilisant un ordre sur les nÅ“uds selon leurs coeï¬ƒcients de cluste-
ring. Les dÂ´eplacements de nÅ“uds sâ€™eï¬€ectuent jusquâ€™`a stabilisation, câ€™est-`a-dire
`a ce quâ€™il nâ€™y ait plus de migrations. les auteurs proposent une estimation en
O(m Ã— log(n)). Cette derni`ere mÂ´ethode dâ€™estimation a Â´etÂ´e dÂ´eveloppÂ´ee sur une
architecture multi-cÅ“urs permettant de travailler sur des graphes de plusieurs
centaines de millions de nÅ“uds ayant un milliard dâ€™arË†etes. Le temps de traite-
ment est dâ€™environ une heure avec une quarantaine de machines. Les machines
ont des processeurs Intel Xeon E5530 de 2.4 Ghz, 32 GO de RAM et 1 tÂ´erabit
dâ€™espace disque. Les rÂ´esultats en termes de qualitÂ´e de partitionnement sont satis-
faisants, lâ€™algorithme surpasse les autres sur sur DBLP, you Tube et live Journal
avec des NMI respectivement de 0.17, 0.05 et 0.030, et des F1-score respective-
ment de 0.38, 0.20 et 0.23. Walktrap ou Louvain donnent cependant de meilleurs
rÂ´esultats en termes de NMI sur Amazon et de DBLP avec des scores respectifs
de 0.29 et 0.31.

Saltz et al. (2015) ont implÂ´ementÂ´e leurs mÂ´ethodes sur Giraph (Hadoop) pour
pouvoir considÂ´erer les tr`es grands graphes. Ils ont testÂ´e leur mÂ´ethode sur des
graphes de plus dâ€™une centaine de millions de nÅ“uds et un milliard dâ€™arË†etes pour
une durÂ´ee dâ€™une heure, en utilisant une quarantaine de machines.

1.3.8 Tableau rÂ´ecapitulatif des mÂ´ethodes disjointes

Nous avons vu de nombreux algorithmes. Certains sont fondÂ´es sur la topo-
logie globale du graphe pour eï¬€ectuer une coupe alors que dâ€™autres agissent de
mani`ere locale, vis-`a-vis du nÅ“ud et de ses voisins. Certains autres sont hy-
brides, utilisant soit une mÂ´ethode locale `a laquelle sont adjointes des mesures
sociales, soit en vis-`a-vis dâ€™un param`etre qui agrandit le voisinage dâ€™un nÅ“ud
`a une certaine distance gÂ´eodÂ´esique. Nous proposons un tableau rÂ´ecapitulalif,
Tableau 1.2, permettant dâ€™observer les caractÂ´eristiques globales des mÂ´ethodes
dans la mesure o`u nous souhaitons travailler sur de grands graphes de plusieurs
millions dâ€™arË†etes.

1.3. D Â´ETECTION DE COMMUNAUT Â´ES DISJOINTES

47

Classiï¬cation des principaux algorithmes de dÂ´etection de communautÂ´es

Algorithmes
agglomÂ´eratifs
Blondel et al. (2008)
Pons et Latapy (2006)
Ronhovde et Nussinov (2010)

Traag et al. (2013)

Newman (2004)
De Meo et al. (2013)
divisifs
Girvan et Newman (2002b)
Donetti et MuËœnoz (2004)
Newman (2006)
Newman (2013)
extrÂ´emaux
Guimera et al. (2004)
LPA
Raghavan et al. (2007)

Leung et al. (2009)
Ë‡Subelj et Bajec (2011)
Lou et al. (2013)
Xing et al. (2014)
Cordasco et Gargano (2012)
Zhang et al. (2014)
Zhang et al. (2015)
Rezaei et al. (2015)
Shi et Zhang (2014a)
Shi et Zhang (2014b)
Hu et al. (2016)
Fang et al. (2016)
Peng et al. (2016)
Zhoua et al. (2016)
Liu et al. (2016)
ThÂ´eorie de
lâ€™information
Rosvall et Bergstrom (2007b)
Rosvall et Bergstrom (2010)
Autres

Radicchi et al. (2004)
Clauset et al. (2004)
Duch et Arenas (2005)

Dend

complexitÂ´e

Par

Type

O(mÎ² log(n))
O(mÎ² log(n))

(ordre)
O(m)
O(n3)
Î² âˆ¼ 1.3
Î² âˆ¼ 1.3
O(nm2)
O(nm)
O(nm2)
O(mn4)
O(mn3)
O(mn3)

âˆ—

O(n Ã— m)

O(n2 Ã— m)
O(n2 Ã— m)
O(n2 Ã— m)
O(2n + 2km)
O(n2 Ã— m)
O(n2 Ã— m)
O(n2 Ã— m)
O(kn2 + m)
O(m + n)
O(m)
O(km)

O(n3 + nm)
O(n2 Ã— m)
O(kn2 + m)
O(kn + m)

âˆ—

O(m)

O( m4
n2 )

O(nlog(n)2)
O(n2log(n))

MPI
non
non

non

non
non

non
non
non
non

non

MPI

Hadoop
Spark
non
non
non
non
non
non
non
non
non
non
non
non
non
non
non

non
non

non
oui
non

oui
non
non

non

oui
non

non
non
non
non

non

non

non
non
non
non
non
non
non
non
non
non
non
non
non
non
non

non
non

non
non
non

local
global

local-hybride

local-hybride

global
hybride

global
global
global
global

global

local

local
local
local

hybride
hybride
hybride
hybride

local
local

hybride
global
hybride
global
hybride

hybride

local

global
local
local

Tableau 1.2 â€“ Principaux algorithmes de dÂ´etection de communautÂ´es. Le symbole â€*â€
signiï¬e que cela dÂ´epend du paramÂ´etrage, diï¬ƒcile `a estimer. Le symbole â€**â€, pour le
type dâ€™algorithme, signiï¬e que cela dÂ´epend du paramÂ´etrage, un algorithme pouvant
Ë†etre local ou hybride. Les notations Dend et Par signiï¬ent respectivement â€dendro-
grammeâ€ et â€parallÂ´elisÂ´eâ€.

Nous pouvons observer, dâ€™apr`es le tableau 1.2, que les mÂ´ethodes globales,
qui utilisent la topologie du graphe dans son entier ont des complexitÂ´es plus
Â´elevÂ´ees que les mÂ´ethodes locales, fondÂ´ees sur les nÅ“uds et leur voisinage. Nous

48

CHAPITRE 1. ETAT DE Lâ€™ART

donnons des ï¬gures portant sur lâ€™Â´echelonnabilitÂ´e pour observer les mÂ´ethodes
pouvant Ë†etre appliquÂ´ees `a de grands graphes, avec des millions dâ€™arË†etes.

Nous avons recueilli, `a travers les diï¬€Â´erents articles, la taille des graphes
sur lesquels ont Â´etÂ´e appliquÂ´es les algorithmes que nous avons rencontrÂ´es. Nous
observons, sur la ï¬gure 1.9 que les mÂ´ethodes locales comme la propagation de
labels ou la mÂ´ethode de Louvain peuvent Ë†etre appliquÂ´ees `a des graphes ayant
une centaine de millions dâ€™arË†etes. Les mÂ´ethodes divisives comme la mÂ´ethode
spectrale ou le recuit-simulÂ´e ayant une complexitÂ´e Â´elevÂ´ee, ne peuvent Ë†etre ap-
pliquÂ´ees `a de trop grands graphes. Les mÂ´ethodes pour la dÂ´etection de cÅ“urs
sont fondÂ´ees sur le lancement en parall`ele de mÂ´ethodes locales, nÂ´ecessitant une
forte consommation mÂ´emoire et ne permettant pas lâ€™application `a des graphes
de plus de cent mille arË†etes.

Figure 1.9 â€“ MÂ´ethodes pour la dÂ´etection de communautÂ´es disjointes.

1.3. D Â´ETECTION DE COMMUNAUT Â´ES DISJOINTES

49

1.3.9 Mesures supervisÂ´ees et non supervisÂ´ees pour la dÂ´etection

de communautÂ´es disjointes

Pour apprÂ´ecier la qualitÂ´e de partitionnement des algorithmes de dÂ´etection de
communautÂ´es, des mesures existent fondÂ´ees sur la comparaison entre partition
rÂ´eelle (observÂ´ee et Â´evaluÂ´ee par des experts) et partition trouvÂ´ee par lâ€™algorithme,
il sâ€™agit des mesures supervisÂ´ees. Par exemple, si lâ€™on consid`ere un rÂ´eseau de col-
laboration scientiï¬que, un syst`eme expert va eï¬€ectuer des regroupements entre
auteurs ayant publiÂ´e sur de mË†emes th`emes scientiï¬ques, cela donnera la vraie
partition. Nous exposons les principales mesures, que nous utiliserons pour me-
ner notre Â´etude. Cependant, dans le cas o`u nous nâ€™avons pas de connnaissance
de la vÂ´eritable partition, des mesures fondÂ´ees sur le nombre de liens `a lâ€™intÂ´erieur
des communautÂ´es et `a lâ€™extÂ´erieur, ou sur la comparaison de structures avec un
graphe alÂ´eatoire sont utilisÂ´ees, il sâ€™agit dans ce cas des mesures non supervisÂ´ees.

Mesures supervisÂ´ees pour la dÂ´etection de communautÂ´es disjointes

Les mesures supervisÂ´ees permettent de comparer directement les rÂ´esultats de
lâ€™algorithme proposÂ´e `a la partition donnÂ´ee par des experts. Dans certains, cas,
elles peuvent Â´egalement Ë†etre utilisÂ´ees pour observer la similaritÂ´e des rÂ´esultats
entre plusieurs algorithmes. Nous prÂ´esentons lâ€™indice de Rand (et la version
ajustÂ´ee), lâ€™information mutuelle normalisÂ´ee et la puretÂ´e.

Lâ€™indice de Rand et la version ajustÂ´ee (Rand (1971))

ConsidÂ´erons deux partitions P1 et P2 dâ€™un mË†eme ensemble S âŠ† V . Lâ€™idÂ´ee pour
Â´evaluer la ressemblance entre deux partitions consiste `a mesurer le taux de
bonnes assignations de ces paires dâ€™observations. Pour chaque couple dâ€™obser-
vations , on peut compter quatre types dâ€™assignations possibles :

â€” N11 le nombre de paires de nÅ“uds classÂ´ees ensemble selon P1 et P2
â€” N10 le nombre de paires de nÅ“uds classÂ´ees ensemble selon P1 et sÂ´eparÂ´ees

selon P2

â€” N01 le nombre de paires de nÅ“uds sÂ´eparÂ´ees selon P1 et classÂ´ees ensemble

selon P2

â€” N00 le nombre de paires de nÅ“uds sÂ´eparÂ´ees `a la fois dans P1 et dans P2

Lâ€™indice de Rand est donnÂ´e par la formule suivante :

Rand(P1, P2) =

N11 + N00

N11 + N10 + N01 + N00

(1.15)

Cette mesure varie entre 0 et 1 et prend la valeur maximale en cas de parfaite
correspondance. Cependant, cet indice ne demande pas dâ€™Â´etablir un appariement
entres les classes rÂ´eelles et celles estimÂ´ees, car seule est prise en compte la clas-
siï¬cation commune des diï¬€Â´erentes paires dâ€™Â´elÂ´ements dans les deux partitions.
Cela induit deux probl`emes majeurs. Premi`erement, lâ€™indice est fondÂ´e exclusi-
vement sur les paires dâ€™objets, et non les objets eux mË†emes. Deuxi`emement, une

50

CHAPITRE 1. ETAT DE Lâ€™ART

inversion de classiï¬cation pour deux Â´elÂ´ements dans deux parties de petite taille
sera moins pÂ´enalisÂ´ee que si elle se produit dans des parties de plus grande taille.
De plus, lâ€™indice de Rand varie beaucoup entre deux partitions tirÂ´ees au hasard.
Câ€™est pourquoi lâ€™indice de Rand ajustÂ´e (ARI) (Hubert et Arabie (1985)) fut pro-
posÂ´e dont lâ€™espÂ´erance est nulle lorsque les partitions sont tirÂ´ees alÂ´eatoirement.
Il a pour forme :

ARI(P1, P2) =

2(N11N00 âˆ’ N01N10)

(N01 + N00)(N11 + N01) + (N00 + N10)(N10 + N11)

(1.16)

Sa valeur est comprise entre 0 et 1. Elle prend la valeur 1 lorsque les deux par-
titions sont identiques. Si la valeur est proche de 0, les deux partitions sont tr`es
diï¬€Â´erentes.

La puretÂ´e (Manning et al. (2008)) : Cette mesure, pour une communautÂ´e
ci âˆˆ P1, avec P1 = {c1, ..., cm}, par rapport `a une autre partition P2 (avec
P2 = {c(cid:48)

n}) se dÂ´eï¬nit comme suit :

1, ..., c(cid:48)

purete(ci, P2) = max
1â‰¤jâ‰¤n

j|

|ci âˆ© c(cid:48)
|ci|

(1.17)

Cette fonction calcule le taux de recouvrement maximal entre la communautÂ´e
ci et les communautÂ´es se trouvant dans la partition P2. On dÂ´eï¬nit la puretÂ´e de
la partition P1 par rapport `a la partition P2 par la somme pondÂ´erÂ´ee de la puretÂ´e
des communautÂ´es de P1 par rapport `a P2, ce qui nous donne :

m(cid:88)

purete(P1, P2) =

wci Ã— purete(ci, P2)

(1.18)

o`u wci =

|ci|(cid:80)m
i=1 |ci|

i=1

Lâ€™information mutuelle normalisÂ´ee (NMI) (Kullback (1959)) : Câ€™est une
mesure qui permet de reprÂ´esenter le degrÂ´e de dÂ´ependance entre deux partitions
P1 et P2. Elle est fondÂ´ee sur la thÂ´eorie de lâ€™information. La probabilitÂ´e quâ€™un
nÅ“ud choisi au hasard dans une partition P1 appartienne `a la communautÂ´e k
est P (k) = nk
n o`u nk est le nombre de nÅ“uds dans la communautÂ´e k et n est
le nombre total de nÅ“uds du syst`eme. Lâ€™entropie de Shannon, en utilisant la
nk
n , o`u
|P1| est le nombre de communautÂ´es dans la partition P1. Lâ€™entropie de Shannon
de la partition P1 reprÂ´esente la quantitÂ´e dâ€™information fournie par cette mË†eme
partition sur la topologie du graphe en termes de communautÂ´es.

distance de Kullback-Leibler, est dÂ´eï¬nie comme : H(P1) = âˆ’(cid:80)|P1|

nk
n log2

k=1

Lâ€™information mutuelle I(P1, P2) Â´evalue le niveau dâ€™inter-dÂ´ependance entre
deux partitions dâ€™un graphe. Il est possible de dÂ´eï¬nir une matrice de confusion
pour les partitions P1 et P2 en identiï¬ant combien de nÅ“uds nij de la com-
munautÂ´e i de la partition P1 sont dans la communautÂ´e j de la partition P2.
) o`u ni est le

Lâ€™information mutuelle est I(P1, P2) = (cid:80)P1

(cid:80)P2

nij

n log2( nij

ninj

i=1

j=1

1.3. D Â´ETECTION DE COMMUNAUT Â´ES DISJOINTES

51

nombre de nÅ“uds de la communautÂ´e i de la partition P1 et nj est le nombre
de nÅ“uds de la communautÂ´e j de la partition P2. La variation de lâ€™information
V (P1, P2) est V (P1, P2) = H(P1) + H(P2)âˆ’ 2I(P1, P2) qui mesure la â€distanceâ€
de lâ€™information entre les deux partitions P1 et P2. Pour lâ€™obtention dâ€™une valeur
comprise entre 0 et 1, on dÂ´eï¬nit lâ€™information mutuelle normalisÂ´ee comme Â´etant
. Sa valeur peut varier entre 0 et 1. Plus la valeur
N M I(P1, P2) =

I(P1,P2)

âˆš

H(P1)+H(P2)

est proche de 1, plus les deux partitions sont identiques.

Le score F1 (van Rijsbergen (1979)), couramment utilisÂ´e dans la recherche
dâ€™information, peut Ë†etre vu comme une mesure dâ€™exactitude de la prÂ´ecision et
du rappel entre deux partitions. En considÂ´erant deux communautÂ´es A et B, le
score F1 est dÂ´eï¬nit par :

F1(A, B) = 2

|A âˆ© B|
|A| + |B|

(1.19)

|Aâˆ©B|
|A| ) et du rappel (rappel(A, B) =

Plus les communautÂ´es A et B partagent de nÅ“uds en commun, plus le score F1
est proche de 1. Un score nul signiï¬e que les deux communautÂ´es ne partagent
aucun nÅ“ud en commun. Cette mÂ´ethode est fondÂ´e sur la combinaison de la
prÂ´ecision (precision(A, B) =
ConsidÂ´erons la partition trouvÂ´ee par lâ€™algorithme de dÂ´etection de commu-
nautÂ´es P1 = {c1, c2, ..., ct} et la partition reprÂ´esentant lâ€™ensemble des commu-
k}. On note que le nombre de com-
nautÂ´es de vÂ´eritÂ´e de terrains P2 = {c(cid:48)
munautÂ´es peut Ë†etre diï¬€Â´erent entre les deux partitions. La moyenne du score F1
que nous utilisons est celle concernant les communautÂ´es trouvÂ´ees par un algo-
rithme o`u nous comparons chacune dâ€™entres elles avec la communautÂ´e la plus
similaire parmi les communautÂ´es de la partition de vÂ´eritÂ´e de terrain, câ€™est-`a-
dire, avec la communautÂ´e de vÂ´eritÂ´e de terrain partageant le plus de nÅ“uds en
commun. Nous avons ainsi :

|Aâˆ©B|
|B| ).

1, ..., c(cid:48)

Â¯F1(P1, P2) =

1
t

max

jâˆˆ(cid:74)1,k(cid:75) F1(ci, c(cid:48)

i)

(1.20)

Cette valeur illustre `a quel point chaque communautÂ´e que lâ€™algorithme a
trouvÂ´ee est similaire aux communautÂ´es de la partition de vÂ´eritÂ´e de terrain, en
regardant les communautÂ´ees entre les deux partitions partageant le plus de
nÅ“uds en commun. Une valeur proche de 0 signiï¬e que les deux partitions sont
totalement diï¬€Â´erentes, sans aucune similaritÂ´e entre communautÂ´es dÂ´etectÂ´ees et
rÂ´eelles alors quâ€™une valeur proche de 1 signiï¬e que les deux partitions sont tr`es
semblables avec les mË†emes nÅ“uds `a lâ€™intÂ´erieur des mË†emes communautÂ´es.

Mesures non supervisÂ´ees pour la dÂ´etection de communautÂ´es disjointes

Les mesures non supervisÂ´ees permettent dâ€™avoir une estimation de la qualitÂ´e
de partitionnement sans connaË†Ä±tre les vÂ´eritables partitions. Ces mesures sont
soit fondÂ´ees sur des structures alÂ´eatoires respectant la topologie du graphe ini-
tial, soit fondÂ´ees sur les densitÂ´es et les liens entre communautÂ´es. Nous utilisons

t(cid:88)

i=1

52

CHAPITRE 1. ETAT DE Lâ€™ART

dans nos futures Â´etudes la modularitÂ´e et la conductance.

La conductance (Kannan et al. (2004)) : Cette mesure est fondÂ´ee sur la
densitÂ´e des communautÂ´es et le nombre de liens sortant de celles-ci. Une structure
communautaire est supposÂ´ee avoir beaucoup de liens en son sein et un nombre
faible de liens sortants. La conductance est fondÂ´ee sur le rapport entre le nombre
de liens sortants, lc
int) pour une
communautÂ´e c.

out, et le nombre total de liens (intÂ´erieurs lc

En considÂ´erant une communautÂ´e c dâ€™un graphe G, avec c = (Vc, Ec) (Vc
lâ€™ensemble des sommets de c et Ec lâ€™ensemble des arË†etes de c), la conductance
out] . En considÂ´erant une
de cette communautÂ´e est dÂ´eï¬nie par Ï•(c,G) =
partition P = {c1, ..., ck} en k parties de nÅ“uds disjoints, la conductance de G
se dÂ´eï¬nit comme suit :

lc
out
int+lc

[2lc

k(cid:88)
k(cid:88)

c=1

Î¦G =

=

1
k

1
k

[

[

Ï•(c,G)]

lc
out

(1.21)

(1.22)

]

[2lc

int + lc

out]

c=1

La conductance peut avoir une valeur comprise entre 0 et 1. Plus cette valeur
sera proche de 0, plus cela signiï¬era que les communautÂ´es ont une densitÂ´e forte
avec peu de liens pointant vers lâ€™extÂ´erieur.

La conductance ne peut Ë†etre utilisÂ´ee que dans certains cas prÂ´ecis. On consid`ere
dans un premier temps que la communautÂ´e c sur laquelle nous appliquons la
conductance est connexe, plusieurs cas sont `a Â´etudier :

â€” Si lc

int (cid:29) lc

out, la conductance sera proche de 0. Le nombre de liens
sortant de c (ayant une extrÂ´emitÂ´e dans c et une autre dans V âˆ’ Vc) est
tr`es faible par rapport au nombre de liens `a lâ€™intÂ´erieur de c. Cela induit,
par lâ€™hypoth`ese de la connexitÂ´e de c, que c a une forte densitÂ´e et cela
sera dâ€™autant plus vrai que c sera proche dâ€™une clique. Ces conditions
induisent la prÂ´esence dâ€™une structure communautaire.

int, la conductance Ï•(c,G) sera proche de 1. Cela entraË†Ä±ne
que le nombre de liens sortant de c sera beaucoup plus important que le
nombre de liens `a lâ€™intÂ´erieur de c, ce qui nâ€™est pas typique dâ€™une structure
communautaire.

â€” Si lc

out (cid:29) lc

Si la communautÂ´e c nâ€™est pas connexe, câ€™est-`a-dire quâ€™il y a des nÅ“uds isolÂ´es
dans c, alors la formule ne peut Ë†etre utilisÂ´ee comme mesure de qualitÂ´e pour la
dÂ´etection de communautÂ´es car le nombre de nÅ“uds isolÂ´es (dont le degrÂ´e est nul)
nâ€™a aucun impact sur la conductance, en eï¬€et, les nÅ“uds isolÂ´es nâ€™agissent pas
sur le nombre de liens. Ainsi, si une communautÂ´e c nâ€™est pas reliÂ´ee au reste du
graphe et quâ€™il existe des nÅ“uds isolÂ´es en son sein, nous aurons une conductance
faible sans pour autant avoir dÂ´etectÂ´e une structure communautaire.

1.3. D Â´ETECTION DE COMMUNAUT Â´ES DISJOINTES

53

Nous illustrons les cas avec des exemples simples. ConsidÂ´erons un graphe
G = (V, E) o`u V = {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12}, dÂ´ecomposÂ´e en deux
communautÂ´es c1 = (Vc1, Ec1), avec Vc1 = {1, 2, 3, 4, 5, 6} et c2 = (Vc2, Ec2)
avec Vc2 = {7, 8, 9, 10, 11, 12} . Les Figures 1.10,1.11 et 1.12 montrent que
le fait dâ€™augmenter les arË†etes entre les communautÂ´es augmente la conductance.
Pour la ï¬gure 1.10, nous avons Î¦G = 1
2âˆ—15+1 ] = 0.06. Pour la ï¬gure
2 [
1.11, nous avons Î¦G = 1
2âˆ—15+2 + 2
2 [
2âˆ—15+2 ] = 0.125. Pour la ï¬gure 1.12, nous
2âˆ—15+3 + 3
avons Î¦G = 1
2âˆ—15+3 ] = 0.18.
2 [

2âˆ—15+1 + 1

1

2

3

Figure 1.10 â€“ Deux communautÂ´es reliÂ´ees par une arË†ete.

Figure 1.11 â€“ Deux communautÂ´es reliÂ´ees par deux arË†etes.

La ï¬gures 1.13 montre le cas o`u les communautÂ´es sont connexes, en considÂ´erant
un nouveau graphe G(cid:48) = (V (cid:48), E(cid:48)) o`u V = {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 11, 12,
13, 14, 15, 16, 17, 18}, dÂ´ecomposÂ´e en deux communautÂ´es c1 = (Vc1, Ec1), avec
Vc1 = {1, 2, 3, 4, 5, 6, 13, 14, 15, 16} et c2 = (Vc2, Ec2) avec Vc2 = {7, 8, 9, 10,
11, 12, 17, 18}. La prÂ´esence de nÅ“uds isolÂ´es ne permet pas de modiï¬er la valeur
de la conductance. On ne peux donc pas utiliser la conductance dans le cas o`u
les communautÂ´es sont non connexes.

Il existe dâ€™autres mesures que nous avons vues auparavant, notamment la
mesure de Mancoridis et al. (1998) ou encore la modularitÂ´e que nous avons

54

CHAPITRE 1. ETAT DE Lâ€™ART

Figure 1.12 â€“ Deux communautÂ´es reliÂ´ees par trois arË†etes.

Figure 1.13 â€“ Deux communautÂ´es reliÂ´ees par trois arË†etes contenant des nÅ“uds isolÂ´es.

prÂ´esentÂ´ee en dÂ´ebut de chapitre.

1.3. D Â´ETECTION DE COMMUNAUT Â´ES DISJOINTES

55

RÂ´ecapitulatif des mesures supervisÂ´ees et non supervisÂ´ees

Nous avons pu observer quâ€™il existait de tr`es nombreuses mesures. Nous pro-
posons un tableau rÂ´ecapitulatif des mÂ´ethodes avec leurs spÂ´eciï¬citÂ´es et leurs gains
dâ€™informations portant sur les communautÂ´es au sein du graphe, Tableau 1.3.

Mesures supervisÂ´ees

Mesures
Rand

rÂ´efÂ´erence

(Rand, 1971)

Rand ajustÂ´ee
NMI

(Hubert et Arabie, 1985)

(Ana et Jain, 2003)

PuretÂ´e

Manning et al. (2008)

F1 score

(van Rijsbergen, 1979)

Information et caractÂ´eristiques

comptages sur les paires

dâ€™objets pareillement classÂ´ees

amÂ´elioration de Rand

quantitÂ´e mesurant la dÂ´ependance
statistique entre deux partitions
taux de recouvrement maximal

entre les communautÂ´es de deux partitions

combine la prÂ´ecision et le rappel

et leur moyenne harmonique

Mesures
ModularitÂ´e

rÂ´efÂ´erence

Information et caractÂ´eristiques

(Newman et Girvan, 2004)

maximise la densitÂ´e des

Mesures non supervisÂ´ees

Conductance

(Kannan et al., 2004)

communautÂ´es `a travers le mod`ele nul

maximise la densitÂ´e
des communautÂ´es et

minimise les liens sortants

Hamiltoniens

(Ronhovde et Nussinov, 2010)

maximise la densitÂ´e des communautÂ´es

`a travers le mod`ele nul avec

un facteur de rÂ´esolution

MQ

Mancoridis et al. (1998)

exprime la somme des diï¬€Â´erences entre

deux ratios de connectivitÂ´es,

calculÂ´es pour chaque groupe de nÅ“ud

Tableau 1.3 â€“ Classiï¬cation des mesures supervisÂ´ees et non supervisÂ´ees pour la
dÂ´etection de communautÂ´es disjointes

Dans la littÂ´erature de la dÂ´etection de communautÂ´es, les mesures les plus

utilisÂ´ees sont les suivantes :

â€” la modularitÂ´e
â€” le F1-score
â€” la puretÂ´e
â€” la conductance
â€” lâ€™indice de Rand ajustÂ´e
â€” le NMI
Ce sont les mesures que nous utiliserons car elles mettent en Å“uvre les prin-
cipales caractÂ´eristiques des communautÂ´es, `a savoir densitÂ´e, nombre de liens sor-
tants et graphe alÂ´eatoire. De plus, elles permettent dâ€™Â´etablir des Â´etudes compara-
tives dans la mesure o`u il sâ€™agit des mesures les plus utilisÂ´ees dans la littÂ´erature
de la dÂ´etection de communautÂ´es.

56

CHAPITRE 1. ETAT DE Lâ€™ART

1.3.10 Synth`ese et discussion

Ce chapitre nous a permis de formuler le probl`eme de dÂ´etection de commu-

nautÂ´es et de prÂ´esenter les principales mÂ´ethodes existantes dans la littÂ´erature.

Nous avons vu quâ€™il existait trois classes dâ€™algorithmes :

â€” les mÂ´ethodes globales qui consid`erent la topologie du graphe dans son
entier pour ensuite eï¬€ectuer une coupe. On peut citer la mÂ´ethode spec-
trale, les mÂ´ethodes gloutonnes de dÂ´eplacement de nÅ“uds ou encore les
mÂ´ethodes utilisant des mesures sociales globales. En eï¬€et, la mÂ´ethode
spectrale demande le calcul des valeurs et des vecteurs propres dont la
complexitÂ´e est en O(n3). Les mÂ´ethodes gloutonnes de dÂ´eplacement de-
mandent dâ€™eï¬€ectuer tous les types de dÂ´eplacement possibles aï¬n dâ€™optimi-
ser une certaine fonction de qualitÂ´e de partitionnement, comme le recuit-
simulÂ´e dont la forte complexitÂ´e dÂ´epend du paramÂ´etrage. Les mesures
comme celles de la centralitÂ´e dâ€™intermÂ´ediaritÂ´e demandent de considÂ´erer,
pour toutes paires de sommets du graphe, les plus courts chemins, avec
une complexitÂ´e O(n3). Les mÂ´ethodes globales ne peuvent Ë†etre appliquÂ´ees
`a de grands graphes, tout au plus, `a ceux de quelques milliers de nÅ“uds
et dâ€™arË†etes.

â€” les mÂ´ethodes locales sont des mÂ´ethodes dont le point de dÂ´epart est le
nÅ“ud et o`u il y a propagation dâ€™une information ou rÂ´ealisation dâ€™une
opÂ´eration. Il y a par exemple propagation de labels (LPA) ou fusion
dâ€™un nÅ“ud avec un des voisins (Louvain). Ces algorithmes ont la ca-
ractÂ´eristique dâ€™Ë†etre quasi-linÂ´eaires en termes dâ€™arË†ete. Ce qui leur adjoint
la possibilitÂ´e dâ€™Ë†etre appliquÂ´es `a de tr`es grands graphes de plusieurs mil-
lions de nÅ“uds et plusieurs centaines de millions dâ€™arË†etes. Cependant ces
algorithmes sont non dÂ´eterministes et hautement instables. Câ€™est-`a-dire
quâ€™il ne retournent jamais la mË†eme rÂ´eponse.

â€” les mÂ´ethodes hybrides sont des mÂ´ethodes locales auxquelles on associe
des mesures sociales ou un gain dâ€™information pour amÂ´eliorer le rÂ´esultat.
Par exemple, la mÂ´ethode de De Meo et al. (2013) utilise un graphe
pondÂ´erÂ´e dont les arË†etes ont Â´etÂ´e placÂ´ees suivant une certaine mesure fondÂ´ee
sur les distances entre nÅ“uds pour y appliquer la mÂ´ethode de Louvain.
Ces mÂ´ethodes donnent gÂ´enÂ´eralement de meilleurs rÂ´esultats en termes de
qualitÂ´e de partitionnement que les mÂ´ethodes originelles. Cependant, les
complexitÂ´es de ces algorithmes dÂ´ependent `a la fois de la complexitÂ´e des
mÂ´ethodes locales et de la complexitÂ´e des mesures sociales utilisÂ´ees. Ainsi,
si les mesures sociales ont une forte complexitÂ´e, lâ€™algorithme hybride ne
pourra pas Ë†etre appliquÂ´e sur un grand graphe.

Nous dÂ´ecidons dâ€™utiliser comme base de nos propositions algorithmiques la

1.3. D Â´ETECTION DE COMMUNAUT Â´ES DISJOINTES

57

propagation de labels. Elle prÂ´esente lâ€™avantage dâ€™avoir une complexitÂ´e assez
faible et permet de travailler sur de grands graphes. Elle a cependant certains
inconvÂ´enients comme :

â€” une mauvaise propagation qui peut mener `a de trop grandes commu-

nautÂ´es (le probl`eme des communautÂ´es gÂ´eantes).

â€” une instabilitÂ´e
â€” de mauvaises propagations qui peuvent donner des communautÂ´es ayant

le mË†eme label.

Ces inconvÂ´enients seront une partie des challenges que nous traË†Ä±terons dans

la partie algorithmique.

58

CHAPITRE 1. ETAT DE Lâ€™ART

1.4 DÂ´etection de communautÂ´es chevauchantes

La section prÂ´ecÂ´edente nous a permis dâ€™explorer les mÂ´ethodes pour la dÂ´etection
de communautÂ´es disjointes. Câ€™est-`a-dire le cas o`u chaque nÅ“ud ne peut appar-
tenir quâ€™`a une seule communautÂ´e. Cependant, dans de nombreux mod`eles, des
nÅ“uds peuvent appartenir `a plusieurs communautÂ´es, on parle alors de commu-
nautÂ´es chevauchantes. Par exemple, il existera des communautÂ´es chevauchantes
dans un rÂ´eseau de chercheurs o`u un auteur aura publiÂ´e dans diï¬€Â´erents domaines.
Lâ€™Â´etude de ces communautÂ´es permet dâ€™avoir une analyse plus ï¬ne du rÂ´eseau. Les
diï¬ƒcultÂ´es `a surmonter sont dâ€™une part la dÂ´eï¬nition dâ€™un nÅ“ud chevauchant, et
dâ€™autre part la mani`ere de maË†Ä±triser la complexitÂ´e algorithmique qui est plus
importante que dans le cas des mÂ´ethodes disjointes.

1.4.1 Formulation du probl`eme de dÂ´etection de commu-

nautÂ´es chevauchantes

Il est possible que certains nÅ“uds appartiennent `a plusieurs communautÂ´es.
Par exemple, certains nÅ“uds ont un nombre de liens identiques `a plusieurs com-
munautÂ´es. En considÂ´erant lâ€™exemple du club de karatÂ´e prÂ´esentÂ´e en introduction,
o`u une dispute entre le manager et lâ€™entraË†Ä±neur du club a scindÂ´e le club en
deux, crÂ´eant deux clubs de karatÂ´e dans une mË†eme rue, on peut voir que le nÅ“ud
montrÂ´e par une ï¬‚Ë†eche est la fois dans la communautÂ´e du manager et dans celle
de lâ€™entraineur. Il a Â´etÂ´e dÂ´eï¬ni comme chevauchant dans la littÂ´erature.

Figure 1.14 â€“ Le graphe de Zachary avec les deux communautÂ´es et le nÅ“ud chevauchant

Des Â´etudes menÂ´ees par Kelley (2009), Lancichinetti et al. (2009), Lee et al.
(2010), Reichardt et Bornholdt (2006), Gregory (2010), Wang et al. (2012) et
Sales-Pardo et al. (2007) ont montrÂ´e que le chevauchement est une caractÂ´eristique
des rÂ´eseaux sociaux.

En dÂ´etection de communautÂ´es chevauchantes, un ensemble de communautÂ´es
constituant un graphe, o`u plusieurs nÅ“uds peuvent appartenir `a plusieurs com-
munautÂ´es, se nomme une couverture (Lancichinetti et al. (2009)). Ainsi, la
dÂ´etection de communautÂ´es chevauchantes consiste `a trouver des groupes de
nÅ“uds fortement connectÂ´es entre eux et faiblement avec le reste du graphe, avec
des nÅ“uds pouvant appartenir `a plusieurs communautÂ´es. Plus formellement, il
sâ€™agit de trouver une couverture C = {C1, ..., Ck}, avec Ck (cid:54)= âˆ…, k nâ€™Â´etant pas `a
i=1Ci = V , en considÂ´erant un
spÂ´eciï¬er avec Ci

(cid:84) Cj (cid:54)= âˆ…, et âˆªk

(cid:84) Cj = âˆ… ou Ci

1.4. D Â´ETECTION DE COMMUNAUT Â´ES CHEVAUCHANTES

59

graphe G = (V, E).
De la dÂ´eï¬nition gÂ´enÂ´erale que nous venons de donner rÂ´esultent deux grandes
grandes catÂ´egories dâ€™algorithmes qui sont la dÂ´etection de communautÂ´es chevau-
chantes au sens ï¬‚ou et la dÂ´etection de communautÂ´es chevauchantes au sens de la
classiï¬cation multi-classe. La dÂ´etection de communautÂ´es chevauchantes au sens
ï¬‚ou porte sur lâ€™imprÂ´ecision de la classe dâ€™appartenance dâ€™un nÅ“ud. Dans cette
catÂ´egorie de probl`eme, on connaË†Ä±t dÂ´ej`a la classe dâ€™appartenance de la majoritÂ´e
des nÅ“uds vis-`a-vis de leurs communautÂ´es. Cependant, certains nÅ“uds situÂ´es `a
la fronti`ere intÂ´erieure (cf. glossaire 6.1) de diï¬€Â´erentes communautÂ´es portent une
imprÂ´ecision sur leurs degrÂ´es dâ€™appartenance quant `a ces derni`eres. La dÂ´etection
de communautÂ´es chevauchantes peut Ë†etre Â´egalement vue comme un probl`eme
de classiï¬cation multi-classe o`u pour tout nÅ“ud du graphe, il sâ€™agit dâ€™Â´etablir le
degrÂ´e dâ€™appartenance `a diï¬€Â´erentes communautÂ´es.

1.4.2 DÂ´etection de communautÂ´es chevauchantes `a base de

propagation de labels

Nous prÂ´esentons les principaux algorithmes pour la dÂ´etection de commu-

nautÂ´es chevauchantes `a base de propagations de labels.

La premi`ere mÂ´ethode connue ayant utilisÂ´e la propagation de labels fut pro-
posÂ´ee par Gregory (2010), `a savoir COPRA. Durant la phase de remplacement
du label dâ€™un nÅ“ud u par un autre, les auteurs proposent dâ€™utiliser un vecteur
pour maintenir les labels les plus communs avec lâ€™intervention dâ€™un seuil de pro-
babilitÂ´e. Le rÂ´esultat, grË†ace `a cette liste, est quâ€™un nÅ“ud peut appartenir `a une
ou plusieurs communautÂ´es. Bien que cette mÂ´ethode ait une complexitÂ´e linÂ´eaire
en termes dâ€™arË†etes, elle nÂ´ecessite de spÂ´eciï¬er le nombre de communautÂ´es (Î½) `a
laquelle pourrait appartenir un nÅ“ud. Cette mÂ´ethode est Â´egalement instable, ne
donnant que tr`es rarement la mË†eme partition dâ€™un lancement `a lâ€™autre. Lâ€™insta-
bilitÂ´e nÂ´ecessite de lancer plusieurs fois lâ€™algorithme avant dâ€™obtenir une solution
correcte en termes de qualitÂ´e. Cette mÂ´ethode est sujette aux mauvaises propa-
gations de labels, donnant des communautÂ´es gÂ´eantes. La Figure 1.15 donne un
exemple de rÂ´esultatde COPRA avec Î½ = 2.

Figure 1.15 â€“ Exemple dâ€™application de COPRA (extrait de Gregory (2010))

60

CHAPITRE 1. ETAT DE Lâ€™ART

SLPA pour â€Speakerlistener Label Propagation Algorithmâ€ (Xie et al. (2011))
est un algorithme fondÂ´e sur une mÂ´emoire de labels et sur la popularitÂ´e des labels
les plus inï¬‚uents au sein du graphe, câ€™est-`a-dire, des labels que lâ€™on retrouve le
plus souvent pour lâ€™identiï¬cation des communautÂ´es rÂ´esultantes du graphe. Le
changement de label dâ€™un nÅ“ud nâ€™est plus fonction du voisinage actuel, mais
dÂ´epend de la mÂ´emoire du nÅ“ud dont les labels voisins ont changÂ´e au cours
du temps. Initialement, on attribue `a chaque nÅ“ud une mÂ´emoire de labels. Il
sâ€™agit dâ€™un vecteur de taille k (si le nÅ“ud courant a k voisins) qui est origi-
nellement constituÂ´e des labels de ses nÅ“uds voisins. Deux types de nÅ“uds sont
dÂ´eï¬nis dans lâ€™algorithme SLPA, les speakers et listeners. Un nÅ“ud est alors
sÂ´electionnÂ´e alÂ´eatoirement comme speaker et propage son label pendant que les
autres observent la propagation, jusquâ€™`a stabilisation. Câ€™est alors quâ€™un autre
nÅ“ud du graphe est sÂ´electionnÂ´e pour jouer le rË†ole du speaker. Une fois le pro-
cessus de propagation terminÂ´e, on peut observer la force dâ€™appartenance quâ€™a
un nÅ“ud vis-`a-vis des diverses communautÂ´es via lâ€™inï¬‚uence des nÅ“uds dans les
diï¬€Â´erentes mÂ´emoires. A la ï¬n du processus, on regarde toutes les mÂ´emoires de
tous les nÅ“uds pour y voir les labels des communautÂ´es les plus frÂ´equentes. Pour
sÂ´electionner les labels les plus frÂ´equents, on utilise un seuil r âˆˆ [0, 1] qui per-
met de considÂ´erer les labels les plus inï¬‚uents (ceux les plus frÂ´equents dans la
mÂ´emoire). Il peut y a voir des labels ayant le mË†eme score dâ€™inï¬‚uence, permettant
ainsi le chevauchement. Les rÂ´esultats en termes de qualitÂ´e de partitionnement
sont encourageants, la majoritÂ´e des nÅ“uds chevauchants dans les graphes uti-
lisÂ´es dans leurs expÂ´erimentations sont dÂ´etectÂ´es comme pour le club de karatÂ´e,
le rÂ´eseau footballistique , le rÂ´eseau de livres scientiï¬ques, le rÂ´eseau de colla-
boration scientiï¬que et dâ€™autres graphes sociologiques. Cependant, lâ€™instabilitÂ´e
persiste avec la possibilitÂ´e quâ€™il y ait de mauvaises propagations, surtout si elles
ont lieu au dÂ´ebut de lâ€™algorithme et inï¬‚uent sur la suite du processus. On peut
Â´egalement se questionner sur la mÂ´ethode employÂ´ee, dans la mesure o`u les com-
munautÂ´es dÂ´etectÂ´ees lorsque quâ€™un speaker envoie son label sont disjointes. Ce
sont les structures communautaires qui empË†echent la propagation du label du
speaker de continuer, mais pas forcÂ´ement les nÅ“uds qui peuvent appartenir `a
plusieurs communautÂ´es. Le param`etre r a Â´egalement une inï¬‚uence forte sur le
pourcentage de nÅ“uds chevauchants. Lâ€™algorithme est Â´egalement assez long car
il nÂ´ecessite dâ€™obtenir la stabilisation, câ€™est-`a-dire que les communautÂ´es dÂ´etectÂ´ees
ne puissent plus Â´evoluer.

BMLPA pour â€balanced multi-label propagation algorithmâ€ (Wu et al. (2012))
est une amÂ´elioration de COPRA. Les auteurs proposent une stratÂ´egie de mise `a
jour, qui demande que les nÅ“uds ayant le mË†eme label aient un cÅ“ï¬ƒcient dâ€™appar-
tenance vis-`a-vis dâ€™autres communautÂ´es. Cela a pour consÂ´equence que certains
nÅ“uds puissent appartenir `a plusieurs communautÂ´es. Les auteurs proposent
Â´egalement de gÂ´enÂ´erer des â€cÅ“urs brutsâ€, qui sont utilisÂ´es pour lâ€™initialisation
des vecteurs pour la propagation de labels multiples. Cela permet dâ€™aller plus
vite et de stabiliser une partie du graphe lors de la propagation. Les rÂ´esultats en
termes de qualitÂ´e de partionnement sont encourageants et permettent de limi-

1.4. D Â´ETECTION DE COMMUNAUT Â´ES CHEVAUCHANTES

61

ter le nombre de mauvaises propagations (phÂ´enom`ene de communautÂ´es gÂ´eantes)
sans toutefois les faire disparaË†Ä±tre.

MLPA pour multi-label propagation algorithm (Dai et al. (2013)) utilise une
propagation de labels avec intensitÂ´e qui permet dâ€™attribuer une force aux labels
des nÅ“uds Â´emettants. Lâ€™idÂ´ee est que lorsquâ€™un nÅ“ud mettra `a jour son label,
il aura connaissance des labels des nÅ“uds voisins, et Â´egalement des zones sur
lesquelles ils se sont dÂ´ej`a propagÂ´es , qui sont en fait, les communautÂ´es en cours
de crÂ´eation. D`es lors, certaines propagations peuvent sâ€™arrË†eter si lâ€™intensitÂ´e du
label en question est trop forte ou au contraire Ë†etre mises en exergue si son
intensitÂ´e est trop faible. Lâ€™utilisation de lâ€™intensitÂ´e des nÅ“uds permet de diriger
la propagation de labels pour Â´eviter de mauvaises propagations (impossibilitÂ´e
de dÂ´etecter de trop petites commununautÂ´es). Cette mÂ´ethode a comme force de
donner de lâ€™information sur les structures topologiques qui se crÂ´eent au fur et
`a mesure du dÂ´eveloppement de lâ€™algorithme. Cependant, câ€™est une faiblesse, no-
tamment pour des graphes dont la densitÂ´e est Â´elevÂ´ee, o`u lâ€™intensitÂ´e devra Ë†etre
ajustÂ´ee pour continuer des propagations de labels non ï¬nies.

Les mÂ´ethodes prÂ´esentÂ´ees ci-dessus se fondent soit sur une modiï¬cation de
la propagation de labels en incluant un facteur dâ€™appartenance, soit sur une
multi-liste de propagations de labels. Cependant, cela ne rÂ´eduit pas lâ€™instabilitÂ´e
et des param`etres doivent Ë†etre Â´evaluÂ´es pour connaË†Ä±tre le pourcentage de nÅ“uds
chevauchants et le nombre de communautÂ´es auxquelles appartient un nÅ“ud.

1.4.3 Autres mÂ´ethodes pour la dÂ´etection de communautÂ´es

chevauchantes

Il existe dâ€™autres mÂ´ethodes pour la dÂ´etection de communautÂ´es chevauchantes,
fondÂ´ees sur la topologie du graphe et le nombre de connexions quâ€™un nÅ“ud a
vis-`a-vis des communautÂ´es avoisinantes.

Palla et al. (2005) ont crÂ´eÂ´e Cï¬nder, un algorithme pour la dÂ´etection de
communautÂ´es chevauchantes fondÂ´e sur la recherche de motifs locaux, par per-
colation de cliques (CPM : Clique Percolation Method). Les auteurs observent
quâ€™une communautÂ´e peut-Ë†etre dÂ´eï¬nie comme une chaË†Ä±ne de k-cliques adjacentes
(cf. glossaire 6.1). Cette mÂ´ethode permet la dÂ´etection de communautÂ´es cou-
vrantes o`u un sommet peut appartenir `a plusieurs k-cliques. Les rÂ´esultats en
termes de qualitÂ´e de partitionnement sont encourageants mais prÂ´esentent trois
inconvÂ´enients majeurs. Le premier est la nÂ´ecessitÂ´e de paramÂ´etrer k (câ€™est-`a-
dire la taille des cliques). Le second concerne la complexitÂ´e algorithmique. Il a
Â´etÂ´e dÂ´emontrÂ´e que la complexitÂ´e pour dÂ´etecter les 3-cliques (Berge (1958)) dâ€™un
graphe Â´etait en O(n1.41) (n Â´etant le nombre de sommets), mais ce nombre aug-
mente de mani`ere non linÂ´eaire en fonction du nombre de sommets. Le troisi`eme
inconvÂ´enient est la recherche de motifs statiques qui nâ€™est pas un trait absolu

62

CHAPITRE 1. ETAT DE Lâ€™ART

des rÂ´eseaux complexes (avec des nÅ“uds chevauchants des communautÂ´es de taille
et de topologie diï¬€Â´erentes). Les expÂ´erimentations menÂ´ees pas Palla et al. (2005)
ont montrÂ´e que la valeur k = 4 donnait les rÂ´esultats en termes de qualitÂ´e de
partitionnement les plus probants. Cette mÂ´ethode peut selon la paramÂ´etrisation
de k Ë†etre appliquÂ´ee `a des graphes de plusieurs centaines de milliers dâ€™arË†etes.
Nous donnons un exemple tirÂ´e du site de Gergely Palla `a la Figure 1.16 o`u les
nÅ“uds de couleur rouge appartiennent `a des communautÂ´es chevauchantes.

Figure 1.16 â€“ Exemple dâ€™application de la mÂ´ethode CFinder (Extrait du site de Palla
et al. (2005))

Zhang et al. (2007) proposent un algorithme spectral pour la dÂ´etection de
communautÂ´es chevauchantes. Le principe est de calculer un certain nombre de
vecteurs propres liÂ´es `a la matrice Laplacienne reprÂ´esentant le graphe, puis dâ€™ap-
pliquer sur cet espace propre un algorithme ï¬‚ou de clustering, le Fuzzy C means
(FCM) et de retranscrire les rÂ´esultats sur le graphe pour obtenir les recouvre-
ments. La mÂ´ethode nÂ´ecessite de spÂ´eciï¬er le nombre de recouvrements et nÂ´ecessite
le calcul des valeurs et des vecteurs propres. Les rÂ´esultats en termes de qualitÂ´e
sont encourageants. Lâ€™algorithme a une complexitÂ´e en O(n3 + ndc2i), avec d, le
nombre de dimensions, c le nombre de clusters et i le nombre dâ€™itÂ´erations.

Psorakis et al. (2011) proposent un mod`ele fondÂ´e sur la factorisation par
matrices non nÂ´egatives bayÂ´esiennes (NMF). Cet algorithme nÂ´ecessite de fournir
le nombre K de recouvrements et demande de tr`es nombreux calculs matriciels.
La complexitÂ´e de cet algorithme est en O(Kn2).

Shen et al. (2009) proposent EAGLE (agglomerativE hierarchicAl clusterinG
based on maximaL cliquE). EAGLE est une mÂ´ethode agglomÂ´erative fondÂ´ee sur
la dÂ´etection de cliques maximales (cf. Glossaire 6.1) et lâ€™optimisation locale dâ€™une
fonction de qualitÂ´e permettant lâ€™Â´elaboration dâ€™un dendrogramme. Lâ€™algorithme
op`ere en deux Â´etapes sur le graphe. Premi`erement, les cliques maximales sont
trouvÂ´ees pour former les premi`eres communautÂ´es. La seconde Â´etape consiste `a
fusionner les communautÂ´es ayant la plus grande similaritÂ´e. La fonction de simi-
laritÂ´e nâ€™est autre que la modularitÂ´e de Newman. Câ€™est sur le nÅ“ud o`u portera
la fusion quâ€™il y aura chevauchement. La coupe optimale est donnÂ´ee en utilisant
une version chevauchante de la modularitÂ´e de Newman, la modularitÂ´e de Shen
que nous dÂ´etaillerons dans la partie concernant les mesures non supervisÂ´ees pour

1.4. D Â´ETECTION DE COMMUNAUT Â´ES CHEVAUCHANTES

63

la dÂ´etection de communautÂ´es chevauchantes. EAGLE donne des rÂ´esultats satis-
faisants en termes de qualitÂ´e de recouvrement. Cependant, dans certains cas,
les nÅ“uds qui peuvent Ë†etre classÂ´es comme chevauchants et qui sont liÂ´es `a des
communautÂ´es faiblement denses ne sont pas dÂ´etectÂ´es. Cette mÂ´ethode peut soule-
ver certaines questions quant aux strutures communautaires chevauchantes. On
peut reprocher `a cet algorithme dâ€™Ë†etre `a la recherche de motifs plutË†ot que dâ€™Ë†etre
`a la recherche de nÅ“uds entre communautÂ´es. Des structures communautaires
peuvent exister sans Ë†etre des cliques. Lâ€™algorithme prÂ´esente Â´egalement une com-
plexitÂ´e assez Â´elevÂ´ee en O(n2 + s(h + n)) avec s le nombre de cliques maximales
et h le nombre de paires de cliques maximales qui sont voisines (partageant un
nÅ“ud en commun).

Lee et al. (2010) ont proposÂ´e GCE (Greedy Clique Expansion). Cet algo-
rithme est tr`es similaire `a EAGLE. Il identiï¬e dans un premier temps les cliques
comme des graines (leaders) au sein du graphe. Ces graines, qui sont des cÅ“urs
de communautÂ´es sâ€™agrandissent par optimisation dâ€™une fonction de qualitÂ´e lo-
cale. Les auteurs choisissent la fonction de ï¬tness de Lancichinetti et al. (2009),
out)Î± o`u Î± est un param`etre
`a savoir pour une communautÂ´e S, FS =
ajustable, kS
out (nombre dâ€™arË†etes ayant
une extrÂ´emitÂ´e hors de S). Cette mesure privilÂ´egie une expansion vers des nÅ“uds
maximisant les liens internes et minimisant les liens externes. Lorsque deux
structures communautaires veulent eï¬€ectuer une agglomÂ´eration sur un nÅ“ud
spÂ´eciï¬que, ce nÅ“ud est classÂ´e comme chevauchant. La complexitÂ´e de cet al-
gorithme est en O(mh) avec m, le nombre dâ€™arË†etes et h le nombre de cliques
maximales dÂ´etectÂ´ees initialement et considÂ´erÂ´ees comme graines. Les rÂ´esultats
expÂ´erimentaux montrent que la qualitÂ´e de recouvrement est lÂ´eg`erement meilleure
que celle dâ€™EAGLE, notamment sur les graphes artiï¬ciels LFR (cf. glossaire 6.1).

in (nombre dâ€™arË†etes internes dans S) et kS

kS
in
in+kS

(kS

Lancichinetti et al. (2011) ont proposÂ´e OSLOM (Order Statistics Local Opti-
mization Method). Il sâ€™agit dâ€™une mÂ´ethode de raï¬ƒnage agissant sur une partition
dÂ´ej`a fournie. OSLOM utilise les algorithmes de Louvain ou dâ€™Infomap pour crÂ´eer
une premi`ere partition. Câ€™est alors que la mÂ´ethode ajoute ou retire des nÅ“uds
pour arriver `a un Â´etat stable o`u il nâ€™est plus intÂ´eressant de modiï¬er la structure
topologique des communautÂ´es. Le principe consiste `a comparer les structures
communautaires entre le mod`ele nul (cf. glossaire 6.1) et la partition rÂ´eelle en se
fondant sur le nombre de liens dans les communautÂ´es et sur le degrÂ´e du nÅ“ud
Â´etudiÂ´e. Si le nÅ“ud Â´etudiÂ´e a plus de connexions vis-`a-vis dâ€™une communautÂ´e que
la valeur moyenne issue du mod`ele nul, ce nÅ“ud sera ajoutÂ´e `a cette communautÂ´e.
Il sera retirÂ´e dans le cas contraire. Le processus se rÂ´ep`ete sur tous les nÅ“uds
du graphe en eï¬€ectuant des modiï¬cations sur la partition originelle si certains
groupes de nÅ“uds nâ€™ont pas la caractÂ´eristique de structures communautaires.
Lâ€™algorithme est non dÂ´eterministe car il dÂ´epend de lâ€™ordre de visite selon lequel
est appliquÂ´ee cette mÂ´ethode.

Lâ€™algorithme comporte quatre param`etres dont un seuil de probabilitÂ´e `a

64

CHAPITRE 1. ETAT DE Lâ€™ART

donner. Lâ€™algorithme est assez lent et est fonction du nombre de nÅ“uds. Il peut
nÂ´ecessiter plusieurs journÂ´ees notamment sur de grands graphes comme Live-
Journal. La paramÂ´etrisation standard donne cependant des rÂ´esultats corrects
en termes de qualitÂ´e pour les communautÂ´es rÂ´esultantes.

1.4.4 Tableau rÂ´ecapitulatif des mÂ´ethodes chevauchantes

Lâ€™Â´etat de lâ€™art concernant la dÂ´etection de communautÂ´es chevauchantes a

montrÂ´e lâ€™existence de tr`es nombreuses mÂ´ethodes. Nous rÂ´ecapitulons les
caractÂ´eristiques concernant leur complexitÂ´e et la taille des rÂ´eseaux sur lesquels
ces solutions peuvent Ë†etre appliquÂ´ees dans la mesure o`u nous souhaitons traË†Ä±ter
de grands graphes de plusieurs millions dâ€™arË†etes.

Algorithmes
LPA
COPRA
SLPA
BLMPA
MLPA
EAGLE
NMF
FCM
OSLOM
CFINDER

articles

dendrogramme

Gregory (2010)
Xie et al. (2011)
Wu et al. (2012)
Dai et al. (2013)
Shen et al. (2009)

Psorakis et al. (2011)
Zhang et al. (2007)

Lancichinetti et al. (2011)

Adamcsek et al. (2006)

non
non
non
non
non
non
non
non
non

O(2n + n2m)

complexitÂ´e
(ordre)
O(kmn)
O(kmn)
O(kmn)
O(Kn2)

O(n2 + (h + n)s)
O(n3 + ndc2i)

â€*â€
O(en)

parallÂ´elisÂ´e

non
non
non
non
non
non
non
non
non

Tableau 1.4 â€“ Ordre de complexitÂ´e des algorithmes chevauchants. Le signe â€*â€ signiï¬e
que la complexitÂ´e est diï¬ƒcile `a Â´etablir. n : nombre de sommets, m : nombre dâ€™arË†etes,
k : paramË†etre (entier), i : nombre dâ€™itÂ´erations, d : le nombre de dimensions de lâ€™espace
propre et c : le nombre de clusters

La comparaison des ï¬gures 1.17 et 1.9 permet dâ€™aï¬ƒrmer que les mÂ´ethodes

chevauchantes ont une complexitÂ´e plus Â´elevÂ´ee que les mÂ´ethodes disjointes.

Dâ€™apr`es nos expÂ´erimentations et la taille des graphes sur lesquels ont Â´etÂ´e
appliquÂ´es les algorithmes de la ï¬gure 1.17, nous pouvons constater que certains
algorithmes peuvent Ë†etre appliquÂ´es sur des graphes dâ€™assez grandes tailles alors
que ce nâ€™est pas le cas pour dâ€™autres. Par exemple, OSLOM peut-Ë†etre appliquÂ´e
sur une machine `a des graphes de plus 18 millions de sommets et 300 millions
dâ€™arË†etes (il sâ€™agit du rÂ´eseau web du Royaume-Uni (SNAP)) alors les autres ne
peuvent pas le traË†Ä±ter. Dâ€™apr`es nos expÂ´erimentations et en considÂ´erant comme
crit`ere lâ€™erreur mÂ´emoire, lâ€™algorithme permettant de traË†Ä±ter les plus grands
graphes est OSLOM. Les mÂ´ethodes ne permettent pas de traiter les graphes
de plus de 10 millions dâ€™arË†etes.

1.4. D Â´ETECTION DE COMMUNAUT Â´ES CHEVAUCHANTES

65

Figure 1.17 â€“ MÂ´ethodes pour la dÂ´etection de communautÂ´es chevauchantes. Lâ€™axe des
abscisses reprÂ´esente la taille des graphes, lâ€™axe des ordonnÂ´ees, la complexitÂ´e.

1.4.5 Mesures supervisÂ´ees et non supervisÂ´ees pour la dÂ´etection

de communautÂ´es chevauchantes

Certaines mesures supervisÂ´ees et non supervisÂ´ees dans le cas de la dÂ´etection
de communautÂ´es disjointes ont Â´etÂ´e retranscrites pour le cas du chevauchement.
Nous nous proposons dâ€™exposer les mesures les plus utilisÂ´ees dans la littÂ´erature
ainsi que leurs spÂ´eciï¬citÂ´es. A la ï¬n de cette section, nous prÂ´esenterons un ta-
bleau rÂ´ecapitulatif des mesures.

Mesures supervisÂ´ees pour la dÂ´etection de communautÂ´es chevauchantes

Lâ€™information mutuelle normalisÂ´ee pour le chevauchement fut pro-
posÂ´ee par Lancichinetti et al. (2009) . ConsidÂ´erons deux couvertures A et B de
V . La probabilitÂ´e de tirer un Â´elÂ´ement et quâ€™il appartienne `a une partie de la
partition (A âˆˆ A) est nA
n , o`u nA est le nombre dâ€™Â´elÂ´ements dans A. Lâ€™entropie
de Shanon de la partition A est ainsi dÂ´eï¬nie par :

H(A) = âˆ’(cid:88)

AâˆˆA

nA
n

log2

nA
n

(1.23)

Lancichinetti et al. (2009) ont proposÂ´e une version du NMI pour la comparaison
de couvertures A et B comme Â´etant :
N M ILF K = 1 âˆ’ 1
2

H(A|B)

H(A|B)

(

A

(1.24)

+

B

)

66

CHAPITRE 1. ETAT DE Lâ€™ART

avec H(A|B) Â´etant lâ€™entropie conditionnelle. Cette quantitÂ´e mesure lâ€™entropie
restante provenant de la couverture B, si lâ€™on connait parfaitement la seconde
couverture A. H(A|B) = 0 si et seulement si la couverture B est compl`etement
dÂ´eterminÂ´ee par la couverture A. La valeur de N M ILF K est comprisentre 0 et
1. Plus cette valeur est proche de 1, plus les deux convertures sont identiques.

McDaid et al. (2011) ont proposÂ´e une extension au NMI de Lancichinetti et
al. avec lâ€™intervention dâ€™une pÂ´enalitÂ´e si les deux couvertures sont trop diï¬€Â´erentes.
Les rÂ´esultats des deux mesures sont Â´equivalents.

Lâ€™indice dâ€™Omega (Collins et Dent (1988)) est fondÂ´ee sur des paires de

nÅ“uds qui sont dans les mË†emes communautÂ´es selon les deux couvertures.

ConsidÂ´erons deux couvertures P1 et P2, lâ€™indice dâ€™omega est dÂ´eï¬ni de la

mani`ere suivante :

â„¦(P1, P2) =

ou(P1, P2) âˆ’ oe(P1, P2)

1 âˆ’ oe(P1, P2)

(1.25)

(cid:80)
o`u ou(P1, P2) reprÂ´esente la fraction de paires de nÅ“uds qui apparaissent en-
semble dans les mË†emes communautÂ´es `a la fois dans P1 et P2.
j |tj(P1) âˆ© tj(P2)| o`u tj(P ) est lâ€™ensemble des paires de
ou(P1, P2) =
nÅ“uds qui apparaissent dans exactement j communautÂ´es dans la couverture P .
Le nombre de paires de nÅ“uds est Â´egale `a n(nâˆ’1)
. Le terme oe(P1, P2) est la
valeur espÂ´erÂ´ee de cette fraction dans le mod`ele nul.

n(nâˆ’1)

2

oe(P1, P2) =

4

n2(n âˆ’ 1)2

|tj(P1)||tj(P2)|

(1.26)

2

(cid:88)

j

Lâ€™indice dâ€™Omega prend sa valeur entre 0 et 1. Une valeur proche de 1 signiï¬e
que les deux couvertures sont identiques. Dans la partie expÂ´erimentale, nous
utiliserons la notation â„¦ pour signaler lâ€™indice dâ€™Omega.

Le F1-score pour le chevauchement se dÂ´eï¬nit de la mË†eme mani`ere que pour

le cas disjoint, `a savoir :

F1 =

2 Ã— prÂ´ecision Ã— rappel
prÂ´ecision + rappel

(1.27)

o`u le rappel est le nombre de bons nÅ“uds chevauchants dÂ´etectÂ´es divisÂ´e par le
vÂ´eritable nombre de nÅ“uds chevauchants. La prÂ´ecision est le nombre de bons
nÅ“uds chevauchants dÂ´etectÂ´es divisÂ´e par le nombre total de nÅ“uds chevauchants
dÂ´etectÂ´es. Le F1-score est un bon compromis entre la qualitÂ´e de nÅ“uds che-
vauchants bien dÂ´etectÂ´es et la qualitÂ´e de ces dÂ´etections. Elle atteint sa valeur
maximale `a 1 et sa plus basse `a 0.

1.4. D Â´ETECTION DE COMMUNAUT Â´ES CHEVAUCHANTES

67

Mesures non supervisÂ´ees pour la dÂ´etection de communautÂ´es chevau-
chantes

Plusieurs extensions de la modularitÂ´e ont Â´etÂ´e proposÂ´ees pour le cas du che-
vauchement. Nous proposons de les exposer en les dÂ´etaillant. Elles se basent
toutes sur un cÅ“ï¬ƒcient dâ€™appartenance entre un nÅ“ud i et une communautÂ´e
c, que lâ€™on note ai,c. On consid`ere par la suite une couverture de communautÂ´es
chevauchantes C = {c1, ..., c|C|} et un vecteur dâ€™appartenance pour un nÅ“ud i `a
chacune des communautÂ´es (ai,c1, ..., ai,c|C|). Le cÅ“ï¬ƒcient dâ€™appartenance dâ€™un
nÅ“ud i est rÂ´egi par deux contraintes qui sont 0 â‰¤ ai,c â‰¤ 1,âˆ€i âˆˆ V,âˆ€c âˆˆ C et par

(cid:80)

câˆˆC ai,c = 1.

Zhang et al. (2007) ont proposÂ´e une extension de la modularitÂ´e qui utilise
la moyenne du cÅ“ï¬ƒcient dâ€™appartenance entre deux nÅ“uds pour mesurer la
qualitÂ´e des structures communautaires chevauchantes :
c | + |Eout
2|E|

|Ein
c |
|E| âˆ’ (

(cid:88)

2|Ein

Ov =

(1.28)

QZ

)2

|

c

câˆˆC

(cid:80)

2

2

i,jâˆˆc

ai,c+aj,c

c | = 1

avec |Ein

Aij, |Eout

Aij et |E| =
1
i,j Aij. La mÂ´ethode proposÂ´ee par Zhang pÂ´enalise les structures dÂ´etectÂ´ees
2
ayant un nombre de liens trop fort en dehors de ces derni`eres. Les rÂ´esultats
en termes de qualitÂ´e pour des graphes dont les communautÂ´es prÂ´esentent des
densitÂ´es Â´equivalentes sont bons, mais la qualitÂ´e se dÂ´etÂ´eriore si les structures
communautaires sont trop diï¬€Â´erentes.

ai,c+(1âˆ’aj,c)

iâˆˆc,j(cid:54)âˆˆc

2

c

(cid:80)

| = (cid:80)

leur vecteur dâ€™appartenance notÂ´e sij =(cid:80)

Nepusz et al. (2008) ont considÂ´erÂ´e le cÅ“ï¬ƒcient dâ€™appartenance ai,c comme
la probabilitÂ´e quâ€™un nÅ“ud i soit dans la communautÂ´e c. Ainsi, la probabilitÂ´e que
le nÅ“ud i appartienne `a la mË†eme communautÂ´e que j est le produit scalaire de
câˆˆC ai,caj,c. Les auteurs ont Â´egalement
considÂ´erÂ´e sij comme une mesure de similaritÂ´e entre les nÅ“uds i et j. Ainsi, en
remplaÂ¸cant le symbole de Kronecker dans la formule gÂ´enÂ´erale de la modularitÂ´e,
les auteurs dÂ´eï¬nissent leur modularitÂ´e comme Â´etant :

(cid:88)

i,j

QN ep

Ov =

1
2|E|

[Aij âˆ’ kikj

2|E| ]sij

(1.29)

La formule est sujette au degrÂ´e des nÅ“uds chevauchants. Câ€™est-`a-dire que si la
distribution des degrÂ´es des nÅ“uds ne suit pas une loi uniforme, la mesure aura
plus de diï¬ƒcultÂ´e a dÂ´etecter les nÅ“uds chevauchants. Les rÂ´esultats en termes de
qualitÂ´e sur les graphes rÂ´eels sont cependant encourageants.

Nicosia et al. (2009) ont fait une extension `a la modularitÂ´e pour le cas du
chevauchement entre communautÂ´es. Les auteurs la dÂ´eï¬nissent de la mani`ere

68

suivante :

(cid:88)

(cid:88)

i,jâˆˆV

c

QN i

Ov =

1
m

CHAPITRE 1. ETAT DE Lâ€™ART

[Î²ij,cAij âˆ’ Î²out

ij,cÎ²in
ij,c

kout
i kin
j
m

]

(1.30)

i

et kin
i

o`u Î²ij,c est le cÅ“ï¬ƒcient dâ€™appartenance du lien ij `a la communautÂ´e c, Î²out
ij,c est
le cÅ“ï¬ƒcient dâ€™appartenance espÂ´erÂ´e de tous les liens possibles ij du nÅ“ud i au
nÅ“ud j `a lâ€™intÂ´erieur de la communautÂ´e c et Î²in
ij,c est le cÅ“ï¬ƒcient dâ€™apparte-
nance de nâ€™importe quel lien ij pointant vers un nÅ“ud j dans la communautÂ´e
c. Les termes kout
sont respectivement le degrÂ´e sortant et entrant du
nÅ“ud i. Il est `a noter que Î²ij,c est une fonction de la forme Î²ij,c = F (ai,c, aj,c)
avec ai,c cÅ“ï¬ƒcient dâ€™appartenance du nÅ“ud i par rapport `a la communautÂ´e
o`u f (ai,c) est une fonction linÂ´eaire
c. F (ai,c, aj,c) =
Â´echelonnable du type f (x) = 2px âˆ’ p, p âˆˆ R. Les auteurs ont proposÂ´e dâ€™uti-
liser la fonction f (x) = 60x âˆ’ 30 pour le paramÂ´etrage de la modularitÂ´e che-
vauchante car elle donnait des rÂ´esultats tr`es encourageants. Il sâ€™agit Â´egalement
de la paramÂ´etrisation standard dans la littÂ´erature et que nous utiliserons pour
nos expÂ´erimentations. La valeur de la modularitÂ´e de Nicosia varie entre 0 et
1. Une valeur proche de 0 implique que lâ€™algorithme nâ€™a dÂ´etectÂ´e quâ€™une seule
communautÂ´e (le graphe en lui mË†eme) alors quâ€™une valeur proche de 1 signiï¬e la
prÂ´esence de structures communautaires possiblement chevauchantes.

âˆ’f (ai,c ))(1+e

âˆ’f (aj,c))

(1+e

1

Shen et al. (2009) ont proposÂ´e une modularitÂ´e avec un cÅ“ï¬ƒcient dâ€™appar-
tenance comme Â´etant lâ€™inverse du nombre de communautÂ´es auxquelles pourrait
appartenir un nÅ“ud, ai,c = 1
o`u Oi est le nombre de communautÂ´es contenant
Oi
le nÅ“ud i. La version quâ€™ont proposÂ´ee les auteurs donne la formule :

(cid:88)

câˆˆC

(cid:88)

[
(
i,jâˆˆc

QShen1

ov

=

1
2|E|

kikj
|E| )]

1

OiOj

(1.31)

(cid:80)

mum dans un rÂ´eseau contenant lâ€™arË†ete (i, k) et ai =(cid:80)

Les rÂ´esultats sont encourageants mais peuvent Ë†etre mauvais si le nombre de
communautÂ´es auxquelles appartient un nÅ“ud par rapport `a un autre est trop
important. Ainsi, certains bons chevauchements risquent de ne pas Ë†etre dÂ´etectÂ´es.
Par la suite, les mË†emes auteurs ont proposÂ´e une nouvelle modularitÂ´e pour le
chevauchement en se fondant sur la prÂ´esence de sous-graphes complets, un
nombre Â´elevÂ´e de cliques et par une modiï¬cation du cÅ“ï¬ƒcient dâ€™appartenance
dâ€™un nÅ“ud aux communautÂ´es auxquelles il pourrait appartenir. Le cÅ“ï¬ƒcient
devient ai,c = 1
Aik o`u Mik reprÂ´esente le nombre de cliques maxi-
ai
Aik, avec
M c
ik reprÂ´esentant le nombre de cliques maximum dans la communautÂ´e c conte-
nant lâ€™arË†ete (i, k). Cette derni`ere formule donne en termes de qualitÂ´e de par-
titionnement pour le chevauchement de meilleurs rÂ´esultats que celle prÂ´esentÂ´ee
auparavant. Sa valeur varie entre 0 et 1, et est sensÂ´ee Ë†etre la meilleure rÂ´eponse
pour une valeur proche de 1. Elle prÂ´esente comme avantage quâ€™un nÅ“ud peut
appartenir `a des communautÂ´es de tailles diï¬€Â´erentes.

(cid:80)

M c
ik
Mik

M c
ik
Mik

câˆˆC

kâˆˆc

kâˆˆc

1.4. D Â´ETECTION DE COMMUNAUT Â´ES CHEVAUCHANTES

69

(cid:88)

Chen et al. (2013) ont proposÂ´e la densitÂ´e de modularitÂ´e dont lâ€™objectif est
de favoriser les petites structures communautaires pour contourner le probl`eme
de rÂ´esolution de limite, câ€™est-`a-dire que si il existe des communautÂ´es de tailles
diï¬€Â´erentes `a lâ€™intÂ´erieur dâ€™un mË†eme graphe, certaines communautÂ´es, mË†eme bien
dÂ´eï¬nies, pourront ne pas Ë†etre distinguÂ´ees dans la partition de modularitÂ´e op-
timale. Pour ce faire, les auteurs font intervenir une pÂ´enalitÂ´e de coupe qui est
simplement la fraction dâ€™arË†etes qui connecte les nÅ“uds `a dâ€™autres communautÂ´es.
La densitÂ´e de modularitÂ´e est dÂ´eï¬nie par :
c | + |Ein
c |
2|E|

câˆˆC
|Ein
c,c(cid:48)|
avec dc = 2|Ein
c |
|c|(|c(cid:48)|) . Les rÂ´esultats en termes de qualitÂ´e sont
bons sur des rÂ´eseaux rÂ´eels mais prÂ´esentent un inconvÂ´enient notamment pour
les graphes faiblement denses. Cela est dâ€™autant plus vrai que le nombre de
communautÂ´es avec une forte densitÂ´e sera important. En 2015, les mË†emes auteurs
(Chen et al. (2015)) ont amÂ´eliorÂ´e leur mÂ´ethode en y incluant le nombre de liens
sortant des structures communautaires dÂ´etectÂ´ees.

dc)2 âˆ’ (cid:88)

c |
|Ein
|E| dc âˆ’ (

|Ec,c(cid:48)|
2|E| dc,c(cid:48)]

|c|(|c|âˆ’1) et dc,c(cid:48) =

c(cid:48)âˆˆC,c(cid:48)(cid:54)=c

2|Ein

QChen1

(1.32)

ds

=

[

dc)2 âˆ’ (cid:88)
(cid:80)
iâˆˆc,jâˆˆc(cid:48) f (ai,c,aj,c(cid:48) ) . |Ein

c |
c | + |Ein
2|E|
(cid:80)
c | =
c(cid:48)âˆˆc,c(cid:48)(cid:54)=c,jâˆˆc(cid:48) f (ai,c, aj,c(cid:48))Aij, |Ec,c(cid:48)| =

|Ec,c(cid:48)|
2|E| dc,c(cid:48)]

c(cid:48)âˆˆC,c(cid:48)(cid:54)=c

|Ein
c,c(cid:48)|

(1.33)

(cid:80)
(cid:80)
(cid:80)
i,jâˆˆc,jâˆˆc(cid:48) f (ai,c,aj,c) et dc,c(cid:48) =
i,jâˆˆc f (ai,c, aj,c)Aij ,|Eout
iâˆˆc,jâˆˆc(cid:48) Aij et|E| le nombre dâ€™arË†etes du graphe.

avec dorÂ´enavant dc =
1
2

| =(cid:80)

2|Ein
c |

iâˆˆc

c

QChen2

ds

=

c |
|Ein
|E| dc âˆ’ (

[

2|Ein

(cid:88)

câˆˆC

La fonction f (ai,c, aj,c(cid:48)) peut Ë†etre le produit ou la moyenne des vecteurs ai,c et
aj,c. Sa valeur varie entre 0 et 1, et donne la meilleure rÂ´eponse pour une valeur
proche de 1. Les rÂ´esultats sont meilleurs que pour leur premi`ere version mais
la formule proposÂ´ee reste fondÂ´ee sur une moyenne dâ€™appartenance. Câ€™est-`a-dire
que si un nÅ“ud est susceptible dâ€™appartenir `a plusieurs communautÂ´es, il aura
plus de chance de considÂ´erer les communautÂ´es avec lesquelles il aura beaucoup
de liens, ce qui peut Ë†etre problÂ´ematique pour les rÂ´eseaux complexes, avec des
tailles de communautÂ´es diï¬€Â´erentes.

RÂ´ecapitulatif des mesures supervisÂ´ees et non supervisÂ´ees

Nous proposons un tableau rÂ´ecapitulatif de toutes les mesures citÂ´ees prÂ´ecÂ´edemment

avec leurs informations relatives en prenant comme source dâ€™information les ar-
ticles en question. Le tableau 1.5 nous montre lâ€™existence de tr`es nombreuses
mesures. Il y en a dâ€™ailleurs dâ€™autres.

Cependant, dans la littÂ´erature de la dÂ´etection de communautÂ´es, les mesures

les plus utilisÂ´ees sont :

70

CHAPITRE 1. ETAT DE Lâ€™ART

Mesures supervisÂ´ees (cas du chevauchement)

Mesures
Omega

rÂ´efÂ´erence

(Collins et Dent, 1988)

NMI

(Lancichinetti et al., 2009)

F1-score

(Yang et Leskovec, 2013)

Information et caractÂ´eristique

comptages sur les paires

disjointes et chevauchantes
dâ€™objets pareillement classÂ´es

quantitÂ´e mesurant la dÂ´ependance
statistique entre deux couvertures.
combine la prÂ´ecision et le rappel

avec leur moyenne harmonique (cf. glossaire 6.1)

en tenant compte des chevauchements.

Mesures non supervisÂ´ees (cas du chevauchement)
rÂ´efÂ´erence

Information et caractÂ´eristique

(Nicosia et al., 2009)

maximise la densitÂ´e des

communautÂ´es `a travers le mod`ele nul

Shen et al. (2009)
(Chen et al., 2013)
(Nepusz et al., 2008)

Mesures
QN icosia

QShen
QChen
QN epusz

Tableau 1.5 â€“ Classiï¬cation des mesures supervisÂ´ees et non supervisÂ´ees pour la
dÂ´etection de communautÂ´es

â€” la modularitÂ´e pour le chevauchement ((Nicosia et al., 2009))
â€” le F1-score pour le chevauchement
â€” le NMI pour le chevauchement
â€” lâ€™indice dâ€™omega
Ce sont les mesures que nous utiliserons car elles mettent en Å“uvre les prin-
cipales caractÂ´eristiques des communautÂ´es, `a savoir la densitÂ´e, le nombre de liens
sortants et la comparaison entre structures dÂ´etectÂ´ees avec un graphe alÂ´eatoire.

1.4.6 Synth`ese et discussion

Cette section a permis de donner notre formulation du probl`eme de dÂ´etection
de communautÂ´es chevauchantes, dâ€™analyser les mÂ´ethodes existantes et de voir
les mesures de qualitÂ´e qui y sont associÂ´ees. Dans la mesure o`u nous souhai-
tons crÂ´eer une mÂ´ethode de chevauchement stable (câ€™est-`a-dire donnant quasi-
systÂ´ematiquement les mË†emes rÂ´esultats) et destinÂ´ee `a des graphes de grandes
tailles, nous portons notre synth`ese sur la complexitÂ´e, le degrÂ´e de paramÂ´etrage
de ces mÂ´ethodes et la stabilitÂ´e.

Les mÂ´ethodes chevauchantes prÂ´esentent des complexitÂ´es plus Â´elevÂ´ees que
les mÂ´ethodes disjointes. Cela sâ€™explique du fait quâ€™une partie des algorithmes
chevauchants repose sur le fait de lancer plusieurs fois un algorithme disjoint
et dâ€™observer pour un nÅ“ud les communautÂ´es auxquelles il appartient le plus
(comme COPRA). Malheureusement, ces algorithmes demandent un espace de
stockage assez fort, dÂ´epassant les capacitÂ´es dâ€™une seule machine.

1.4. D Â´ETECTION DE COMMUNAUT Â´ES CHEVAUCHANTES

71

Les mÂ´ethodes chevauchantes prÂ´esentent Â´egalement un degrÂ´e de paramÂ´etrage
plus Â´elevÂ´e. Pour les algorithmes robustes `a base de mÂ´ethodes disjointes, cela
exige de connaË†Ä±tre le nombre dâ€™algorithmes `a lancer en parall`ele. De nombreux
algorithmes nÂ´ecessitent Â´egalement de donner un nombre de communautÂ´es aux-
quelles un nÅ“ud pourrait appartenir, ce qui nÂ´ecessite des Â´etudes prÂ´ealables.

La plupart des algorithmes de dÂ´etection de communautÂ´es chevauchantes sont
instables. Cela est dË†u en partie `a ce que beaucoup dâ€™algorithmes reposent sur
des algorithmes non dÂ´eterministes disjoints.

Cependant, les mÂ´ethodes par propagation de labels ont Â´etÂ´e lâ€™objet de nom-
breuses Â´etudes et constituent, pour lâ€™Â´etude des grands graphes, lâ€™option `a pri-
vilÂ´egier.

72

CHAPITRE 1. ETAT DE Lâ€™ART

Chapitre 2

ParallÂ´elisme et distribution

Ce chapitre dÂ´ecrit dans un premier temps les principaux outils pour la pro-
grammation et la gestion de graphes dans un domaine parall`ele et distribuÂ´e.
Dans un second temps, les algorithmes pour la dÂ´etection de communautÂ´es dans
un environnement parall`ele et distribuÂ´e sont prÂ´esentÂ´es. Nous donnerons `a la ï¬n
de ce chapitre un tableau rÂ´ecapitulatif des mÂ´ethodes de dÂ´etection de commu-
nautÂ´es dans le domaine parall`ele et distribuÂ´e et nous discuterons lâ€™axe `a choisir
pour nos objectifs de recherche.

2.1 ProblÂ´ematique de la dÂ´etection de commu-

nautÂ´es dans de grands graphes

Notre sociÂ´etÂ´e moderne produit un nombre de donnÂ´ees de plus en plus impor-
tant. Des annÂ´ees 1970 avec le â€minitelâ€ dont les mÂ´emoires moyennes Â´etaient de
lâ€™ordre de 8,25 Ko (exemple du minitel 1 bistandard Alcatel/Telic.) au datacen-
ter (417 600 serveurs `a Douglas County, 204 160 serveurs `a Dallas ou 241 280 ser-
veurs `a Council Bluï¬€s dâ€™apr`es le site â€http ://www.artiï¬cialbrains.com/google/
datacentersâ€) de nos jours qui peut stocker plusieurs centaines de milliers de te-
raoctets et consomme en moyenne 103 MW (selon le journal â€The Guardianâ€),
soit autant que la ville anglaise de Newcastle, le monde a connu une Â´evolution
en informatique sans prÂ´ecÂ´edent. Les ensembles de donnÂ´ees devenant de plus en
plus volumineux, il est diï¬ƒcile de travailler avec des outils classiques de gestion
de bases de donnÂ´ees ou de gestion de lâ€™information. Cela nous am`ene `a la notion
de donnÂ´ees massives.

Aucune dÂ´eï¬nition prÂ´ecise ou universelle ne peut Ë†etre donnÂ´ee du Big Data.
Il sâ€™agit dâ€™un concept de stockage dâ€™un nombre tr`es important dâ€™informations
sur une base numÂ´erique, utilisant plusieurs machines qui forment un cluster,
et les algorithmes peuvent Ë†etre utilisÂ´es de mani`ere parall`ele et distribuÂ´ee. La
gestion des donnÂ´ees massives marque une rupture dans lâ€™Â´evolution des syst`emes

73

74

CHAPITRE 2. PARALL Â´ELISME ET DISTRIBUTION

dâ€™information et rÂ´epond `a une quintuple exigence, on parle de la r`egle des â€5Vâ€ :
â€” grand V olume de donnÂ´ees (qui ne peut gÂ´enÂ´eralement Ë†etre stockÂ´e sur une

seule machine)

â€” importante V ariÂ´etÂ´e de ces mË†emes donnÂ´ees.
â€” V itesse de traitement avoisinant le temps rÂ´eel.
â€” V Â´eracitÂ´e : La vÂ´eracitÂ´e ou ï¬abilitÂ´e des donnÂ´ees (sâ€™assurer que les donnÂ´ees

soient rÂ´eelles et non faussÂ´ees).

â€” V aleur : Dans un contexte de surcharge informationnelle, il sâ€™agit de

sÂ´electionner lâ€™information pertinente pour lâ€™obtention dâ€™un meilleur rÂ´esultat.

Lâ€™analyse de grands graphes est un exemple de problÂ´ematique. Par exemple,
la librairie igraph en python, permettant lâ€™analyse de graphes, ne peut charger
un graphe dont la capacitÂ´e de ï¬chier reprÂ´esentant les arË†etes exc`ede 60 Mo. Cela
pose un probl`eme majeur dans la mesure o`u de plus en plus de graphes ont des
tailles de ï¬chier tr`es importantes. Ainsi, les graphes reprÂ´esentant Twitter, Fa-
cebook, You Tube ou encore Amazon ne peuvent Ë†etre Â´etudiÂ´es. Une autre limite
concerne le cË†otÂ´e algorithmique de lâ€™analyse des grands graphes. Certains algo-
rithmes ont une complexitÂ´e bien trop grande pour pouvoir donner une rÂ´eponse en
un temps acceptable. Câ€™est ainsi que naË†Ä±t le besoin de distribuer et de rÂ´epartir
les donnÂ´ees sur plusieurs machines pour y appliquer un algorithme parall`ele,
donnant une rÂ´eponse en un temps acceptable. Câ€™est pourquoi depuis ces trente
derni`eres annÂ´ees des plateformes sont apparues permettant le dÂ´eveloppement de
mani`ere parall`ele et distribuÂ´ee.

2.2 Plateformes parall`eles et distribuÂ´ees

Pour traiter de grandes quantitÂ´es de donnÂ´ees, des outils permettant la pa-
rallÂ´elisation dâ€™algorithmes et la distribution des donnÂ´ees ont Â´etÂ´e proposÂ´es. Nous
prÂ´esenterons dans un premier temps les principales plateformes parall`eles et dis-
tribuÂ´ees. Nous focaliserons notre Â´etude sur les derni`eres technologies Hadoop et
Spark pour leur eï¬ƒcacitÂ´e `a traË†Ä±ter de grandes volumÂ´etries de donnÂ´ees. Nous
prÂ´esenterons Â´egalement des plateformes exclusivement destinÂ´ees aux graphes.

2.2.1 Hadoop

Apache Hadoop, est un logiciel open source, dÂ´eveloppÂ´e sous lâ€™Â´egide de la fon-
dation Apache depuis 2005, dont la version 1.0 a vu le jour en 2011. Elle consiste
en deux grandes composantes autour desquelles sâ€™agr`egent dâ€™autres fonctionna-
litÂ´es. La premi`ere grande composante est le framework 1 MapReduce (Dean et
Ghemawat (2008)), la seconde est le HDFS (pour Hadoop Distributed File Sys-
tem).

1. un framework ou structure logicielle est un ensemble de composants logiciels, qui sert `a

crÂ´eer les fondations de tout ou dâ€™une partie dâ€™un logiciel.

2.2. PLATEFORMES PARALL `ELES ET DISTRIBU Â´EES

75

MapReduce est un patron de conception destinÂ´e `a eï¬€ectuer des analyses et
des opÂ´erations pour de grandes quantitÂ´es de donnÂ´ees et qui permet de distribuer
les donnÂ´ees sur plusieurs machines . Cette grappe de machines est communÂ´ement
appelÂ´ee cluster. MapReduce comprend trois grandes Â´etapes. Une fonction Map
qui prend en param`etre un bloc de donnÂ´ees du lecteur dâ€™entrÂ´ee et le traite. Cette
fonction gÂ´en`ere un ensemble de paires intermÂ´ediaires < cle, valeur >. Une partie
de shuï¬„e o`u lâ€™ensemble des paires de < cle, valeur > Â´emis par les mappers est
triÂ´e selon les clÂ´es, scindÂ´e en lots puis Â´ecrit sur le disque. Enï¬n, la fonction Reduce
est invoquÂ´ee pour chaque clÂ´e intermÂ´ediaire distincte et applique un traitement
aux valeurs associÂ´ees `a ces mË†emes clÂ´es. Le langage natif de programmation sous
Hadoop est le Java, mais il a Â´etÂ´e Â´etendu Â´egalement aux langages Python et R.

Hadoop int`egre un syst`eme de ï¬chiers distribuÂ´es qui prend en charge toutes
les fonctions de rÂ´eplication des donnÂ´ees et de tolÂ´erance aux pannes sur un clus-
ter. Il sâ€™agit du HDFS. Le HDFS dÂ´eï¬nit la notion de bloc qui correspond `a
la plus petite quantitÂ´e de donnÂ´ees quâ€™il est possible de lire ou dâ€™Â´ecrire sur un
disque. Cette taille est de 64 Mo. Lâ€™architecture du HDFS consiste en un syst`eme
maË†Ä±tre-esclave. Un nÅ“ud maË†Ä±tre, appelÂ´e NameNode permet de gÂ´erer lâ€™espace de
nommage et les mÂ´etadonnÂ´ees du syst`eme de ï¬chier. Il associe les blocs aux
diï¬€Â´erentes machines du cluster. Des processus associÂ´es `a chaque nÅ“ud, que lâ€™on
nomme DataNode g`erent les opÂ´erations de stockage locales, le tout dirigÂ´e par les
instructions du NameNode. Par dÂ´efaut, chaque ï¬chier sur le HDFS est rÂ´epliquÂ´e
trois fois sur des machines diï¬€Â´erentes au sein du cluster, pour prÂ´evenir et assurer
la tolÂ´erance aux pannes.

Dâ€™autres fonctionnalitÂ´es sâ€™agr`egent autour du logiciel Hadoop pour rÂ´epondre
`a des contraintes tr`es spÂ´eciï¬ques. Le tableau suivant rÂ´ecapitule les fonctionna-
litÂ´es annexes du logiciel Hadoop.

Les principales distributions dâ€™Hadoop sont Cloudera, Hortonworks, MapR

et Amazon Elastic MapReduce.

2.2.2 Apache Spark

Spark (Zaharia et al. (2010)) est un projet open source dâ€™analyse de donnÂ´ees
ayant vu le jour en 2009 `a Berkeley et qui fut lâ€™un des projets prioritaires de la
fondation Apache depuis fÂ´evrier 2014. Spark utilise lâ€™infrastructure distribuÂ´ee de
Hadoop, en particulier le HDFS, sans toutefois faire appel au patron de concep-
tion MapReduce. Les performances annoncÂ´ees en termes de vitesse sont jusquâ€™`a
100 fois plus importantes grË†ace `a son architecture in memory. Le dÂ´eveloppement
Spark se veut fonctionnel, câ€™est en ce sens que le langage de programmation na-
tif de Spark est le Scala. Il est actuellement Â´etendu aux langages Python et R.

Lâ€™un des atouts de Spark vis-`a-vis dâ€™Hadoop est de maintenir les rÂ´esultats in-
termÂ´ediaires en mÂ´emoire plutË†ot que sur le disque, ce qui reprÂ´esente un avantage

76

CHAPITRE 2. PARALL Â´ELISME ET DISTRIBUTION

HBase
Zookeeper

Pig

Hive

Oozie

Flume

Sqoop

FonctionnalitÂ´es agrÂ´egÂ´ees autour de Hadoop

Base de donnÂ´ees NOSQL orientÂ´ee colonne

Service de coordination de processus
distribuÂ´es au moyen dâ€™un espace de

nommage partagÂ´e disponible en lecture
Langage procÂ´edural qui parse, optimise

et exÂ´ecute des scripts PigLatin comme une

sÂ´erie de jobs MapReduce au sein dâ€™un cluster Hadoop.

Infrastructure de datawarehouse construite

sur Hadoop pour simpliï¬er lâ€™analyse

dâ€™ensembles de donnÂ´ees tr`es volumineuses.

Outil permettant de construire

des combinaisons complexes MapReduce, PigLatin ou Sqoop

en une seule unitÂ´e logique et permet

la planiï¬cation de jobs Hadoop.

Solution permettant dâ€™agrÂ´eger en temps

rÂ´eel diï¬€Â´erents ï¬‚ux de logs de serveurs webs.
Outil permettant de transfÂ´erer eï¬ƒcacement

de grands volumes de donnÂ´ees entre
Hadoop et des SGBD traditionnels

comme MySQL, Oracle, IBM DB2 et Microsoft SQL.

Tableau 2.1 â€“ Composants de lâ€™Â´eco-syst`eme Hadoop

en termes de temps dâ€™exÂ´ecution. Spark a Â´etÂ´e conÂ¸cu pour travailler aussi bien en
mÂ´emoire que sur le disque. Si les opÂ´erations ne tiennent plus en mÂ´emoire, Spark
utilise alors lâ€™espace disque.

Spark se base sur la notion de RDD (Resilient Distributed Datasets) qui
sont des collections pouvant contenir tout type de donnÂ´ees, qui distribuent les
donnÂ´ees sur le cluster tout en supportant des opÂ´erateurs parall`eles. Les RDD
permettent de rÂ´earranger les calculs et dâ€™optimiser le traitement. Ils sont aussi
tolÂ´erants aux pannes. Les RDD supportent deux types dâ€™opÂ´erations, les trans-
formations et les actions. Les transformations ne retournent pas de valeur seule,
elles retournent seulement un nouveau RDD. Aucune Â´evaluation nâ€™est eï¬€ectuÂ´ee
lorsque lâ€™on fait appel `a une fonction de transformation. Les actions Â´evaluent et
retournent une nouvelle valeur. A lâ€™instant o`u une fonction dâ€™action est appelÂ´ee
sur un objet RDD, toutes les requË†etes de traitement des donnÂ´ees sont calculÂ´ees
(qui correspondent aux transformations) et le rÂ´esultat est retournÂ´e. Câ€™est en ce
sens que lâ€™on qualiï¬e Spark de syst`eme paresseux (lazy) dans la mesure o`u les
transformations ne sâ€™eï¬€ectuent pas de suite.

Tout comme Hadoop, Spark contient son propre Â´eco-syst`eme sur lequel
sâ€™agr`egent diï¬€Â´erentes librairies et fonctionnalitÂ´es. Nous rÂ´ecapitulons les librairies
les plus importantes dans le tableau 2.3.

2.2. PLATEFORMES PARALL `ELES ET DISTRIBU Â´EES

77

Spark Streaming

UtilisÂ´e pour le traitement en temps rÂ´eel.

FonctionnalitÂ´es agrÂ´egÂ´ees autour de Spark

En sâ€™appuyant sur un mode de traitement de â€micro batchingâ€,

il utilise pour les donnÂ´ees temps-rÂ´eel DStream,

câ€™est-`a-dire une sÂ´erie de RDD.

Spark SQL

Outil agissant comme un ETL. Les jeux de donnÂ´ees Spark

sont mis en exergue via lâ€™API JDBC.

Spark SQL exÂ´ecute des requË†etes de type

SQL en utilisant les outils BI

et de visualisation traditionnels.
MLlib est une librairie contenant
un grand nombre dâ€™algorithmes et

utilitaires dâ€™apprentissage classiques,
comme la classiï¬cation, la rÂ´egression,
le clustering, le ï¬ltrage collaboratif,

la rÂ´eduction de dimensions, en plus des
primitives dâ€™optimisation sousâˆ’jacentes.

Outil pour le traitement des

Spark MLlib

Spark GraphX

graphes avec des opÂ´erations parall`eles dÂ´ediÂ´ees.

GraphX Â´etend les RDD de Spark en introduisant
le Resilient Distributed Dataset Graph (RDDG),

un multi-graphe orientÂ´e avec des

propriÂ´etÂ´es attachÂ´ees aux nÅ“uds et aux arË†etes.

On peut citer PageRank, la dÂ´etection de composantes connexes,

le parcours en largeur ou la propagation de

labels comme algorithmes Â´etant dÂ´ej`a implÂ´ementÂ´es sous cet outil.

Tableau 2.2 â€“ Composants de lâ€™Â´eco-syst`eme Spark

2.2.3 Syst`eme de traitement de graphes parall`eles

Il existe dâ€™autres logiciels permettant la distribution et la parallÂ´elisation
dâ€™algorithmes comme OpenMP ou encore les syst`emes MPI. Certains de ces lo-
giciels sont intrins`equement destinÂ´es aux graphes. Nous proposons de lister les
principales solutions permettant le traitement de graphes et le dÂ´eveloppement
dâ€™algorithmes de graphes dans un environnement parall`ele et distribuÂ´e.

Pour gÂ´erer la parallÂ´elisation et la distribution dâ€™algorithmes, les syst`emes ont
dË†u choisir entre diï¬€Â´erents mod`eles. Nous avons dÂ´ej`a vu le patron de conception
MapReduce dâ€™Hadoop ou encore la notion de RDD avec Spark, mais il en existe
dâ€™autres comme les BSP (pour â€Bulk synchronous parallelâ€) ou encore le mod`ele
RAD (pour â€Rassembler-Appliquer-Disperserâ€).

Le mod`ele BSP (Valiant (1990)) dÂ´ecrit un ensemble de paires processeurs-
mÂ´emoires homog`enes en nombre ï¬xe. De par un rÂ´eseau de communication et
une unitÂ´e de synchronisation globale, les Â´echanges de donnÂ´ees entre proces-

78

CHAPITRE 2. PARALL Â´ELISME ET DISTRIBUTION

seurs sont rendus possibles. Lâ€™exÂ´ecution se dÂ´eroule en plusieurs Â´etapes, chacune
constituÂ´ee dâ€™une phase de calculs locaux (eï¬€ectuÂ´ee sur chaque processeur) et
dâ€™une phase de communication entre les diï¬€Â´erents processeurs qui sâ€™eï¬€ectue
avec des phases de synchronisation. Ce syst`eme garantit le dÂ´eterminisme des
applications dÂ´eveloppÂ´ees et assure lâ€™absence dâ€™Â´etreintes fatales (interblocages).

Le mod`ele RAD (Gonzalez et al. (2012)) est intrins`equement destinÂ´e au
graphe. Dans la premi`ere phase de â€Rassemblementâ€, un sommet accumule de
lâ€™information sur ses voisins. La seconde phase â€Applicationâ€ applique la va-
leur accumulÂ´ee `a ce sommet et met `a jour ses sommets adjacents et arË†etes. La
derni`ere phase â€Dispersionâ€ active les sommets voisins. Les sommets peuvent
directement tirer de lâ€™information des sommets voisins sans toujours interagir
avec eux, `a lâ€™instar du mod`ele BSP. Le mod`ele GAS permet des exÂ´ecutions asyn-
chrones sans lâ€™aide de barri`ere de synchronisation.

A partir des deux mod`eles citÂ´es ci-dessus, des syst`emes pour le traitement

de graphes en environnement parall`ele et distribuÂ´e ont pu voir le jour.

Pregel (Malewicz et al. (2010)) est la premi`ere implÂ´ementation utilisant le
principe du BSP. Ce logiciel a Â´etÂ´e orientÂ´e vers les sommets du graphe. Les cal-
culs portant sur le graphe sont spÂ´eciï¬Â´es en termes de ce que doivent faire les
nÅ“uds. Les arË†etes servent de canaux et transmettent lâ€™information rÂ´esultante
dâ€™un sommet vers un autre mais ne participent pas au calcul. Un sommet peut
avoir deux Â´etats : actif et inactif. Les nÅ“uds actifs peuvent envoyer et recevoir
les messages de leurs voisins (ou dâ€™un autre sommet du graphe). Les super-
Â´etapes se terminent avec une barri`ere de synchronisation, assurant que tous les
messages ont bien Â´etÂ´e transmis. Pregel se termine lorsque tous les sommets sont
inactifs. Toutes les opÂ´erations avec Pregel sont eï¬€ectuÂ´ees en mÂ´emoire. Pregel ne
permet pas lâ€™Â´ecriture sur disque, ce qui oblige `a avoir un important cluster de
machines si la quantitÂ´e de donnÂ´ees `a traiter est grande. Lâ€™architecture de Pregel
est de type maË†Ä±tre-esclave. Le nÅ“ud maË†Ä±tre du cluster coupe les donnÂ´ees en lots
qui forment des sous-graphes. Chaque sous-graphe est envoyÂ´e `a un â€workerâ€
spÂ´eciï¬que (ordinateur du cluster qui eï¬€ectue une tË†ache) qui travaille de mani`ere
indÂ´ependante des autres. Le nÅ“ud maË†Ä±tre est responsable de la bonne synchro-
nisation.

Giraph (Avery (2011)) est une solution open source construite sur Hadoop et
utilisant le HDFS pour stocker les donnÂ´ees. Giraph permet la crÂ´eation de struc-
tures de graphes et autorise certaines opÂ´erations MapReduce. Giraph utilise Zoo-
keeper pour la coordination, les points de reprise et la dÂ´efaillance des syst`emes de
rÂ´ecupÂ´eration. Facebook (Ching (2013)) a utilisÂ´e Giraph avec quelques amÂ´eliorations
de performances pour analyser 1000 milliards dâ€™arË†etes (relations) en 4 minutes
sur un cluster de 200 machines, dans le but de faire un algorithme de recherche
dâ€™information sur les sommets. Cependant, Giraph cessa depuis 2015 dâ€™Ë†etre
documentÂ´e, cela Â´etant dË†u principalement `a la complexitÂ´e de dÂ´eveloppement
et au temps de traitement des donnÂ´ees trop important pour certains algo-

2.2. PLATEFORMES PARALL `ELES ET DISTRIBU Â´EES

79

rithmes, principalement globaux. De nombreux bugs ont Â´egalement Â´etÂ´e signalÂ´es,
dÂ´ecrÂ´edibilisant lâ€™utilisation ce cette solution (Salihoglu et al. (2015)).

GPS (Salihoglu et Widom (2013)) (pour â€A Graph Processing Systemâ€) est
un logiciel open source fondÂ´e sur Pregel. Des expÂ´erimentations ont montrÂ´e quâ€™il
Â´etait jusquâ€™`a 12 fois plus rapide que Giraph sur certains algorithmes comme
le parcours en largeur. Des optimisations par rapport `a Pregel portent sur
lâ€™amÂ´elioration des communications, o`u les opÂ´erations se font par processeur dans
un premier temps, puis entre processeurs dans un second temps, et non plus par
voisinage comme sur Pregel. Cela permet une rÂ´eduction de la synchronisation
des threads (moins dâ€™Â´echanges entre processeurs) et une amÂ´elioration de la per-
formance dâ€™exÂ´ecution en termes de temps. Une caractÂ´eristique de GPS est un
partitionnement de graphe dynamique pour la rÂ´epartition des donnÂ´ees sur le
cluster. Alors que certains syst`emes partitionnent le graphe avant dâ€™eï¬€ectuer
un processus, des migrations dynamiques de sommets ont lieu entre machines
du cluster. Cette migration est fondÂ´ee non sur une Â´equirÂ´epartition des som-
mets (rÂ´epartition de mani`ere uniforme) du graphe au sein du cluster, mais sur
une Â´equirÂ´epartition des messages envoyÂ´es entre sommets aï¬n de minimiser leur
nombre. Cependant, la mise `a jour des listes de voisins lors des migrations en-
traË†Ä±ne un gain de temps qui ne permet pas au syst`eme dâ€™Ë†etre plus performant en
termes dâ€™exÂ´ecution que le mod`ele de base de Pregel. GPS oï¬€re aussi les â€grandes
listes dâ€™adjacences partitionnablesâ€ (GLAP) qui permettent de gÂ´erer des nÅ“uds
avec beaucoup de connexions. Une migration des algorithmes de graphes sâ€™ef-
fectue `a ce jour vers GraphX.

Mizan (Khayyat et al. (2013); Kalnis et al. (2012)) est un logiciel open source
fondÂ´e sur lâ€™architecture de GPS avec des amÂ´eliorations concernant les structures
de donnÂ´ees utilisÂ´ees et les mÂ´ethodes de partitionnement. Il a Â´etÂ´e reportÂ´e comme
Â´etant deux fois plus rapide que Giraph en mode statique (sans lâ€™option de migra-
tion de nÅ“uds au cours de la partition). Mizan a un partitionnement se fondant
sur la topologie du graphe. Lâ€™algorithme, par une estimation de Kolmogorov
(Pettitt et Stephens (1977)), peut dÂ´etecter si le graphe est un graphe de ter-
rain, auquel cas, un partitionnement spÂ´eciï¬que aura lieu, dans lequel les hubs
(nÅ“uds avec de fortes connexions) seront rÂ´epliquÂ´es sur plusieurs processeurs.
Comme GPS, Mizan a une option avec partitionnement dynamique au cours
de lâ€™exÂ´ecution dâ€™un programme en se fondant sur la distribution des messages
entre sommets du graphe. On reporte cependant de tr`es nombreux bugs. La
documentation laisse `a penser que le projet nâ€™est plus dâ€™actualitÂ´e.

GraphLab (Low et al. (2014)) est un projet open source qui int`egre les fonc-
tionnalitÂ´es de Powergraph (Gonzalez et al. (2012)). GraphLab utilise le mod`ele
RAD. Lâ€™une des diï¬€Â´erences avec les autres logiciels est que le partitionnement
ne concerne que les nÅ“uds, pas les arË†etes. Les arË†etes ne sont assignÂ´ees que sur
une seule machine alors que les nÅ“uds sont rÂ´epliquÂ´es dans la mÂ´emoire cache des
machines du cluster suivant la distribution de leurs degrÂ´es (cela prÂ´evaut pour les
hubs). Cela a pour consÂ´equence un gain de temps notable. GraphLab supporte

80

CHAPITRE 2. PARALL Â´ELISME ET DISTRIBUTION

les modes dâ€™exÂ´ecution synchrone et asynchrone. Les sommets qui nâ€™envoient pas
de messages ne sont pas considÂ´erÂ´es lors des calculs et retirÂ´es du cache, ce qui
amÂ´eliore le temps de calcul.

HAMA (Seo et al. (2010)) est un logiciel fondÂ´e sur le mod`ele BSP tout en
Â´etant construit sur Hadoop. Il nâ€™est pas exclusivement destinÂ´e aux graphes mais
prÂ´esente de tr`es nombreux avantages. Il fut conÂ¸cu pour gÂ´erer de tr`es grandes
matrices ainsi que leurs opÂ´erations Â´elÂ´ementaires (multiplication, inversion, etc.).
Il est principalement destinÂ´e `a lâ€™alg`ebre linÂ´eaire. HAMA prÂ´esente cependant un
intÂ´erË†et particulier pour les algorithmes itÂ´eratifs car il permet de conserver les
donnÂ´ees en mÂ´emoire et de ne pas les Â´ecrire sur le disque, tel un prÂ´ecurseur de
Spark. Les expÂ´erimentations rÂ´ealisÂ´ees sur PageRank ont montrÂ´e que HAMA
Â´etait jusquâ€™`a trois fois plus rapide que Giraph.

Syst`emes permettant le traitement de graphes parall`eles
Langage

optimisation

Mod`ele

partitionnement

Syst`eme
Hadoop
Spark

Pregel
GPS

Mizan

Giraph
GraphLab

Java
Scala

C + +
Java

C + +

Java
C + +

MapReduce

RDD

BSP
BSP

BSP

-

rÂ´eutilisation
des donnÂ´ees

-

GLAP,

migration
dynamique
migration,
rÂ´eplication

BSP, MapReduce

Â´ecriture en mÂ´emoire

RAD

calcul synchrone

et asynchrone

graphes

de terrains

avec une coupe

minimale

hashage
1Dâˆ’2D

hashage
GLAP

Mizan Î± âˆ’ Î²

hashage
hashage
Metis,

ParMetis,
hashage

sur les arË†etes

Powergraph

C + +

BSP,RAD

Tableau 2.3 â€“ CaractÂ´eristiques globales des syst`emes pour le traitement de graphes de
mani`ere parall`ele et distribuÂ´ee

2.3 DÂ´etection de communautÂ´es dans un envi-

ronnement parall`ele et distribuÂ´e

Des mÂ´ethodes issues de la littÂ´erature de la dÂ´etection de communautÂ´es ont Â´etÂ´e
appliquÂ´ees et retranscrites pour de grands graphes. Nous nous proposons dâ€™ex-
poser les plus importantes et celles qui permettront dâ€™aboutir `a une stratÂ´egie

2.3. D Â´ETECTION DE COMMUNAUT Â´ES DANS UN ENVIRONNEMENT PARALL `ELE ET DISTRIBU Â´E81

pour notre solution concernant les grands graphes.

Riedy et al. (2011) ont implÂ´ementÂ´e lâ€™algorithme de Clauset et al., algorithme
agglomÂ´eratif optimisant la modularitÂ´e, en utilisant le multithreading Cray XMT.
Cray XMT est une gamme de super-ordinateurs qui poss`edent plusieurs proces-
seurs. Lâ€™algorithme fut lancÂ´e sur un graphe de deux milliards dâ€™arË†etes et 122
millions de sommets avec plus de 128 processeurs. Les rÂ´esultats sont satisfaisants
mais la qualitÂ´e ne fut jugÂ´ee que par le score de la modularitÂ´e. Les technologies
Cray XMT permettent de rÂ´ealiser des calculs sur de gros volumes de donnÂ´ees
mais sont tr`es onÂ´ereuses. De plus, depuis lâ€™apparition des technologies Hadoop
et Spark, la technologie Cray XMT est de moins en moins utilisÂ´ee. Riedy et al.
(2012) ont amÂ´eliorÂ´e leur algorithme en y incluant une implementation OpenMP.
En utilisant 4 processeurs de 80 cÅ“urs, les auteurs ont fait marcher leurs algo-
rithmes sur un graphe de 3,3 milliards dâ€™arË†etes en 500 secondes. Cependant, les
tests concernant la qualitÂ´e ne purent Ë†etre faits `a cause de la taille des graphes.

|E(S)|

|S|

Bahmani et al. (2012) ont proposÂ´e un algorithme pour dÂ´etecter des groupes
de nÅ“uds denses, fondÂ´e sur la maximisation de fonctions fondÂ´ees sur la densitÂ´e
de sous graphes. Soit G = (V, E) et S âŠ† V , la densitÂ´e de Bahman Bahmani
. Plus Ï(S) augmente, plus la structure se
et al. est dÂ´eï¬nie par Ï(S) =
rapproche de celle dâ€™un graphe complet. Les auteurs proposent un algorithme
avec deux versions. La premi`ere concerne les graphes denses et construira la
communautÂ´e S si lâ€™inÂ´egalitÂ´e degS(i) â‰¤ 2(1 + )Ï(S) est vÂ´eriï¬Â´ee, avec  un rÂ´eel
donnÂ´e par lâ€™utilisateur. On peut comprendre cette inÂ´egalitÂ´e comme le fait que
chaque nÅ“ud doit avoir un degrÂ´e suï¬ƒsant pour appartenir `a la communautÂ´e
S. La seconde version, destinÂ´ee `a des graphes tr`es denses, doit vÂ´eriï¬er pour la
crÂ´eation de structures communautaires lâ€™inÂ´egalitÂ´e suivante degS(i) â‰¤ 
Les deux versions op`erent de la mË†eme mani`ere. Des nÅ“uds sont enlevÂ´es dans
le but de maximiser la densitÂ´e des structures communautaires. Lâ€™inconvÂ´enient
majeur de cette mÂ´ethode est la paramÂ´etrisation qui a une grande inï¬‚uence sur
la qualitÂ´e de partitionnement. Il faut dÂ´ej`a avoir une idÂ´ee de la densitÂ´e ÏG du
graphe rÂ´esultant que lâ€™on cherche `a obtenir mais Â´egalement avoir `a lâ€™esprit une
taille moyenne pour les communautÂ´es `a  pr`es. La derni`ere contrainte peut poser
probl`eme pour des graphes complexes, o`u la taille des communautÂ´es peut Ë†etre
tr`es variable. On peut en eï¬€et, avec une mauvaise paramÂ´etrisation, dÂ´etecter des
communautÂ´es contenant elles mË†emes dâ€™autres communautÂ´es. Lâ€™une des forces
de cet algorithme est dâ€™avoir Â´etÂ´e appliquÂ´e `a de grands graphes, avec plus de 6
milliards dâ€™arË†etes avec 2000 reducers pour un temps dâ€™exÂ´ecution dâ€™environ 260
minutes. La qualitÂ´e de partitionnement des mÂ´ethodes nâ€™a pas Â´etÂ´e sujette `a des
Â´etudes, le seul crit`ere Â´etant de maximiser les densitÂ´es des communautÂ´es.

1+|S|.

Tsironis et al. (2013) ont implÂ´ementÂ´e une mÂ´ethode spectrale sous Hadoop.
La mÂ´ethode consiste `a construire la matrice Laplacienne sur laquelle vont Ë†etre
calculÂ´es les K vecteurs propres associÂ´es aux K plus petites valeurs propres de la
matrice, puis `a lancer un k-means pour obtenir k clusters. Le calcul des vecteurs

82

CHAPITRE 2. PARALL Â´ELISME ET DISTRIBUTION

propres se fait en utilisant HEIGEN (Kang et al. (2014)), un algorithme sous
MapReduce reprenant la mÂ´ethode de Lanczos.
Cette mÂ´ethode prÂ´esente lâ€™inconvÂ´enient dâ€™Ë†etre fondÂ´ee sur le k-means, mais est ce-
pendant destinÂ´ee au partitionnement de graphes. De plus, il faut eï¬€ectuer une
recherche prÂ´ealable pour sÂ´electionner les vecteurs propres contenant le plus dâ€™in-
formation. Bien que lâ€™algorithme soit parall`ele et distribuÂ´e, la taille des graphes
sur lesquels il a Â´etÂ´e appliquÂ´e est relativement faible, le plus grand graphe ne
contenant que 20000 nÅ“uds.

Ovelgonne (2013) propose un algorithme ensembliste fondÂ´e sur la propaga-
tion de label tout en rÂ´eduisant la complexitÂ´e du probl`eme, via une rÂ´eduction de
la taille des donnÂ´ees de dÂ´epart. En lanÂ¸cant en parall`ele plusieurs propagations de
labels, une mÂ´ethode de chevauchement maximale permet de trouver les cÅ“urs.
Cependant, OvelgÂ¨onne nâ€™a pas appliquÂ´e la mÂ´ethode asynchrone sous Hadoop
car trop gourmande en temps. Il choisit plutË†ot une version avec mise `a jour en
fonction de probabilitÂ´es de telle sorte que le nombre de propagations de labels
synchrones soit minimisÂ´e. Cela dÂ´etÂ´eriore la qualitÂ´e de partitionnement. De plus,
pour Â´eviter dâ€™Â´ecrire de trop nombreuses fois sur le disque, certains nÅ“uds ne
sont mis `a jour quâ€™une seule fois avec un nombre dâ€™itÂ´erations assez faible d`es le
dÂ´epart.
Les rÂ´esultats ont Â´etÂ´e appliquÂ´es sur de tr`es grands rÂ´eseaux de terrain comme
LiveJournal avec une heure pour 20 propagations de labels en parall`ele sur un
cluster de 50 machines. Les rÂ´esultats sont Â´evaluÂ´es avec la modularitÂ´e qui donne
des valeurs correctes pour la qualitÂ´e de partitionnement.

Staudt et Meyerhenke (2013) proposent une version â€OpenMPâ€ implÂ´ementant
la propagation de labels et la mÂ´ethode de Louvain en C ++, avec trois mÂ´ethodes
fondÂ´ees sur le clustering dâ€™ensemble et vote par consensus :

â€” Ensemble de prÂ´etraitement
â€” Ensemble multi-niveaux
â€” Clustering de cÅ“ur et contraction de graphe

Ensemble de prÂ´etraitement (EPP) : il consiste dans un premier temps `a
assigner le graphe `a plusieurs algorithmes de dÂ´etection de communautÂ´es. Une
contraction du graphe a lieu selon un consensus entre tous les rÂ´esultats des
diï¬€Â´erentes dÂ´etections de communautÂ´es. Le graphe est ainsi contractÂ´e. Lâ€™objectif
de ce syst`eme est de pouvoir allier qualitÂ´e (par le consensus) et rapiditÂ´e (par la
contraction).
Ensemble multi-niveaux (EM) : il est une amÂ´elioration de lâ€™EPP dans un
sens itÂ´eratif. A la ï¬n de lâ€™Â´etape de contraction, un nouveau graphe G(cid:48) est crÂ´eÂ´e et
le processus fondÂ´e sur lâ€™EPP continue de mani`ere itÂ´erative. Les conditions pour
arrË†eter la contraction sont multiples comme i) obtenir un singleton ii) mettre
un seuil sur la taille du graphe rÂ´eduit en dessous duquel la contraction est in-
terdite iii) la prÂ´esence dâ€™une diminution de la modularitÂ´e dâ€™une contraction `a
la suivante et iv) la stagnation de la qualitÂ´e des communautÂ´es dÂ´etectÂ´ees.
Clustering de cÅ“ur et contraction de graphe (CCGC) : reprÂ´esente
la mÂ´ethode la plus stricte en termes de consensus. Si une paire de nÅ“uds a

2.3. D Â´ETECTION DE COMMUNAUT Â´ES DANS UN ENVIRONNEMENT PARALL `ELE ET DISTRIBU Â´E83

Â´etÂ´e identiï¬Â´ee comme appartenant `a la mË†eme communautÂ´e, et ceci dans toutes
les dÂ´etections de communautÂ´es, alors ces deux nÅ“uds seront contractÂ´es. Cette
derni`ere mÂ´ethode permet de trouver les meilleurs cÅ“urs en termes de qualitÂ´e.
Cependant, il se peut que certains rÂ´esultats de dÂ´etection de communautÂ´es ne
soient pas de bonne qualitÂ´e. La consÂ´equence est que des cÅ“urs ne puissent Ë†etre
trouvÂ´es.
Câ€™est en utilisant ces derni`eres mÂ´ethodes que la propagation de labels pondÂ´erÂ´ee
et la mÂ´ethode de Louvain ont Â´etÂ´e appliquÂ´ees dans leurs versions parall`eles.
Le parallÂ´elisme de la propagation de labels sur OpenMP (notÂ´e PLP) rÂ´eside en
un tri des nÅ“uds se faisant sur plusieurs threads qui opÂ´erent sur des tableaux de
labels communs. La mise `a jours des labels peut ainsi se faire de mani`ere syn-
chrone ou asynchrone. Il sâ€™agit dâ€™une implÂ´ementation pour des graphes pondÂ´erÂ´es,
avec une mise `a jour des labels dont les arË†etes liant le nÅ“ud sont les plus impor-
tantes. Un seuil Î´ doit cependant Ë†etre spÂ´eciï¬Â´e en dessous duquel le changement
de labels devient impossible.
Le parallÂ´elisme de lâ€™algorithme de Louvain sur OpenMP intervient dans le calcul
de la fonction de modularitÂ´e, qui se fait en utilisant plusieurs threads. En eï¬€et,
chaque mouvement dâ€™un nÅ“ud dans une autre communautÂ´e a pour consÂ´equence
la variation de la modularitÂ´e qui est calculÂ´ee localement.
Il ressort des expÂ´erimentations que CCGC semble donner les meilleurs rÂ´esultats
en termes de qualitÂ´e pour PLM et PLP. PLP est extrË†emement rapide mais de
qualitÂ´e moyenne, alors que PLM obtient de meilleurs rÂ´esultats, mais nÂ´ecessite
plus de temps.

Moon et al. (2014) dÂ´evelopp`erent lâ€™algorithme de Girvan et Newman (2002b)
sous Hadoop. Une version du plus court chemin fut dÂ´eveloppÂ´ee sous MapReduce
en quatre Â´etapes. La premi`ere phase consiste `a calculer entre chaque paire de
nÅ“uds le plus court chemin. La seconde Â´etape consiste dans le calcul de la
centralitÂ´e dâ€™intermÂ´ediaritÂ´e. La troisi`eme Â´etape permet de sÂ´electionner k arË†etes
ayant les centralitÂ´es dâ€™intermÂ´ediaritÂ´e les plus Â´elevÂ´ees. k est un param`etre de
lâ€™utilisateur. La derni`ere phase consiste `a retirer les arË†etes sÂ´electionnÂ´ees. Lâ€™al-
gorithme fut appliquÂ´e `a deux graphes de petite taille de 6000 et 10000 nÅ“uds
avec respectivement 290 000 et 51 000 arË†etes. Avec plus de 20 machines, le
syst`eme requiert un temps dâ€™exÂ´ecution de pr`es de 300 secondes. Bien que les
rÂ´esultats en termes de qualitÂ´e soient encourageants, lâ€™algorithme prÂ´esente deux
inconvÂ´enients majeurs. Le premier est le choix du nombre dâ€™arË†etes `a retirer qui
nâ€™est a priori pas connu de lâ€™utilisateur. Le second inconvÂ´enient est le temps de
calcul du plus court chemin entre chaque paire de nÅ“uds qui est beaucoup trop
important pour des graphes ayant quelques dizaines de milliers dâ€™arË†etes. De ce
fait, lâ€™algorithme ne peut pas Ë†etre appliquÂ´e `a de grands graphes de plusieurs
millions dâ€™arË†etes.

Kuzmin et al. (2015) ont implÂ´ementÂ´e le SLPA dans sa version parall`ele dans
un contexte multithreading. Chaque thread rÂ´ealise une propagation de labels
sur un sous ensemble de nÅ“uds qui a Â´etÂ´e prÂ´ealablement partitionnÂ´e. Le parti-
tionnement est utilisÂ´e pour ne pas dÂ´epasser la mÂ´emoire vive. Câ€™est alors que les

84

CHAPITRE 2. PARALL Â´ELISME ET DISTRIBUTION

sous-graphes rÂ´esultants sont assignÂ´es `a des threads o`u les propagations de labels
sont lancÂ´ees.
Les rÂ´esultats ont montrÂ´e que la mÂ´ethode Â´etait Â´equivalente en termes de qualitÂ´e
de partionnement `a la version non parall`ele. Elle obtient cependant de meilleurs
rÂ´esultats en choisissant une mÂ´ethode de partitionnement particuli`ere, mais une
Â´etude prÂ´ealable doit Ë†etre eï¬€ectuÂ´ee. Elle fut lancÂ´ee sur des graphes comme DBLP,
Amazon ou Livejournal, avec plusieurs millions de sommets et jusquâ€™`a une cen-
taine de millions dâ€™arË†etes.

La propagation de label a Â´egalement Â´etÂ´e dÂ´eveloppÂ´ee sous Apache Spark, par
une implÂ´ementation et par une intÂ´egration Pregel dont le mod`ele suit un BSP.
Comme nous lâ€™avons vu, Pregel est un BSP qui permet lâ€™implÂ´ementation dâ€™algo-
rithmes sur les graphes. Pregel fut construit sur la philosophie â€Penser comme
un sommetâ€. Chaque calcul est fait sur chaque sommet et les arË†etes sont des
canaux de communication permettant dâ€™envoyer ou de recevoir des informa-
tions ou opÂ´erations des voisinages des nÅ“uds (ou mË†eme dâ€™un nÅ“ud `a un autre
nÅ“ud en connaissant lâ€™identiï¬ant). Pregel ï¬nit une â€super Â´etapeâ€ lorsque tous
les nÅ“uds du graphe sont dans un Â´etat inactif. La propagation de labels fut ainsi
implÂ´ementÂ´ee de mani`ere synchrone o`u chaque itÂ´eration consiste en une â€super
Â´etapeâ€. A la ï¬n dâ€™une super Â´etape, chaque nÅ“ud prend connaissance du label
majoritaire de son voisin et un vote est ainsi eï¬€ectuÂ´e. Le processus se continue
un nombre de fois spÂ´eciï¬Â´e par lâ€™utilisateur. En considÂ´erant lâ€™implÂ´ementation sur
Spark, `a chaque super Â´etape, un RDD (Resilient distributed dataset) est crÂ´eÂ´e et
est utilisÂ´e pour lâ€™itÂ´eration de la propagation de labels suivante. La signature du
LPA sous Spark est lib.LabelPropagation.run(par1, par2).vertices
o`u par1 se rÂ´ef`ere au graphe o`u sera appliquÂ´e le LPA et par2 sera le nombre
dâ€™itÂ´erations (de super Â´etapes) du LPA. Cette implÂ´ementation peut Ë†etre ap-
pliquÂ´ee `a des graphes de plusieurs millions dâ€™arË†etes en utilisant un cluster de
machines important, mais souï¬€re dâ€™un inconvÂ´enient qui lui est intrins`eque. Son
implÂ´ementation synchrone laisse lâ€™algorithme instable et non dÂ´etermiste. La so-
lution pour rÂ´esoudre ce probl`eme est que lâ€™ordre de visite des nÅ“uds soit toujours
le mË†eme, aï¬n de rendre plus dÂ´eterministe lâ€™algorithme. Cependant, si lâ€™ordre de
visite commence par un nÅ“ud qui est situÂ´e entre plusieurs structures commu-
nautaires, de mauvaises propagations peuvent se produire.

2.4. TABLEAU R Â´ECAPITULATIF DES M Â´ETHODES PARALL `ELES ET DISTRIBU Â´EES85

2.4 Tableau rÂ´ecapitulatif des mÂ´ethodes parall`eles

et distribuÂ´ees

Classiï¬cation des principaux algorithmes de dÂ´etection de communautÂ´es parall`eles et distribuÂ´es

articles

d

c

complexitÂ´e

framework

Algorithmes
parall`eles
Zhang et al
Bahman et al.
EJ Riedy et al.
EJ Riedy et al.

Tsironis et al.
Ovelgonne
Staudt et al.
Moon et al.
A Prat-PÂ´erez

(Zhang et al., 2009)

(Bahmani et al., 2012)

(Riedy et al., 2011)
(Riedy et al., 2012)

(Tsironis et al., 2013)

(Ovelgonne, 2013)

(Staudt et Meyerhenke, 2013)

(Moon et al., 2014)
(Saltz et al., 2015)

non
non
non
non

non
non
oui
non
non

non
non
non
non

non
non
non
non
non

(ordre)

O(exp(n))
O(kmn)
O(kmn)
O(kmn)
O(kmn)
O(kmn)

Hadoop
Hadoop

Cray XMT
Cray XMT,
OpenMPI

Hadoop
Hadoop

MPI

Hadoop
Giraph-
Hadoop

MPI

Kuzmin et al.

(Kuzmin et al., 2015)

non

oui

Tableau 2.4 â€“ Principaux algorithmes de dÂ´etection de communautÂ´es parall`eles et dis-
tribuÂ´es. â€*â€ dÂ´epend du paramÂ´etrage, diï¬ƒcile `a estimer, d pour dendrogramme et c
pour chevauchement. Premi`ere partie.

Figure 2.1 â€“ MÂ´ethodes parall`eles et distribuÂ´ees. Lâ€™axe des abscisses reprÂ´esente la taille
des graphes, lâ€™axe des ordonnÂ´ees, la complexitÂ´e.

En Â´etudiant la ï¬gure 2.1, on voit que les algorithmes permettant de traiter
les plus grands graphes concernent les mÂ´ethodes portant sur la maximisation
de la densitÂ´e des structures communautaires et celles se fondant sur la propaga-
tion de labels. Nous observons que les mÂ´ethodes gobales telles que la mÂ´ethode
spectrale ou celle concernant la centralitÂ´e dâ€™intermÂ´ediaritÂ´e ne permettent pas de
travailler avec des graphes de plus de 30 000 nÅ“uds. Cependant, ces derni`eres
reprÂ´esentent une avancÂ´ee sur la taille des rÂ´eseaux vis-`a-vis de leurs homologues
originellement non parall`eles et non distribuÂ´ees.

86

CHAPITRE 2. PARALL Â´ELISME ET DISTRIBUTION

2.5 Synth`ese et discussion

Ce chapitre nous a permis dâ€™exposer la problÂ´ematique de la dÂ´etection de com-
munautÂ´es dans de grands graphes dont les diï¬ƒcultÂ´es majeures rÂ´esident dans :
â€” le stockage des donnÂ´ees massives du ï¬chier reprÂ´esentant le graphe et

Â´egalement durant le processus de lâ€™algorithme.

â€” lâ€™Â´echelonnabilitÂ´e, câ€™est-`a-dire le fait quâ€™un algorithme puisse Ë†etre capable
de travailler `a la fois sur de petits graphes et de grands graphes en don-
nant la mË†eme qualitÂ´e de partitionnement et dont le stockage de donnÂ´ees
soit linÂ´eaire.

Ce seront les challenges pour notre contribution sur de grands graphes.

Ce chapitre a Â´egalement permis de voir les plus importantes plateformes pa-
rall`eles et distribuÂ´ees existantes, particuli`erement les PGPS destinÂ´es aux graphes.
Câ€™est en ce sens que nos choix se porteront principalement sur deux plate-
formes Hadoop et Spark. Les raisons principales sont leur faible coË†ut ï¬nancier
et le fait que de nombreux algorithmes de graphes furent dÂ´eveloppÂ´es en utili-
sant ces plateformes, comme PEGASUS (Kang et al. (2009)) (le degrÂ´e, Page-
Rank, marche alÂ´eatoire avec redÂ´emarrage (MAR), le diam`etre, les composantes
connexes, etc.) et Giraph pour Hadoop et GraphX (Avery (2011)) pour Spark
(Zaharia et al. (2010)). Hadoop permet lâ€™utilisation du HDFS qui autorise le
traitement de donnÂ´ees massives et la tolÂ´erance aux pannes. Cependant, cette
plateforme connaË†Ä±t des diï¬ƒcultÂ´es dans le traitement de donnÂ´ees en temps rÂ´eel,
ce qui peut Ë†etre le cas de la propagation de labels o`u tout autre nÅ“ud doit
connaË†Ä±tre le label de ses voisins en temps rÂ´eel (version asynchrone). Câ€™est un
challenge auquel nous souhaitons faire face. Lâ€™Â´etat de lâ€™art nous a permis de
voir que les mÂ´ethodes `a propagation de labels permettaient de traiter de grands
graphes, câ€™est donc lâ€™option que nous privilÂ´egions.

Chapitre 3

Propositions algorithmiques
sur la dÂ´etection de
communautÂ´es

Sommaire

3.1 LPA avec barrages et dendrogrammes . . . . . . .

3.1.1 Propagation de labels asynchrone avec barrages . . .
3.1.2 Propagation de labels asynchrone avec barrages et

88
89

dÂ´etection de cÅ“urs . . . . . . . . . . . . . . . . . . .

91

3.1.3 ExpÂ´erimentations portant sur les propositions algo-
rithmiques pour la dÂ´etection de communautÂ´es dis-
jointes . . . . . . . . . . . . . . . . . . . . . . . . . .

98

3.1.4 Conclusion sur les algorithmes de propagation de la-

bels avec barrages et dÂ´etection de cÅ“urs . . . . . . . 121
3.2 LPA avec coloration . . . . . . . . . . . . . . . . . . 123

3.2.1 Propagation de labels asynchrone avec dÂ´etection de

cÅ“urs et coloration . . . . . . . . . . . . . . . . . . . 123
3.2.2 ExpÂ´erimentation sur R-POP, POP-UP et POP-DOWN125
3.2.3 Conclusion sur les propositions algorithmiques `a base

de coloration . . . . . . . . . . . . . . . . . . . . . . 136
3.3 Analyse comparative des mÂ´ethodes disjointes
. . 137
3.4 Propositions sur le chevauchement . . . . . . . . . 141

3.4.1 De la propagation de labels avec dÂ´etection de cÅ“urs

au chevauchement

. . . . . . . . . . . . . . . . . . . 141
3.4.2 Fonction dâ€™appartenance . . . . . . . . . . . . . . . . 142
3.4.3 Propositions algorithmiques . . . . . . . . . . . . . . 145
3.4.4 ExpÂ´erimentations sur CDLPOV . . . . . . . . . . . . 147
3.4.5 Etude portant sur le temps dâ€™exÂ´ecution . . . . . . . 155
3.4.6 Analyse comparative . . . . . . . . . . . . . . . . . . 156

87

88

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

3.4.7 Conclusion sur les propositions algorithmiques che-

vauchantes

. . . . . . . . . . . . . . . . . . . . . . . 158

Lâ€™Â´etat de lâ€™art concernant la dÂ´etection de communautÂ´es disjointes nous a
permis de voir lâ€™existence de trois grandes classes dâ€™algorithmes, `a savoir les
mÂ´ethodes globales, les mÂ´ethodes locales et les mÂ´ethodes hybrides. Dans le but
de crÂ´eer un algorithme pouvant travailler sur de grands graphes, nous avons
privilÂ´egiÂ´e dâ€™utiliser la propagation de labels. Cependant, lâ€™algorithme de propa-
gation de labels souï¬€re de certains probl`emes liÂ´es `a des choix alÂ´eatoires, comme
celui du choix dâ€™un label lorsquâ€™il y a Â´equidistribution des labels majoritaires au
sein du voisinage dâ€™un nÅ“ud. Cela peut mener `a :

â€” de mauvaises propagations de labels (susceptibles de donner des com-
munautÂ´es gÂ´eantes, groupes de nÅ“uds o`u les structures nâ€™ont pu Ë†etre
dÂ´etectÂ´ees) ou des communautÂ´es non connectÂ´ees avec le mË†eme label)

â€” lâ€™instabilitÂ´e (ne donnant que tr`es rarement la mË†eme partition apr`es plu-

sieurs lancements)

â€” lâ€™impossibilitÂ´e de crÂ´eer un dendrogramme
â€” lâ€™impossibilitÂ´e de trouver des communautÂ´es chevauchantes.

Dans cette section, nous allons exposer nos propositions hybrides, fondÂ´ees
sur la propagation de labels en utilisant la dÂ´etection de cÅ“urs et la mise en place
de barrages artiï¬ciels sur certaines arË†etes interdisant toute propagation. Nous
ferons une Â´etude portant sur la qualitÂ´e de la dÂ´etection de nos algorithmes mais
aussi sur leurs paramÂ´etrages. Par la suite, nous proposerons des algorithmes,
fondÂ´es sur nos mÂ´ethodes disjointes, ayant pour vocation le chevauchement. Lâ€™ob-
jectif de la partie de chevauchement est de crÂ´eer une mÂ´ethode permettant `a un
nÅ“ud dâ€™appartenir `a autant de communautÂ´es que nÂ´ecessaire suivant certaines
conditions que nous expliciterons. Une Â´etude comparative sera eï¬€ectuÂ´ee.

Dans la suite de ce manuscrit, nous notons par su â† sv le fait que la valeur

du label du nÅ“ud u prenne la valeur du label du nÅ“ud v.

3.1 Propagation de labels avec dÂ´etection de cÅ“urs,

barrages et dendrogrammes

Pour diminuer la probabilitÂ´e quâ€™une mauvaise propagation puisse surve-
nir, nous avons rÂ´eï¬‚Â´echi `a un moyen de limiter cette derni`ere. Il serait souhai-
table que la propagation de labels puisse se faire dans des rÂ´egions du graphe
densÂ´ement connectÂ´ees en Â´evitant de mauvaises propagations entre rÂ´egions fai-
blement connectÂ´ees, ce qui aurait pour consÂ´equence dâ€™obtenir de trop grosses
communautÂ´es.

ConsidÂ´erons deux exemples donnant une mauvaise propagation de labels. Le

3.1. LPA AVEC BARRAGES ET DENDROGRAMMES

89

premier traite des communautÂ´es gÂ´eantes alors que le second traite de commu-
nautÂ´es non liÂ´ees ayant les mË†emes labels.

Figure 3.1 â€“ Exemple dâ€™une mauvaise propagation donnant une communautÂ´e gÂ´eante

En considÂ´erant lâ€™odre de visite sur le graphe de la ï¬gure 3.1

(cid:19)

(cid:18) 1

s2

Ïƒ =

2
s5

3
s6

4
s4

5
s1

6
s3

Une suite dâ€™opÂ´erations possibles peut Ë†etre s2 â† s4 (par choix alÂ´eatoire), s5 â† s4
(par choix alÂ´eatoire) s6 â† {s4, s5} (par vote majoritaire) s4 â† {s2, s5, s6} (par
vote majoritaire) s1 â† s2 (par choix alÂ´eatoire) et s3 â† {s2, s1} (par vote ma-
joritaire). Ainsi, les deux structures communautaires, `a savoir {s1, s2, s3} et
{s5, s4, s6} nâ€™ont pas pu Ë†etre dÂ´etectÂ´ees. Il sâ€™agit dâ€™une communautÂ´e gÂ´eante.

Un autre exemple porte sur des communautÂ´es ayant un mË†eme label mais qui

ne sont pas reliÂ´ees.

Figure 3.2 â€“ Exemple dâ€™une mauvaise propagation donnant des communautÂ´es avec le
mË†eme label. s7 a transmis son label `a deux structures communautaires
OpÂ´erations de la ï¬gure 3.2 : s2 â† s7, s4 â† s7 ,s5 â† s4,s6 â† {s4, s5},
s1 â† s2, s3 â† {s2, s1}, s10 â† s9, s8 â† {s9, s10}, s9 â† {s8, s10} and s7 â†
{s8, s9, s10}.

Lâ€™idÂ´ee est donc dâ€™imaginer une mÂ´ethode pour interdire ce genre de mauvaises

propagations.

3.1.1 Propagation de labels asynchrone avec barrages

La solution que nous proposons est de mettre des barrages artiï¬ciels per-
mettant de stopper certaines propagations, particuli`erement sur des liens o`u le
risque de mauvaises propagations est Â´elevÂ´e, ce qui pourrait induire par la suite
la crÂ´eation de trop grandes communautÂ´es.

La propagation de labels avec barrages a pour objectif de dÂ´etecter des com-
munautÂ´es, en utilisant `a la fois lâ€™information globale topologique du graphe et
une mÂ´ethode locale. La propagation de labels souï¬€rant dâ€™instabilitÂ´e et du fait

90

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

de produire de trop grandes communautÂ´es, nous proposons une mÂ´ethode pour
rÂ´esoudre ces deux probl`emes en interdisant `a certaines arË†etes de propager un
label tout en eï¬€ectuant une dÂ´etection de cÅ“urs en lanÂ¸cant plusieurs fois lâ€™al-
gorithme non dÂ´eterministe. Pour une raison de stabilisation (Raghavan et al.
(2007)), nous privilÂ´egions la version asynchrone de la propagation de labels.

Les mesures issues de lâ€™analyse des rÂ´eseaux sociaux peuvent se rÂ´evÂ´eler tr`es
utiles pour connaË†Ä±tre lâ€™importance de certaines arË†etes ou sommets au sein dâ€™un
graphe. Nous proposons dâ€™utiliser la mesure dâ€™intermÂ´ediaritÂ´e de Girvan et New-
man (2002a) (prÂ´esentÂ´ee au premier chapitre) qui nous permettra de placer des
barrages lors de lâ€™exÂ´ecution de la propagation de labels. Ce choix vient du fait
que cette mesure permet de dÂ´eceler des arË†etes connectant des groupes de nÅ“uds
gÂ´enÂ´eralement densÂ´ement connectÂ´es.

Nous proposons dâ€™utiliser la centralitÂ´e dâ€™intermÂ´ediaritÂ´e pour mettre nos bar-
rages et Â´eviter lâ€™obtention de trop grandes communautÂ´es. Nous notons cet al-
gorithme, la propagation de labels avec barrages (PLAB) (Algorithme 2). La
complexitÂ´e de la centralitÂ´e dâ€™intermÂ´ediaritÂ´e Â´etant en O(n3) (Fortunato (2010)),
la complexitÂ´e de PLAB est en O(n3 + k(m âˆ’ Î² Ã— m)), o`u k est le nombre
dâ€™itÂ´erations pour les diï¬€Â´erentes propagations de labels.

Algorithme 2 PLAB
Param`etres : Un graphe G = (V, E), un rÂ´eel Î² (pourcentage de barrages)
Sortie : Une partition P = {P1, ..., PC} (communautÂ´es de G)
1: Calcul de la centralitÂ´e dâ€™intermÂ´ediaritÂ´e de G
2: SÂ´electionner Î² pourcentage des arË†etes ayant les plus grandes valeurs de

centralitÂ´e dâ€™intermÂ´ediaritÂ´e et mettre des barrages

3: Lancer la propagation de labels asynchrone.
4: Retourner Une partition P = {P1, ..., PC}

Figure 3.3 â€“ Exemples de propagation de labels avec barrages a) le graphe originel b)
mise en place dâ€™un barrage sur lâ€™arË†ete avec la plus forte centralitÂ´e dâ€™intermÂ´ediaritÂ´e c)
lancement de la propagation de labels

Dans lâ€™exemple de la ï¬gure 3.3, le graphe comprend 6 sommets. On calcule
dans un premier temps la centralitÂ´e dâ€™intermÂ´ediaritÂ´e des arË†etes. Un tri est alors
eï¬€ectuÂ´e sur les arË†etes. Une sÂ´election permet de prendre lâ€™arË†ete ayant la plus

3.1. LPA AVEC BARRAGES ET DENDROGRAMMES

91

grande valeur dâ€™intermÂ´ediaritÂ´e. On place alors un barrage artiï¬ciel qui sera uti-
lisÂ´e lors de la propagation de labels. Ce barrage interdit `a la propagation de
sâ€™eï¬€ectuer. On trouve par la suite deux communautÂ´es.

Notre premi`ere Â´etude consiste `a apprÂ´ecier la mise en place de barrages aï¬n
dâ€™observer une possible amÂ´elioration de la qualitÂ´e par rapport `a la propagation
de labels standards. Nous proposons de faire varier le nombre de barrages sur
certains rÂ´eseaux classiques de la littÂ´erature dont nous connaissons les vraies
structures communautaires, tout en calculant les mesures supervisÂ´ees et non
supervisÂ´ees.

En utilisant PLAB sur le rÂ´eseau de karatÂ´e, la Figure 3.4, lâ€™ajout de bar-
rages nâ€™amÂ´eliore pas signiï¬cativement la qualitÂ´e de partitionnement. La qualitÂ´e
se dÂ´etÂ´eriore par la suite avec une augmentation du nombre de communautÂ´es.
Cependant, les rÂ´esultats ne sont pas stables. On peut voir lâ€™exemple sur le NMI,
la Figure 3.4c, la prÂ´esence de nombreux pics respectivement `a 20%, 40% et 60%.
Cela est dË†u `a lâ€™instabilitÂ´e de la dÂ´etection de communautÂ´es qui ne produit que
tr`es rarement le mË†eme rÂ´esultat dâ€™un test `a un autre. On peut ainsi ne pas obte-
nir une dÂ´ecroissance linÂ´eaire, mais avec cassures.

En considÂ´erant lâ€™exemple des clubs de foot o`u les communautÂ´es rÂ´eprÂ´esentent
des confÂ´erences, sur la Figure 3.5, on voit que lâ€™apport de barrages augmente
sensiblement la qualitÂ´e de partitionnement. De 2, 5% `a 55% de barrages, les
rÂ´esultats sont meilleurs que ceux du LPA, avec un NMI atteignant 0.93 pour
PLAB par rapport `a 0.88 pour le LPA. Des pics rÂ´ecurrents apparaissent, signa-
lant lâ€™instabilitÂ´e de la mÂ´ethode.

3.1.2 Propagation de labels asynchrone avec barrages et

dÂ´etection de cÅ“urs

Lâ€™algorithme PLAB prÂ´esente deux inconvÂ´enients : le choix du nombre de
barrages, et lâ€™instabilitÂ´e rÂ´eduite, mais toujours prÂ´esente. Pour remÂ´edier `a ces
probl`emes nous proposons deux algorithmes fondÂ´es sur la dÂ´etection de cÅ“urs.
Le premier algorithme est fondÂ´e sur lâ€™optimisation dâ€™une fonction de qualitÂ´e qui
peut par exemple Ë†etre la modularitÂ´e ou la conductance. Nous eï¬€ectuons plu-
sieurs fois PLAB avec un certain Î² (le pourcentage de barrages sur les arË†etes
ayant la plus forte valeur de centralitÂ´e dâ€™intermÂ´ediaritÂ´e) pour alimenter une ma-
trice de frÂ´equence. Cette matrice permet de voir, pour chaque paire de nÅ“uds
i et j, le nombre de fois quâ€™ils sont dans la mË†eme communautÂ´e au cours des N
propagations de labels. Nous recommenÂ¸cons le procÂ´edÂ´e en changeant la valeur
de Î², Î² variant de 0 `a 1 par un pas âˆ† choisi par lâ€™utilisateur avec une nouvelle
matrice de frÂ´equence de frÂ´equence. Pour chaque matrice de frÂ´equence, nous cal-
culons les composantes connexes qui reprÂ´esentent les communautÂ´es et eï¬€ectuons
une Â´evaluation avec une fonction de qualitÂ´e et en utilisant un seuil Î±. Le seuil Î±
est un rÂ´eel positif permettant de crÂ´eer un nouveau graphe `a partir dâ€™une matrice

92

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

Mesure supervisÂ´ees

Mesure non supervisÂ´ees

(a) La puretÂ´e

(b) La conductance

(c) Le NMI

(d) La modularitÂ´e

(e) ARI

(f) #

Figure 3.4 â€“ Mesures supervisÂ´ees et non supervisÂ´ees avec PLAB sur le rÂ´eseau Zachary.
# reprÂ´esente le nombre de communautÂ´es. Lâ€™axe des abcisses reprÂ´esente le pourcentage
de barrages.

de frÂ´equence. En faisant varier Î± de 0 `a 1 par un certain pas âˆ†, il est possible
dâ€™obtenir un dendrogramme. Chaque matrice de frÂ´equence donne un dendro-
gramme en faisant varier le seuil Î±. Parmi tous les dendrogrammes, le rÂ´esultat
ayant le score optimal de modularitÂ´e ou de conductance permet de retourner une
partition. La complexitÂ´e de lâ€™algorithme est en O(n3 + 1
o`u k est le nombre dâ€™itÂ´erations pour les diï¬€Â´erentes propagations de labels.
Nous exposons ci-dessous la multiple propagations de labels avec barrages et
stabilisation avec optimisation dâ€™une fonction de qualitÂ´e (MPLBS) (Algorithme
3).

âˆ† Ã— k Ã—N Ã— (mâˆ’ Î²m)),

3.1. LPA AVEC BARRAGES ET DENDROGRAMMES

93

Mesure supervisÂ´ees

Mesure non supervisÂ´ees

(a) La puretÂ´e

(b) La conductance

(c) Le NMI

(d) La modularitÂ´e

(e) ARI

(f) #

Figure 3.5 â€“ Mesures supervisÂ´ees et non supervisÂ´ees avec PLAB sur le rÂ´eseau foot-
ballistique. # reprÂ´esente le nombre de communautÂ´es. Lâ€™axe des abcisses reprÂ´esente le
pourcentage de barrages.

Nous donnons un exemple dâ€™application sur un petit graphe de la mÂ´ethode

MPLBS, Figure 3.6. Dans cet exemple, chaque matrice est alimentÂ´ee par diï¬€Â´erentes
propagations de labels (ici 10 pour lâ€™exemple) avec un certain pourcentage de
barrages. On commence avec un barrage en appliquant 10 propagations de labels
qui alimentent une matrice de frÂ´equence, puis on alimente une nouvelle matrice
de frÂ´equence avec deux barrages et ainsi de suite jusquâ€™au nombre maximal
de barrages possibles. On sâ€™aperÂ¸coit que plus le nombre de barrages augmente,
plus la matrice de frÂ´equence se transforme en matrice diagonale. Lâ€™obtention
dâ€™une matrice diagonale signiï¬e que chaque nÅ“ud reprÂ´esente sa propre commu-
nautÂ´e. En utilisant un seuil Î± que lâ€™on fait varier entre 0 et 1, nous pouvons
obtenir diï¬€Â´erents dendrogrammes selon les valeurs des Â´elÂ´ements de la matrice
de frÂ´equence. Nous voyons que certaines matrices de frÂ´equences sont identiques

94

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

Algorithme 3 MPLBS
Param`etres : Un graphe G = (V, E), un seuil Î±, N le nombre de propagations

de labels, âˆ† le pas

Sortie : communautÂ´es de G

1: Calcul de la centralitÂ´e dâ€™intermÂ´ediaritÂ´e de G
2: Liste P artition = []
3: Pour j = 0 `a 1 avec un pas de âˆ† Faire
4: Mettre des barrages sur les j Ã— |E| arË†etes ayant les plus grandes valeurs

5:

6:

7:

ij (j)

ij (j) en lanÂ¸cant N fois la propagation de labels

dâ€™intermÂ´ediaritÂ´e
Allouer une matrice vide P N
Alimenter la matrice P N
sur le graphe avec barrages.
CrÂ´eer un nouveau graphe G(cid:48) = (V, E(cid:48)) en partant de P N
arË†etes dont la pondÂ´eration est Â´egale ou supÂ´erieure `a Î±
CrÂ´eer une partition Pj en considÂ´erant les C composantes connexes.
Liste P artition.ajouter(Pj)
j = j + âˆ†

8:
9:
10:
11: Fin Pour
12: Retourner la partition Pk de Liste P artition avec le meilleur score de la

ij (j) avec des

fonction de qualitÂ´e choisie par lâ€™utilisateur : P âˆ—

k = {P1, ..., PC}

avec un nombre diï¬€Â´erent de barrages. Pour sÂ´electionner le dendrogramme pou-
vant donner le meilleur rÂ´esultat en termes de qualitÂ´e de partitionnement, nous
utilisons les mesures non supervisÂ´ees de modularitÂ´e et de conductance.

Le second algorithme fait varier le nombre de barrages en alimentant une
seule matrice de frÂ´equence, puis dÂ´etecte les composantes connexes. Lâ€™idÂ´ee est
quâ€™alimenter une matrice de frÂ´equence par une mË†eme mÂ´ethode, qui ne produit
pas toujours de bons rÂ´esultats ne peut pas Ë†etre satisfaisant. Lâ€™alimentation est
faite en lanÂ¸cant la mÂ´ethode non dÂ´eterministe sÂ´equentiellement un nombre N
de fois pour remplir la matrice de frÂ´equence, et ainsi voir les nÅ“uds ayant une
forte probabilitÂ´e dâ€™Ë†etre dans une mË†eme communautÂ´e. Cependant, alimenter une
matrice, avec diï¬€Â´erentes mÂ´ethodes, ayant diï¬€Â´erents niveaux de barrage pourrait
amÂ´eliorer la qualitÂ´e des composantes connexes trouvÂ´ees pour la dÂ´etection de
communautÂ´e. Lâ€™algorithme prend en param`etre, outre le seuil Î± et le nombre
dâ€™essais N , lâ€™intervalle considÂ´erÂ´e pour lâ€™alimentation de notre matrice, âˆ†[x;y],
x âˆˆ [0, 1],y âˆˆ [0, 1] et x < y, avec un pas pour parcourir cet intervalle âˆ†.
Nous exposons ci-dessous lâ€™algorithme de propagation de labels avec barrages
utilisant la stabilisation (PLBS) (Algorithme 4). La complexitÂ´e de lâ€™algorithme
est en O(n3 + k Ã— N Ã— (m âˆ’ Î²m) Ã— (yâˆ’x)
âˆ† ), o`u k est le nombre dâ€™itÂ´erations
pour les diï¬€Â´erentes propagations de labels. Nous exposons un exemple dâ€™appli-
cation de la mÂ´ethode PLBS, Figure 3.7. Dans cet exemple, une seule matrice
de frÂ´equence est alimentÂ´ee par diï¬€Â´erentes propagations de labels avec des pour-
centages de barrages diï¬€Â´erents. Nous observons que nous obtenons une matrice

3.1. LPA AVEC BARRAGES ET DENDROGRAMMES

95

Figure 3.6 â€“ Exemple de la multiple propagations de labels avec barrages et stabilisa-
tion avec optimisation dâ€™une fonction de qualitÂ´e

96

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

par bloc. Bien que le graphe poss`ede une structure de symÂ´etrie (deux triangles),
on peut observer que les valeurs des Â´elÂ´ements dans la matrice de frÂ´equence sont
diï¬€Â´erents, notamment en comparant les triangles a, b, c et d, e, f . Cela vient
du fait que lorsquâ€™il existe une symÂ´etrie, le choix pour mettre un barrage est
alÂ´eatoire. Ainsi, il est possible que des barrages se mettent dans une structure
communautaire alors quâ€™une autre structure, identique, attendra plus tard pour
la mise en place de barrages en son sein. Par alimentation, les valeurs dans ces
structures symÂ´etriques sont diï¬€Â´erentes, ce qui explique que la frÂ´equence dâ€™ap-
partition des nÅ“uds e et d soit de 0.4, diï¬€Â´erente de la frÂ´equence dâ€™apparition
au sein dâ€™une mË†eme communautÂ´e des nÅ“uds a et c, qui est de 0.3. En utilisiant
un seuil Î±, que lâ€™on fait varier entre 0 et 1, un dendrogramme apparaË†Ä±t. Nous
utilisons les mesures non supervisÂ´ees de modularitÂ´e et de conductance pour re-
tourner la partition selon la valeur de Î±.

Algorithme 4 PLBS
Param`etres : Un graphe G = (V, E), un seuil Î±, N le nombre de propagations

de labels, âˆ† le pas, lâ€™intervalle pour lâ€™alimentation âˆ†[x;y]

Sortie : communautÂ´es de G

Calcul de la centralitÂ´e dâ€™intermÂ´ediaritÂ´e de G

Pour j = x `a y avec un pas âˆ† Faire

2: Allocation dâ€™une matrice de frÂ´equence vide
4: Mettre des barrages sur les j Ã— |E| arË†etes ayant les plus grandes valeurs
dâ€™intermÂ´ediaritÂ´e
Lancer N fois la propagation de labels avec un nombre diï¬€Â´erent de bar-
rages
Remplir la matrice de frÂ´equence avec les rÂ´esultats des diï¬€Â´erentes propa-
gations de labels
j = j + âˆ†

6:

8: Fin Pour

CrÂ´eer un nouveau graphe G(cid:48) = (V, E(cid:48)) en partant de P N
dont la pondÂ´eration est Â´egale ou supÂ´erieure `a Î±
Retourner La partition P = {P1, ..., PC}.

10: CrÂ´eer une partition P en considÂ´erant les C composantes connexes.

ij avec des arË†etes

Enï¬n, nous proposons la propagation de labels avec dÂ´etection de cÅ“urs sans
barrage, notÂ´ee CDLP. La complexitÂ´e de lâ€™algorithme est en O(N Ã— kÃ— (n + m)),
o`u k est le nombre dâ€™itÂ´erations pour les diï¬€Â´erentes propagations de labels. Nous
donnons un exemple de la propagation de labels avec dÂ´etection de cÅ“urs `a la
Figure 3.8. Dans cet exemple, une seule matrice de frÂ´equence est alimentÂ´ee par
diï¬€Â´erentes propagations de labels. On voit que la matrice de frÂ´equence donne
une matrice par bloc, avec des valeurs diï¬€Â´erentes entre certaines paires de nÅ“uds
permettant de voir les deux structures communautaires. En faisant varier Î± de
0 `a 1 pour obtenir un dendrogramme, on sâ€™aperÂ¸coit que des valeurs diï¬€Â´erentes
de Î± donnent parfois de mË†emes partitions. Nous utilisons les mesures non su-

3.1. LPA AVEC BARRAGES ET DENDROGRAMMES

97

Figure 3.7 â€“ Exemple de la propagation de labels avec barrages utilisant la stabilisation

pervisÂ´ees de modularitÂ´e et de conductance pour retourner la partition selon la
valeur de Î±. Lâ€™objectif dâ€™utiliser le CDLP dans nos futures expÂ´erimentations est
dâ€™observer si des barrages peuvent donner de meilleurs rÂ´esultats en termes de
qualitÂ´e de partitionnement.

Algorithme 5 CDLP
Param`etres : Un graphe G = (V, E), un seuil Î±, N le nombre de propagations

de labels

Sortie : communautÂ´es de G
2: Lancer N fois la propagation de labels asynchrone.

Allocation dâ€™une matrice de frÂ´equence vide

Remplir la matrice de frÂ´equence avec les rÂ´esultats des diï¬€Â´erentes propaga-
tions de labels.

4: CrÂ´eer un nouveau graphe G(cid:48) = (V, E(cid:48)) en partant de P N

ij avec des arË†etes

dont la pondÂ´eration est Â´egale ou supÂ´erieure `a Î±
CreÂ´er une partition P en considÂ´erant les C composantes connexes.

6: Retourner la partition P = {P1, ..., PC}.

98

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

Figure 3.8 â€“ Exemple de la propagation de labels avec dÂ´etection de cÅ“urs

3.1.3 ExpÂ´erimentations portant sur les propositions algo-
rithmiques pour la dÂ´etection de communautÂ´es dis-
jointes

Nous nous proposons dâ€™eï¬€ectuer notre Â´etude sur des rÂ´eseaux rÂ´eels modÂ´elisant
des phÂ´enom`enes sociologiques, pour lesquels des experts ont Â´etabli les com-
munautÂ´es quâ€™ils jugent correctes. Cependant, certains rÂ´eseaux rÂ´eels nâ€™ont pas
bÂ´enÂ´eï¬ciÂ´e dâ€™Â´etudes permettant de connaË†Ä±tre les vÂ´eritables partitions, câ€™est en ce
sens que nous nâ€™utiliserons que les mesures non supervisÂ´ees sur ces derni`eres.

Les rÂ´esultats du PLBS et du MPLBS seront donnÂ´es dans un tableau avec
un pas faible âˆ† = 0, 025. La ligne des abscisses reprÂ´esente le pourcentage de
barrages alors que lâ€™ordonnÂ´ee reprÂ´esente le score avec la matrice de frÂ´equence
relative au nombre de barrages. Pour le PLBS, nous choisirons 3 intervalles,
âˆ†[0.0;0.33] ; âˆ†[0.33;0.66] et âˆ†[0.66;1.0], en utilisant un pas âˆ† = 0.025.

Dans la suite de cette Â´etude, nous avons utilisÂ´e une machine Predator G3,

IntelCoreT M i5 processeur 4440, 3,60 Ghz avec 16 GO de RAM. Le dÂ´eveloppement
des algorithmes est en Python 2.7.

Stabilisation du CDLP

Lâ€™une des premi`eres Â´etudes porte sur le nombre de propagations de labels

permettant de stabiliser la propagation de labels, avec le CDLP.

3.1. LPA AVEC BARRAGES ET DENDROGRAMMES

99

Figure 3.9 â€“ Stabilisation

Figure 3.10 â€“ Conductance

100

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

Figure 3.11 â€“ #

Nous observons que la valeur Î± joue un rË†ole sur la stabilisation du LPA,
Figure 3.9. Pour Î± â‰¥ 0.5, on voit quâ€™il faut `a peu pr`es 80 itÂ´erations pour arriver
`a stabilisation. Pour Î± â‰¥ 0.6, la stabilisation se fait apr`es 54 propagations de
labels. En considÂ´erant la conductance pour son information sur la densitÂ´e intra
et inter communautÂ´e, Figure 3.10, plus Î± est important, plus la stabilisation
arrivera rapidement, avec plus de communautÂ´es de petites tailles, Figure 3.11.

3.1. LPA AVEC BARRAGES ET DENDROGRAMMES

101

Etude expÂ´erimentale sur le MLPBS

Nous avons lancÂ´e la propagation de labels avec barrages et dÂ´etections de
cÅ“urs sur des rÂ´eseaux dont nous connaissions dâ€™avance les vraies communautÂ´es,
mais aussi sur certains o`u ce nâ€™est pas le cas. Nous avons choisi pour tous
les rÂ´eseaux un nombre de propagations de labels pour alimenter la matrice de
frÂ´equence de N = 100. Le seuil permettant de crÂ´eer les composantes connexes `a
partir de la matrice de frÂ´equence se situera dans lâ€™intervalle Î± âˆˆ [0, 3; 0, 8] avec
un pas de 0, 1

Graphe avec vÂ´eritÂ´e de terrains

Pour Zachary, Figure 3.12, nous observons que les rÂ´esultats sont assez diï¬€Â´erents
selon les valeurs du seuil Î±. Pour Î± â‰¥ {0.3, ..., 0.5}, la mise en place de barrages
a une incidence sur la dÂ´etection de communautÂ´es. De base, CDLP ne trouve
quâ€™une grande communautÂ´e. Câ€™est entre 20% et 45% de barrages que la mÂ´ethode
obtient de meilleurs rÂ´esultats. Pour Î± â‰¥ 0, 6, on obtient un pic du NMI `a 0.78
`a 20% de barrages. Pour de tr`es fortes valeurs de Î±, la prÂ´esence des barrages
ne permet pas dâ€™amÂ´eliorations notables de la qualitÂ´e de partitionnement, ce qui
est le cas pour Î± â‰¥ {0, 7; 0, 8}. Plus le nombre de barrages augmente, moins
la propagation de labels peut sâ€™eï¬€ectuer. On voit que pour toutes les valeurs
de Î±, un forte augmentation de la conductance a lieu apr`es 40% de barrages,
avec une augmentation du nombre de communautÂ´es. Apr`es 60% de barrages,
on voit une convergence pour toutes les valeurs Î±, due au tr`es grand nombre de
barrages. Pour ce graphe, lâ€™utilisation des barrages semble intÂ´eressante pour de
faibles valeurs de Î±.

102

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

Mesures supervisÂ´ees

Mesures non supervisÂ´ees

(a) NMI

(b) Nombre de communautÂ´es

(c) ARI

(d) ModularitÂ´e

(e) PuretÂ´e

(f) Conductance

Figure 3.12 â€“ RÂ´esultat de la propagation de labels avec barrages et dÂ´etection de cÅ“urs
sur Zachary (lâ€™axe des ordonnÂ´ees reprÂ´esente les scores des mesures supervisÂ´ees et non
supervisÂ´ees, lâ€™axe des abscisses reprÂ´esente le pourcentage de barrages).

Pour le club de football, Figures 3.13b, 3.13a, 3.13f, 3.13d 3.13e et 3.13c,
la qualitÂ´e augmente jusquâ€™`a 50% de barrages. La matrice de frÂ´equence stabilise
correctement le LPA, sans prÂ´esence de grands pics. Le nombre de communautÂ´es
nâ€™augmente que tr`es faiblement jusquâ€™`a 40% et stagne jusquâ€™`a 50%. Les arË†etes
o`u les barrages ont Â´etÂ´e mis sont sur les liens qui lient les communautÂ´es entre
elles. Apr`es 55% de barrages, la qualitÂ´e se dÂ´etÂ´eriore tr`es rapidement. Selon nos
observations, câ€™est `a partir de ce seuil que les barrages se mettent dans des
zones fortement denses, câ€™est-`a-dire dans des sous graphes complets, ce qui a
pour consÂ´equence de dÂ´etruire les structures communautaires. La propagation
de labels ne peut plus sâ€™eï¬€ectuer et la qualitÂ´e de partitionnement se dÂ´etÂ´eriore.

3.1. LPA AVEC BARRAGES ET DENDROGRAMMES

103

Mesures supervisÂ´ees

Mesures non supervisÂ´ees

(a) NMI

(b) Nombre de communautÂ´es

(c) ARI

(d) ModularitÂ´e

(e) PuretÂ´e

(f) Conductance

Figure 3.13 â€“ RÂ´esultat de la propagation de labels avec barrages et dÂ´etection de cÅ“urs
sur le rÂ´eseau footballistique (lâ€™axe des ordonnÂ´ees reprÂ´esente les scores de mesures su-
pervisÂ´ees et non supervisÂ´ees, lâ€™axe des abscisses reprÂ´esente le pourcentage de barrages).

Pour le rÂ´eseau de dauphins, Figures 3.14, les meilleurs rÂ´esultats sont obtenus
pour Î± â‰¥ {0.3, 0.4}. La qualitÂ´e se dÂ´etÂ´eriore apr`es Î± â‰¥ 0.6. Pour Î± â‰¥ 0.3, jusquâ€™`a
7.5% de barrages, aucune communautÂ´e nâ€™est dÂ´etectÂ´ee `a 10%, deux communautÂ´es
sont dÂ´etectÂ´ees avec un NMI de 0.95. Pour de faibles valeurs de Î±, la mise en
place de barrages peut se rÂ´evÂ´eler bÂ´enÂ´eï¬que et permet dâ€™amÂ´eliorer la qualitÂ´e de
la dÂ´etection de communautÂ´es, ce qui nâ€™est pas le cas pour des valeurs de Î± tr`es
Â´elevÂ´ees. Pour Î± â‰¥ 0.8, les conductances sont tr`es Â´elevÂ´ees et lâ€™utilisation de bar-
rages devient inutile.

104

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

Mesures supervisÂ´ees

Mesures non supervisÂ´ees

(a) NMI

(b) Nombre de communautÂ´es

(c) ARI

(d) ModularitÂ´e

(e) PuretÂ´e

(f) Conductance

Figure 3.14 â€“ RÂ´esultat de la propagation de labels avec barrages et dÂ´etection de cÅ“urs
sur le rÂ´eseau de dauphins (lâ€™axe des ordonnÂ´ees reprÂ´esente les scores de mesures super-
visÂ´ees et non supervisÂ´ees, lâ€™axe des abscisses reprÂ´esente le pourcentage de barrages).

3.1. LPA AVEC BARRAGES ET DENDROGRAMMES

105

Pour les livres politiques de Krebs, Figures 3.15, jusquâ€™`a 10%, le nombre de
communautÂ´es reste stable avec un bon NMI et un bon ARI. Puis, ce nombre
augmente de mani`ere proportionnelle avec le nombre de barrages.

Mesures supervisÂ´ees

Mesures non supervisÂ´ees

(a) NMI

(b) Nombre de communautÂ´es

(c) ARI

(d) ModularitÂ´e

(e) PuretÂ´e

(f) Conductance

Figure 3.15 â€“ RÂ´esultat de la propagation de labels avec barrages et dÂ´etection de cÅ“urs
sur les livres politiques de Krebs (lâ€™axe des ordonnÂ´ees reprÂ´esente les scores de me-
sures supervisÂ´ees et non supervisÂ´ees, lâ€™axe des abscisses reprÂ´esente le pourcentage de
barrages).

Les premiers rÂ´esultats de ces expÂ´erimentations permettent dâ€™aï¬ƒrmer que la
qualitÂ´e de partionnement avec la mise en place de barrages sera fonction de la
valeur de Î±. Si la valeur de Î± est faible ( Î± â‰¤ 0, 3 ), le graphe est considÂ´erÂ´e
comme une seule communautÂ´e. Lâ€™algorithme se comportera comme si on enl`eve
les arË†etes ayant la plus forte centralitÂ´e dâ€™intermÂ´ediaritÂ´e. Pour une valeur de Î±
comprise entre 0, 3 et 0, 7, notamment pour les graphes sociaux, la mise en place

106

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

de barrages permet dâ€™amÂ´eliorer la qualitÂ´e de partitionnement jusquâ€™`a un certain
seuil. Les observations montrent que le nombre de barrages pour une partition
de bonne qualitÂ´e tourne autour de 25% `a 40% sur les rÂ´eseaux sociaux. Pour
un Î± fort (â‰¥ 0, 8 pour les graphes sociaux), la mise en place de barrages nâ€™a
pas dâ€™eï¬€et signiï¬catif sur la qualitÂ´e de partitionnement, les communautÂ´es Â´etant
de petites tailles. Cependant, un pourcentage trop Â´elevÂ´e de barrages dÂ´etÂ´eriore
la qualitÂ´e de partitionnement car ces derniers se mettent sur des sous-graphes
complets, des cliques.

Graphe sans connaissance des communautÂ´es de terrains

Le rÂ´eseau de jazz Gleiser et Danon (2003) est un graphe o`u les nÅ“uds sont
les musiciens et les liens le fait quâ€™ils aient jouÂ´e ensemble ou pas. Il comporte
198 nÅ“uds pour 5484 arË†etes. On observe dans ce cas que Î± joue un rË†ole im-
portant sur la stabilitÂ´e et la qualitÂ´e de lâ€™algorithme. Pour Î± â‰¥ {0, 3; 0, 4}, la
modularitÂ´e est faible avec un pic entre 15% et 20% de barrages puis `a 65%.
Un faible Î± ne permet pas de trouver de bonnes structure communautaires. Les
meilleurs rÂ´esultats de la modularitÂ´e sont atteints avec Î± â‰¥ {0, 7; 0, 8}, o`u il nâ€™y a
pas de prÂ´esence de cassures. Les communautÂ´es Â´etant de plus petites tailles, cela
diminue le risque de mauvaise propagation. Les meilleurs rÂ´esultats sont atteints
entre 15% et 20% de barrages. On voit dâ€™ailleurs la conductance plus Â´elevÂ´ee avec
Î± â‰¥ {0, 7; 0, 8} que pour Î± â‰¥ {0, 3; 0, 4}.

(a) Conductance

(b) #

(c) ModularitÂ´e

Figure 3.16 â€“ RÂ´esultat de la propagation de labels avec barrages et dÂ´etection de cÅ“urs
sur le rÂ´eseau de musiciens de jazz avec Î± â‰¥ 0, 5 (lâ€™axe des ordonnÂ´ees reprÂ´esente les
scores des mesures supervisÂ´ees et non supervisÂ´ees, lâ€™axe des abscisses, le pourcentage
de barrages). # dÂ´enote le nombre de communautÂ´es.

3.1. LPA AVEC BARRAGES ET DENDROGRAMMES

107

Le rÂ´eseau Netscience Newman (2006) est un graphe de collaboration dans
le domaine des rÂ´eseaux et leurs applications. Il comprend 1589 nÅ“uds et 2742
arË†etes. Les liens se font en utilisant la condition â€ lâ€™auteur X a Â´ecrit de mani`ere
conjointe un travail avec lâ€™auteur Y â€.

(a) Conductance

(b) #

(c) ModularitÂ´e

Figure 3.17 â€“ RÂ´esultat de la propagation de labels avec barrages et dÂ´etection de cÅ“urs
sur le rÂ´eseau de collaboration scientiï¬que Netscience (lâ€™axe des ordonnÂ´ees reprÂ´esente
les scores des mesures supervisÂ´ees et non supervisÂ´ees, lâ€™axe des abscisses le pourcentage
de barrages). # dÂ´enote le nombre de communautÂ´es.

Les rÂ´esultats sont quasi-linÂ´eaires en fonction du nombre de barrages. Il sâ€™agit
dâ€™un exemple o`u le fait de mettre des barrages nâ€™apporte pas dâ€™amÂ´elioration dans
le partitionnement.

Le rÂ´eseau US-Air 97 est un graphe reprÂ´esentant des infrastructures pour le
transport aÂ´erien entre le Canada, les Etats-Unis et le Mexique. Il comprend 332
nÅ“uds et 2126 arË†etes. Les communautÂ´es reprÂ´esentent des infrastructures comme
des aÂ´eroports, et les arË†etes, leurs connexions. Cependant, elles y sont tr`es rares,
ce graphe ayant une distribution des degrÂ´es des nÅ“uds assez uniforme.

(a) Conductance

(b) #

(c) ModularitÂ´e

Figure 3.18 â€“ RÂ´esultat de la propagation de labels avec barrages et dÂ´etection de cÅ“urs
sur le rÂ´eseau de collaboration scientiï¬que Netscience avec Î± â‰¥ 0.5 (lâ€™axe des ordonnÂ´ees
reprÂ´esente les scores des mesures supervisÂ´ees et non supervisÂ´ees, lâ€™axe des abscisses, le
pourcentage de barrages). # dÂ´enote le nombre de communautÂ´es.

Lâ€™obtention de la modularitÂ´e maximale requiert pr`es de 80% de barrages.
Ceci sâ€™explique par le fait que ce graphe nâ€™a pas de vÂ´eritables structures com-
munautaires.

108

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

De ces analyses, nous pouvons observer que des intervalles sont plus propices
`a donner de meilleurs rÂ´esultats que dâ€™autres, ce qui nous a amenÂ´e `a lâ€™Â´elaboration
du PLBS.

3.1. LPA AVEC BARRAGES ET DENDROGRAMMES

109

Etudes expÂ´erimentales portant sur le PLBS

MPLBS retournait la meilleure partition sur un intervalle, mais au prix dâ€™une
forte complexitÂ´e. PLBS nâ€™utilise plus quâ€™une seule matrice de frÂ´equence, dont
lâ€™alimentation se fait sur un intervalle spÂ´eciï¬que.

Algorithmes
Zac #2
âˆ†[0.0;0.3]
âˆ†[0.3;0.6]
âˆ†[0.6;1.0]
Foot #11
âˆ†[0.0;0.3]
âˆ†[0.3;0.6]
âˆ†[0.6;1.0]
Dauphins #2
âˆ†[0.0;0.3]
âˆ†[0.3;0.6]
âˆ†[0.6;1.0]
Pol #3
âˆ†[0.0;0.3]
âˆ†[0.3;0.6]
âˆ†[0.6;1.0]

Experiences portant sur PLBS

Q

Î¦

NMI

ARI

PuretÂ´e #

0.1314
0.378
0.0736

0.599
0.5844
0.3133

0.2749
0.3924
0.281

0.4961
0.4594
0.2122

0.0309
0.0728
0.5502

0.012
0.0419
0.3271

0.0684
0.4098
0.6943

0.0288
0.104
0.3129

0.2283
0.5653
0.3773

0.9108
0.9311
0.8309

0.5466
0.4558
0.3283

0.5649
0.6006
0.4344

0.0908
0.498
0.068

0.8523
0.9066
0.622

0.5968
0.2991
0.0708

0.6713
0.6684
0.1941

0.6765
0.9706

1.0

0.913
0.9565
0.9913

0.9032

1.0
1.0

0.8571
0.9333
0.9619

3
6
23

12
16
48

3
18
35

6
16
45

Tableau 3.1 â€“ RÂ´esultats du PLBS sur des rÂ´eseaux connus de la littÂ´erature

A partir du tableau 3.1, les meilleurs rÂ´esultats pour les rÂ´eseaux Zac,Pol et
Foot sont en prenant lâ€™intervalle [0.3, 0.6] (en faisant donc varier le nombre de
barrages de 30 `a 60 %.), permettant lâ€™alimentation de la matrice de frÂ´equence.
Pour les dauphins, il sâ€™agit de lâ€™intervalle [0.0, 0.3]. Nous notons que plus les
bornes de lâ€™intervalle ont des valeurs importantes (avec un pourcentage de bar-
rages assez fort), plus le nombre de communautÂ´es est important. Cela sâ€™explique
du fait que la propagation ne peut plus sâ€™eï¬€ectuer dans certaines rÂ´egions du
graphe. Par voie de consÂ´equence, plus le nombre de communautÂ´es est important,
plus les densitÂ´es de ces derni`eres augmentent, ce qui entraË†Ä±ne une augmentation
de la conductance. On observe que la qualitÂ´e des communautÂ´es se dÂ´egrade, avec
un NMI et un ARI tendant vers 0.

Etudes comparative entre le PLBS et CDLP

Nous proposons dâ€™analyser le comportement du PLBS vis-`a-vis de CDLP
sur de petits graphes rÂ´eels. Lâ€™objectif est dâ€™observer lâ€™impact du pourcentage de
barrages lors de lâ€™alimentation de la matrice du PLBS sur la qualitÂ´e de partition-
nement, dâ€™observer la sensibilitÂ´e des mÂ´ethodes vis-`a-vis du seuil Î± (qui permet de
crÂ´eer le graphe seuillÂ´e `a partir de la matrice de frÂ´equence) et de voir si augmenter
le nombre de propagations de labels a un impact sur les partitions rÂ´esultantes.

110

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

Nous proposons dâ€™utiliser le PLBS alimentÂ´e par 10%, 20% puis par 30% de
barrages avec comme fonction supervisÂ´ee le NMI, et avec N = 100, N = 500
puis N = 1000. Les Figures 3.19,3.20,3.21 et 3.22 montrent les rÂ´esultats res-
pectivement sur Zachary, les dauphins, le rÂ´eseau footballistique et le rÂ´eseau de
livres politiques vis-`a-vis du seuil Î± qui permet de crÂ´eer le graphe seuillÂ´e pour
la dÂ´etection des communautÂ´es.

Figure 3.19 â€“ Etude comparative entre PLBS et CDLP sur Zachary

Figure 3.20 â€“ Etude comparative entre PLBS et CDLP sur les dauphins

Figure 3.21 â€“ Etude comparative entre PLBS et CDLP sur le rÂ´eseau footballistique

Figure 3.22 â€“ Etude comparative entre PLBS et CDLP sur le rÂ´eseau de livres politiques

3.1. LPA AVEC BARRAGES ET DENDROGRAMMES

111

Dâ€™apr`es les expÂ´erimentations, PLBS est plus sensible aux valeurs de Î± que ne
lâ€™est CDLP. En eï¬€et, les premi`eres communautÂ´es dÂ´etectÂ´ees pour le PLBS sont
`a partir de Î± â‰¥ 0.2 pour Zachary avec 30% de barrages alors que les premi`eres
communautÂ´es avec CDLP ne sont dÂ´etectÂ´ees quâ€™`a partir de Î± â‰¥ 0.4. Pour les
livres politiques, câ€™est `a partir de Î± â‰¥ 0.20 que les premi`eres communautÂ´es sont
dÂ´etectÂ´ees avec PLBS et Î± â‰¥ 0.38 pour CDLP. De mË†eme, pour le rÂ´eseau de
dauphins, avec Î± â‰¥ 0.22 PLBS dÂ´etecte ses premi`eres communautÂ´es alors que
CDLP dÂ´etecte les siennes `a partir de Î± â‰¥ 0.40. Les communautÂ´es sont dÂ´etectÂ´ees
plus vite avec un fort pourcentage de barrage (30%).
Augmenter N ne stabilise pas davantage le PBLS. Pour le rÂ´eseau de dau-
phins, augmenter N stabilise plus le CDLP o`u des ï¬‚uctuations avec N = 100
apparaissent `a Î± = 0.45 etÎ± â‰¥ 0.58, que lâ€™on ne voit plus pour N = 500 et
N = 1000. CDLP montre des rÂ´esultats parfois meilleurs que PBLS notamment
pour Zachary, mais sur des intervalles tr`es petits. PBLS donne en moyenne de
meilleurs rÂ´esultats que CDLP. Alimenter les matrices de 10% `a 30% de barrages
donne des rÂ´esultats tr`es similaires pour PLBS pour ces types de rÂ´eseaux.

Visualisation des matrices PLBS et CDLP

Dans cette section, nous nous focalisons sur lâ€™alimentation des matrices de
frÂ´equence, mais Â´egalement sur lâ€™ajout de barrages pour lâ€™alimentation de la ma-
trice du PLBS.

Pour le CDLP, nous lanÂ¸cons sÂ´equentiellement N propagations de labels,
indÂ´ependantes les unes des autres. A chaque propagation de label, les Â´elÂ´ements
de la matrice de frÂ´equence sont incrÂ´ementÂ´es de 1. Lorsque toutes les propaga-
tions de labels ont Â´etÂ´e eï¬€ectuÂ´ees, il y a normalisation en divisant chaque Â´elÂ´ement
par N . Pour PLBS, nous verrons que la mise en place de barrages va modiï¬er
signiï¬cativement la matrice de frÂ´equence. Lâ€™idÂ´ee est Â´egalement dâ€™observer si des
zones, avec un pourcentage fort de barrages, apparaissent. Nous exposons le
CDLP et le PLBS avec diï¬€Â´erents pourcentages de barrages sur le graphe de Ka-
ratÂ´e Figure 3.23, sur celui des dauphins Figure 3.24, sur le rÂ´eseau footballistique
3.25, sur le rÂ´eseau de livres politiques 3.26 et sur le rÂ´eseau de jazz 3.27.

112

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

Figure 3.23 â€“ Matrices du PLBS et du CDLP sur Zachary

3.1. LPA AVEC BARRAGES ET DENDROGRAMMES

113

Figure 3.24 â€“ Matrices du PLBS et du CDLP sur le rÂ´eseau de dauphins

114

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

Figure 3.25 â€“ Matrices du PLBS et du CDLP sur le rÂ´eseau footballistique

3.1. LPA AVEC BARRAGES ET DENDROGRAMMES

115

Figure 3.26 â€“ Matrices du PLBS et du CDLP sur les livres politiques

116

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

Figure 3.27 â€“ Matrices du PLBS et du CDLP sur le rÂ´eseau de jazz

Les matrices rÂ´esultantes sont des matrices par bloc comme nous pouvons le
voir pour le club de KaratÂ´e, les dauphins et les livres politiques. En observant les
matrices de CDLP, nous pouvons voir des groupes de nÅ“uds qui ont une forte
probablitÂ´e dâ€™Ë†etre ensemble. Par exemple, en observant la matrice du club de
KaratÂ´e, nous voyons de petites matrice rouges, qui pour le PBLS, en augmentant
les barrages, restent prÂ´esentes. Ces liens qui ont une forte valeur sont signiï¬catifs
de la prÂ´esence de cÅ“urs. Câ€™est par exemple le cas pour le rÂ´eseau footballistique

3.1. LPA AVEC BARRAGES ET DENDROGRAMMES

117

o`u les points rouges, sont les paires de nÅ“uds se trouvant tr`es frÂ´equemment dans
les mË†emes communautÂ´es.

En augmentant le pourcentage de barrages, les matrices deviennent presque

diagonales, ce qui est le cas sur tous nos exemples.

Etude sur le temps dâ€™exÂ´ecution

Lâ€™algorithme est composÂ´e de plusieurs parties dont les temps dâ€™exÂ´ecution
sont diï¬€Â´erents les uns des autres. Nous rappelons que nous avons utilisÂ´e une
machine Predator G3, IntelCoreT M i5 processeur 4440, 3,60 Ghz avec 16 GO
de RAM. Le dÂ´eveloppement des algorithmes est en Python 2.7.

Le temps dâ€™exÂ´ecution du PLBS nÂ´ecessite 3 Â´etapes :
â€” le temps de calcul de la centralitÂ´e dâ€™intermÂ´ediaritÂ´e (âˆ†CI )
â€” le temps pour mettre les barrages, lâ€™allocation dâ€™une matrice de frÂ´equence
et son alimentation par les diï¬€Â´erentes propagations de labels (âˆ†matriceLP A)
â€” le temps pour la dÂ´etection de composantes connexes correspondant `a nos

communautÂ´es (âˆ†CC)

Cela peut se schÂ´ematiser par la formule suivante :

âˆ†TP LBS = âˆ†CI + âˆ†matriceLP A + âˆ†CC

(3.1)

Les parties de lecture et dâ€™Â´ecriture nâ€™ont pas Â´etÂ´e mises dans la mesure o`u elles ne
consid`erent pas le corps de lâ€™algorithme. Nous obtenons les rÂ´esultats suivants :
Pour lâ€™algorithme PLBS, nous prenons N = 100, un intervalle de âˆ†[x,y] =

âˆ†[0.0,0.3] avec un pas âˆ† = 0.025.

Temps dâ€™exÂ´ecution en secondes

RÂ´eseau
Zac
Dauphins
Pol
Foot
Jazz
US-Air 97
Netscience

|V | et |E|
34 \ 78
62 \ 159
105 \ 441
115 \ 615
198 \ 5484
332 \ 2126
1589 \ 2742

âˆ†CI
0.0004
0.002
0.008
0.010
0.125
0.095
0.061

âˆ†M atrice(LP A) âˆ†CC âˆ†TP LBS
0.284
0.608
4.382
4.6

0.280
0.587
4.158
4.309
15.432
16.935
91.72

0.003
0.019
0.217
0.276
0.077
0.226
1.218

15.634
17.256
93.098

Tableau 3.2 â€“ RÂ´esultats sur le temps dâ€™Â´execution du PLBS

Nous observons que la partie prenant le plus de temps concerne lâ€™alimenta-
tion de la matrice par les N propagations de labels. Pour Netscience, le temps
commence `a devenir consÂ´equent avec pr`es de 93.1 secondes. Le calcul de la cen-
tralitÂ´e dâ€™intermÂ´ediaritÂ´e est assez rapide sur Igraph, bien que sa complexitÂ´e soit
Â´elevÂ´ee.

MPLBS utilise quant `a elle K matrices diï¬€Â´erentes avec diï¬€Â´erents niveaux de

barrages. Le temps dâ€™exÂ´ecution du MPLBS comprend 4 Â´etapes :

118

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

â€” le temps de calcul de la centralitÂ´e dâ€™intermÂ´ediaritÂ´e (âˆ†CI )
â€” le temps pour mettre les barrages, lâ€™allocation des K matrices de frÂ´equence
et leur alimentation par les diï¬€Â´erentes propagation de labels (âˆ†matriceLP A)
â€” le temps pour la dÂ´etection de composantes connexes correspondant `a nos

communautÂ´es (âˆ†CC)

â€” le temps de calcul de la fonction de qualitÂ´e choisie, la modularitÂ´e âˆ†Q ou
Pour lâ€™algorithme MPLBS, nous prenons un intervalle âˆ† = 0.025 et N = 100.

la conductance âˆ†Î¦

Le temps dâ€™exÂ´ecution peut se schÂ´ematiser par la formule suivante :

âˆ†TM P LBS = âˆ†CI + âˆ†matriceLP A + âˆ†CC

(3.2)

Pour le calcul du temps global, nous sommerons le temps de calcul de la

modularitÂ´e et celui de la conductance.

RÂ´eseau
Zac
Dauphins
Pol
Foot
Jazz
US-Air 97
Netscience

âˆ†CI
0.0005
0.084
0.018
0.022
0.147
0.095
0.061

Temps dâ€™exÂ´ecution en secondes

âˆ†M atrice(LP A)

âˆ†Q

|V | et |E|
34 \ 78
62 \ 159
105 \ 441
115 \ 615
198 \ 5484
332 \ 2126
1589 \ 2742

0.0005
0.0005
0.0007
0.0009
0.0011
2.631
0.007
Tableau 3.3 â€“ RÂ´esultats sur le temps dâ€™exÂ´ecution du MPLBS

0.642
1.711
4.355
3.614
21.676
98.381
376.167

âˆ†CC
0.0006
0.001
0.002
0.002
0.006
0.042
0.02

âˆ†Î¦
0.068
0.002
0.002
0.958
0.639
0.484
73.981

âˆ†TM P LBS

0.712

1.8

4.378
4.597
22.47

101.632
450.236

En observant les Tableaux 3.2 et 3.3, nous voyons que le temps dâ€™exÂ´ecution
du MPLBS est beaucoup plus important que celui du PLBS. Cela vient du
fait quâ€™il y a 1
âˆ† matrices de frÂ´equence `a alimenter, dâ€™apr`es les notations de
lâ€™Algorithme 3. Câ€™est Â´egalement cette alimentation qui prend le plus de temps
par rapport aux autres traitements, qui prennent beaucoup moins de temps.
Le temps de calcul de la conductance et de la modularitÂ´e ainsi que le temps
de calcul des composantes connexes sont tr`es faibles. La taille de la matrice `a
alimenter est fonction de la taille du graphe considÂ´erÂ´e. Plus le graphe aura de
nÅ“uds, plus le temps dâ€™alimentation sera important. Une Â´etude comparative
avec les algorithmes de dÂ´etection de communautÂ´es issus de la littÂ´erature pourra
Ë†etre trouvÂ´ee `a la sous-section 3.3.

Etude de la corrÂ´elation entre la centralitÂ´e dâ€™intÂ´ermÂ´ediaritÂ´e et la ma-
trice de frÂ´equence du CDLP

Les Â´etudes prÂ´ecÂ´edentes ont montrÂ´e que lâ€™ajout de barrage en utilisant lâ€™infor-
mation de la centralitÂ´e dâ€™intermÂ´ediaritÂ´e pouvait dans certains cas amÂ´eliorer la
qualitÂ´e de partitionnement. Cependant, la question est de savoir si mettre des
barrages sur les liens de forte centralitÂ´e dâ€™intermÂ´ediaritÂ´e ne serait pas Â´equivalent
`a mettre des barrages en fonction des valeurs des Â´elÂ´ements de la matrice de

3.1. LPA AVEC BARRAGES ET DENDROGRAMMES

119

frÂ´equence, câ€™est`a-dire des Â´elÂ´ements ayant une faible probabilitÂ´e dâ€™Ë†etre ensemble.
Pour rÂ´epondre `a cette question, nous Â´etudions expÂ´erimentalement la corrÂ´elation
entre les valeurs de la matrice de frÂ´equence pij et la centralitÂ´e dâ€™intermÂ´ediaritÂ´e
fondÂ´ee sur les arË†etes. Nous faisons diï¬€Â´erents tests avec un nombre de propaga-
tions de labels diï¬€Â´erent pour voir si cela peut avoir une inï¬‚uence sur le rÂ´esultat,
notamment avec N = 100, N = 500 et N = 1000.

Figure 3.28 â€“ Etude de la corrÂ´elation entre la centralitÂ´e dâ€™intermÂ´ediaritÂ´e et les Â´elÂ´ements
de la matrice de frÂ´equence sur Zachary

Figure 3.29 â€“ Etude de la corrÂ´elation entre la centralitÂ´e dâ€™intermÂ´ediaritÂ´e et les Â´elÂ´ements
de la matrice de frÂ´equence sur le rÂ´eseau de dauphins

Figure 3.30 â€“ Etude de la corrÂ´elation entre la centralitÂ´e dâ€™intermÂ´ediaritÂ´e et les Â´elÂ´ements
de la matrice de frÂ´equence sur le rÂ´eseau footballistique

120

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

Figure 3.31 â€“ Etude de la corrÂ´elation entre la centralitÂ´e dâ€™intermÂ´ediaritÂ´e et les Â´elÂ´ements
de la matrice de frÂ´equence sur le rÂ´eseau de livres politique

Figure 3.32 â€“ Etude de la corrÂ´elation entre la centralitÂ´e dâ€™intermÂ´ediaritÂ´e et les Â´elÂ´ements
de la matrice de frÂ´equence sur le rÂ´eseau de jazz

Figure 3.33 â€“ Etude de la corrÂ´elation entre la centralitÂ´e dâ€™intermÂ´ediaritÂ´e et les Â´elÂ´ements
de la matrice de frÂ´equence sur le rÂ´eseau de collaboration scientiï¬que

RÂ´eseaux
Zachary
Dauphins
Foot
Livres politiques
Jazz
Netscience

N = 100 N = 500 N = 1000
âˆ’0.592
âˆ’0.573
âˆ’0.226
âˆ’0.216
âˆ’0.756
âˆ’0.761
âˆ’0.570
âˆ’0.571
âˆ’0.189
âˆ’0.186
âˆ’0.170
âˆ’0.176

âˆ’0.592
âˆ’0.229
âˆ’0.762
âˆ’0.575
âˆ’0.189
âˆ’0.197

Tableau 3.4 â€“ Coeï¬ƒcient de Pearson entre la centralitÂ´e dâ€™intermÂ´ediaritÂ´e et les Â´elÂ´ements
de la matrice de frÂ´equence.

3.1. LPA AVEC BARRAGES ET DENDROGRAMMES

121

Les ï¬gures ci-dessus et le Tableau 3.4 montrent le degrÂ´e de corrÂ´elation entre
la centralitÂ´e dâ€™intermÂ´ediaritÂ´e et les Â´elÂ´ements de la matrice de frÂ´equence du CDLP,
soit les pij. Nous aurions pu nous attendre `a ce que les liens ayant une forte cen-
tralitÂ´e dâ€™intermÂ´ediaritÂ´e soient des arË†etes avec un faible pij, câ€™est-`a-dire dont les
sommets auraient une faible probabilitÂ´e dâ€™Ë†etre dans une mË†eme communautÂ´e et
inversement. Cependant, les coeï¬ƒcients de Pearson montrent quâ€™il y a une faible
anti-corrÂ´elation (parfois mË†eme quâ€™il nâ€™y a pas de corrÂ´elation du tout comme pour
Netscience avec âˆ’0.170) entre les deux sÂ´eries de mesures. De plus le Tableau 3.4
montre que le fait dâ€™augmenter le nombre de propagations de labels pour stabi-
liser la mÂ´ethode nâ€™amÂ´eliore pas la corrÂ´elation entre les deux sÂ´eries de mesures.

3.1.4 Conclusion sur les algorithmes de propagation de

labels avec barrages et dÂ´etection de cÅ“urs

Nous avons exposÂ´e de nouveaux algorithmes fondÂ´es sur la propagation de
labels. Nos expÂ´erimentations ont montrÂ´e que notre mÂ´ethode hybride, liant pro-
pagation de labels et barrages issus de lâ€™intermÂ´ediaritÂ´e des arË†etes permettait
lâ€™obtention de rÂ´esultats satisfaisants.

Le choix du seuil Î± dÂ´epend de la topologique du graphe considÂ´erÂ´e. Pour nos
exemples, et ce qui concerne le CDLP, un Î± faible ne permet pas de dÂ´etecter
de communautÂ´es. Ainsi câ€™est pour Zachary, câ€™est avec Î± â‰¥ 0.5 que les premi`eres
communautÂ´es sont dÂ´etectÂ´ees, il en est de mË†eme pour le rÂ´eseau de dauphins et le
rÂ´eseau de livres politiques. Pour le rÂ´eseau footballistique et le rÂ´eseau de collabo-
ration scientiï¬que, les premi`eres communautÂ´es sont dÂ´etectÂ´ees avec Î± â‰¥ 0.3. Plus
le seuil Î± augmente, plus le nombre de LPA nÂ´ecessaires est faible. Sur le club
de karatÂ´e, il faut `a peu pr`es une soixantaine de LPA pour rendre la mÂ´ethode
dÂ´eterministe et seulement une vingtaine avec Î± â‰¥ 0.8. Ce constat peut Ë†etre
rÂ´ealisÂ´e pour tous les rÂ´eseaux que nous avons Â´etudiÂ´es.

Concernant le PLBS, lâ€™ajout de barrages stabilise davantage lâ€™algorithme
que le CDLP. En mettant des barrages sur les liens, certaines propagations
de labels ne peuvent plus sâ€™eï¬€ectuer. En augmentant le nombre de barrages `a
lâ€™alimentation du PLBS, la matrice de frÂ´equence se rapproche dâ€™une matrice
diagonale. Nous avons observÂ´e quâ€™avec un pourcentage de barrages assez fort,
(60%,70%,80% et 90%) des paires de nÅ“uds apparaissent, ce qui montre la
prÂ´esence de cÅ“urs. Ce constat peut Ë†etre rÂ´ealisÂ´e pour tous les rÂ´eseaux que nous
avons Â´etudiÂ´es.

Lâ€™ajout de barrages permet de dÂ´etecter plus rapidement les communautÂ´es,
câ€™est-`a-dire avec un seuil Î± plus faible, par exemple, pour le club de karatÂ´e,
En eï¬€et, les premi`eres communautÂ´es dÂ´etectÂ´ees pour PLBS le sont `a partir de
Î± â‰¥ 0.2 pour Zachary avec 30% de barrages alors que les premi`eres commu-
nautÂ´es avec CDLP ne sont dÂ´etectÂ´ees quâ€™`a partir de Î± â‰¥ 0.5. Sur lâ€™ensemble du
spectre du seuil Î± PLBS donne de meilleurs rÂ´esultats que CDLP en termes de

122

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

qualitÂ´e de partitionnement.

Nous avons menÂ´e une Â´etude expÂ´erimentale qui a montrÂ´e quâ€™il nâ€™y avait pas de
fortes corrÂ´elations entre la centralitÂ´e dâ€™intermÂ´ediaritÂ´e des arË†etes et les valeurs de
la matrice de frÂ´equence du CDLP. Par exemple, le coeï¬ƒcient de Pearson entre
les sÂ´eries de mesures pour le rÂ´eseau de dauphins nâ€™est que de âˆ’0.216.

Les algorithmes MPLBS, PLBS et CDLP sont dÂ´eterministes par rapport `a
des algorithmes tels que Louvain ou le LPA. Cependant, un crit`ere de partition-
nement est nÂ´ecessaire pour couper le dendrogramme, câ€™est en ce sens que des
mesures non supervisÂ´ees comme la modularitÂ´e sont utilisÂ´ees. En utilisant comme
crit`ere de partionnement la modularitÂ´e, nous verrons dans la section portant sur
lâ€™analyse comparative 3.3, que nos mÂ´ethodes donnent de meilleurs rÂ´esultats en
termes de qualitÂ´e de partitionnement que le LPA. Cependant, leur complexitÂ´e
est plus Â´elevÂ´ee.

Au chapitre 4, nous proposons une version parall`ele et distribuÂ´ee du CDLP

pour travailler sur les grands graphes ayant plusieurs millions dâ€™arË†etes.

3.2. LPA AVEC COLORATION

123

3.2 Propagation de labels avec dÂ´etection de cÅ“urs,

ordre et coloration pour la dÂ´etection de com-
munautÂ´es disjointes

Nous avons utilisÂ´e dans la section prÂ´ecÂ´edente la notion de barrages en uti-
lisant la centralitÂ´e dâ€™intermÂ´ediaritÂ´e fondÂ´ee sur les arË†etes. Bien que permettant
de meilleurs rÂ´esultats que le LPA, la complexitÂ´e algorithmique pour le calcul de
la centralitÂ´e dâ€™intermÂ´ediaritÂ´e est de O(n3) (et peut Ë†etre rÂ´eduite en O(nm) par
approximation). Nous nous proposons dâ€™observer le comportement de la propa-
gation de labels avec cÅ“urs en utilisant un ordre de visite fondÂ´e sur certaines
mesures sociales. Lâ€™objectif est dâ€™Â´etudier `a la fois la stabilitÂ´e de lâ€™algorithme et
la qualitÂ´e par rapport aux versions prÂ´ecÂ´edemment proposÂ´ees.

Nous avons vu au chapitre 1 que la propagation de labels avait Â´etÂ´e modÂ´elisÂ´ee
en utilisant la coloration dans un but de parallÂ´elisation, nommÂ´ee la propagation
de labels semi-synchrone. Ainsi, des groupes de nÅ“uds connectÂ´es ayant la mË†eme
coloration peuvent faire la mise `a jour de leurs labels alors que dâ€™autres sont dans
un Â´etat dâ€™attente (ou en â€pauseâ€). En itÂ´erant sur toutes les couleurs, une pro-
pagation de label globale a lieu. Lâ€™idÂ´ee est de rÂ´eutiliser le concept de coloration
mais pour eï¬€ectuer une mise `a jour des labels des nÅ“uds en fonction de leurs
structures sociales et topologiques au sein du rÂ´eseau. En introduisant un ordre
fondÂ´e sur la topologie des groupes de nÅ“uds dâ€™une coloration, la propagation de
label pourra ainsi Ë†etre eï¬€ectuÂ´ee. Il sâ€™agit dâ€™une proposition algorithmique dans
un but expÂ´erimental, aï¬n de savoir si lâ€™ordre peut jouer sur la stabilitÂ´e et sur la
qualitÂ´e de la dÂ´etection de communautÂ´es.

3.2.1 Propagation de labels asynchrone avec dÂ´etection de

cÅ“urs et coloration

En eï¬€ectuant une coloration du graphe G = (V, E), nous obtenons une parti-
tion D = {D1, D2, ..., Dl} (de l parties). Lâ€™idÂ´ee est de trier ces groupes de nÅ“uds
non connectÂ´es en fonction de leurs caractÂ´eristiques topologiques. Câ€™est alors
quâ€™un ordre de visite permet de mettre `a jour les labels des nÅ“uds dâ€™une cer-
taine couleur de mani`ere croissante ou dÂ´ecroissante selon les valeurs des rÂ´esultats
des mesures sociologiques utilisÂ´ees.

Nous considÂ´erons comme ordre :
â€” la centralitÂ´e de degrÂ´es
â€” lâ€™alÂ´eatoire

En considÂ´erant lâ€™exemple suivant, on peut sâ€™apercevoir que lâ€™ordre fondÂ´e sur
la coloration permet de rÂ´eduire le nombre de propagations de labels et de gagner

124

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

en temps de calcul.

Figure 3.34 â€“ Exemple de propagation de label semi-sychrone fondÂ´e sur lâ€™ordre de
visite

En appliquant un algorithme de coloration, nous obtenons les deux groupes
de nÅ“uds D1 = {s1} et D2 = {s2, s3, s4, s5, s6, s7}. Le degrÂ´e moyen des nÅ“uds de
D1 (ici juste du nÅ“ud s1) est de 6 alors que le degrÂ´e moyen du groupe D2 est de
1. Notons par Ïƒ, la matrice qui reprÂ´esente lâ€™ordre de visite pour la propagation
de labels, o`u les Â´elÂ´ements de la ieme colonne reprÂ´esentent en premi`ere ligne
le numÂ´ero de visite du nÅ“ud dont lâ€™identiï¬ant est en seconde ligne (si). En
commenÂ¸cant par la mise `a jour des labels des nÅ“uds Â´etant dans le groupe dont
la centralitÂ´e est la plus faible, nous obtenons lâ€™ordre et la propagation de labels
suivants :

(cid:19)

(cid:18) 1

s2

Ïƒ =

2
s4

3
s5

4
s6

5
s7

6
s3

7
s1

s2 â† s1, s4 â† s1 ,s5 â† s1, s6 â† s1, s7 â† s1, s3 â† s1, s1 â† {s2, s3, s4, s5, s6, s7}

Une seule itÂ´eration de propagation de labels suï¬ƒt pour que tous les nÅ“uds
aient le mË†eme label. En ayant considÂ´erÂ´e lâ€™ordre commenÂ¸cant par D1 et ensuite
D2, nous aurions dË†u avoir plusieurs itÂ´erations de la propagation de label pour
obtenir le mË†eme label pour tous les nÅ“uds.

La complexitÂ´e de lâ€™algorithme dans le pire cas est en O(n Ã— N Ã— k Ã— (m) +
n2 + n + m), o`u k est le nombre dâ€™itÂ´erations de propagations de labels et m le
nombre dâ€™arË†etes du graphe.

Dans le cadre de lâ€™Algorithme 6, nous proposons de mettre `a jour les labels
des nÅ“uds en commenÂ¸cant par les groupes de nÅ“uds de mË†eme couleur ayant
la centralitÂ´e la plus faible (POP-UP), cela de mani`ere croissante. Nous pro-
posons Â´egalement une seconde version, qui consiste `a commencer de mani`ere
dÂ´ecroissante, des groupes de nÅ“uds ayant la centralitÂ´e la plus Â´elevÂ´ee vers ceux
ayant la centralitÂ´e la moins forte (POP-DOWN). Le cas o`u lâ€™ordre est alÂ´eatoire
sera notÂ´e R-POP (R pour random). De ces trois derni`eres propositions, il est
possible, en faisant ï¬‚uctuer la valeur de Î±, dâ€™obtenir des dendrogrammes. La
question est de savoir si elles sont fonci`erement diï¬€Â´erentes, tant en termes de
niveaux quâ€™en termes de partition.

3.2. LPA AVEC COLORATION

125

Algorithme 6 La propagation de label semi-synchrone avec ordre prÂ´efÂ´erentiel
(POP)
Input : Un graphe G = (V, E), un seuil Î±, N le nombre de propagations de

labels, une mesure sociale M fondÂ´ee sur les nÅ“uds

Output : Les communautÂ´es trouvÂ´ees par lâ€™algorithme sur le graphe G = (V, E)
1: Eï¬€ectuer une coloration du graphe G, D = {D1, D2, ..., Dl} (de l parties)
2: Allouer une matrice de frÂ´equence vide P N
3: Pour chaque groupe de nÅ“uds dâ€™une mË†eme couleur Di, calculer la mesure
moyenne de la mesure sociale M, puis trier les groupes de nÅ“uds suivant
les rÂ´esultats de mani`ere croissante ou dÂ´ecroissante pour crÂ´eer un ordre de
visite Ïƒ.
4: Appliquer N fois la propagation de labels semi-synchrone en utilisant lâ€™ordre
prÂ´efÂ´erentiel Ïƒ et remplir la matrice P N

ij

ij

poids supÂ´erieur ou Â´egal `a Î±

5: CrÂ´eer un nouveau graphe G(cid:48) = (V, E(cid:48)) issu de P N
ij dont les arË†etes ont un
6: CrÂ´eer une partition P en considÂ´erant les C composantes connexes comme
7: Retourner la partition P = {P1, ..., PC}.

cÅ“urs

3.2.2 ExpÂ´erimentation sur R-POP, POP-UP et POP-DOWN

Dans cette partie expÂ´erimentale, nous souhaitons :

1. savoir si lâ€™ordre de visite fondÂ´e sur la centralitÂ´e moyenne des groupes de
nÅ“uds ayant la mË†eme couleur amÂ´eliorera la qualitÂ´e des communautÂ´es
dÂ´etectÂ´ees

2. connaË†Ä±tre le nombre N de propagations de labels semi-synchrones `a lancer

pour stabiliser le processus de dÂ´etection de communautÂ´es

3. savoir sâ€™il existe un seuil pour lequel la valeur Î± nâ€™est plus sujette `a lâ€™ordre

de visite

4. savoir si lâ€™ordre de visite a une consÂ´equence sur la taille des dendro-

grammes crÂ´eÂ´es

Dans la suite des expÂ´erimentations, nous notons par Ix le fait que les pro-

pagations de labels ont Â´etÂ´e itÂ´erÂ´ees x fois.

Etude sur la stabilisation de la propagation de label semi-synchrone

Les expÂ´erimentations portÂ´ees sur trois rÂ´eseaux montrent que lâ€™ordre joue un

rË†ole sur la stabilisation de la propagation de labels.

126

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

Figure 3.35 â€“ StabilitÂ´e de la propagation de labels semi-sychrone fondÂ´ee sur lâ€™ordre de
visite sur Zachary

Figure 3.36 â€“ StabilitÂ´e de la propagation de labels semi-sychrone fondÂ´ee sur lâ€™ordre de
visite sur les dauphins

3.2. LPA AVEC COLORATION

127

Figure 3.37 â€“ StabilitÂ´e de la propagation de labels semi-sychrone fondÂ´ee sur lâ€™ordre de
visite sur les livres politiques

En comparant la stabilisation du CDLP et des algorithmes `a base de co-
loration, Figures 3.9, 3.35,3.36 et 3.37, on observe que les mÂ´ethodes `a base de
coloration nÂ´ecessitent moins de LPA pour arriver `a stabilisation de lâ€™algorithme
pour des Î± â‰¤ 0.8. Nous observons que lâ€™ordre joue un rË†ole Â´egalement sur la
stabilitÂ´e de lâ€™algorithme.

Pour Zachary, Figure 3.35, avec Î± â‰¤ 0, 5, R-POP ne dÂ´etecte pas de commu-
nautÂ´e alors que CDLP en dÂ´etecte 2. Pour les algorithmes `a base de coloration,
il faut une vingtaine de LPA pour arriver `a stabilisation. Î± a une incidence plus
forte sur les algorithmes sans coloration que sur ceux avec.

Pour les dauphins, Figure 3.36, lâ€™ordre a un rË†ole plus marquÂ´e sur le nombre de
LPA nÂ´ecessaires `a la stabilisation. POP-UP nÂ´ecessite entre 45 et 50 LPA contre
une vingtaine pour POP-DOWN et POP-UP. Pour Î± â‰¥ {0.3; 0.4} R-POP ne
trouve pas de communautÂ´es. CDLP est plus sensible `a Î± que les mÂ´ethodes `a
base de coloration.

Pour les livres politiques, Figure 3.37, CDLP ne trouve pas de communautÂ´e
pour Î± â‰¥ {0.3; 0.4} alors que les autres mÂ´ethodes dÂ´etectent de petits groupes
de nÅ“uds d`es Î± â‰¥ 0.3 qui correspondent aux livres neutres sur le plan politique.
POP-DOWN est lâ€™algorithme nÂ´ecessitant le moins de LPA pour arriver `a stabi-
lisation.

Etude expÂ´erimentale sur des rÂ´eseaux rÂ´eels avec connaissance des com-
munautÂ´es de terrains

Le Club de KaratÂ´e de Zachary

128

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

Coloration de graphe sur Zachary

Couleurs
C1
C2
C3
C4
C5
C6

distribution

38.235 %
26.47 %
20.588 %
5.882 %
5.882 %
2.941 %

Â¯d

7.383
3.889
4.286

9.0
4.5
17.0

V ar
39.172
4.543
7.061

9.0
0.25
0.0

Tableau 3.5 â€“ Distribution des tailles pour chaque groupe de nÅ“uds ayant la mË†eme
couleur Ci, Â¯d reprÂ´esente le degrÂ´e moyen du groupe de nÅ“uds ayant la couleur Ci et
V ar reprÂ´esente la variance concernant le degrÂ´e des nÅ“uds au sein dâ€™une mË†eme couleur.

R-POP sur Zachary (I5 ey N = 100)
Î± â‰¥ 0.5

Î± â‰¥ 0.6
0.133
0.001
0.206
0.072
0.647

ModularitÂ´e
Conductance
NMI
ARI
PuretÂ´e
#
Tableau 3.6 â€“ Mesures supervisÂ´ees et non supervisÂ´ees avec R-POP

0.0
0.0
0.0
0.0
0.5
1

2

5

Î± â‰¥ 0.7
0.399
0.032
0.649
0.63
0.97

4

Î± â‰¥ 0.8
0.376
0.061
0.615
0.593
0.97

5

Î± â‰¥ 0.9
0.376
0.061
0.615
0.593
0.97

Î± â‰¥ 0.5
0.37

POP-UP sur Zachary (I5 et N = 100) OK
Î± â‰¥ 0.8
0.376
0.032
0.653
0.648
0.97

Î± â‰¥ 0.7
0.399
0.002
0.691
0.684
0.97

Î± â‰¥ 0.6
0.399
0.0023
0.691
0.684
0.97

0.0004
0.837
0.882
0.97

2

3

3

4

ModularitÂ´e
Conductance
NMI
ARI
PuretÂ´e
#

Î± â‰¥ 0.9
0.392
0.035
0.571
0.472
0.97

5

Tableau 3.7 â€“ Mesures supervisÂ´ees et non supervisÂ´ees avec POP-UP

POP-DOWN sur Zachary (I5 et N = 100) OK
Î± â‰¥ 0.8
0.402
0.002
0.568
0.59
0.941

Î± â‰¥ 0.6
0.402
0.002
0.568
0.59
0.941

Î± â‰¥ 0.5
0.372
0.0004
0.677
0.772
0.941

Î± â‰¥ 0.7
0.402
0.002
0.568
0.59
0.941

2

3

3

3

Modularity
Conductance
NMI
ARI
PuretÂ´e
#

Î± â‰¥ 0.9
0.376
0.061
0.615
0.593
0.97

5

Tableau 3.8 â€“ Mesures supervisÂ´ees et non supervisÂ´ees avec POP-DOWN

3.2. LPA AVEC COLORATION

129

Sur la ï¬gure 3.38, nous exposons les rÂ´esultats de R-POP, POP-UP et POP-
DOWN en lanÂ¸cant 100 propagations de labels (N = 100). Les nÅ“uds 0 et
33 reprÂ´esentent respectivement le manager et lâ€™entraË†Ä±neur qui se sont fË†achÂ´es.
Dâ€™apr`es les Tableaux 3.7, 3.6 et 3.8, et leurs reprÂ´esentations sur les Figures
3.41, 3.39 et 3.40 avec la visualisation sur la ï¬gure 3.38, nous obtenons 6 ni-
veaux pour le dendrogramme avec R-POP et 5 niveaux pour POP-UP et POP-
DOWN. POP-UP a un NMI de 0.837 pour Î± â‰¥ 0.5 et produit les meilleurs
rÂ´esultats alors que POP-DOWN produit les moins bons. POP-UP et POP-
DOWN trouvent bien les deux communautÂ´es pour Î± â‰¥ 0.5 alors que R-POP
ne trouve quâ€™une seule grande communautÂ´e. Pour Î± â‰¥ 0.6 R-POP trouve une
petite communautÂ´e reliÂ´ee au manager, alors que 3 communautÂ´es sont dÂ´etectÂ´ees
par les autres mÂ´ethodes. Pour R-POP et POP-DOWN, les meilleurs rÂ´esultats
sont obtenus pour Î± â‰¥ 0.7. Pour Î± â‰¥ 0.8, POP-DOWN conserve une conduc-
tance assez faible alors quâ€™elle devient importante pour R-POP et POP-UP. Au
niveau du nombre de communautÂ´es, nous obtenons un nombre tr`es semblable
pour toutes les mÂ´ethodes. Les changements se font vis-`a-vis de nÅ“uds particu-
liers souvent considÂ´erÂ´es comme chevauchants dans littÂ´erature. On note que le
nÅ“ud â€9â€, qui est souvent considÂ´erÂ´e comme appartenant `a deux communautÂ´es
est dÂ´etectÂ´e seul avec R-POP, alors quâ€™avec POP-UP, il rejoint la plus grande
communautÂ´e et avec POP-DOWN, la plus petite.

130

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

Figure 3.38 â€“ Dendrogramme (Etude visuelle) sur Zachary, a) R-POP b) POP-UP c)
POP-DOWN d)les valeurs de Î± (supÂ´erieur strictement)

Figure 3.39 â€“ Dendrogramme avec R-POP sur Zachary

3.2. LPA AVEC COLORATION

131

Figure 3.40 â€“ Dendrogramme avec POP-UP sur Zachary

Figure 3.41 â€“ Dendrogramme avec POP-DOWN sur Zachary

distribution

Coloration de graphe sur les dauphins
Var
4.289
7.979
6.321
4.531

4.884
4.857
5.889
7.571

Â¯d

8.0
8.0
10.0

3.5
1.0
0.0

Couleurs
C1
C2
C3
C4
C5
C6
C7

40.322 %
22.58 %
14.516 %
11.29 %
6.452 %
3.226 %
1.613 %

Tableau 3.9 â€“ Distribution des tailles pour chaque groupe de nÅ“uds ayant la mË†eme
couleur Ci, Â¯d reprÂ´esente le degrÂ´e moyen du groupe de nÅ“ud ayant la couleur Ci

et V ar reprÂ´esente la variance concernant le degrÂ´e des nÅ“uds au sein dâ€™une mË†eme

couleur.

R-POP sur les Dauphins (I5 and N = 100)
Î± â‰¥ 0.8
0.492
0.07

ModularitÂ´e
Conductance
NMI
ARI
PuretÂ´e
#
Tableau 3.10 â€“ Mesures supervisÂ´ees et non supervisÂ´ees avec R-POP

Î± â‰¥ 0.5
0.478
0.0004
0.756
0.63
1.0
3

Î± â‰¥ 0.7
0.498
0.0503
0.604
0.443

Î± â‰¥ 0.6
0.51
0.018
0.638
0.469

0.5555
0.386

1.0
9

Î± â‰¥ 0.9
0.461
0.082
0.476
0.272

1.0
12

1.0
5

1.0
7

Nous obtenons 7 couleurs 3.9. la distribution nâ€™est pas uniforme, avec les

132

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

Î± â‰¥ 0.5
0.48

POP-UP sur les dauphins (I5 and N = 100)
Î± â‰¥ 0.8
0.483
0.071
0.506
0.295

Î± â‰¥ 0.6
0.5202
0.0013
0.585

0.43250

Î± â‰¥ 0.7
0.52
0.001
0.5852
0.4325
0.984

0.0004
0.676
0.58
0.984

3

ModularitÂ´e
Conductance
NMI
ARI
PuretÂ´e
#

0.984

4

4

1.0
10

Î± â‰¥ 0.9
0.461
0.082
0.476
0.272

1.0
12

Tableau 3.11 â€“ Mesures supervisÂ´ees et non supervisÂ´ees avec POP-UP

POP-DOWN sur les dauphins (I5 and N = 100)

Î± â‰¥ {0.3, 0.4, 0.5}

ModularitÂ´e
Conductance
NMI
ARI
PuretÂ´e
#

0.373

6.2*e-05

1.0
1.0
1.0
2

Î± â‰¥ 0.6
0.5196
0.001
0.652
0.465

Î± â‰¥ 0.7
0.515
0.0208
0.594
0.412

1.0
4

1.0
6

Î± â‰¥ 0.8
0.505
0.0372
0.582
0.408

1.0
7

Tableau 3.12 â€“ Mesures supervisÂ´ees et non supervisÂ´ees avec POP-DOWN

deux couleurs les plus importantes reprÂ´esentant `a elles seules 62.902 % de la
population totale (en termes de nÅ“uds). Dâ€™apr`es les rÂ´esultats des tableaux 3.10,
3.11 et 3.12, le dendrogramme de R-POP poss`ede 6 niveaux, comme pour POP-
DOWN. POP-DOWN trouve parfaitement les deux communautÂ´es avec un NMI
de 1.0 avec de faibles valeurs de Î± ( {0.3; 0.2}). Pour POP-UP, nous obtenons
5 niveaux. En termes de qualitÂ´e, câ€™est POP-DOWN qui produit les meilleurs
rÂ´esultats et qui est persistant par rapport `a Î±. La qualitÂ´e se dÂ´etÂ´eriore plus ra-
pidement avec POP-UP et R-POP lorsque Î± augmente.

Le rÂ´eseau footballistique de Newman

Â¯d

distribution

Coloration de graphe sur le rÂ´eseau footballistique
Couleur
C1
C2
C3
C4
C5
C6
C7
C8
C9

16.522 %
14.783 %
16.522 %
15.652 %
12.174 %
11.304 %
6.956 %
4.348 %
1.739 %

Var
1.008
1.031
0.875
0.6944
0.143
0.71
0.25
0.64
0.0

10.853
10.705
10.579
10.5
11.0
10.538
10.5
10.6
11.0

Tableau 3.13 â€“ Distribution des tailles pour chaque groupe de nÅ“uds ayant la mË†eme
couleur Ci, Â¯d reprÂ´esente le degrÂ´e moyen du groupe de nÅ“uds ayant la couleur Ci

et V ar reprÂ´esente la variance concernant le degrÂ´e des nÅ“uds au sein dâ€™une

mË†eme couleur.

3.2. LPA AVEC COLORATION

133

R-POP sur le rÂ´eseau footballistique (I5 et N = 100)

Î± â‰¥ 0.5 Î± â‰¥ 0.6 Î± â‰¥ 0.7 Î± â‰¥ 0.8 Î± â‰¥ 0.9
0.0628
0.053
0.51
0.002
0.699
0.172
0.015
0.164
0.2
0.904
3

ModularitÂ´e
Conductance
NMI
ARI
PuretÂ´e
#
Tableau 3.14 â€“ Mesures supervisÂ´ees et non supervisÂ´ees avec R-POP

0.284
0.055
0.575
0.2927
0.591

0.134
0.192
0.663
0.269
0.722

0.102
0.333
0.6832
0.2362

0.8
40

55

12

18

POP-UP sur le rÂ´eseau footballistique (I5 et N = 100)

Î± â‰¥ 0.5 Î± â‰¥ 0.6 Î± â‰¥ 0.7 Î± â‰¥ 0.8 Î± â‰¥ 0.9
0.375
0.478
0.0004
0.249
0.417
0.756
0.214
0.63
1.0
1.0
3
21

Modularity
Conductance
NMI
ARI
PuretÂ´e
#
Tableau 3.15 â€“ Mesures supervisÂ´ees et non supervisÂ´ees avec POP-UP

0.498
0.05
0.604
0.443
1.0
7

0.51
0.018
0.638
0.469
1.0
5

0.492
0.07
0.555
0.386
1.0
9

POP-DOWN sur Football (I5 et N = 100)

ModularitÂ´e
Conductance
NMI
ARI
PuretÂ´e
#

Î± â‰¥ 0.5 Î± â‰¥ 0.6 Î± â‰¥ 0.7 Î± â‰¥ 0.8 Î± â‰¥ 0.9
0.033
0.148
0.607
0.002
0.248
0.693
0.109
0.046
0.235
0.922

0.242
0.087
0.545
0.197
0.548

0.054
0.451
0.655
0.116
0.817

0.11
0.222
0.628
0.221
0.704

3

13

17

42

67

Tableau 3.16 â€“ Mesures supervisÂ´ees et non supervisÂ´ees avec POP-DOWN

Lâ€™algorithme de coloration trouve bien 9 couleurs dont la distribution sur les
nÅ“uds est assez uniforme. 6 couleurs reprÂ´esentent pr`es de 86,99 % de nÅ“uds.
Les rÂ´esultats sur cet exemple sont assez diï¬€Â´erents, notamment en fonction de Î±.
Pour R-POP et POP-DOWN, les meilleurs rÂ´esultats sont obtenus pour Î± â‰¥ 0.6.
Cependant, le nombre de communautÂ´es rÂ´esultantes par ces mÂ´ethodes est tr`es
volatil par rapport `a Î±. Pour R-POP et POP-DOWN, apr`es Î± â‰¥ 0.7, le nombre
de communautÂ´es augmente considÂ´erablement.

134

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

Les livres politiques de Krebs (Â´election prÂ´esidentielle amÂ´ericaine

de 2004)

distribution

Coloration de graphes sur les livres politiques de Krebs
Couleurs
C1
C2
C3
C4
C5
C6
C7
C8

30.476 %
22.857 %
15.238 %
10.476 %
11.428 %
3.809 %
3.809 %
1.904 %

Â¯d
8.41
8.0
8.75
9.091
9.25
15.5
11.5
20.5

Var
45.05
21.5
33.81
34.44
18.18
41.25
17.25
6.25

Tableau 3.17 â€“ Distribution des tailles pour chaque groupe de nÅ“uds ayant la mË†eme
couleur Ci, Â¯d reprÂ´esente le degrÂ´e moyen du groupe de nÅ“ud ayant la couleur Ci

et V ar reprÂ´esente la variance concernant le degrÂ´e des nÅ“uds au sein dâ€™une

mË†eme couleur.

R-POP sur les livres politiques de Krebs (I5 et N = 100)

Î± â‰¥ 0.5
0.493
0.0002
0.578
0.69
0.85

Î± â‰¥ 0.6
0.493
0.0002
0.578
0.69
0.847

ModularitÂ´e
Conductance
NMI
ARI
PuretÂ´e
#
Tableau 3.18 â€“ Mesures supervisÂ´ees et non supervisÂ´ees avec R-POP

3

3

9

7

Î± â‰¥ 0.8
0.503
0.03
0.550
0.668
0.857

Î± â‰¥ 0.9
0.485
0.04
0.515
0.55
0.867

Î± â‰¥ 0.7
0.503
0.03
0.55
0.668
0.857

7

POP-UP sur les livres politiques de Krebs (I5 et N = 100)

ModularitÂ´e
Conductance
NMI
ARI
PuretÂ´e
#

Î± â‰¥ 0.5
0.09

0.0002
0.049
0.057
0.486

2

Î± â‰¥ 0.6
0.0905
0.0002
0.049
0.057
0.486

Î± â‰¥ 0.7
0.494
0.01
0.592
0.703
0.857

Î± â‰¥ 0.8
0.494
0.01
0.592
0.703
0.857

Î± â‰¥ 0.9
0.483
0.047
0.504
0.521
0.867

2

4

4

10

Tableau 3.19 â€“ Mesures supervisÂ´ees et non supervisÂ´ees avec POP-UP

La Figure 3.42 et les tableaux 3.18, 3.19 et 3.20 sont la retranscription des
rÂ´esultats de R-POP, POP-DOWN et POP-UP. Pour Î± â‰¥ 0.5, R-POP trouve
bien 3 communautÂ´es, avec pour chaque communautÂ´e, une identiï¬cation politique

3.2. LPA AVEC COLORATION

135

POP-DOWN sur les livres politiques de Krebs (I5 et N = 100)
Î± â‰¥ 0.9
0.49
0.046
0.539
0.668
0.876

Î± â‰¥ 0.5
0.457
0.000
0.598
0.667
0.848

Î± â‰¥ 0.6
0.4568
0.000
0.598
0.667
0.848

Î± â‰¥ 0.7
0.489
0.011
0.585
0.705
0.866

Î± â‰¥ 0.8
0.489
0.011
0.585
0.705
0.866

ModularitÂ´e
Conductance
NMI
ARI
PuretÂ´e
#

2

2

5

5

10

Tableau 3.20 â€“ Mesures supervisÂ´ees et non supervisÂ´ees avec POP-DOWN

Figure 3.42 â€“ Visualisation des communautÂ´es pour Î± â‰¥ 0.5 et Î± â‰¥ 0.7 a)
R-POP b) POP-UP c) POP-DOWN

distincte. Nous notons que la communautÂ´e reprÂ´esentant les livres â€neutresâ€ sur
le plan politique est dispatchÂ´ee entre les trois principales communautÂ´es. POP-
DOWN ne dÂ´etecte que deux communautÂ´es, les rÂ´epublicains et les dÂ´emocrates,
les neutres Â´etant majoritairement placÂ´es dans la communautÂ´e dÂ´emocrate. Pour
Î± â‰¥ 0.7, R-POP est celui qui dissocie le mieux les neutres des deux plus grands
partis. Les dÂ´emocrates et les rÂ´epublicains sont parfaitement dÂ´etectÂ´es.Une par-
tie des neutres se retrouve nÂ´eanmoins chez les dÂ´emocrates. POP-UP dÂ´etecte la
majoritÂ´e des neutres, mais la coupe en deux grandes parties.

Dâ€™apr`es les rÂ´esultats, les principaux groupes de nÅ“uds, `a savoir les dÂ´emocrates

136

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

et les rÂ´epublicains sont bien dÂ´etectÂ´es par les trois mÂ´ethodes. Les diï¬€Â´erences
portent entre les livres neutres sur le plan politique.

3.2.3 Conclusion sur les propositions algorithmiques `a base

de coloration

Lâ€™idÂ´ee de donner un ordre de visite en utilisant la coloration fut dâ€™Â´eviter
la survenue de mauvaises propagations, câ€™est-`a-dire, dâ€™Â´eviter quâ€™une propaga-
tion suive un chemin menant `a une communautÂ´e gÂ´eante par succession de choix
alÂ´eatoires inadÂ´equats.

Nos expÂ´erimentations ont montrÂ´e que lâ€™ordre de visite a un impact sur la qua-
litÂ´e de partitionnement, mais Â´egalement vis-`a-vis du seuil Î± lors des dÂ´etections
des toutes premi`eres communautÂ´es. Par exemple, avec le rÂ´eseau de dauphins,
R-POP ne dÂ´etecte les premi`eres communautÂ´es quâ€™`a partir de Î± â‰¥ 0.5 alors que
POP-UP et POP-DOWN ne dÂ´etectent leurs premi`eres communautÂ´es quâ€™`a partir
de Î± â‰¥ 0.3. Le nombre de communautÂ´es varie selon les mÂ´ethodes. Par exemple,
sur le rÂ´eseau footballistique, avec Î± â‰¥ 0.7, POP-UP dÂ´etecte 7 communautÂ´es
alors que R-POP en dÂ´etecte 11 et POP-DOWN en dÂ´etecte 17.

Nos expÂ´erimentations ne dÂ´emontrent pas quâ€™un ordre dÂ´eterminÂ´e amÂ´eliore
la qualitÂ´e de partitionnement mais rÂ´ev`elent lâ€™obtention de partitions de qualitÂ´e
diï¬€Â´erente. Cependant, ces mÂ´ethodes sont dÂ´eterministes. Nous verrons quâ€™il est
dÂ´elicat de comparer les rÂ´esultats de qualitÂ´e de partitionnement avec les autres
algorithmes car lâ€™ordre induit une incertitude quant aux partitions obtenues.

3.3. ANALYSE COMPARATIVE DES M Â´ETHODES DISJOINTES

137

3.3 Analyse comparative des mÂ´ethodes disjointes

Nous proposons dâ€™utiliser les algorithmes de la littÂ´erature suivants pour la
dÂ´etection de communautÂ´es, `a savoir : la mÂ´ethode de Girvan et Newman (GN)
Girvan et Newman (2002a), la mÂ´ethode de Louvain (Louvain) Blondel et al.
(2008) et sa version avec les cÅ“urs Seiï¬ et al. (2013), la mÂ´ethode spectrale fondÂ´ee
sur lâ€™optimisation de la modularitÂ´e (spectral Newman) de Newman (2006), le
mod`ele de Potts (spin) de Ronhovde et Nussinov (2010), le LPA (LPA) de Ra-
ghavan et al. (2007) et ses amÂ´eliorations comme Ë‡Subelj et Bajec (2011) (DPA)
et Leung et al. (2009) (Leung) , lâ€™algorithme `a base de leaders (LICOD) de Ka-
nawati (2011), un algorithme venant de la thÂ´eorie de lâ€™information (Infomap)
de Rosvall et Bergstrom (2007a), et ï¬nalement, la mÂ´ethode de marche alÂ´eatoire
(Walktrap) de Pons et Latapy (2006).

Les observations des tableaux 3.23, 3.21 et 3.22 montrent que les algorithmes
MPLBS et PLAB proposÂ´es apportent des amÂ´eliorations par rapport `a ceux issus
de la littÂ´erature, donnant de bonnes valeurs pour le NMI et le ARI, ainsi que
notre version ï¬nale PLBS. En eï¬€et, PLBS pour le rÂ´eseau de football obtient un
NMI de 0.931 et un ARI de 0.907.
Nos expÂ´erimentations ont Â´egalement montrÂ´e quâ€™alimenter une matrice dâ€™appar-
tenance avec diï¬€Â´erents barrages pouvait donner de tr`es bons rÂ´esultats comme le
montre PLBS. En eï¬€et, selon les rÂ´esultats des mesures supervisÂ´ees, PLBS montre
quâ€™elle donne de meilleurs rÂ´esultats dans la majeure partie des cas par rapport au
MPLBS. Imposer des barrages limite la propagation de labels et Â´evite le fait de
tomber dans de trop grandes communautÂ´es. Câ€™est ce que montrent les rÂ´esultats
de PLAB qui nÂ´ecessitent cependant de tester Î². Pour la paramÂ´etrisation, nous
avons choisi Î± = 0.5 pour tous les rÂ´eseaux de PLBS. Un Î± trop fort donne-
rait de trop nombreuses communautÂ´es, et trop faible, risquerait de ne don-
ner quâ€™une communautÂ´e. Le MPLBS utilisant la modularitÂ´e, nous retourne la
paramÂ´etrisation maximisant cette derni`ere, avec la partition rÂ´esultante. Une
derni`ere observation montre que PLBS et MPLBS donnent des conductances
assez faibles en comparaison des autres algorithmes de la littÂ´erature, ceci sâ€™ex-
pliquant par le fort nombre de barrages. Par rapport au LPA ou `a la mÂ´ethode
de Louvain, nos mÂ´ethodes sont dÂ´eterministes.

Concernant les algorithmes `a base de colorations et de visites prÂ´efÂ´erentielles,

nos algorithmes donnent des rÂ´esultats tr`es satisfaisants par rapport `a la littÂ´erature.
On observe que lâ€™ordre joue un rË†ole sur le dÂ´eterminisme de la mÂ´ethode utili-
sant la matrice de frÂ´equence. On a pu observer que les communautÂ´es classiques
avaient Â´etÂ´e dÂ´etectÂ´ees par toutes les mÂ´ethodes (R-POP,POP-UP et POP-DOWN)
mais que la diï¬€Â´erence rÂ´esidait surtout sur certains nÅ“uds qui sont dâ€™apr`es la
littÂ´erature chevauchants. Comme lâ€™exemple de Zachary ou celui des livres poli-
tiques, les nÅ“uds qui diï¬€`erent de communautÂ´es selon la mÂ´ethode utilisÂ´ee sont
surtout des nÅ“uds appelÂ´es chevauchants. Câ€™est-`a-dire que ce sont des nÅ“uds
susceptibles dâ€™appartenir `a plusieurs communautÂ´es. On observe Â´egalement quâ€™en

138

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

Analyse comparative avec certains algorithmes de dÂ´etection de communautÂ´es

Q

Î¦

NMI

ARI

PuretÂ´e

#

Zachary #2
0.420
Louvain
0.420
Seiï¬
0.401
GN
0.005
Spin
0.393
Spectral
0.353
WalkTrap
0.399
Leung
0.336
LPA*
0.42
DPA
0.402
Infomap
0.24
LICOD
0.347
SLPH*
0.399
R-POP
POP-UP
0.399
POP-DOWN 0.402
PLBS
0.378
0.399
PLAB
0.402
MPLBS
CDLP
0.376
Football #11
0.602
Louvain
0.602
Seiï¬
0.600
GN
0.003
Spin
0.488
Spectral
0.604
WalkTrap
0.569
Leung
0.595
LPA*
0.606
DPA
0.579
Infomap
0.49
LICOD
0.59
SLPH*
0.284
R-POP
POP-UP
0.510
POP-DOWN 0.242
0.584
PLBS
0.598
PLAB
0.602
MPLBS
CDLP
0.602

0.005
0.005
0.0348
0.2740
0.005
0.01
0.002
0.001

0.002

0.147
0.032
0.002
0.002
0.073
0.178
0.181
0.242

0.002
0.002
0.003
0.293
0.002
0.002
0.005
0.005

0.013

0.312
0.055
0.018
0.087
0.042
0.317
0.310
0.310

0.49
0.49
0.485
0.588
0.579
0.49
0.328
0.575
0.660
0.568
0.60
0.615
0.649
0.691
0.568
0.565
0.691
0.5684
0.6154

0.855
0.855
0.879
0.892
0.695
0.887
0.900
0.887

0.9
0.9
0.83
0.893
0.555
0.638
0.545
0.931
0.929
0.927
0.927

0.392
0.392
0.3915
0.464
0.435
0.321
0.515
0.570

0.59
0.62
0.628
0.63
0.684
0.59
0.498
0.684
0.591
0.593

0.728
0.728
0.778
0.816
0.891
0.815
0.836
0.779

0.853
0.69
0.799
0.293
0.469
0.197
0.907
0.900
0.889
0.889

0.941
0.941
0.941
0.97
0.97
0.912
0.97
0.895

0.941

0.909
0.97
0.97
0.941
0.97
0.97
0.941
0.97

0.922

0.8

0.835
0.8696
0.626
0.922
0.922
0.854

0.913

0.879
0.591
1.0
0.548
0.957
0.939
0.930
0.930

4
4
5
4
4
5
3

2.61

3
3
2
5
3
3
6
3
3
5

9
9
10
10
8
10
13

10.39

12
16
4
18
5
21
16
13
12
12

Tableau 3.21 â€“ Analyse comparative avec certains algorithmes issus de la littÂ´erature
(Part 1)

* signiï¬e que nous avons lancÂ´e lâ€™algorithme 100 fois et que nous avons retranscrit la
moyenne des scores.

3.3. ANALYSE COMPARATIVE DES M Â´ETHODES DISJOINTES

139

Analyse comparative avec certains algorithmes de dÂ´etection de communautÂ´es

Q

Î¦

NMI

ARI

PuretÂ´e

#

Dauphins #2
0.519
Louvain
0.519
Seiï¬
0.519
GN
0.529
Spin
0.491
Spectral
0.489
WalkTrap
0.519
Leung
0.483
LPA*
0.529
DPA
0.519
Infomap
0.35
LICOD
0.491
SLPH*
0.511
R-POP
POP-UP
0.520
POP-DOWN 0.373
PLBS
0.275
0.376
PLAB
0.457
MPLBS
CDLP
0.518
Politiques #3
0.521
Louvain
0.521
Seiï¬
0.517
GN
0.526
Spin
0.467
Spectral
0.507
WalkTrap
0.498
Leung
0.492
LPA*
0.527
DPA
0.522
Infomap
0.42
LICOD
0.495
SLPH*
0.503
R-POP
POP-UP
0.495
POP-DOWN 0.49
0.459
PLBS
0.495
PLAB
0.495
MPLBS
CDLP
0.506

0.002
0.002
0.006
0.003
0.002
0.005
0.003
0.000

0.008

0.003
0.018
0.001
0.000
0.068
0.055
0.043
0.197

0.001
0.001
0.002
0.003
0.001
0.001
0.001
0.000

0.002

0.094
0.030
0.009
0.046
0.104
0.078
0.069
0.120

0.510
0.511
0.554
0.586
0.449
0.537
0.481
0.623
0.774
0.481
0.41
0.621
0.632
0.585
1.0
0.547
0.943
0.598
0.631

0.512
0.512
0.559
0.466
0.520
0.543
0.348
0.555
0.805
0.493
0.68
0.553
0.551
0.592
0.539
0.601
0.573
0.586
0.541

0.327
0.327
0.395
0.373
0.283
0.417
0.299
0.502

0.291
0.32
0.488
0.469
0.433
1.0
0.597
0.956
0.667
0.454

0.558
0.558
0.682
0.466
0.547
0.653
0.393
0.651

0.536
0.67
0.656
0.668
0.703
0.668
0.668
0.675
0.689
0.652

0.968
0.968
0.984
1.0
0.952
0.952
0.968
0.979

0.968

0.984
1.0
0.984
1.0
0.903
1.0
0.848
1.0

0.724
0.848
0.857
0.439
0.847
0.848
0.867
0.845

0.848

0.846
0.857
0.857
0.876
0.933
0.848
0.848
0.857

5
5
5
5
5
4
6

3.85

6
2
4
5
4
2
3
3
2
5

4
4
5
6
4
4
7

3.38

6
6
3
7
4
10
16
4
3
7

Tableau 3.22 â€“ Analyse comparative avec certains algorithmes issus de la littÂ´erature
(Part 2)

* signiï¬e que nous avons lancÂ´e lâ€™algorithme 100 fois et que nous avons pris la
moyenne des scores.

140

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

Foot #11
Î±
Î²
Zac #2
Î±
Î²

PLAB
PLBS
{0.6}
{0.5}
{0.05} âˆ†[0.3;0.6]
PLAB
PLBS
{0.6}
{0.5}
{0.1}
âˆ†[0.3;0.6]

MPLBS
{0.5}âˆ—
{0.3}âˆ—
MPLBS
{0.5}âˆ—
{0.5}âˆ—

Dauphins #2

Î±
Î²

Pol #3

Î±
Î²

PLAB
PLBS
{0.6}
{0.5}
{0.05} âˆ†[0.0;0.3]
PLAB
PLBS
{0.6}
{0.5}
{0.3}
âˆ†[0.3;0.6]

MPLBS
{0.3 âˆ’ 0.5}âˆ—
{0.3}âˆ—
MPLBS
{0.3 âˆ’ 0.5}âˆ—
{0.0}âˆ—

Tableau 3.23 â€“ ParamÂ´etrisation de nos algorithmes, â€*â€ signiï¬e que câ€™est le rÂ´esultat
retournÂ´e par lâ€™algorithme par optimisation de la modularitÂ´e. Î± est la valeur pour la
crÂ´eation du graphe issu de la matrice de frÂ´equence et Î², le pourcentage de barrages.

moyenne, la mÂ´ethode `a base de coloration produit en gÂ´enÂ´eral plus de commu-
nautÂ´es que les autres mÂ´ethodes, avec une conductance plus importante, câ€™est-`a-
dire la crÂ´eation de tr`es petites communautÂ´es.

3.4. PROPOSITIONS SUR LE CHEVAUCHEMENT

141

3.4 Propagation de labels avec dÂ´etection de cÅ“urs

pour la dÂ´etection de communautÂ´es chevau-
chantes

La section prÂ´ecÂ´edente a prÂ´esentÂ´e divers algorithmes pour la dÂ´etection de com-
munautÂ´es disjointes dont les objectifs sont dâ€™amÂ´eliorer le LPA. En considÂ´erant
lâ€™exemple du CDLP et par observation de la matrice de frÂ´equence, on voit
des nÅ“uds frÂ´equemment ensemble au cours des diï¬€Â´erentes LPA, mais aussi des
nÅ“uds induire une idÂ´ee de chevauchement car appartenant `a diï¬€Â´erentes com-
munautÂ´es. Dans certains rÂ´eseaux, comme celui de collaborations scientiï¬ques o`u
des chercheurs publient leurs travaux de recherche, il peut y avoir des personnes
appartenant `a plusieurs communautÂ´es. Câ€™est par exemple le cas si un chercheur
a publiÂ´e un article dans le domaine des graphes, et un autre dans le domaine
de lâ€™oncologie. Les citations du premier se feront par des articles liÂ´es au graphe
alors que le second sera citÂ´e par des articles traitant de lâ€™oncologie. Lâ€™auteur
sera donc citÂ´e par deux groupes de personnes dont les champs scientiï¬ques sont
diï¬€Â´erents. Nous proposons dans cette section la possibilitÂ´e pour un nÅ“ud dâ€™ap-
partenir `a plusieurs communautÂ´es suivant certaines conditions en utilisant une
fonction dâ€™appartenance fondÂ´ee sur la topologie du graphe, la pondÂ´eration des
arË†etes et les caractÂ´eristiques sociales des communautÂ´es.

3.4.1 De la propagation de labels avec dÂ´etection de cÅ“urs

au chevauchement

Lâ€™objectif principal du CDLP prÂ´esentÂ´e `a la section prÂ´ecÂ´edente fut de stabili-
ser la propagation de labels en lanÂ¸cant plusieurs fois lâ€™algorithme tout en utili-
sant une matrice de frÂ´equence. Cependant, bien que cette mÂ´ethode puisse mettre
en exergue des cÅ“urs de communautÂ´es, câ€™est-`a-dire des nÅ“uds frÂ´equemment en-
semble durant les diï¬€Â´erentes propagations de labels, elle montre que certains
nÅ“uds peuvent appartenir `a des communautÂ´es diï¬€Â´erentes suite `a lâ€™application
de plusieurs CDLP. Ce sont sur ces nÅ“uds, dont lâ€™imprÂ´ecision dâ€™appartenance `a
plusieurs classes est Â´elevÂ´ee, que nous portons notre attention. Dans le cadre de
ce travail doctoral, nous proposons dâ€™Â´etablir une mesure de dÂ´ecision permettant
de spÂ´eciï¬er pour un certain nombre de nÅ“uds, dÂ´elicats `a classer, leurs diï¬€Â´erentes
communautÂ´es dâ€™appartenance possibles, crÂ´eant par voie de consÂ´equence, le che-
vauchement entre communautÂ´es. Pour ce faire, nous proposons de donner ou
de rappeler certaines dÂ´eï¬nitions que nous utiliserons pour lâ€™Â´elaboration dâ€™une
fonction de dÂ´ecision pour le chevauchement.

DÂ´eï¬nition Un cÅ“ur de communautÂ´e est lâ€™ensemble des nÅ“uds se trouvant
frÂ´equemment ensemble dans une mË†eme communautÂ´e apr`es plusieurs lancements
dâ€™un algorithme non dÂ´eterministe (exemple de Louvain avec Seiï¬ et al. (2013)).

Ainsi, les nÅ“uds Â´etant presque toujours dans les mË†emes communautÂ´es au
cours des diï¬€Â´erentes propagations de labels ne portent pas `a confusion quant `a

142

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

la communautÂ´e `a laquelle ils appartiennent. Cependant, certains nÅ“uds ont une
frÂ´equence dâ€™apparition vis-`a-vis de certaines communautÂ´es bien plus faible. Nous
portons notre attention sur les nÅ“uds qui sont liÂ´es `a plusieurs communautÂ´es.
Nous dÂ´eï¬nissons ainsi la bordure de communautÂ´e.

DÂ´eï¬nition La bordure (ou fronti`ere) dâ€™une communautÂ´e est lâ€™ensemble des
nÅ“uds ayant au moins un lien vers une autre communautÂ´e. Elle constitue lâ€™en-
semble des candidats potentiels au chevauchement.

Figure 3.43 â€“ Exemple de bordure (ou fronti`ere), ici les nÅ“uds B, C et D

Dans lâ€™exemple de la Figure 3.43, il y a deux communautÂ´es avec la partition
P = {{A, B, E, F},{C, D}}. En considÂ´erant la communautÂ´e P1 = {A, B, E, F},
seul le nÅ“ud B poss`ede des liens `a lâ€™extÂ´erieure de la sa communautÂ´e, il ap-
partient donc `a la bordure de sa communautÂ´e (sa fronti`ere). En considÂ´erant la
communautÂ´e P2 = {C, D}, les nÅ“uds C et D poss`edent au moins un lien vers
une autre communautÂ´e, ils sont donc aussi sur la bordure de leurs communautÂ´es.

Pour nos Â´etudes expÂ´erimentales, nous utilisons certaines statistiques portant
sur les nÅ“uds chevauchants. Nous dÂ´eï¬nissons pour cela le pourcentage de chevau-
chement, le taux de chevauchement pour un nÅ“ud et le taux de chevauchement
moyen.

DÂ´eï¬nition Le pourcentage de chevauchement est le pourcentage de nÅ“uds ap-
partenant `a plusieurs communautÂ´es.

DÂ´eï¬nition Le taux de chevauchement pour un nÅ“ud est le rapport entre le
nombre de communautÂ´es auxquelles le nÅ“ud appartient et le nombre de com-
munautÂ´es auxquelles il est reliÂ´e.

DÂ´eï¬nition Le taux de chevauchement moyen est la moyenne des taux de che-
vauchement de tous les nÅ“uds du graphe.

3.4.2 Fonction dâ€™appartenance

La proposition algorithmique pour la dÂ´etection de communautÂ´es chevau-
chantes est fondÂ´ee sur lâ€™aspect sociologique dâ€™un individu vis-`a-vis de ses rela-
tions et des communautÂ´es auxquelles il est liÂ´e.

3.4. PROPOSITIONS SUR LE CHEVAUCHEMENT

143

ConsidÂ´erons lâ€™exemple sociologique suivant o`u le nÅ“ud Â´etudiÂ´e est u avec deux
communautÂ´es dâ€™individus. Les nÅ“uds sont des individus et les arË†etes leurs degrÂ´es
dâ€™amitiÂ´es. On suppose que le nÅ“ud u est ami avec Rebecca et avec Valentin.
Lors dâ€™une soirÂ´ee, la question est de savoir vers quelle communautÂ´e pourrait
aller le nÅ“ud u.

Figure 3.44 â€“ ExpÂ´erience sociale

Le nÅ“ud u a donc le choix entre trois communautÂ´es. Sa dÂ´ecision se fera selon
son degrÂ´e dâ€™amitiÂ´e avec Rebecca, Valentin et William mais aussi vis-`a-vis des
relations de ses amis. On peut sâ€™apercevoir de la forte collaboration au sein du
groupe de Valentin avec les nÅ“uds ayant une forte centralitÂ´e (certains ayant un
degrÂ´e de 4 ou de 5). Dans le groupe de Rebecca, la collaboration semble moins
forte mais est prÂ´esente. Dans le groupe de William, la collaboration semble faible,
certains nÅ“uds ne communiquent pas ensemble. En observant la topologie des
structures communautaires, le nÅ“ud u pourrait rejoindre au cours de la soirÂ´ee
le groupe de Rebecca ou celui de Valentin. Cependant, le nÅ“ud u ira cotoyer
un groupe si son lien avec lâ€™individu est assez fort. Si u a une plus grande
aï¬ƒnitÂ´e pour Rebecca et Valentin que pour William, u ira cotoyer en premier le
groupe de Rebecca puis celui de Valentin. Le nÅ“ud u pourrait alors appartenir `a
deux communautÂ´es. Notre proposition algorithmique repose sur le graphe seuillÂ´e
G(cid:48), rÂ´esultante de la matrice de frÂ´equence P N
ij . Lâ€™idÂ´ee est de pouvoir utiliser la
pondÂ´eration des liens que lâ€™on peut trouver dans la matrice de frÂ´equence comme
une relation dâ€™amitiÂ´e.
Le nouveau graphe G(cid:48) est alors projetÂ´e sur le graphe originel G, tout en
respectant sa topologie. Cela signiï¬e que les arË†etes prÂ´esentes dans G(cid:48) mais pas
dans G ne seront pas considÂ´erÂ´ees, aï¬n de ne pas mettre de liens absurdes. Ce
peut Ë†etre le cas sâ€™il y a des conï¬‚its entre personnes ou que des individus re-
fusent de parler `a dâ€™autres individus, comme dans le graphe de Zachary entre
le manager et lâ€™entraË†Ä±neur. Nous utilisons ainsi lâ€™information stockÂ´ee dans P N
ij
pour pondÂ´erer G. Cela nous permet de voir les paires de nÅ“uds ayant une forte
probabilitÂ´e dâ€™Ë†etre ensemble en terme communautaire. En utilisant le seuil Î± sur
le nouveau graphe pondÂ´erÂ´e, nous obtenons les communautÂ´es et les liens entre
communautÂ´es (LEC). Les nÅ“uds qui sont `a la fronti`ere de leurs communautÂ´es
et reliÂ´es `a dâ€™autres sont de possibles candidats pour le chevauchement. Pour sa-
voir si ces nÅ“uds candidats sont de potentiels futurs nÅ“uds chevauchants, nous
proposons les fonctions dâ€™appartenances suivantes.

ConsidÂ´erant un nÅ“ud candidat u, lâ€™idÂ´ee est de mesurer le pouvoir dâ€™ap-
partenance quâ€™a ce nÅ“ud en observant ses communautÂ´es avoisinantes et leurs
structures topologiques. Nous Â´ecrivons Cu = {Cu
K}, les diï¬€Â´erentes commu-

1 , ...,Cu

144

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

nautÂ´es auxquelles le nÅ“ud u est liÂ´e. Si u est liÂ´e `a K diï¬€Â´erentes communautÂ´es,
nous le notons par |Cu| = K.

Fonctions dâ€™appartenance pour le chevauchement

En considÂ´erant les K diï¬€Â´erentes communautÂ´es prÂ´esentes dans le voisinage

du nÅ“ud u, nous proposons la fonction dâ€™appartenance :

fX : u Ã— {C u

1 , ..., C u

K} (cid:55)âˆ’â†’ R+

fX (u,{C u

1 , ..., C u

K}) =

câˆˆ(cid:0)Cu

K
j

(cid:1),jâˆˆ{1,...,K}

max

(

(3.3)

Ï‰u,iX S(i))

(3.4)

|c| Ã—(cid:88)

1

iâˆˆc

o`u c est une liste de combinaisons de communautÂ´es voisines dâ€™un nÅ“ud u et
X un param`etre portant sur une mesure sociale fondÂ´ee sur la structure topolo-
gique dâ€™un sous-graphe. Le terme c va prendre toutes les combinaions possibles,
notamment avec j âˆˆ {1, ..., K}. Par la suite, le terme i âˆˆ c signiï¬e que lâ€™on
va regarder toutes les combinaisons de communautÂ´es de c, ainsi, nous pourrons
avoir les pondÂ´erations des liens Ï‰u,i, o`u Ï‰u,i est la somme des poids des arË†etes
liant le nÅ“ud u aux communautÂ´es dans la liste i. Le terme X S(i) reprÂ´esente la
valeur dâ€™une mesure sociale du sous graphe (ici la communautÂ´e) S constituÂ´e de
lâ€™union des communautÂ´es de i.

(cid:1) permet de calculer les j combinaisons dans un
(cid:1)). Cela permet au nÅ“ud u dâ€™appartenir `a une ou plusieurs commu-

ensemble de Cu
K Â´elÂ´ements, les Â´elÂ´ements Â´etant les communautÂ´es. Ainsi, un nÅ“ud
va essayer toutes les combinaisons de communautÂ´es auquel il pourrait appartenir

Le cÅ“ï¬ƒcient binomial (cid:0)Cu
(c âˆˆ (cid:0)Cu

K
j

nautÂ´es. La conï¬guration ayant le score le plus Â´elevÂ´e permettra lâ€™assignement du
nÅ“ud u aux communautÂ´es choisies.

K
j

Nous notons dans la formule ci-dessus que j âˆˆ {1, ..., K}, mais il est tout `a
fait possible de forcer un nÅ“ud candidat soit chevauchÂ´e par au moins L com-
K|}. Cela permet `a lâ€™utilisateur de choisir le
munautÂ´es, en Â´ecrivant j âˆˆ {L, ...,|C u
nombre de communautÂ´es auxquelles peut appartenir un nÅ“ud candidat.

Pour les mesures sociales portant sur la structure topologique des commu-
nautÂ´es, nous proposons dâ€™utiliser la densitÂ´e (dont la fonction dâ€™appartenance est
notÂ´e fd) et le cÅ“ï¬ƒcient de clustering (dont la fonction dâ€™appartenance est notÂ´e
fcc). Ces mesures sont utilisÂ´ees pour eï¬€ectuer une Â´etude comparative.

En ce qui concerne la fonction dâ€™appartenance fondÂ´ee sur la densitÂ´e, un nÅ“ud
avec une forte pondÂ´eration sur ses liens connectÂ´es `a des communautÂ´es ayant de
fortes densitÂ´es aura plus de chance dâ€™Ë†etre chevauchant plutË†ot quâ€™un nÅ“ud avec
de faibles pondÂ´erations sur ses arË†etes connectÂ´ees `a des communautÂ´es de faibles

3.4. PROPOSITIONS SUR LE CHEVAUCHEMENT

145

densitÂ´es. Cependant, dans certaines situations, les chevauchements ne peuvent
pas se faire. Cela peut Ë†etre le cas si un nÅ“ud u est tr`es faiblement liÂ´e `a ses
communautÂ´es avoisinantes, elles mË†emes de faibles densitÂ´es, avec une valeur de
fd relativement faible. FondÂ´e sur ce constat, le chevauchement sera eï¬€ectuÂ´e si
et seulement si fd(u,{C u
Sâˆˆc dS o`u dS est la densitÂ´e du sous
graphe (ici la communautÂ´e) S.

K}) â‰¥ 1|c|

1 , ..., C u

(cid:80)

Lâ€™idÂ´ee dâ€™utiliser ensuite le cÅ“ï¬ƒcient de clustering est que le nÅ“ud candi-
dat observera les connexions au sein des communautÂ´es, et la prÂ´esence de lea-
ders, caractÂ´eristique des graphes de terrains dont la distribution des degrÂ´es
des nÅ“uds suit une loi faible. De mË†eme que pour la densitÂ´e, si un nÅ“ud u
est tr`es faiblement liÂ´e `a ses communautÂ´es avoisinantes, elles mË†emes de faibles
cÅ“ï¬ƒcients de clustering, il nâ€™y a pas de raison pour quâ€™il y ait de chevauche-
ment. FondÂ´e sur ce constat, le chevauchement sera eï¬€ectuÂ´e si et seulement si
fcc(u,{C u
Sâˆˆc ccS o`u ccS est le coeï¬ƒcient de clustering du sous
graphe (ici la communautÂ´e) S.

K}) â‰¥ 1|c|

1 , ..., C u

(cid:80)

Supposons que nous ayons le graphe de la ï¬gure 3.45, avec la partition
P = {C1, C2, C3, C4} telle que C1 = {v1, v2, v3},C2 = {v4, v5, v6}, C3 = {v7, v8}
and C4 = {u}, rÂ´esultante de la propagation de labels avec matrice de frÂ´equence.
La question est de savoir si le nÅ“ud u peut appartenir `a plusieurs communautÂ´es.
On observe que la meilleure conï¬guration pour lâ€™obtention de communautÂ´es che-
vauchantes sur le nÅ“ud u est donnÂ´ee avec C1 et C2. Le nÅ“ud u est ainsi assignÂ´e
dans la combinaison o`u les densitÂ´es sont les plus Â´elevÂ´ees, et les pondÂ´erations des
liens sont les plus fortes.

Figure 3.45 â€“ Apr`es avoir calculÂ´e fd et fcc sur le nÅ“ud u, u appartient `a deux com-
munautÂ´es.

3.4.3 Propositions algorithmiques pour la dÂ´etection de com-

munautÂ´es chevauchantes

Nous exposons la propagation de labels avec dÂ´etection de cÅ“urs et chevau-

chement (CDLPOV), algorithme 7.

fappartenance fait rÂ´efÂ´erence `a la fonction choisie par lâ€™utilisateur, `a savoir fd ou
fCC. SN M (S) est la mesure dâ€™analyse des rÂ´eseaux sociaux utilisÂ´ee concernant
lâ€™aspect topologique de la communautÂ´e S, `a savoir la densitÂ´e ou le CC. En faisant

146

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

Algorithme 7 Le CDLP avec fonction dâ€™appartenance (CDLPOV)
EntrÂ´ee : Un graphe G = (V, E), le seuil Î±, N le nombre de lancements
Sortie : Les communautÂ´es chevauchantes de G
1: Allouer une matrice de frÂ´equence vide
2: Lancer N fois la propagation de labels asynchrone
3: Remplir la matrice de frÂ´equence avec les rÂ´esultats des N LPA
4: CrÂ´eer un nouveau graphe G(cid:48) = (V, E(cid:48)) de P N
ij avec des arË†etes dont la pondÂ´eration
5: Projeter le graphe G(cid:48) sur G avec la pondÂ´eration (mais en enlevant les arË†etes
6: CrÂ´eer une partition P = {P1, ..., PC} en considÂ´erant les C composantes connexes

est supÂ´erieure ou Â´egale `a Î±
prÂ´esentes dans G(cid:48) mais pas dans G)

comme cÅ“urs

7: Calculer les arË†etes entre communautÂ´es (AEC)
8: Cand â† [] {Cand est une liste de candidats potentiels au chevauchement (nÅ“uds

`a la fronti`ere des communautÂ´es)}

Cand.ajouter(u)

9: Pour chaque nÅ“ud u ayant une arË†ete dans AEC Faire
10:
11: Fin Pour
12: P Ov â† P {Partition chevauchante que renverra lâ€™algorithme}
13: Pour chaque nÅ“ud u dans Cand Faire
14:
15: Fin Pour
16: Pour chaque nÅ“ud u dans Cand Faire
17:

Si fappartenance(u,{C u

K}) â‰¥(cid:80)

Cand.ajouter(u)

18:
Fin Si
19:
20: Fin Pour
21: Retournez la partition P Ov = {P Ov

1

, ..., P OvC }.

Dupliquer le nÅ“ud u dans les communautÂ´es correspondantes de P Ov

1 , ..., C u

Sâˆˆ{Cu

1 ,...,Cu

K} SN M (S) Alors

3.4. PROPOSITIONS SUR LE CHEVAUCHEMENT

147

varier Î± dans un intervalle et avec un pas spÂ´eciï¬que, nous pouvons obtenir un
dendrogramme chevauchant.

3.4.4 ExpÂ´erimentations sur CDLPOV

Nous testons nos mÂ´ethodes sur des graphes rÂ´eels sociologiques que nous avons
exposÂ´es en introduction. Pour lâ€™Â´evaluation de nos mÂ´ethodes, nous considÂ´erons
lâ€™information mutuelle normalisÂ´ee dans sa forme chevauchante (NMI), le F-Score
dans sa forme chevauchante (F1), lâ€™indice dâ€™omega (â„¦) et la modularitÂ´e de
Nicosia (QN ic
Ov ). Dâ€™autres informations sont donnÂ´ees telles que le pourcentage
de candidats au chevauchement (cand), le pourcentage de nÅ“uds chevauchants
(candOv) et le pourcentage dâ€™arË†etes entre communautÂ´es (AEC).

Pour analyser les rÂ´esultats des deux mÂ´ethodes proposÂ´ees, nous utilisons des
rÂ´eseaux rÂ´eels dont certains sont connus comme ayant des nÅ“uds chevauchants.
A ce titre, nous exposons les caractÂ´eristiques portant sur le chevauchement des
rÂ´eseaux que nous utilisons. Nous mettons Â´egalement les ï¬gures pour certains.

Le graphe de Zachary KaratÂ´e club est connu comme ayant deux commu-
nautÂ´es, et mË†eme trois pour certains. La littÂ´erature montre lâ€™existence de deux
nÅ“uds appartenant `a plusieurs communautÂ´es. Le graphe de Zachary sâ€™est construit
sur une dispute opposant le manager et lâ€™entraË†Ä±neur dâ€™un club de karatÂ´e. Le
rÂ´esultat de cette dispute fut la crÂ´eation de deux clubs de karatÂ´e dans une mË†eme
rue. Le premier nÅ“ud qui est chevauchant est ami `a la fois avec le manager et
lâ€™entraineur du club. Il poss`ede un lien dans chacune des deux communautÂ´es. Le
second nÅ“ud chevauchant est interne `a une grande communautÂ´e, que lâ€™on peut
subdiviser en deux. Il sâ€™agit dâ€™un groupe de personnes amies entre elles dont
lâ€™unique connexion au groupe est une personne amie du manager. Ce nÅ“ud ap-
partient `a un chevauchement.

Figure 3.46 â€“ Les nÅ“uds chevauchants dans le graphe de Zachary

148

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

Le rÂ´eseau de dauphins est caractÂ´erisÂ´e par deux communautÂ´es reprÂ´esentant
dâ€™un cË†otÂ´e les mË†ales et de lâ€™autre les femelles. Câ€™est un graphe o`u il nâ€™y a pas de
chevauchement.

Le rÂ´eseau footbalistique reprÂ´esente 11 confÂ´erences. On consid`ere quâ€™il y a

huit clubs qui appartiennent `a plusieurs communautÂ´es.

Le graphe des livres politiques, des annÂ´ees 50 `a lâ€™Â´election prÂ´esidentielle
amÂ´ericaine de 2004 est constituÂ´e de trois communautÂ´es, `a savoir les rÂ´epublicains,
les neutres et les dÂ´emocrates. Les livres politiquement neutres sont une rÂ´etrospective
de la politique amÂ´ericaine, notamment par des explications historiques. La po-
litique amÂ´ericaine a connu une succession de diï¬€Â´erentes politiques dÂ´emocrates et
rÂ´epublicaines. Depuis 1961 et jusquâ€™en 2004, quatre prÂ´esidents ont Â´etÂ´e dÂ´emocrates
et cinq prÂ´esidents ont Â´etÂ´e rÂ´epublicains. Certains livres du rÂ´eseau citent des
pÂ´eriodes prÂ´esidentielles marquÂ´ees par des politiques diï¬€Â´erentes, menÂ´ees par des
partis diï¬€Â´erents. Câ€™est par exemple le cas de â€Ghost warsâ€, de Steve Coll qui
retrace lâ€™histoire de la CIA depuis les cinquantes derni`eres annÂ´ees. Nous nous
attendons `a ce que ce livre puisse appartenir aux trois communautÂ´es que sont
les rÂ´epublicains, les neutres et les dÂ´emocrates.

Le rÂ´eseau de collaboration scientiï¬que montre des communautÂ´es caractÂ´erisÂ´ees
par un th`eme scientiï¬que. Cependant, certains chercheurs ont publiÂ´e dans di-
vers domaines et sont susceptibles dâ€™appartenir `a plusieurs communautÂ´es. Par
exemple, Mark Newman, physicien amÂ´ericain, publie `a la fois dans le domaine
de la dÂ´etection de communautÂ´es mais Â´egalement dans divers domaines liÂ´es au
graphe comme les hypergraphes. Cependant, le graphe qui a Â´etÂ´e formÂ´e a dÂ´ej`a
Â´etÂ´e bien dÂ´eï¬ni au sens communautaire et il nâ€™y a que peu de chevauchement.

Zachary Karate Club

Le graphe est caractÂ´erisÂ´e par deux communautÂ´es.

Figure 3.47 â€“ CommunautÂ´es avec diï¬€Â´erentes valeurs de Î± en utilisant fd et fcc, a)
Î± â‰¥ 0.6, b) Î± â‰¥ 0.7 c) Î± â‰¥ 0.8

Sur la ï¬gure 3.47, les candidats pour le chevauchement avec fd et fcc sont

3.4. PROPOSITIONS SUR LE CHEVAUCHEMENT

149

les mË†emes. Pour Î± â‰¤ 0.6, seul le nÅ“ud 10 est chevauchant. Il est assignÂ´e `a la
communautÂ´e C2 avec fcc alors quâ€™il est assignÂ´e `a deux communautÂ´es avec fd
(qui sont C3 et C4). Cela vient du fait que la communautÂ´e C2 a un nombre plus
important de triangles que C4.

Pour Î± â‰¥ 0.8, le nÅ“ud 3 qui est connu dans la littÂ´erature comme Â´etant che-
vauchant, est assignÂ´e `a deux communautÂ´es avec fd (C5 et C4), mais juste `a une
communautÂ´e avec fcc (C4). Le nÅ“ud 1 est assignÂ´e `a une communautÂ´e (C2) pour
chacune des deux mÂ´ethodes.

Dâ€™apr`es les rÂ´esultats du tableau 3.24, plus la valeur de Î± est Â´elevÂ´ee, plus le
nombre de candidats pour le chevauchement devient important. Cela vient du
fait que les tailles des communautÂ´es diminuent alors que Î± croË†Ä±t. De ce fait,
le pourcentage AEC devient plus important, augmentant les nÅ“uds candidats.
MË†eme si les nÅ“uds chevauchants sont les mË†emes selon fd et fcc jusque Î± â‰¥ 0.9,
la qualitÂ´e des rÂ´esultats est meilleure en utilisant fd plutË†ot que fcc. La valeur de
la modularitÂ´e la plus Â´elevÂ´ee est pour Î± â‰¥ 0.7 (0.62 pour chacune des mÂ´ethodes)
avec les valeurs les plus fortes pour le NMI et pour lâ€™indice â„¦.

RÂ´esultat avec fd et fcc sur le club de Karate

Cand

CandOv
2.94% (1)
8.824% (3)

47.058%
41.17%
55.88% 32.352% (11)
55.88% 32.352% (11)
Cand

NMI #
fd
Î± â‰¥ 0.6
2
0.237
Î± â‰¥ 0.7
4
0.518
Î± â‰¥ 0.8
5
0.349
Î± â‰¥ 0.9
0.349
5
NMI #
fcc
Î± â‰¥ 0.6
2
0.237
Î± â‰¥ 0.7
3
0.518
Î± â‰¥ 0.8
5
0.349
Î± â‰¥ 0.9
0.349
5
Tableau 3.24 â€“ Cand : candidats possibles , CandOv : Pourcentage de nÅ“uds chevau-
chants

QN ic
AEC
Ov
17.95% 0.399
16.0%
0.621
26.92% 0.420
26.92% 0.420
QN ic
AEC
Ov
17.948% 0.399
0.621
26.923% 0.420
26.923% 0.420

2.941% (1)
8.823% (3)

47.058%
41.176%
55.882% 32.353% (11)
55.882% 32.353% (11)

F1
0.65
0.857
0.75
0.75
F1
0.65
0.857
0.75
0.75

â„¦

0.065
0.711
0.492
0.492

â„¦

0.064
0.711
0.492
0.492

CandOv

16.0%

Les femmes du sud de Davis (rÂ´eseau bipartie)

Il sâ€™agit dâ€™un rÂ´eseau reprÂ´esentant 18 femmes, observÂ´ees sur une pÂ´eriode de 9
mois dans les annÂ´ees 1930. Durant cette pÂ´eriode, de nombreux sous-groupes de
ces femmes vont se rencontrer dans une sÂ´erie de 14 Â´ev`enements sociaux infor-
mels. Chacun des nÅ“uds dans ce rÂ´eseau `a deux modes a un nom, reprÂ´esentant
une femme ou un Â´ev`enement (avec la notation Ek pour le k`eme Â´ev`enement).

150

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

Figure 3.48 â€“ RÂ´esultat sur le reseau FM avec Î± â‰¥ 0.9

RÂ´esultat avec fd sur FM

Î± â‰¥ 0.9
Î± â‰¥ 1.0

Cand

71.875%

87.5%

CandOv
25.0% (5)
75.0% (14)

QN ic
AEC
Ov
33.33% 0.502âˆ—
56.99% 0.021âˆ—

RÂ´esultat avec fcc sur FM

Î± â‰¥ 0.9
Î± â‰¥ 1.0

Cand

CandOv

71.875% 65.625% (12)

87.5%

87.5% (16)

QN ic
AEC
Ov
33.33% 0.157*
0.0âˆ—
56.989%

#
4
17

#
4
17

Tableau 3.25 â€“ Cand : candidats possibles, CandOv : Pourcentage de nÅ“uds chevau-
chants

En considÂ´erant le Tableau 3.25, pour Î± â‰¥ 0, 8, nous nâ€™avons quâ€™une commu-
nautÂ´e. Pour Î± â‰¥ 0, 9, sur la ï¬gure 3.48, nous obtenons quatre communautÂ´es.
Apr`es avoir calculÂ´e fd, nous avons 25% de nÅ“uds dans des communautÂ´es che-
vauchantes. Comme nous pouvons le voir, câ€™est `a la fois les nÅ“uds reprÂ´esentant
des individus et des Â´ev`enements qui sont assignÂ´es `a des communautÂ´es chevau-
chantes. Verne est assignÂ´e `a E7, E8, E9 et E12. E7 et E9 sont assignÂ´es `a
Theresa, Laura et Brenda (dans la communautÂ´e C1), puis pour Verne dans C4
et ï¬nalement pour HÂ´el`ene et Sylvia C3, soit `a trois communautÂ´es diï¬€Â´erentes.
Theresa est assignÂ´ee aux activitÂ´es E6, E7 et E8. A la ï¬n du processus, certains
nÅ“uds sont liÂ´es `a plusieurs Â´ev`enements comme Verne avec E7, E8, E9 et E12.
pour Î± = 1, 0, nous obtenons 17 communautÂ´es. La majoritÂ´e des communautÂ´es
regroupe des personnes avec leurs Â´ev`enements qui sont assignÂ´es aux personnes
ayant de fortes centralitÂ´es.

On observe quâ€™utiliser fcc entraË†Ä±ne un pourcentage de chevauchement plus
important quâ€™en utilisant fd (65.625% contre 25.0%), avec un taux de chevau-
chement moyen plus important, particuli`erement pour les Â´ev`enements.

Les dauphins de Nouvelle ZÂ´elande

Le graphe est composÂ´e de deux communautÂ´es, qui regroupent les mË†ales et les
femelles.

3.4. PROPOSITIONS SUR LE CHEVAUCHEMENT

151

RÂ´esultats avec fd et fcc sur le rÂ´eseau de dauphins

Cand

CandOv

0.0%

6.451% (4)
8.065% (5)

19.355% (12)
25.81% (16)

51.61% %
54.838%
64.51%
61.29%
77.41%
Cand

fd
Î± â‰¥ 0.5
Î± â‰¥ 0.6
Î± â‰¥ 0.7
Î± â‰¥ 0.8
Î± â‰¥ 0.9
fcc
Î± â‰¥ 0.5
Î± â‰¥ 0.6
0.594
Î± â‰¥ 0.7
0.457
Î± â‰¥ 0.8
0.442
Î± â‰¥ 0.9
0.277
Tableau 3.26 â€“ Cand : candidats possibles, CandOv : Pourcentage de nÅ“uds chevau-
chants

QN ic
AEC
Ov
20.38% 0.7959
24.050% 0.750
0.714
30.57%
29.30%
0.605
0.542
43.94%
QN ic
AEC
Ov
20.382% 0.796
24.051% 0.750
0.714
30.57%
29.3%
0.606
43.949% 0.441

NMI #
2
1.0
4
0.594
5
0.457
8
0.442
0.246
12
NMI #
2
1.0
4
5
8
12

51.613%
54.838%
64.516%
61.29%
77.419%

F1
1.0
.857
0.75
0.618
0.549

â„¦
1.0

0.617
0.478
0.478
0.355

â„¦
1.0

0.613
0.429
0.478
0.588

CandOv

0.0%

6.451% (4)
8.065% (5)

F1
1.0
.857
0.75

0.6184
0.533

19.355% (12)
35.483% (22)

A partir du tableau 3.26, pour Î± â‰¥ 0.5, lâ€™algorithme et les fonctions trouvent
les deux communautÂ´es, sans aucun chevauchement, avec un NMI, un indice
dâ€™omega et un F1 score de 1,0. En augmentant la valeur de Î±, la taille des
communautÂ´es diminue tandis que le nombre de candidats possibles pour le che-
vauchement augmente. Le pourcentage de chevauchement est le mË†eme pour
Î± â‰¥ 0.6 jusquâ€™`a Î± â‰¥ 0.8. MalgrÂ´e cela, les deux mÂ´ethodes nâ€™assignent pas les
nÅ“uds candidats de la mË†eme mani`ere. fcc produit la mË†eme qualitÂ´e en termes de
communautÂ´es mais a un pourcentage de chevauchement et un taux de chevau-
chement moyen plus important quâ€™avec fd, surtout pour de fortes valeurs de Î±.

Figure 3.49 â€“ RÂ´eseaux de dauphins a) Î± â‰¥ 0, 5, b) Î± â‰¥ 0, 6, les nÅ“uds chevauchants
avec fcc et fdd sont les mË†emes

En observant la ï¬gure 3.49, pour Î± â‰¥ 0.6, nous voyons que 4 nÅ“uds ont
Â´etÂ´e selectionnÂ´es pour appartenir `a plus dâ€™une communautÂ´e. En considÂ´erant leurs
aspects topologiques, SN 89 est liÂ´e `a deux communautÂ´es avec une arË†ete liÂ´ee `a
chacune, il est assignÂ´e `a ses communautÂ´es voisines. Il en est de mË†eme pour
T opless qui a 6 arË†etes `a lâ€™intÂ´erieur de sa communautÂ´e et 4 `a lâ€™extÂ´erieur. Zap a
trois nÅ“uds `a lâ€™intÂ´erieur de sa communautÂ´e et 2 `a lâ€™extÂ´erieur. Il est assignÂ´e `a C4.
SN 100 a 4 arË†etes `a lâ€™intÂ´erieur de sa communautÂ´e et deux `a lâ€™extÂ´erieur vers deux
communautÂ´es. Il est assignÂ´e aux communautÂ´es C3 et C4. SN 9 a juste une arË†ete

152

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

de plus que SN 100 `a lâ€™intÂ´erieur de la communautÂ´e avec la mË†eme conï¬guration
topologique, il nâ€™est cependant pas assignÂ´e. Pour Î± â‰¥ 0.6, les rÂ´esultats, que cela
soit en utilisant fd ou fcc sont les mË†emes. Pour chacune des deux mÂ´ethodes, la
taille des dendrogrammes est de 6. De Î± â‰¥ 0.5 `a Î± â‰¥ 0.9, le nombre de nÅ“uds
sÂ´electionnÂ´es pour le chevauchement est le mË†eme, mais le pourcentage de che-
vauchement avec fcc est plus important avec fd.

Le rÂ´eseau footballistique

RÂ´esultats avec fd sur le rÂ´eseau footballistique

â„¦

CandOv

0.0%
0.0%
0.0%

F1

0.762
0.810
0.854
0.854
0.861
0.819
0.819

0.530
0.681
0 .865
0.851
0.882
0.825
0.825

Cand
100.0%
100.0%
100.0%
100.0% 0.87% (1)
100.0% 1.74% (2)
100.0% 8.69% (10)
100.0% 8.69% (10)
Cand
100.0%
100.0%
100.0%
100.0% 0.87% (1)
100.0% 1.74% (2)
100.0% 8.69% (10)
100.0% 8.69% (10)

fd
Î± â‰¥ 0.2
Î± â‰¥ 0.3
Î± â‰¥ 0.4
Î± â‰¥ 0.5
Î± â‰¥ 0.6
Î± â‰¥ 0.7
Î± â‰¥ 0.8
fcc
Î± â‰¥ 0.2
Î± â‰¥ 0.3
Î± â‰¥ 0.4
Î± â‰¥ 0.5
Î± â‰¥ 0.6
Î± â‰¥ 0.7
Î± â‰¥ 0.8
Tableau 3.27 â€“ Cand : Candidats possibles, CandOv : Pourcentage de nÅ“uds chevau-
chants

NMI #
9
0.597
10
.639
0.685
11
11
0.682
12
0.666
13
0.629
0.629
13
NMI #
9
0.512
10
0.639
11
0.685
0.682
11
12
0.666
13
0.629
0.629
13

F1
0.76
0.81
0.854
0.854
0.85
0.819
0.819

0.7

EC

QN ic
Ov
29.53% 0.722
29.53% 0.708
30.01%
30.01% 0.699
30.83% 0.690
31.32% 0.629
31.32% 0.629
QN ic
Ov
29.53% 0.722
29.53% 0.708
30.016% 0.699
30.016% 0.699
30.832% 0.690
31.321% 0.629
31.32% 0.629

EC

â„¦

0.530
0.681
0.865
0.851
0.882
0.825
0.825

CandOv

0.0%
0.0%
0.0%

Selon le tableau 3.27, câ€™est pour Î± â‰¥ 0, 5 que les premiers nÅ“uds chevau-
chants apparaissent. De Î± â‰¥ 0, 5 `a Î± â‰¥ 0.9, le nombre de nÅ“uds chevauchants
est le mË†eme, ainsi que leur taux de chevauchement moyen. Les rÂ´esultats en
termes de similaritÂ´e de score de qualitÂ´es sont semblables. les meilleurs scores
sont pour Î± â‰¥ 0, 5 avec un NMI 0.68. Le nombre de communautÂ´es augmente
tr`es lentement puis fortement avec Î± = 1.0.

Les livres politiques de Kreb

3.4. PROPOSITIONS SUR LE CHEVAUCHEMENT

153

Câ€™est un rÂ´eseau de livres politiques datant de lâ€™Â´election prÂ´esidentielle amÂ´ericaine

de 2004 et vendus sur le site de vente en ligne Amazon.com. Ce graphe comporte
trois communautÂ´es au sens politique, `a savoir les dÂ´emocrates, les rÂ´epublicains
et le centre sur lâ€™Â´echiquier politique.

0.0%

Resultats avec fcc et fd sur les livres politiques de Kreb
F1

CandOv

EBC

â„¦

Cand

0.95% (1)
1.90% (2)
5.71% (6)

24.762%
26.67%
31.43%
32.38%
35.24%
Cand

NMI #
fd
Î± â‰¥ 0.4
2
0.452
Î± â‰¥ 0.5
2
0.494
Î± â‰¥ 0.6
0.387
3
Î± â‰¥ 0.7
4
0.354
Î± â‰¥ 0.8
0.290
7
NMI #
fd
Î± â‰¥ 0.4
0.504
2
Î± â‰¥ 0.5
2
0.494
Î± â‰¥ 0.6
3
0.449
Î± â‰¥ 0.7
4
0.340
Î± â‰¥ 0.8
0.28
7
Tableau 3.28 â€“ Cand : Candidats possibles , CandOv : Pourcentage de nÅ“uds chevau-
chants

QN ic
Ov
5.215% 0.834
6.576% 0.834
7.71%
0.845
0.76
9.07%
0.653
9.98%
QN ic
EBC
Ov
5.215% 0.834
6.576% 0.834
7.709% 0.844
9.070% 0.782
9.977% 0.6533

24.761%
26.67%
31.428%
32.380%
35.238% 15.238% (16)

0.952% (1)
0.952% (1)
5.714% (6)

0.788
0.784
0.713
0.664
0.566

0.667
0.654
0.676
0.686
0.667

F1

0.788
0.774
0.719
0.653
0.532

â„¦

0.667
0.654
0.676
0.687
0.667

15.24% (16)

CandOv

0.0%

Dâ€™apr`es le tableau 3.30, câ€™est pour Î± â‰¥ 0.5 que les premiers nÅ“uds chevau-
chants apparaissent. Les rÂ´esultats sont tr`es similaires pour les deux mÂ´ethodes,
nÂ´eanmoins, fd donne un pourcentage de chevauchement et un taux de chevau-
chement moyen plus Â´elevÂ´e selon nos observations quâ€™en utilisant fcc. Le nombre
de communautÂ´es augmente lentement en fonction de la valeur Î±, comme celui
des candidats au chevauchement. De 0.4 â‰¤ Î± â‰¤ 0.8, la majoritÂ´e des nÅ“uds che-
vauchants sont neutres sur le plan politique amÂ´ericain.

(a) Le rÂ´eseau de livres politiques avec
Î± â‰¥ 0, 3

(b) Le rÂ´eseau de livres politiques avec
Î± â‰¥ 0, 6

Figure 3.50 â€“ RÂ´esultats avec fd et fcc

Sur la ï¬gure 3.50a, nous voyons que la mÂ´ethode pour Î± â‰¥ 0.3 donne deux
communautÂ´es qui reprÂ´esentent les rÂ´epublicains et les dÂ´emocrates, il nâ€™y a pas
de chevauchements. Sur la ï¬gure 3.50b, avec Î± â‰¥ 0.6, la mÂ´ethode trouve trois

154

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

communautÂ´es, les rÂ´epublicains, les dÂ´emocrates et les neutres et un nÅ“ud che-
vauchant, mais qui nâ€™est pas associÂ´e aux communautÂ´es de la mË†eme faÂ¸con selon
les fonctions dâ€™appartenance utilisÂ´ees. Il sâ€™agit du livre â€Ghost Warsâ€ Â´ecrit par
Steve Coll et publiÂ´e en 2004. Ce livre retrace lâ€™action de la CIA des annÂ´ees
1965 `a 2004, sous les diï¬€Â´erentes administrations amÂ´ericaines, contre des rÂ´eseaux
criminels. Ce livre nâ€™a pas dâ€™orientation politique et nâ€™est quâ€™historique. Les
tableaux 3.29 et 3.30 montrent certains livres chevauchant plusieurs commu-
nautÂ´es. Pour Ghost Wars, le livre est neutre pour Î± â‰¥ 0.5, puis chevauche la
communautÂ´e rÂ´epublicaine avec Î± â‰¥ 0.6 et ï¬nalement chevauche Â´egalement la
communautÂ´e dÂ´emocrate avec Î± â‰¥ 0.7, quelles que soient les fonctions utilisÂ´ees.
Ce livre est chevauchant car il est citÂ´e de nombreuses fois par les communautÂ´es
rÂ´epublicaines et dÂ´emocrates. En eï¬€et, des annÂ´ees 1965 `a 2004, les diï¬€Â´erentes ad-
ministrations amÂ´ericaines Â´etaient soit dÂ´emocrates (Lyndon B. Johnson, Jimmy
Carter et Bill Clinton), soit rÂ´epublicaines (Richard M. Nixon, Gerald R. Ford,
Ronald W. Reagan, George H. W. Bush). NÂ´eanmoins,il existe plus de liens vers
la communautÂ´e rÂ´epublicaine (4) que vers la communautÂ´e dÂ´emocrate (3), câ€™est
lâ€™une des raisons qui ont pu le placer dans le parti rÂ´epublicain lors du premier
chevauchement. Les autres livres ont une appartenance politique, mais restent
proches de la fronti`ere des communautÂ´es. Ils sont chevauchÂ´es avec la commu-
nautÂ´e neutre.

Livres
Ghost Wars
Ghost Wars
Ghost Wars
Disarming
Disarming
Rise of the Vulcans
The choice
The great unraveling
American Dynasty

DÂ´emocrates

Neutres

Resultats avec fd
âˆš
âˆš
âˆš
âˆš
âˆš
âˆš
âˆš
âˆš

âˆš
âˆš
âˆš
âˆš
âˆš
âˆš

RÂ´epublicains

âˆš
âˆš
âˆš
âˆš
âˆš
âˆš

Tableau 3.29 â€“ Les livres chevauchants

Livres
Ghost Wars
Ghost Wars
Ghost Wars
Disarming
Disarming
Rise of the Vulcans
The choice
The great unraveling
American Dynasty

DÂ´emocrates

Neutres

Resultats avec fcc
âˆš
âˆš
âˆš
âˆš
âˆš
âˆš
âˆš
âˆš
âˆš

âˆš
âˆš
âˆš
âˆš
âˆš

RÂ´epublicains

âˆš
âˆš

âˆš
âˆš

Tableau 3.30 â€“ Les livres chevauchants

Î±
0.5
0.6
0.7
0.6
0.7
0.7
0.7
0.7
0.7

Î±
0.5
0.6
0.7
0.7
0.7
0.7
0.7
0.7
0.7

3.4. PROPOSITIONS SUR LE CHEVAUCHEMENT

155

Les rÂ´eseaux de collaborations scientiï¬ques de Newman (Netscience)

Ce graphe reprÂ´esentant des collaborations scientiï¬ques entre chercheurs est ca-
ractÂ´erisÂ´e par une tr`es faible densitÂ´e 0.0021. Les tailles de communautÂ´es dÂ´etectÂ´ees
sont tr`es petites. Observant le tableau 3.31, câ€™est pour Î± â‰¥ 0.4 que les premiers
nÅ“uds chevauchants apparaissent. Le nombre dâ€™arË†etes entre communautÂ´es est
relativement faible, de 2.39% dâ€™arË†etes avec Î± â‰¥ 0.2 `a 18.27% avec Î± â‰¥ 0.8,
impliquant un faible pourcentage de candidats. Seulement 0.61% de nÅ“uds sont
candidats avec Î± â‰¥ 0.4 tandis que lâ€™on obtient 6.36% pour fd. Pour chacune
des mÂ´ethodes, le pourcentage de chevauchement est tr`es similaire et relative-
ment faible. Observant la modularitÂ´e, les rÂ´esultats sont tr`es similaires. On peut
conclure que pour des graphes faiblement denses, les rÂ´esultats sont tr`es similaires
en utilisant les fonctions fondÂ´ees sur la densitÂ´e ou sur le coeï¬ƒcient de clustering.

fd
Î± â‰¥ 0.2
Î± â‰¥ 0.3
Î± â‰¥ 0.4
Î± â‰¥ 0.5
Î± â‰¥ 0.6
Î± â‰¥ 0.7
Î± â‰¥ 0.8
fcc
Î± â‰¥ 0.2
Î± â‰¥ 0.3
Î± â‰¥ 0.4
Î± â‰¥ 0.5
Î± â‰¥ 0.6
Î± â‰¥ 0.7
Î± â‰¥ 0.8

CandOv (nombre)

0.0%
0.0%

CandOv (nombre)

0.616% (9)
0.684% (10)
2.396% (35)
4.517% (72)
6.366% (101)

Resultats avec fd sur Netscience
QN ic
AEC
Ov
2.396% 0.977
4.175% 0.972
5.79%
0.948
7.734% 0.940
12.731% 0.886
15.332% 0.845
18.275% 0.817
QN ic
AEC
Ov
2.396% 0.977
4.175% 0.972
3.146% 0.949
4.232% 0.942
6.966% 0.886
0.855
8.39%
10.0%
0.813

Cand
3.285%
5.544%
7.392%
9.240%
14.099%
16.016%
18.07%
Cand
3.285%
5.544%
7.392%
9.240%
14.1%
16.016%
18.07%

0.0%
0.0%

0.548% (8)
0.616% (9)
2.164% (36)
5.339% (85)
7.05% (112)

#
293
297
308
315
342
360
371
#
293
297
308
315
342
360
371

Tableau 3.31 â€“ Cand : Candidats possibles, CandOv : Pourcentage de nÅ“uds chevau-
chants

3.4.5 Etude portant sur le temps dâ€™exÂ´ecution

Le temps dâ€™exÂ´ecution de lâ€™algorithme dÂ´epend `a la fois du temps nÂ´ecessaire au
calcul des N propagations de labels alimentant la matrice de frÂ´equence âˆ†CDLP
(incluant le temps de crÂ´eation du nouveau graphe qui induit la recherche des
composantes connexes qui sont nos communautÂ´es) et le temps de calcul de la
fonction dâ€™appartenance âˆ†f onction. Le temps de lecture et dâ€™Â´ecriture des ï¬chiers

156

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

nâ€™est pas pris en compte. Le temps dâ€™exÂ´ecution est ainsi dÂ´ecomposÂ´e de la mani`ere
suivante : âˆ†T = âˆ†CDLP + âˆ†f onction.

Concernant le temps dâ€™exÂ´ecution du CDLP, ï¬gure a) 3.51, le temps est
presque constant, avec une tr`es lÂ´eg`ere diminution lorsque Î± augmente. Plus Î± est
Â´elevÂ´e, plus le nombre dâ€™arË†etes du graphe seuillÂ´e devient faible. Par consÂ´equence,
le temps dâ€™exÂ´ecution pour le calcul des composantes connexes diminue.

Pour la fonction dâ€™appartenance fondÂ´ee sur la densitÂ´e des communautÂ´es, ï¬-
gure b) 3.51, en observant tous les rÂ´eseaux, le temps est quasi-linÂ´eaire jusquâ€™`a
ce quâ€™une cassure intervienne `a Î± â‰¤ 0.8, o`u parall`element le temps augmente
soudainement, de mË†eme que lâ€™AEC et par voie de consÂ´equence, le nombre de
candidats potentiels au chevauchement. Le nombre de combinaisons devenant
de plus en plus important, le temps augmente. Nous voyons Â´egalement que plus
la densitÂ´e du graphe est Â´elevÂ´ee, plus le temps de calcul de fd est important.

Concernant la fonction dâ€™appartenance fondÂ´ee sur le cÅ“ï¬ƒcient de clustering,
deux choses sont `a considÂ´erer : le temps de calcul du CCL et le nombre potentiel
de candidats au chevauchement. Dâ€™apr`es la ï¬gure b) 3.51, les temps ne sont pas
constants. Pour le rÂ´eseau des dauphins, le temps augmente jusquâ€™`a Î± â‰¥ 0.5,
et diminue juste apr`es. Cela vient du fait que dans les grosses communautÂ´es,
le temps de calcul du CCL est plus important. Avec une forte valeur de Î±, le
temps de calcul du CCL diminue alors que le nombre de candidats potentiels
au chevauchement augmente, avec un nombre de combinaisons plus important
pour la fonction dâ€™appartenance. Pour Î± â‰¥ 0.8, le temps dâ€™exÂ´ecution augmente
brutalement.

Figure 3.51 â€“ Temps dâ€™exÂ´ecution du CDLP, lâ€™axe horizontal reprÂ´esentant la valeur Î±
et lâ€™axe vertical reprÂ´esentant le temps en secondes. a) Temps du CDLP b) Temps de
fd c) Temps du fcc

3.4.6 Analyse comparative

Nous comparons nos propositions algorithmiques avec celles issues de la
littÂ´erature les plus utilisÂ´ees, `a savoir : CFinder Palla et al. (2005), COPRA
(Î½ = 2 et Î½ = 3 Gregory (2010), Î½ Â´etant le nombre de communautÂ´es auquel un
nÅ“ud appartient), OSLOM Lancichinetti et al. (2011), SLPA Xie et al. (2011),

3.4. PROPOSITIONS SUR LE CHEVAUCHEMENT

157

et CONGA Gregory (2007).

Analyse comparative

F1

â„¦

NMI

0.48
0.86
0.65
0.281
0.684
0.86
0.852
0.852

0.701
0.954
0.823
0.933
0.944
0.748
0.854
0.854

0.57
1.0
0.85
0.933
0.893
0.56
1.0
1.0

0.855
0.814
0.688
0.687
0.702
0.755
0.784
0.788

0.35
0.84
0.113
0.266
0.359
0.633
0.711
0.711

0.64
0.802
0.321
0.788
0.747
0.684
0.865
0.865

0.35
0.914
0.892
0.788
0.767
0.754
1.0
1.0

0.740
0.704
0.651
0.637
0.649
0.648
0.654
0.667

0.18
0.80
0.274
0.228
0.347
0.564
0.518
0.518

0.55
0.759
0.423
0.705
0.712
0.612
0.751
0.751

0.26
0.852
0.821
0.751
0.701
0.632
1.0
1.0

0.79
0.55
0.49
0.385
0.416
0.497
0.495
0.503

RÂ´eseaux
Zac #2
CFinder
OSLOM
CONGA
COP RA2*
COP RA3*
SLPA*
CDLPOV fd*
CDLPOV fcc*
Foot #12
CFinder
OSLOM
CONGA
COP RA2*
COP RA3*
SLPA*
CDLPOV fd*
CDLPOV fcc*
SW
CDLPOV fd*
CDLPOV fcc*
#2
CFinder
OSLOM
CONGA
COP RA2*
COP RA3*
SLPA*
CDLPOV fd*
CDLPOV fcc*
Pol #4
CFinder
OSLOM
CONGA
COP RA2*
COP RA3*
SLPA*
CDLPOV fd*
CDLPOV fcc*
NS
CDLPOV fd*
CDLPOV fcc*

QN ic
Ov

0.52
0.748
0.441
0.414
0.452
0.608
0.621
0.621

0.51
0.696
0.451
0.693
0.668
0.715
0.699
0.699
0.502âˆ—
0.157âˆ—

0.66
0.742
0.746
0.693
0.677
0.742
0.796
0.796

0.884
0.847
0.779
0.825
0.827
0.83
0.844
0.834

0.977
0.977

#

3
2
2

11.3
6.4
2.12

4
4

13
12
11
10.8
11.2
10.30

11
11

4
4

4
2
2

10.8
3.7
3.44

2
2

4
2
4
3
2.8
3.40

3
2

293
293

%

5.88%
2.94%
2.94%
5.58%
12.64%
2.20%
8.82%
8.82%

6.9%
0.0%
60.0%
0.52%
2.52%
1.69%
0.0%
0.0%

25.0%
65.6%

3.72%
1.61%
3.22%
0.52%
7.73%
2.00%
0.0%
0.0%

(9)

1.90%
4.16%
1.05%
6.47%
12.5%
1.90%
0.0%

0.0%
0.0%

Tableau 3.32 â€“ (*) algorithmes `a base de propagation de labels

158

CHAPITRE 3. PROPOSITIONS ALGORITHMIQUES

Nous montrons les rÂ´esultats de nos mÂ´ethodes donnant les scores des me-
sures non supervisÂ´ees les plus Â´elÂ´evÂ´es dans le tableau 3.32. Nos propositions
algorithmiques donnent dâ€™assez bons rÂ´esultats en termes de qualitÂ´e. Nous ob-
tenons de meilleurs rÂ´esultats que COPRA et une meilleure stabilisation. MË†eme
si les algorithmes `a base de propagation de labels produisent en moyenne plus
de communautÂ´es, le CDLP avec fd et fcc en produit moins. Nous expliquons ce
fait par la prÂ´esence de la matrice de frÂ´equence qui stabilise la propagation de
labels.

3.4.7 Conclusion sur les propositions algorithmiques che-

vauchantes

Nous avons proposÂ´e deux mÂ´ethodes appliquÂ´ees `a la propagation de label
par cÅ“urs pour la dÂ´etection de communautÂ´es chevauchantes. Chacune de ces
mÂ´ethodes utilise la matrice de frÂ´equence et les caractÂ´eristiques sociales et topo-
logiques des communautÂ´es pour savoir si certains nÅ“uds peuvent appartenir `a
plusieurs communautÂ´es. Les utilisateurs ont le choix entre laisser lâ€™algorithme
assigner de possibles candidats au chevauchement `a un nombre spÂ´eciï¬que de
communautÂ´es auxquelles ces nÅ“uds appartiendraient, ou laisser les fonctions
dâ€™appartenance tester toutes les combinaisons pour des assignations automa-
tiques. Les fonctions dâ€™appartenances sont fondÂ´ees sur la densitÂ´e (fd), le CC
(fcc) et sur les communautÂ´es dÂ´etectÂ´ees. Les rÂ´esultats selon les diï¬€Â´erentes fonc-
tions sont assez similaires en termes de qualitÂ´e. NÂ´eanmoins, le taux dâ€™assigna-
tion de nÅ“uds chevauchants `a un plus grand nombre de communautÂ´es est plus
important avec fd quâ€™avec fcc. Concernant le temps dâ€™exÂ´ecution, plus la den-
sitÂ´e du graphe Â´etudiÂ´e est importante, plus le nombre de candidats est grand,
augmentant ainsi le nombre de combinaisons `a tester pour nos fonctions, et par
consÂ´equence le temps augmentera. Nous avons vu que calculer les 100 LPA pour
alimenter la matrice de frÂ´equence est assez rapide, (1 seconde pour Zachary et
6 secondes pour NS). NÂ´eanmois, le temps de calcul de fcc est plus important
que celui de fd. Cela vient du calcul du nombre de triangles au sein des commu-
nautÂ´es pour calculer le CCL. Le temps de calculs des deux fonctions augmente
parall`element `a Î±. Mais `a partir dâ€™un seuil (Î± â‰¥ 0.8 ou Î± â‰¥ 0.9 selon les graphes
testÂ´es), le temps devient tr`es important. Pour Î± â‰¥ 0.5 , nous avons besoin de
30 secondes pour calculer fd et 60 secondes sur NS. Pour Î± â‰¥ 0.8, nous avons
besoin dâ€™une centaine de secondes pour calculer fd et fcc toujours sur NS. Pour
les rÂ´eseaux portant sur Zachary, les dauphins, SW ou les livres politiques, il
faut approximativement 10 secondes pour fd et pr`es de 20 secondes avec fcc.
Les perspectives seront prÂ´esentÂ´ees au chapitre 4.

Chapitre 4

Propositions algorithmiques
sur la dÂ´etection de
communautÂ´es parall`eles et
distribuÂ´ees

Sommaire

4.1 Propagation de labels avec dÂ´etection de cÅ“urs

avec Apache Hadoop . . . . . . . . . . . . . . . . . 160

4.1.1 Proposition algorithmique pour la propagation de

labels parall`ele et distribuÂ´ee avec dÂ´etection de cÅ“urs 161

4.1.2 ModÂ´elisation MapReduce de PAR-CDLP . . . . . . 161

4.1.3 CrÂ´eation dâ€™un dendrogramme . . . . . . . . . . . . . 171

4.2 ExpÂ´erimentations

. . . . . . . . . . . . . . . . . . . 173

4.2.1 Etude de la stabilisation . . . . . . . . . . . . . . . . 173

4.2.2 Etude sur de grands graphes de terrains . . . . . . . 174

4.2.3 Etude volumÂ´etrique traitÂ´ee par le HDFS . . . . . . . 183

4.3 Conclusion portant sur les propositions liÂ´ees au

parallÂ´elisme et la distribution . . . . . . . . . . . . 186

Dans le chapitre prÂ´ecÂ´edent, nous avions prÂ´esentÂ´e des propositions algorith-
miques permettant la dÂ´etection de communautÂ´es disjointes et chevauchantes.
Cependant, dans un monde o`u le volume des donnÂ´ees devient de plus en plus
important, il est utile de pouvoir retranscrire nos propositions algorithmiques
pour de grands graphes.

Ce chapitre aura comme objectif de prÂ´esenter une version parall`ele et dis-
tribuÂ´ee du CDLP sous Apache Hadoop. Nous testerons notre framework sur

159

160CHAPITRE 4. PROPOSITIONS SUR LE PARALL Â´ELISME ET LA DISTRIBUTION

quatre grands graphes de la littÂ´erature et eï¬€ectuerons une Â´etude comparative
avec dâ€™autres algorithmes issus de la littÂ´erature.

4.1 Propositions sur le parallÂ´elisme et la distri-

bution

Apache Hadoop est une architecture permettant dâ€™eï¬€ectuer du calcul pa-
rall`ele et distribuÂ´e pour rÂ´epondre aux traitements des donnÂ´ees de taille massive.
Comme nous lâ€™avons vu au chapitre 1, Hadoop poss`ede un framework MapRe-
duce composÂ´e de deux fonctions, un mapper et un reducer.

La propagation de labels peut sâ€™eï¬€ectuer de mani`ere synchrone ou asyn-
chrone (cette derni`ere Â´etant plus stable et oï¬€rant une meilleure qualitÂ´e de par-
titionnement). Cependant, la mÂ´ethode asynchrone nÂ´ecessite la mise en place
dâ€™un ordre de visite sur les nÅ“uds (qui peut Ë†etre alÂ´eatoire) aï¬n dâ€™eï¬€ectuer les
changements de labels pour chacun des nÅ“uds. Cette opÂ´eration sâ€™eï¬€ectue dâ€™or-
dinaire de mani`ere sÂ´equentielle. Câ€™est-`a-dire que lorsquâ€™un nÅ“ud a son label
modiï¬Â´e, les autres nÅ“uds du graphe sont informÂ´es et un autre nÅ“ud change
son label par un vote majoritaire en utilisant la nouvelle information. Cela peut
Ë†etre fait pour de petits graphes, mais pas pour de grands rÂ´eseaux. Il ne serait
pas souhaitable dâ€™avoir un graphe de plusieurs centaines de milliers de nÅ“uds et
de visiter sÂ´equentiellement chacun dâ€™entre eux pour en modiï¬er le label. Câ€™est
en ce sens que nous proposons dâ€™utiliser la mÂ´ethode semi-synchrone pour eï¬€ec-
tuer un changement de label qui puisse Ë†etre parall`ele et distribuÂ´e. Pour rendre
lâ€™algorithme semi-synchrone plus dÂ´eterministe, nous utilisons la matrice de co-
frÂ´equence. La propagation de labels semi-synchrone consiste `a colorier le graphe
de telle sorte que chaque nÅ“ud du graphe ait une couleur diï¬€Â´erente de celle
de ses voisins. La propagation de labels se fait en suivant les nÅ“uds ayant une
mË†eme couleur. Ainsi, lorsquâ€™un nÅ“ud met `a jour son label par un vote majori-
taire, son label est changÂ´e alors que celui de ses nÅ“uds voisins ne lâ€™est pas. Ce
processus se fait sur tous les nÅ“uds ayant la mË†eme couleur. Puis, on fait savoir
aux nÅ“uds voisins le nouveau label du nÅ“ud derni`erement modiï¬Â´e. On passe
alors `a une autre couleur pour continuer la propagation de label. Le processus
consiste donc `a colorier, propager les labels des nÅ“uds ayant une couleur donnÂ´ee,
faire une mise `a jour des voisins des nÅ“uds ayant subi une modiï¬cation de leurs
labels puis rÂ´epÂ´eter les phases de propagation de labels et de mise `a jour sur les
nÅ“uds restants. Ce sont ces opÂ´erations que nous avons mises sous forme Ma-
pReduce pour parallÂ´eliser et distribuer le CDLP. Nous rappelons que le CDLP
a deux param`etres principaux qui sont le seuil Î± (utilisÂ´e apr`es lâ€™alimentation
de la matrice de frÂ´equence pour crÂ´eer un nouveau graphe pondÂ´erÂ´e) et le nombre
de propagations de labels (N ) lancÂ´ees en parall`ele. En utilisant le seuil Î±, les
composantes connexes ainsi crÂ´eÂ´ees reprÂ´esentent les communautÂ´es.

4.1. PROPAGATION DE LABELS AVEC D Â´ETECTION DE CÅ’URS AVEC APACHE HADOOP161

4.1.1 Proposition algorithmique pour la propagation de
labels parall`ele et distribuÂ´ee avec dÂ´etection de cÅ“urs

Nous exposons la propagation de labels parall`ele et distribuÂ´ee avec dÂ´etection
de cÅ“urs, Algorithme 8. Il sâ€™agit de la version parall`ele et distribuÂ´ee du CDLP
prÂ´esentÂ´e au Chapitre 2. La complexitÂ´e de lâ€™algorithme est en O(N Ã— k Ã— (m) +
n + m + n2 Ã— m).

Algorithme 8 La propagation de labels semi-synchrone parall`ele et distribuÂ´ee
avec dÂ´etection de cÅ“urs PAR-CDLP
Input : Un graphe G = (V, E), un seuil Î±, N le nombre de propagations de

labels

trice P N

ij

Output : Les communautÂ´es trouvÂ´ees par lâ€™algorithme sur le graphe G = (V, E)
1: Eï¬€ectuer une coloration du graphe G, D = {D1, D2, ..., Dl} (de l parties)
2: Allouer une matrice de co-frÂ´equence vide P N
3: Appliquer N fois la propagation de labels semi-synchrone et remplir la ma-

ij

poids supÂ´erieur ou Â´egal `a Î±

4: CrÂ´eer un nouveau graphe G(cid:48) = (V, E(cid:48)) issu deP N
ij , dont les arË†etes ont un
5: CrÂ´eer une partition P en considÂ´erant les C composantes connexes comme
6: Retourner la partition P = {P1, ..., PC}.

cÅ“urs

4.1.2 ModÂ´elisation MapReduce de PAR-CDLP

Notre proposition algorithmique comprend 4 grandes parties :
â€” la mise en place dâ€™un algorithme de coloriage de graphe
â€” le lancement de N propagations de labels semi-synchrones
â€” lâ€™alimentation dâ€™une matrice de co-frÂ´equence
â€” la dÂ´etection des composantes connexes avec un seuil Î±

Dans la suite de cette section, nous proposons de suivre un petit exemple vi-
suel pour une meilleure comprÂ´ehension du dÂ´eveloppement de PAR-CDLP. Nous
considÂ´erons un ï¬chier dâ€™arË†etes o`u chaque ligne reprÂ´esente un lien iâˆ’ j (et j âˆ’ i),
Figure 4.1.

Etape de coloration de graphe :

Cette Â´etape consiste `a attribuer `a chaque nÅ“ud une couleur de telle sorte
que deux nÅ“uds adjacents nâ€™aient pas la mË†eme couleur. Câ€™est `a partir de cette
couleur que la propagation de labels semi-synchrone pourra Ë†etre eï¬€ectuÂ´ee, o`u les
nÅ“uds ayant une mË†eme couleur vont changer leur label en fonction de leur voi-
sinage, qui a une couleur diï¬€Â´erente. Nous commenÂ¸cons avec un ï¬chier contenant

162CHAPITRE 4. PROPOSITIONS SUR LE PARALL Â´ELISME ET LA DISTRIBUTION

Figure 4.1 â€“ Exemple avec un triangle pour lâ€™illustration de notre proposition algo-
rithmique PAR-CDLP.

toutes les arË†etes du graphe sous la forme iâˆ’j et jâˆ’i comme le montre lâ€™exemple
Figure 4.1. Un algorithme de coloration est appliquÂ´e. Une implantation dâ€™un
tel algorithme a Â´etÂ´e proposÂ´ee par Gandhi et Misra (2015). Le rÂ´esultat est un
ï¬chier contenant les rÂ´esultats de la nouvelle coloration avec les lignes i âˆ’ j âˆ’ Cj
et j âˆ’ i âˆ’ Ci, o`u Ci est la couleur du nÅ“ud i, Figure 4.2.

Figure 4.2 â€“ Exemple avec un triangle ayant subi une coloration de graphe

Propagation de label semi-synchrone :

A chaque nÅ“ud est associÂ´e une vecteur de labels qui permet dâ€™eï¬€ectuer les N
propagations de labels en parall`ele. Chaque couleur servira dâ€™ordre de visite sur
le graphe avec lâ€™intention de faire la mise `a jour des labels aï¬n de faire la propa-
gation de labels semi-synchrone. Une Â´etape suivante de mise `a jour consistera `a
transmettre les nouveaux labels aux nÅ“uds voisins qui nâ€™ont pas encore connu
de mise `a jour de leur label.

Le premier job consiste en une fonction FirstReadMap, Algorithme 9, et
une fonction FirstReadReduce, Algorithme 10. Le mapper FirstReadMap
lit le ï¬chier dâ€™entrÂ´ee et Â´emet j âˆ’ li âˆ’ i âˆ’ Ci o`u li est un vecteur de taille N ,
contenant le label courant du nÅ“ud i pour les N diï¬€Â´erentes propagations de
labels. Nous notons par |li| la taille du vecteur li. Initialement, chaque nÅ“ud
a son propre label pour les N propagations de labels, li = [i, i, ..., i]. La ligne

4.1. PROPAGATION DE LABELS AVEC D Â´ETECTION DE CÅ’URS AVEC APACHE HADOOP163

j âˆ’ liâˆ’ iâˆ’ Ci signiï¬e que le nÅ“ud j va recevoir le vecteur li du nÅ“ud i. Le nÅ“ud
j connaË†Ä±tra donc les labels de son voisin i pour les N propagations de labels.
La phase de shuï¬„ing groupe les nÅ“uds selon le nÅ“ud j qui reÂ¸coit lâ€™information
pour la phase de rÂ´eduction. Les reducers, prenant comme clÂ´e spÂ´eciï¬que j et
comme valeur, les lignes j o`u Â´etait le receveur lors de la phase de map, Â´emettent
j âˆ’ li âˆ’ Ci sans faire la moindre opÂ´eration, Figure 4.3.

Figure 4.3 â€“ RÂ´esultats de la fonction FirstReadMap avec N = 5

La seconde partie consiste en une boucle sur deux jobs. Le premier job rÂ´ealise
un vote sur les nÅ“uds de la couleur courante. Cela consiste en VoteMap, Al-
gorithme 11 et VoteReduce, Algorithme 12. Le second job eï¬€ectue une mise
`a jour sur les nÅ“uds ayant transmis lâ€™information ou sur les nÅ“uds concernÂ´es
par la prochaine propagation de labels (comme les voisins des nÅ“uds ayant subi
une modiï¬cation de leur label). Cela consiste en UpdateMap, Algorithme 11
et UpdateReduce, Algorithme 13. La boucle sur ces deux jobs se fonde sur
la coloration comme compteur (le vote ayant lieu pour les nÅ“uds de la couleur
courante).

164CHAPITRE 4. PROPOSITIONS SUR LE PARALL Â´ELISME ET LA DISTRIBUTION

Algorithme 9 FirstReadMap
EntrÂ´ee : N le nombre de lancements, Map( ClÂ´e : Nom du ï¬chier, Valeur :
ï¬chier dâ€™arË†etes reprÂ´esentant un graphe G = (V, E) avec la coloration
(i âˆ’ j âˆ’ Cj))

Sortie : Â´emettre les lignes (j âˆ’ lj âˆ’ i âˆ’ Cj) ,avec |lj| = N
1: lj â†âˆ’ [] {vecteur pour les N propagations de labels diï¬€Â´erentes}
2: Pour ligne dans valeur Faire
3: Pour j = 0 `a N Faire

lj.ajouter(label(i)) {label(i) est le label du nÅ“ud i}

4:
5:
6: Fin Pour
7: Emettre(j âˆ’ lj âˆ’ i âˆ’ Cj) {la ligne contient N + 3 Â´elÂ´ements du fait que lj

Fin Pour

contient N Â´elÂ´ements, j, i et Cj, juste un pour chaque}

ItÂ´erateur [ [lj âˆ’ Cj],...)

Algorithme 10 FirstReadReduce
EntrÂ´ee : N le nombre de lancements, Reduce(ClÂ´e
Sortie : Â´emettre les lignes (i âˆ’ lj âˆ’ j âˆ’ Cj) avec |lj| = N
1: Pour ligne dans Itvaleur Faire
2: Emettre (j âˆ’ line) {Â´equivalent `a j âˆ’ lj âˆ’ i âˆ’ Cj, avec une longueur de
N + 3 Â´elÂ´ements, du fait que li contient N Â´elÂ´ements, j, i et Cj, une pour
chacune}
3: Fin Pour

: nÅ“ud i,

Itvaleur

:

Algorithme 11 VoteMap,UpdateMap,CommunityMap,GPrimAlphaMap
EntrÂ´ee : N le nombre de lancements, Map( ClÂ´e : nom de ï¬chier , Valeur :
ï¬chier dâ€™arË†etes avec la propagation de labels avec couleurs (j âˆ’ li âˆ’ i âˆ’ Cj))
Sortie : Â´emettre des lignes j âˆ’ lj âˆ’ i âˆ’ Cj (avec |lj| = N )
1: lj â†âˆ’ [] {vecteur pour les N propagations de labels}
2: Pour ligne dans Valeur Faire
3: Emettre(j âˆ’ li âˆ’ i âˆ’ Cj) {ligne contenant N + 3 Â´elÂ´ements, du fait que li

contient N Â´elÂ´ements, j, i et Cj, une pour chaque ligne}

4: Fin Pour

4.1. PROPAGATION DE LABELS AVEC D Â´ETECTION DE CÅ’URS AVEC APACHE HADOOP165

Algorithme 12 VoteReduce
EntrÂ´e : N le nombre de lancements, Reduce(ClÂ´e : j, ItÂ´erateur valeurs : lignes
avec la propagation de labels et coloration [[(li âˆ’ i âˆ’ Cj)],...]) {valeurs est
un vecteur de vecteurs, on note par valeurs[k] le kth Â´elÂ´ement du vecteur
valeurs}

Sortie : Â´emettre des lignes (j âˆ’ lj âˆ’ i âˆ’ Cj) avec |lj| = N
1: couleur actuelle â†âˆ’ lignevaleurs[k][N + 3] {valeurs[k][N + 3] correspond `a

la couleur du nÅ“ud j pour le kith Â´elÂ´ement du vecteur valeurs}

2: Si couleur actuelle = Cj Alors
3:
4:

liste de vote â†âˆ’ [] {vecteur pour les N propagations de labels}
nouvelle ligne de labels â†âˆ’ [] {vecteur pour les N propagations de la-
bels}

5: Pour w = 0 `a N par pas de 1 Faire

Pour k = 0 `a T aille(values) par pas de 1 Faire

{utilisation dâ€™une double boucle Pour pour permettre de faire le vote
colonne par colonne, pour les N propagations de labels diï¬€Â´erentes}
liste de vote.ajouter(values[w][k]) {valeurs[w][k] rÂ´ef`ere au label du
kth voisin du nÅ“ud j de la wth propagation de labels}

6:
7:

8:

9:

15:

Fin Pour
vote majoritaire â†âˆ’ arg maxl |N l(j)| utilisant liste de vote
ligne de nouveaux .ajouter(vote majoritaire)

10:
11:
12:
13: Pour k = 0 `a T aille(valeurs) par un pas de 1 Faire
14:

valeurs[k][N +2]

Fin Pour

-

- nouvelle ligne de labels

Emettre(j
cou-
leur actuelle) {valeurs[k][N + 2] est le nÅ“ud transmetteur pour
les labels, }
Emettre(valeurs[k][N +2]âˆ’nouvelle ligne de labelsâˆ’couleur actuelleâˆ’
â€âˆ—â€) {le signe â€âˆ—â€ sera utilisÂ´e pour la mise `a jour des labels du voisinage
du nÅ“ud transmettant la nouvelle information. Elle sera `a la position
(N + 2) de la ligne Â´emise}

-

Fin Pour
Emettre( j âˆ’ li âˆ’ i âˆ’ Cj)

16:
17: Sinon
18:
19: Fin Si

166CHAPITRE 4. PROPOSITIONS SUR LE PARALL Â´ELISME ET LA DISTRIBUTION

Algorithme 13 UpdateReduce
EntrÂ´ee : N le nombre de lancements, Reduce(ClÂ´e : j, ItÂ´erateur valeurs : lignes
avec propagation de labels, coloration et nÅ“uds `a mettre `a jour [[(li âˆ’ i âˆ’
Cj)],[li âˆ’ i âˆ’ â€ âˆ— â€],...]
Sortie : Â´emettre les lignes

j âˆ’ lj âˆ’ i âˆ’ Cj (with |lj| = N )

1: Pour w = 0 `a Taille(valeur) par pas de 1 Faire
2:
3:

Si valeurs[w][N + 1] = â€ âˆ— â€ Alors
nÅ“ud a modif ier â†âˆ’ valeurs[w][N ]
nouveaux labels â†âˆ’ valeurs[w]
Pour k = 0 `a Taille(valeurs) par pas de 1 Faire

Si non(â€ âˆ— â€ dans values[k]) et (nÅ“ud a modif ier = valeurs[w][N ])
Alors

values[k] â†âˆ’ nouveaux labels {Phase de mise `a jour}

4:
5:
6:

7:
8:

Sinon

Ne rien faire

Sinon

Ne rien faire

Fin Si
Fin Pour

9:
10:
11:
12:
13:
Fin Si
14:
15: Fin Pour
16: Pour k = 0 `a Taille(valeurs) par pas de 1 Faire
17:
18:

Si pas(â€ âˆ— â€ dans valeurs[k]) Alors
Emettre(j âˆ’ valeurs[k]) { Â´equivalent `a j âˆ’ nouveaux labels âˆ’ i âˆ’ Cj
(avec |nouveaux labels| = N )}

19:

Sinon

Ne rien faire

20:
Fin Si
21:
22: Fin Pour

4.1. PROPAGATION DE LABELS AVEC D Â´ETECTION DE CÅ’URS AVEC APACHE HADOOP167

bels}

nÅ“ud j}

avec propagation de labels et coloration [[(li âˆ’ i âˆ’ Cj)],...])

Algorithme 14 CommunityReduce
EntrÂ´ee : N le nombre de lancements, Reduce(ClÂ´e : j, ItÂ´erateur valeurs : lignes
Sortie : Â´emission de lignes i âˆ’ li (avec |li| = N )
1: couleur actuelle â†âˆ’ ligne[N + 3] {ligne[N + 3] correspond `a la couleur du
2: liste des votes â†âˆ’ [] {vecteur pour les N propagations de labels}
3: ligne de nouveaux labels â†âˆ’ [] {vecteur pour les N propagations de la-
4: Pour w = 0 `a N par pas de 1 Faire
5: Pour k = 0 `a T aille(values) par pas de 1 Faire
6:

liste des votes.ajouter(valeurs[w][k]) {valeurs[w][k] rÂ´ef`ere au label du
kieme voisin du nÅ“ud j `a la wieme propagation de label}
Fin Pour
vote majoritaire â†âˆ’ arg maxl |N l(j)| avecg liste des votes
ligne de nouveaux labels.ajouter(vote majoritaire)

8:
9:
10: Fin Pour
11: Pour k = 0 `a T aille(valeurs) par pas de 1 Faire
12: Emettre(valeurs[k] [N + 2 ] - ligne de nouveaux labels) {Un dernier
vote est fait, valeurs[k][N + 2] est Â´equivalent au nÅ“ud i, ainsi (i âˆ’
ligne de nouveaux labels)}

7:

13: Fin Pour

chier dâ€™arË†etes avec propagation de labels i li)

Algorithme 15 OccurrenceMatrixMap
EntrÂ´ee : N le nombre de lancements, Map(ClÂ´e : nom du ï¬chier , valeur : ï¬-
Sortie : Â´emission de lignes k âˆ’ i âˆ’ lk
1: lj â†âˆ’ [] {vecteur pour les N propagations de labels}
2: Pour line in Input Faire
3: Pour k = 0 to N Faire
Emettre(k âˆ’ i âˆ’ lk

i ) {label(i) signiï¬e le label du nÅ“ud i }

i (pour la kth propagation de labels du

nÅ“ud i)

4:
5:
6: Fin Pour

Fin Pour

168CHAPITRE 4. PROPOSITIONS SUR LE PARALL Â´ELISME ET LA DISTRIBUTION

valeurs [[i1, 1], [i2, 1], ..., [iK, 1]], rÂ´eel : Î± )

Algorithme 16 GPrimAlphaReduce -Î±
EntrÂ´ee : N le nombre de lancements, Reduce(ClÂ´e : nÅ“ud i, Valeur : ItÂ´erateur
Sortie : Â´emission de lignes (nÅ“ud iâˆ’ nÅ“ud j âˆ’ Î±ij) avec Î±ij â‰¥ Î± et i > j
1: Pour v âˆˆ valeurs Faire
3: N bOcc â†âˆ’ nombre dâ€™occurrences du nÅ“ud v dans valeurs

depuis que la matrice est symÂ´etrique

2:

Somme â†âˆ’ 0
Si N bOccN â‰¥ Î± Alors
Î±iv â†âˆ’ N bOccN
Emettre (i, v, Î±i,v)

4:

5:
6:

Ne rien faire

Sinon

7:
8:
Fin Si
9:
10: Fin Pour

Si k est le nombre de couleurs, les votes auront lieu pour les nÅ“uds ayant la
couleur C1, suivis dâ€™une mise `a jour (permettant la mise `a jour des labels pour
les nÅ“uds Â´emetteurs ou concernÂ´es par ces changements de labels). Câ€™est ensuite
pour les nÅ“uds ayant la couleur C2 que le vote sâ€™eï¬€ectue, suivi Â´egalement dâ€™une
mise `a jour. Le processus continue jusquâ€™`a parvenir `a la couleur Ck.
VoteMap consiste `a Â´emettre j âˆ’ li âˆ’ i âˆ’ Cj, aucune opÂ´eration spÂ´eciï¬que nâ€™est
eï¬€ectuÂ´ee. La phase de shuï¬„ing permet de trier les donnÂ´ees selon le nÅ“ud j, qui
sera mis `a jour si Cj est la couleur du nÅ“ud actuel considÂ´erÂ´e. Toutes les lignes
avec la mË†eme clÂ´e j vont dans le mË†eme reducer. VoteReduce prend comme clÂ´e
le nÅ“ud j et comme valeur, des vecteurs de labels des nÅ“uds qui sont voisins
du nÅ“ud j.

VoteReduce fait un vote pour le nÅ“ud j si la couleur associÂ´ee `a j est la
couleur actuelle. Cela aura pour consÂ´equence la mise `a jour du vecteur de labels.
Pour chacune des N propagations de labels, le vote majoritaire est fait suivant
le LPA standard, colonne par colonne, par utilisation des vecteurs de labels des
nÅ“uds qui sont voisins du nÅ“ud j, dans ce cas lj1, lj2 , ..., ljk (si le nÅ“ud j a k
voisins). Le reducer Â´emet pour le nÅ“ud j son nouveau vecteur de labels qui est
reÂ¸cu de ses voisins, j âˆ’ lnouveau
est le nouveau vecteur de
labels de i qui est transmis `a j, rÂ´esultant du vote. Une information de mise `a
jour est aussi Â´emise pour les nÅ“uds qui sont concernÂ´es par le nouveau label du
nÅ“ud j, en Â´emettant iâˆ’lnouveau
âˆ’jâˆ’âˆ—, âˆ— permettant de connaË†Ä±tre lâ€™information
de mise `a jour et i Â´etant le nÅ“ud dont le vecteur de propagation de labels sera
mis `a jour pour le prochain job. Nous donnons un petit exemple avec lâ€™exemple
du triangle `a Fig. 4.4.

âˆ’ i âˆ’ Cj o`u lnouveau

i

i

i

4.1. PROPAGATION DE LABELS AVEC D Â´ETECTION DE CÅ’URS AVEC APACHE HADOOP169

Figure 4.4 â€“ a) Les rÂ´esultats de VoteMap avec VoteReduce, b) UpdateMap avec
UpdateReduce

Le job comprenant UpdateMap Algorithme 11 et UpdateReduce, Algo-
rithme 13 eï¬€ectue la mise `a jour dâ€™information des nÅ“uds qui sont aï¬€ectÂ´es
directement par les changements de labels du dernier VoteReduce. Pour sa-
voir quels nÅ“uds sont concernÂ´es, nous utilisons les lignes contenant le symbole
â€*â€, Â´emis par VoteReduce.

UpdateMap : Cette fonction lit les donnÂ´ees, et Â´emet chaque ligne sans faire

170CHAPITRE 4. PROPOSITIONS SUR LE PARALL Â´ELISME ET LA DISTRIBUTION

de modiï¬cation. Aucune opÂ´eration spÂ´eciï¬que nâ€™est eï¬€ectuÂ´ee. La phase de shuf-
ï¬‚ing permet de trier les donnÂ´ees selon le nÅ“ud receveur j.
UpdateReduce : Cette fonction prend en param`etre les donnÂ´ees ayant la mË†eme
clÂ´e j, et comme valeur, un itÂ´erateur avec les diï¬€Â´erentes propagations de labels
âˆ’ j âˆ’âˆ—). Pour chaque partie ayant la mË†eme
(j âˆ’ lnouveau
clÂ´e, si la fonction dÂ´etecte le symbole âˆ—, une mise `a jour se fera sur les lignes
sujettes `a lâ€™ancienne propagation de labels (des nÅ“uds voisins ou des nÅ“uds
transmetteurs dâ€™information). Ainsi, les lignes j âˆ’ lnew
i âˆ’ i âˆ’ âˆ— serviront `a faire
la mise `a jour des lignes de la forme i âˆ’ li âˆ’ j âˆ’ Ci.

âˆ’ iâˆ’ Cj et iâˆ’ lnouveau

i

i

La troisi`eme Â´etape consiste `a donner `a chaque nÅ“ud un vecteur de label,
sans coloration. Cette Â´etape est rÂ´ealisÂ´ee par le job comprenant CommunityMap,
Algorithme 11, et CommunityReduce, Algorithme 14. Les rÂ´esultats seront
utilisÂ´es pour la phase de dÂ´etection de cÅ“urs.

MapCommunity : Cette fonction, Algorithme. 9, lit les donnÂ´ees, et Â´emet
chaque ligne sans aucune modiï¬cation. Aucune opÂ´eration spÂ´eciï¬que nâ€™est ef-
fectuÂ´ee. la phase de shuï¬„ing permet de trier les donnÂ´ees sur le disque suivant
le nÅ“ud receveur j. La signature de cette fonction est : CommunityMap (ClÂ´e :
ï¬chier (j âˆ’ li âˆ’ i âˆ’ Cj) â†’ (ClÂ´e : j, Valeur : (li, i, Cj))).

CommunityReduce : Cette fonction reÂ¸coit comme entrÂ´ee toutes les lignes
ayant la mË†eme clÂ´e j et leurs vecteurs de labels, les nÅ“uds voisins et la couleur
relative comme valeur. Pour chaque ligne j, un dernier vote est fait de telle
sorte que le reducer Â´emette chaque nÅ“ud avec son vecteur de labels associÂ´e :
j âˆ’ li âˆ’ i âˆ’ Ci(âˆ€i âˆˆ V (j)) â†’ i âˆ’ lnouveau
. La signature de cette fonction est :
CommunityReduce(ClÂ´e : j , Valeur : ItÂ´erateur ([[li âˆ’ i âˆ’ Cj], ...]) â†’ (ClÂ´e : i,
Valeur : (lnouveau

))).

i

i

La quatri`eme partie consiste `a remplir une matrice de co-frÂ´equence, P N

ij , o`u
la colonne i et la ligne j reprÂ´esentent le nombre de fois que les nÅ“uds i et j
sont ensemble durant les N diï¬€Â´erentes propagations de labels. Ce job consiste
en OccurrenceMatrixMap, Algorithme 15 et OccurrenceMatrixReduce.
Le mapper retourne pour chaque propagation de labels le nÅ“ud avec sa couleur
associÂ´ee et le reducer Â´emet chaque paire de nÅ“uds qui sont ensemble durant les
N propagations de labels avec le chiï¬€re â€1â€.

OccurrenceMatrixMap prend comme entrÂ´ee i âˆ’ li (le nÅ“ud et son vec-
teur associÂ´e de labels) et retourne rk âˆ’ i âˆ’ lk
i o`u rk est la kieme propagation de
labels et lk
i , le kieme label correspondant au nÅ“ud i. La phase de shuï¬„ing trie
les donnÂ´ees selon la clÂ´e rk, soit la kieme propagation de labels. La signature de
cette fonction est : OccurrenceMatrixMap(Cle : ï¬chier (i âˆ’ li) â†’ (ClÂ´e : rk,

4.1. PROPAGATION DE LABELS AVEC D Â´ETECTION DE CÅ’URS AVEC APACHE HADOOP171

i )). OccurrenceMatrixReduce prend en param`etre rk âˆ’ i âˆ’ li
Valeur : (i, lk
et Â´emet i âˆ’ j âˆ’ 1, soit chaque paire de nÅ“uds qui sont dans les mË†emes com-
munautÂ´es, propagation de labels apr`es propagation de labels. La signature de
cette fonction est : OccurrenceMatrixReduce(Cle : rk , Valeur : ItÂ´erateur
([[i, lk

i ], ...]) â†’ (ClÂ´e : (i, j), Valeur : 1)).

La cinqui`eme partie consiste en GPrimAlphaMap, Algorithme 11 et

GPrimAlphaReduce, Algorithme 16.
GPrimAlphaMap prend en entrÂ´ee i âˆ’ j âˆ’ 1 et Â´emet cette mË†eme ligne. Aucune
opÂ´eration spÂ´eciï¬que nâ€™est eï¬€ectuÂ´ee. La phase de shuï¬„ing permet de trier la ligne
selon le nÅ“ud i. La signature de cette fonction est : GPrimAlphaMap(Cle : ï¬-
chier (i, j, 1) â†’ (Cle : i, j, Valeur : 1)).
GPrimAlphaReduce prend comme clÂ´e le nÅ“ud i, i âˆ’ j âˆ’ 1 et Î± comme
valeur. Î± permet dâ€™Â´emettre les arË†etes dont les nÅ“uds ont une frÂ´equence dâ€™ap-
parition commune dans les mË†emes communautÂ´es supÂ´erieure ou Â´egale `a ce seuil.
Cette fonction Â´emet iâˆ’ jâˆ’ Î±ij ou Î±ij â‰¥ Î±, o`u Î±ij est la frÂ´equence o`u les nÅ“uds i
et j se sont trouvÂ´es dans les mË†emes communautÂ´es au cours des N diï¬€Â´erentes pro-
pagations de labels. La signature de cette fonction est : GPrimAlphaReduce-Î±
(ClÂ´e : rk , Valeur : ItÂ´erateur ([[j, 1], ...]) â†’ (ClÂ´e : (i, j), Valeur : Î±ij)).

La derni`ere Â´etape consiste `a trouver les composantes connexes qui corres-
pondent aux communautÂ´es. PEGASUS (Kang et al. (2009)), un outil dâ€™ana-
lyse de rÂ´eseaux sociaux destinÂ´e aux grands graphes et fondÂ´e sur le patron de
conception MapReduce oï¬€re une implantation dâ€™un algorithme de dÂ´etection de
composantes connexes.

On peut ainsi rÂ´esumer les diï¬€Â´erentes Â´etapes du Par-CDLP par lâ€™algorithme
regroupant la succession de jobs, Algorithme 17. On note quâ€™il est possible dâ€™ap-
pliquer la simple propagation de label semi-synchrone (SLPH) sous Hadoop avec
N = 1 en terminant avec la fonction CommunityReduce.

4.1.3 CrÂ´eation dâ€™un dendrogramme

Il est Â´egalement possible de produire un dendrogramme avec notre mod`ele
Hadoop en crÂ´eant plusieurs jobs (GPrimAlphaMap et GPrimAlphaReduce)
avec diï¬€Â´erentes valeurs de Î±. Il est ainsi possible de crÂ´eer un intervalle avec
un pas âˆ†, et plusieurs ï¬chiers avec diï¬€Â´erentes valeurs de Î±, comme une suite
numÂ´erique (un)minâ‰¤nâ‰¤max de telle sorte un+1 = un + âˆ†. Le dendrogramme
entier peut Ë†etre obtenu avec u0 = 0 et max = 1. Si le niveau un+1 est le mË†eme
que le niveau un (mË†eme partitionnement, donnant les mË†emes communautÂ´es au

172CHAPITRE 4. PROPOSITIONS SUR LE PARALL Â´ELISME ET LA DISTRIBUTION

Figure 4.5 â€“ a) CommunityMap et CommunityReduce b) OccurrenceMatrixMap c)
GPrimAlphaMap d) GPrimAlphaReduce

4.2. EXP Â´ERIMENTATIONS

173

Algorithme 17 Le CDLP
EntrÂ´ee : Un graphe G = (V, E), le seuil Î±, N le nombre de lancements, âˆ† le

pas

VoteMap
VoteReduce-Ci
MapUpdate
UpdateReduce

Sortie : communautÂ´es de G
1: FirstReadMap-N
2: FirstReadReduce
3: Pour i = 0 au nombre de couleur de G Faire
4:
5:
6:
7:
8: Fin Pour
9: CommunityMap
10: CommunityReduce
11: OccurrenceMatrixMap
12: OccurrenceMatrixReduce
13: GPrimAlphaMap
14: GPrimAlphaReduce
15: return La partition : P = {P1, ..., PC}.

nÅ“ud pr`es), le niveau un+1 nâ€™est pas Â´ecrit. Plus faible sera le pas âˆ†, plus grand
sera la taille de lâ€™arbre.

4.2 ExpÂ´erimentations

Nous expÂ´erimentons notre proposition algorithmique sur quatre grands graphes

de la littÂ´erature qui sont Amazon, DBLP, You Tube et Live Journal pour Â´etudier
la qualitÂ´e des communautÂ´es rÂ´esultantes, la scalabilitÂ´e de notre proposition al-
gorithmique, le temps dâ€™exÂ´ecution et la masse des donnÂ´ees gÂ´enÂ´erÂ´ees et traitÂ´ees.
Pour nos expÂ´erimentations, nous avons un cluster Hadoop de cinq machines
dont la description est au Tableau 4.1. Une Â´etude comparative sera proposÂ´ee
avec certains algorithmes de la littÂ´erature.

4.2.1 Etude de la stabilisation

Comme nous lâ€™avions vu au chapitre 2, notamment pour le CDLP, un cer-
tain nombre de propagations de labels suï¬ƒt `a stabiliser lâ€™algorithme suivant
la topologie du graphe. Cependant, cela ne rend pas lâ€™algorithme totalement
dÂ´eterministe. Certaines oscillations peuvent apparaË†Ä±tre, notamment sur les nÅ“uds
considÂ´erÂ´es comme chevauchants. Sur lâ€™exemple de Zachary, nous avions vu quâ€™il
suï¬ƒsait de 55 propagations de labels pour stabiliser la mÂ´ethode, avec une ï¬‚uc-
tuation sur le nÅ“ud 10 qui est entre les deux principales communautÂ´es. Ainsi,

174CHAPITRE 4. PROPOSITIONS SUR LE PARALL Â´ELISME ET LA DISTRIBUTION

Cluster Hadoop (5 machines Acer Predator G3-605 )

Nb. de cÅ“urs
Nb. de threads
FrÂ´equence de base
FrÂ´equence Turbo maxi
Hadoop
Connection ethernet
CapacitÂ´e mÂ´emoire maxi

4 (Cor TM i7)
12
3.00 GHz
3.60 GHz
version 2.7.2
1 Gigabits entre les machines
1 TO

Tableau 4.1 â€“ CaractÂ´eristique du cluster Hadoop

des oscillations faisaient que nous avions 1 ou 2 communautÂ´es pour Î± â‰¤ 0.5. Si
lâ€™on consid`ere de grands graphes de terrain tels quâ€™Amazon, DBLP, You-Tube
Ou Live Journal, des oscillations peuvent Â´egalement avoir lieu. Câ€™est ce que nous
avons pu observer et qui a rendu lâ€™Â´etude de la stabilisation tr`es complexe. On
ne peut pas simplement se fonder comme indicateur sur le nombre de commu-
nautÂ´es, la ï¬‚uctuation due `a certains nÅ“uds rend lâ€™Â´etude tr`es diï¬ƒcile. Il a Â´etÂ´e
montrÂ´e quâ€™il existait des milliers de structures communautaires dans les rÂ´eseaux
que nous avons citÂ´es. En ayant observÂ´e de tr`es nombreuses oscillations, nous
ne sommes pas dans la capacitÂ´e de conclure quant au nombre de propagations
de labels nÂ´ecessaire. Câ€™est actuellement une voie de recherche sur laquelle nous
portons notre attention. Câ€™est en ce sens que nous avons dÂ´ecidÂ´e de poser pour la
suite de nos expÂ´erimentations N = 200. Nous proposons Â´egalement une Â´etude
sur la propagation de label semi-synchrone sous Hadoop (SLPH avec N = 1).

Nous donnons un exemple dâ€™expÂ´erimentation o`u la seule observation tangible
est que lâ€™augmentation du nombre de propagations de labels permet de rÂ´eduire
le nombre de communautÂ´es jusquâ€™`a des oscillations qui ne permettent pas de
conclure. Pour le calcul du NMI et du F1 scores, nous utilisons la connais-
sance des vraies communautÂ´es, leur top 5000, disponible sur SNAP `a lâ€™adresse
http : //snap.stanf ord.edu.

4.2.2 Etude sur de grands graphes de terrains

Etude sur Amazon

Le nombre de couleurs dÂ´etectÂ´ees est de 24 pour faire marcher la propagation
de labels semi-synchrone, Tableau 4.2. La distribution des degrÂ´es moyens selon
les couleurs est Â´egalement donnÂ´ee au Tableau 4.2.

La premi`ere analyse traite de la distribution des couleurs. Il y a 24 couleurs
dÂ´etectÂ´ees sur le graphe dâ€™Amazon. Nous voyons que 48.8% des nÅ“uds ont la
mË†eme couleur, câ€™est-`a-dire quâ€™ils mettront `a jour leurs propres vecteurs de la-
bels en mË†eme temps durant le processus Hadoop. Nous observons Â´egalement que
le pourcentage de nÅ“uds par couleur nâ€™est pas uniformÂ´ement distribuÂ´e. Les cou-
leurs C1,C2,C3,C4,C5 et C23 reprÂ´esentent 86.5206% des nÅ“uds du graphe alors

4.2. EXP Â´ERIMENTATIONS

175

Figure 4.6 â€“ ExpÂ´erimentation sur la stabilisation du Par-CDLP avec Amazon et Î± â‰¥ 0.5

Coloration de graphe sur Amazon
dist

dist

0.117 %
0.106 %
0.035 %
0.030 %
0.008 %
0.007 %
0.002 %
0.001 %
0.0008 %
0.0005 %
5.5142 %
0.0003 %

Color
C1
C2
C3
C4
C5
C6
C7
C8
C9
C10
C11
C12

48.449 %
4.0476 %
16.003 %
4.524 %
7.987 %
3.856 %
3.659 %
2.420 %
1.369 %
1.065 %
0.429 %
0.361 %

Color
C13
C14
C15
C16
C17
C18
C19
C20
C21
C22
C23
C24

Tableau 4.2 â€“ Distribution des tailles (dist) pour chaque groupe ayant une couleur
spÂ´eciï¬que Ci

que C13,C14,C15,C16, C17,C18, C19,C20,C21,C22,C23 et C24 ne reprÂ´esentent que
0.3076% du total des nÅ“uds du graphe.

Notre premi`ere Â´etude porte sur le SLPH, câ€™est-`a-dire notre proposition Ha-
doop avec N = 1. Nous avons fait marcher le SLPH itÂ´eration apr`es itÂ´eration, 10
fois, Tableau 4.3. Lâ€™objectif Â´etant de voir si la propagation de label sâ€™eï¬€ectue
de mani`ere correcte itÂ´eration apr`es itÂ´eration. Les observations nous montrent

176CHAPITRE 4. PROPOSITIONS SUR LE PARALL Â´ELISME ET LA DISTRIBUTION

que les communautÂ´es deviennent de plus en plus importantes itÂ´eration apr`es
itÂ´eration. La premi`ere propagation de label (I1) donne 85, 913% de commu-
nautÂ´es avec une taille comprise entre 1 et 10 nÅ“uds. A la dixi`eme propagation
de labels, nous avons 57, 0532% de communautÂ´es dont la taille est comprise entre
1 et 10. Lâ€™algorithme est capable de dÂ´etecter des communautÂ´es de diï¬€Â´erentes
tailles, petites et plus grandes. A I10, 1, 4774% des communautÂ´es ont une taille
comprise entre 41 et 50, alors que 0, 3776% des communautÂ´es ont une taille
supÂ´erieure `a 100. La ï¬gure 4.7 montre lâ€™existence dâ€™une convergence apr`es 10
itÂ´erations. La conductance diminue parall`element `a la diminution constante du
nombre de communautÂ´es, dont les densitÂ´es augmentent. Câ€™est en ce sens que
nous proposons dâ€™augmenter le nombre dâ€™itÂ´erations `a 15, pour une meilleure
qualitÂ´e de partitionnement.

Figure 4.7 â€“ Propagation de labels semi-synchrone sur Hadoop (SLPH)avec N = 1,
itÂ´eration apr`es itÂ´eration.

En observant le Tableau 4.4, nous voyons que le seuil Î± joue bien un rË†ole
sur la taille des communautÂ´es et la qualitÂ´e qui en rÂ´esulte. Plus Î± est important,
plus le nombre de communautÂ´es augmente.

Pour N = 100, Tableau 4.5, avec Î± â‰¥ 0, 4, 73, 081% des communautÂ´es ont
une taille comprise entre 1 et 10 nÅ“uds alors quâ€™avec Î± â‰¥ 0, 6, ce pourcentage
sâ€™Â´el`eve `a 89, 057%. NÂ´eanmoins, certaines grandes communautÂ´es sont trouvÂ´ees
pour chaque valeur de Î±, montrant la robustesse de certaines communautÂ´es.
Avec Î± â‰¥ 0, 4, 1, 012% des communautÂ´es ont une taille supÂ´erieure `a 100. Appli-
quer une matrice de co-frÂ´equence diminue fortement la taille des communautÂ´es.
Avec Î± â‰¥ 0, 8, seulement 0, 0018% des communautÂ´es ont une taille supÂ´erieure `a

Tailles
1-10
11-20
21-30
31-40
41-50
51-60
61-70
71-80
81-90
91-100
> 100
Tailles
1-10
11-20
21-30
31-40
41-50
51-60
61-70
71-80
81-90
91-100
> 100

85.913 % 72.8953 % 66.7653 % 63.1801 % 61.1225 %
11.1707 % 19.5767 % 22.7308 % 24.4647 % 25.2975 %
2.046 %
8.0646 %
2.7505 %
0.5455 %
1.3159 %
0.1854 %
0.6652 %
0.0759 %
0.0388 %
0.302 %
0.000 %
0.000 %
0.1546 %
0.0106 %
0.0791 %
0.0018 %
0.0124 %
0.2411 %

4.7709 %
1.5736 %
0.5957 %
0.3163 %
0.1476 %
0.000 %
0.029 %
0.0316 %
0.0604 %

7.2787 %
2.6763 %
1.1455 %
0.5728 %
0.2864 %
0.000 %
0.133 %
0.0545 %
0.2009 %

6.369 %
2.312 %
0.8725 %
0.4518 %
0.243 %
0.000 %
0.0623 %
0.0592 %
0.1276 %

I6

I7

I8

I9

I10

59.5642 % 58.6458 % 58.0986 % 57.4829 % 57.0532 %
26.9699 % 27.1485 %
26.0335 % 26.5051 %
8.4246 %
8.9127 %
9.0191 %
3.336 %
3.2328 %
2.9832 %
1.4774 %
1.5005 %
1.3892 %
0.8062 %
0.8131 %
0.6965 %
0.3538 %
0.3967 %
0.4527 %
0.000 %
0.000 %
0.000 %
0.2065 %
0.2043 %
0.1713 %
0.1152 %
0.1139 %
0.108 %
0.268 %
0.4084 %
0.3776 %

26.63 %
8.763 %
3.1534 %
1.5612 %
0.7399 %
0.3951 %
0.000 %
0.2014 %
0.1162 %
0.3255 %

8.52 %
3.1702 %
1.3794 %
0.7964 %
0.3658 %
0.000 %
0.202 %
0.0953 %
0.3085 %

4.2. EXP Â´ERIMENTATIONS

177

Distribution des tailles de communautÂ´es avec SLPH sur Amazon
I5

I4

I3

I2

I1

Tableau 4.3 â€“ Distribution des tailles des communautÂ´es SLPH (N = 1)

CDLP on Amazon (I15 and N = 100)
Î± â‰¥ 0.5
0.3522
0.3552
0.328038
0.404496
101821

Î± â‰¥ 0.6
0.3248
Q
0.4125
Ï†
0.3015
NMI
0.3849
F1
#
113972
Tableau 4.4 â€“ Scores des mesures supervisÂ´ees et non supervisÂ´ees

Î± â‰¥ 0.4
0.4789
0.2160
0.359236
0.4240019

Î± â‰¥ 0.2
0.5559
0.1176
0.3604
0.4225
60077

Î± â‰¥ 0.3
0.5768
0.1150
0.377456
0.433952

85801

69628

100. Plus Î± augmente, plus la taille des communautÂ´es diminue. Le SLPH trouve
approximativement 25 000 communautÂ´es.

Lâ€™analyse des mesures supervisÂ´ees et non supervisÂ´ees montre que la mÂ´ethode
de dÂ´etection de cÅ“urs donne de relativement bons rÂ´esultats mais reste Â´equivalente
en termes de qualitÂ´e au SLPH. Cela vient du fait que les structures communau-
taires du graphe Amazon sont de tr`es petite taille.

178CHAPITRE 4. PROPOSITIONS SUR LE PARALL Â´ELISME ET LA DISTRIBUTION

Î± â‰¥ 0.6

CDLP sur Amazon (distribution des tailles des communautÂ´es) (I10 and N = 20)
Tailles
1-10
11-20
21-30
31-40
41-50
51-60
61-70
71-80
81-90
91-100
101-200
201-300
>300

Î± â‰¥ 0.7
Î± â‰¥ 0.5
82.145% 89.057 % 94.4227 %
10.257 % 7.303 %
4.2461 %
5.251 % 1.9563 % 0.8188 %
1.258 % 0.7863 % 0.2952 %
0.554 % 0.3535 % 0.0984 %
0.2748 % 0.1775 % 0.0594 %
0.082 % 0.1125 % 0.0297 %
0.0240 %
0.0345 % 0.0563 % 0.0084 %
0.0347 % 0.0476 % 0.0046 %
0.062% 0.1239 %
0.014 %
0.0186 % 0.0009 %
0.120
0.0232
0.0042 % 0.0012 %

Î± â‰¥ 0.4
73.081
12.057
7.548
3.314
1.369
0.845
0.145
0.378
0.024
0.1458
0.275
0.351
0.386

0.0006 %
Tableau 4.5 â€“ Distribution des tailles de communautÂ´es du CDLP et de SLPH

Î± â‰¥ 0.8
97.729 %
1.9291 %
0.2488 %
0.0611 %
0.0167 %
0.009 %
0.0026 %

0.0 %

0.0013 %
0.0006 %
0.0012 %

0.0 %

0.0 %

0.0 %

Nous donnons quelques exemples dâ€™Â´elÂ´ements issus des communautÂ´es que Par-

CDLP a dÂ´etectÂ´ees, Tableau 4.6.

CommunautÂ´es

Agatha Christie

Judith Philips

Exemples de communautÂ´es dÂ´etectÂ´ees

articles
The Man in the Brown Suit
(St. Martinâ€™s Minotaur Mysteries)
Lord Edgware Dies
Poirot Investigates
Murder on the Orient Express :
A Hercule Poirot Mystery
4 : 50 from Paddington Miss
Marple Mysteries
Southwestern Landscaping with Native Plants
New Mexico Gardenerâ€™s Guide (Gardenerâ€™s Guides)
New Mexico Gardenerâ€™s Guide (Jul 3, 2001)
Natural by Design : Beauty
and Balance in Southwest Gardens
Plants for Natural Gardens : Southwestern

Kelli Dolecek

Native, Adaptive Trees, Shrubs,
Wildï¬‚owers, Grasses
Month-To-Month
Gardening, New Mexico

Tableau 4.6 â€“ Exemple de communautÂ´es dÂ´etectÂ´ees sur Amazon

genre et th`eme
enquË†ete polici`ere

enquË†ete polici`ere
enquË†ete polici`ere
enquË†ete polici`ere

enquË†ete polici`ere

jardinage (gÂ´enÂ´eral)
jardinage (dÂ´esert)
jardinage (dÂ´esert)
jardinage (sud-ouest)

jardinage
(Texas et Californie)

jardinage (dÂ´esert)

4.2. EXP Â´ERIMENTATIONS

179

Etude sur DBLP

Tailles
Q
Ï†
NMI
F1
#

Î± â‰¥ 0.3
0.6424
0.0361
0.1948
0.267489

24771

CDLP sur DBLP (I10 et N = 100)
Î± â‰¥ 0.4
0.6979
0.0523
0.2202
0.304575

Î± â‰¥ 0.5
0.7104
0.00647
0.260057
0.373641

Î± â‰¥ 0.6
0.6680
0.025

0.246206
0.367221

28660

36218

35439

Î± â‰¥ 0.7
0.6273
0.045
0.2364
0.345877

40521

SLPH
0.6546
0.0612
0.2241
0.325454

45276

Tableau 4.7 â€“ Scores des mesures supervisÂ´ees et non supervisÂ´ees

Î± â‰¥ 0.6

Î± â‰¥ 0.7

SLPH

Distribution des tailles de communautÂ´es, CDLP sur DBLP (I20 et N = 100)
Tailles
1-10
11-20
21-30
31-40
41-50
51-60
61-70
71-80
81-90
91-100
101-200
201-300
> 300

Î± â‰¥ 0.8
Î± â‰¥ 0.5
79.300 % 85.6181 % 90.2142 % 93.4246 %
5.1026 %
13.400 % 10.0392 % 7.2451 %
3.800 %
1.5352 %
0.921 %
0.315 %
0.5514 %
1.500 %
0.1235 %
0.2162 %
0.800 %
0.0403 %
0.1097 %
0.400 %
0.300 %
0.0494 %
0.029 %
0.000 %
0.0 %
0.0455 %
0.100 %
0.0238 %
0.100 %
0.2701 %
0.300 %
0.0929 % 0.0785 %
0.000 %
0.0132 %

0.0014
0.00 %
Tableau 4.8 â€“ Distribution des tailles des communautÂ´es avec Par-CDLP

69.8484 %
19.8401 %
5.9319 %
2.2757 %
0.9611 %
0.4954 %
0.284 %
0.0 %

0.0113 %
0.0063 %
0.0293 %
0.0428 %
0.00 %

0.0 %

0.0154 %
0.0108 %
0.0477 %
0.0517 %
0.008 %

2.488 %
0.8986 %
0.4176 %
0.2197 %
0.1306 %

0.0 %

0.0727 %
0.0892 %
0.1749 %

Lâ€™algorithme de coloration trouve pour le graphe DBLP 116 couleurs. La
distribution des tailles des groupes de nÅ“uds suivant les couleurs nâ€™est pas uni-
formÂ´ement rÂ´epartie. 7 couleurs rÂ´eprÂ´esentent pr`es de 90, 377%. Certaines couleurs
ne rÂ´eprÂ´esentent que 0, 0003% de la population totale.

Le SLPH trouve 24469 communautÂ´es avec une modularitÂ´e de 0.6894 et un
NMI de 0.218794. La majoritÂ´e des communautÂ´es dÂ´etectÂ´ees sont de taille comprise
entre 1 et 10 (69.8484 %). Cependant, de grandes communautÂ´es sont dÂ´etectÂ´ees
avec plus de 0.1895% des communautÂ´es ayant une taille supÂ´erieure `a 100 nÅ“uds.

Nous observons au tableau 4.7 que la qualitÂ´e des communautÂ´es dÂ´etectÂ´ees par
Par-CDLP, notamment pour Î± â‰¥ {0.5, 0.6, 0.7, 0.8}, est meilleure quâ€™avec le
SLPH. Par-CDLP obtient un NMI de 0.260057 avec Î± â‰¥ 0.5. La mÂ´ethode `a
base de dÂ´etection de cÅ“urs permet dâ€™amÂ´eliorer la qualitÂ´e de partitionnement.
Pour Î± â‰¥ 0.8, le nombre de communautÂ´es avec Par-CDLP devient tr`es im-
portant. Comme SLPH, Par-CDLP dÂ´etecte quelques grandes communautÂ´es qui

180CHAPITRE 4. PROPOSITIONS SUR LE PARALL Â´ELISME ET LA DISTRIBUTION

disparaissent avec lâ€™augmentation de Î±.
Nous donnons quelques exemples de communautÂ´es dÂ´etectÂ´ees avec plusieurs va-
leurs de Î±, Tableau 4.9. (Il ne sâ€™agit que dâ€™une partie des communautÂ´es).

4.2. EXP Â´ERIMENTATIONS

181

Exemples de communautÂ´es dÂ´etectÂ´ees sur DBLP (n = 317080 et m = 1049866)

Auteurs
Maria Malek
(Î± â‰¥ 0.3)

Maria Malek (Î± â‰¥ 0.85)
Marc Zolghadri (Î± â‰¥ 0.3)

communautÂ´es
â€Dominique Laurentâ€
â€Dalia Suliemanâ€
â€Hubert Kadimaâ€
â€Rushed Kanawatiâ€
â€Sylvie Salottiâ€
â€Farida Zehraouiâ€
â€Vincent Rialleâ€
â€Ahmad A. Kardanâ€
â€AHM Ragabâ€
â€M Ebrahimiâ€
â€DR Millenâ€
â€Nicola Spyratosâ€
etc.
â€Rushed Kanawatiâ€
â€Rachid Chelouahâ€
â€Citlalih Gutierrez Estradaâ€
â€Bruno Vallespirâ€
â€Yan Liuâ€
â€Salah Zouggarâ€
â€StÂ´ephane Brunelâ€
â€Philippe Girardâ€
â€Claude Olivierâ€
â€P Agarwalâ€
â€M Sahaiâ€
â€V Mishraâ€
â€Claude Baronâ€
etc.

genre et th`eme
Recommandation sÂ´ematique et sociale
Recommandation sÂ´emantique et sociale
Recommandation sÂ´emantique et sociale
COBRA

recommandation

syst`eme multi-agent

COBRA
Meta-heuristics

Power-based supplier
Power-based supplier
Power-based supplier

Tableau 4.9 â€“ Exemple de communautÂ´es dÂ´etectÂ´ees

182CHAPITRE 4. PROPOSITIONS SUR LE PARALL Â´ELISME ET LA DISTRIBUTION

Etude comparative

Nous proposons une Â´etude comparative portant sur la qualitÂ´e de partition-
nement. Les algorithmes pour cette Â´etude sont la mÂ´ethode de Louvain (Blondel
et al. (2008)), WalkTrap (Pons et Latapy (2006)), OSLOM (Lancichinetti et al.
(2011)), Infomap (Rosvall et Bergstrom (2008)), Bigclam (Yang et Leskovec
(2013)), SCD (Prat-PÂ´erez et al. (2014)), LPA (Raghavan et al. (2007)) et SLPA
(Xie et al. (2011)) sur quatre grands graphes, Amazon, DBLP, You Tube et Live
Journal.

Figure 4.8 â€“ NMI sur les quatre grands rÂ´eseaux avec diï¬€Â´erents algorithmes

Figure 4.9 â€“ F1 sur les quatre grands rÂ´eseaux avec diï¬€Â´erents algorithmes

Les premi`eres observations des Figures 4.8 et 4.9 montrent que notre solution
est compÂ´etitive par rapport aux solutions issues de la litÂ´erature. On observe

4.2. EXP Â´ERIMENTATIONS

183

que le CDLP donne de meilleurs rÂ´esultats que les autres mÂ´ethodes `a base de
propagation de labels. SLPH est presque Â´equivalent au LPA sur you Tube et
live Journal, mais donne cependant de meilleurs rÂ´esultats en termes de qualitÂ´e
sur Amazon ou DBLP. Cependant, dâ€™autres mÂ´ethodes surpassent CDLP comme
Louvain ou SCD en termes de qualitÂ´e de partitionnement.

4.2.3 Etude volumÂ´etrique traitÂ´ee par le HDFS

Nous Â´etudions la quantitÂ´e de donnÂ´ees produites par chaque job. En ef-
fet, certaines solutions de cloud computing comme â€Google Cloud Paltformâ€
(https ://cloud.google.com/) ou â€Amazon EMRâ€ (https ://aws.amazon.com)
facturent selon la quantitÂ´e de donnÂ´ees stockÂ´ee. Sur la Figure 4.10, nous rÂ´ecapitulons
chaque job, avec les mappers et reducers associÂ´es.

job1
job2
job3
job4
job5
job6

Jobs MapReduce

FirstReadMap

VoteMap
MapUpdate

MapCommunity

FirstReadReduce
VoteReduceâˆ’Ci
UpdateReduce

ReduceCommunity

MapOccurrenceMatrix

ReduceOccurrenceMatrix

MapGPrimAlpha

ReduceGPrimAlpha

Tableau 4.10 â€“ jobs MapReduce pour le Par-CDLP

Figure 4.10 â€“ QuantitÂ´e de donnÂ´ees produite par les jobs et stockÂ´ee par le HDFS en
fonction du nombre de propagations de labels lancÂ´ees en parall`ele, â€*â€ signiï¬e que le
calcul est une moyenne, Î± â‰¥ 0.1.

Initialement, nous utilisons 80 reducers pour une simple machine. Le nombre
de reducers sera multipliÂ´e par deux `a chaque fois quâ€™une nouvelle machine sera
ajoutÂ´ee. Le temps nÂ´ecessaire, Figure 4.11, pour faire marcher la propagation

184CHAPITRE 4. PROPOSITIONS SUR LE PARALL Â´ELISME ET LA DISTRIBUTION

Figure 4.11 â€“ Temps dâ€™exÂ´ecution (en heures), lâ€™axe des abcisses reprÂ´esente le nombre
de machines fonctionnant en parall`ele

de labels semi-synchrone sur Amazon, de lâ€™Â´etape de coloration `a lâ€™Â´etape de la
dÂ´etection des composantes connexes avec N = 100 est dâ€™environ deux heures
pour une simple machine (avec une version Hadoop standalone) alors quâ€™il nâ€™est
que de 35 minutes pour le SLPH. Il est donc intÂ´eressant de pouvoir utiliser un
cluster de machines pour tenter de rÂ´eduire le temps dâ€™exÂ´ecution. Avec lâ€™augmen-
tation des machines, le temps dâ€™exÂ´ecution diminue pour arriver `a 35 minutes,
toujours avec N = 100.

La quantitÂ´e de donnÂ´ees stockÂ´ee est reprÂ´esentÂ´ee `a la Figure 4.10. Par dÂ´efaut,
le HDFS rÂ´eplique chaque bloc de donnÂ´ees produit 3 fois sur son cluster. Nous
avons volontairement supprimÂ´e cette fonctionnalitÂ´e pour mieux rendre compte
de la quantitÂ´e de donnÂ´ees produite par le logiciel. Nous rappelons que les noms
des jobs sont au Tableau 4.10. Pour les jobs 2, 3, 4 et 5, nous donnons la quantitÂ´e
de donnÂ´ees moyenne produite par une couleur depuis que nous procÂ´edons `a la

4.2. EXP Â´ERIMENTATIONS

185

destruction des donnÂ´ees intermÂ´ediaires, avec un script de nettoyage de donnÂ´ees.
Nous observons un facteur de proportionnalitÂ´e en fonction de N . Les jobs 1, 2
et 3 produisent les plus grandes quantitÂ´es de donnÂ´ees. Pour le job 5 et pour
chaque N , la quantitÂ´e de donnÂ´ees est presque la mË†eme depuis que ce job associe
`a chaque nÅ“ud sa communautÂ´e.

Nous avons Â´egalement observÂ´e que la valeur de Î± nâ€™avait aucune inï¬‚uence
sur le temps et sur la quantitÂ´e de donnÂ´ees produites par les jobs 1 `a 5. Cela
vient du fait que ce param`etre nâ€™intervient pas dans le processus algorithmique.
Il intervient cependant au job 6 o`u la volumÂ´etrie et le temps dâ€™exÂ´ecution ï¬‚uc-
tueront en fonction de la valeur Î±. La valeur de Î± aura pour consÂ´equence une
ï¬‚uctuation du temps de calcul des composantes connexes, qui reprÂ´esentent nos
communautÂ´es. Un Î± produisant plus dâ€™arË†etes demandera un temps de calcul
pour les composantes connexes plus important.

Sur la Figure 4.10, le volume de donnÂ´ees a Â´etÂ´e calculÂ´e avec Î± â‰¥ 0, 1. Câ€™est
le job 1 qui produit la plus importante quantitÂ´e de donnÂ´ees depuis quâ€™il a fallu
instancier un vecteur de labels de taille N , j âˆ’ li âˆ’ i âˆ’ Ci.

Nous avons, `a titre expÂ´erimental, testÂ´e plusieurs valeurs de N et jouÂ´e sur
le nombre de couleurs pour le temps dâ€™exÂ´ecution, `a la Figure 4.11. Le temps
dâ€™exÂ´ecution de notre mod`ele sera fonction de N , mais Â´egalement du nombre de
couleurs dÂ´etectÂ´ees par lâ€™algorithme de coloration. Plus le nombre de couleurs
est important, plus le temps dâ€™exÂ´ecution est important. Sur DBLP, nous avons
pr`es de 90, 377% des nÅ“uds qui ne rÂ´eprÂ´esentent que 7 couleurs alors que cela
est du mË†eme ordre pour Amazon, avec une couverture de 90.355% de nÅ“uds
avec juste 7 couleurs. Cela sous entend que de nombreux jobs traiteront uni-
quement 10% des nÅ“uds du graphe, avec un temps excessivement important
dË†u `a lâ€™importance du nombre de couleurs. Câ€™est en ce sens que nous lanÂ¸cons
`a la fois lâ€™algorithme original et une version rÂ´eduite (CDLPRED) comprenant
exclusivement 7 couleurs plus 1 qui servira `a la propagation des autres labels `a
la ï¬n du processus.

En ce qui concerne Par-CDLP, augmenter le nombre de machines et le
nombre de reducers diminue le temps dâ€™exÂ´ecution pour un N Â´elevÂ´e. Ce nâ€™est
pas toujours le cas lorsque la quantitÂ´e de donnÂ´ees `a traiter nâ€™est pas tr`es inpor-
tante comme pour SLPH. Nous voyons que les versions rÂ´eduites vont beaucoup
plus vite. En eï¬€et, certaines couleurs ne reprÂ´esentent que certains nÅ“uds du
graphe (comme la couleur C24 avec moins de 0, 0003% du total des nÅ“uds du
graphe). Il faut beaucoup de temps pour eï¬€ectuer la propagation dâ€™un nombre
aussi faible de labels.

186CHAPITRE 4. PROPOSITIONS SUR LE PARALL Â´ELISME ET LA DISTRIBUTION

4.3 Conclusion portant sur les propositions liÂ´ees

au parallÂ´elisme et la distribution

Dans ce chapitre, nous avons dÂ´ecrit une implantation informatique possible
parall`ele et distribuÂ´ee de la propagation de labels avec cÅ“urs. Pour rÂ´esoudre
le probl`eme de la propagation de labels asynchrone, nous avons proposÂ´e dâ€™uti-
liser le principe de coloration, o`u des groupes de nÅ“uds changent leurs labels
en mË†eme temps suivant la propagation de labels habituelle, alors que dâ€™autres
attendent leur tour.

En utilisant comme crit`ere la modularitÂ´e, les expÂ´erimentations ont montrÂ´e
de meilleurs rÂ´esultats en termes de qualitÂ´e de partitionnement par rapport aux
mÂ´ethodes `a base de propagation de labels comme le LPA, mais cependant moins
bons que pour la mÂ´ethode de Louvain.

La mÂ´ethode proposÂ´ee est relativement lente. Le temps dâ€™exÂ´ecution, que ce
soit pour DBLP, You Tube ou live Journal peut nÂ´ecessiter plusieurs heures. Le
nombre de couleurs joue un rË†ole majeur sur le temps dâ€™exÂ´ecution. Par exemple,
nous avons trouvÂ´e 24 couleurs sur le graphe dâ€™Amazon alors que 6 couleurs
reprÂ´esentent 86.52% des nÅ“uds du graphe. Certaines couleurs ne reprÂ´esentent
quant-`a-elles que 0.0003% du total des nÅ“uds du graphe, soit une dizaine de
nÅ“uds. Appliquer Par-CDLP sur un aussi petit groupe de nÅ“uds requiert un
temps tr`es important. Ce constat fut Â´etabli pour tous les grands graphes qui
furent utilisÂ´es pour les expÂ´erimentations. De plus, lâ€™Â´ecriture sur disque des
donnÂ´ees requiert un temps qui peut Ë†etre tr`es important.

Nous Â´etudions actuellement un moyen de rÂ´eduire le temps dâ€™exÂ´ecution, comme
fusionner des groupes de nÅ“uds de couleurs diï¬€Â´erentes au risque de dÂ´etÂ´eriorer
la qualitÂ´e de partitionnement. Cette implÂ´ementation pourrait Â´egalement Ë†etre
utile pour une version parall`ele et distribuÂ´ee destinÂ´ee au chevauchement. Nous
Â´etudions Â´egalement une version en mÂ´emoire RAM, notamment en utilisant
Apache Spark.

Chapitre 5

Conclusion

Sommaire

5.1 Contributions algorithmiques . . . . . . . . . . . . 188

5.2 Perspectives . . . . . . . . . . . . . . . . . . . . . . . 189

Dans cette th`ese, nous nous sommes intÂ´eressÂ´es aux probl`emes de dÂ´etections
de communautÂ´es disjointes et chevauchantes, et `a la scalabilitÂ´e de nos mÂ´ethodes
en proposant une version Hadoop pour la propagation de labels avec dÂ´etection
de cÅ“urs.

Le premier chapitre a permis de dÂ´ecrire trois grandes classes dâ€™algorithmes en
dÂ´etection de communautÂ´es disjointes : les mÂ´ethodes globales, locales et hybrides.
Il a Â´etÂ´e observÂ´e que les mÂ´ethodes locales, câ€™est-`a-dire dont le point de dÂ´epart est
atomique (par le nÅ“ud), permettaient de traË†Ä±ter de plus grands graphes que les
mÂ´ethodes globales, ou encore divisives. La propagation de labels est une mÂ´ethode
locale, qui a lâ€™avantage dâ€™Ë†etre rapide et applicable `a des graphes de plusieurs
millions de nÅ“uds et dâ€™arË†etes mais elle prÂ´esente certains inconvÂ´enients, `a savoir
de mauvaises propagations qui peuvent donner des communautÂ´es gÂ´eantes, une
forte instabilitÂ´e due au non dÂ´eterminisme de lâ€™algorithme et lâ€™impossibilitÂ´e de
trouver des communautÂ´es chevauchantes. Câ€™est en ce sens que notre premi`ere
contribution fut i) de proposer une version amÂ´eliorÂ´ee de la propagation de labels
en y incluant une stabilisation par recherche de cÅ“urs et la mise en place de bar-
rages artiï¬ciels pour Â´eviter de mauvaises propagations. La seconde contribution
ii) fut dâ€™amÂ´eliorer la mÂ´ethode prÂ´ecÂ´edente pour le chevauchement en y incluant
une fonction dâ€™appartenance permettant de dÂ´etecter des nÅ“uds pouvant ap-
partenir `a plusieurs communautÂ´es. Plusieurs fonctions dâ€™appartenance fondÂ´ees
sur la densitÂ´e et le cÅ“ï¬ƒcient de clustering sont proposÂ´ees en vue dâ€™une Â´etude
comparative. Enï¬n, nous avons proposÂ´e iii) une implÂ´ementation MapReduce de
notre propagation de labels pour travailler sur de plus grands graphes ayant au
moins plusieurs millions de nÅ“uds et dâ€™arË†etes. La propagation de labels dans
sa forme asynchrone prÂ´esenta une diï¬ƒcultÂ´e pour le parallÂ´elisme `a laquelle nous

187

188

avons rÂ´epondu.

CHAPITRE 5. CONCLUSION

5.1 Contributions algorithmiques

Pour rÂ´epondre `a la problÂ´ematique de dÂ´etection de communautÂ´es disjointes,
et remÂ´edier aux probl`emes de la propagations de labels, nous avons proposÂ´e la
propagation de labels avec barrages qui a montrÂ´e des rÂ´esultats encourageants
en termes de qualitÂ´e de partionnement sur des graphes sociaux.

Nous avons proposÂ´e deux versions fondÂ´ees sur la dÂ´etection de cÅ“urs et sur
des matrices de frÂ´equence. La premi`ere mÂ´ethode Â´etait fondÂ´ee sur la crÂ´eation
de plusieurs matrices de frÂ´equence alimentÂ´ees avec diï¬€Â´erents niveaux de bar-
rages. La seconde mÂ´ethode consiste `a alimenter une seule matrice de frÂ´equence
mais avec diï¬€Â´erents niveaux de barrages. La premi`ere mÂ´ethode nÂ´ecessite lâ€™in-
tervention dâ€™une mesure de qualitÂ´e pour savoir quelle matrice serait capable de
donner le meilleur partitionnement. La seconde mÂ´ethode, notÂ´ee PLBS, nÂ´ecessite
de donner un intervalle sur lequel les propagations de labels avec diï¬€Â´erents ni-
veaux de barrages alimenteraient la matrice de frÂ´equence. Les rÂ´esultats pour
la simple propagation de labels avec barrages ont montrÂ´e que le fait de mettre
des barrages artiï¬ciels pouvait amÂ´eliorer la qualitÂ´e de partitionnement comme
sur le rÂ´eseau footballistique. Cependant, il y certains cas o`u la mise en place de
barrages semble inutile, comme le cas du rÂ´eseau de collaboration scientiï¬que o`u
les communautÂ´es sont dÂ´ej`a bien dÂ´eï¬nies. Concernant les mÂ´ethodes de dÂ´etection
par cÅ“urs, PLBS montre des rÂ´esultats tr`es satisfaisants, notamment en alimen-
tant la la matrice de co-frÂ´equence de 0 `a 30 % de barrages. En alimentant une
matrice de co-frÂ´equence par diï¬€Â´erents niveaux de labels, le syst`eme assure que
les nÅ“uds avec une forte probabilitÂ´e dâ€™Ë†etre ensemble auront une valeur Â´elevÂ´ee
au sein de la matrice. Si le nombre de barrages est trop grand, le risque est
dâ€™obtenir dans le pire des cas un nÅ“ud correspondant `a une communautÂ´e, ce
qui est Â´equivalent `a ce que la diagonale de la matrice de co-occurence ne soit
pas vide. Cependant, la diagonale nâ€™est pas prise en compte pour la crÂ´eation des
composantes connexes (ce qui est un avantage de la solution). On souhaiterait
nÂ´eanmoins trouver un intervalle pour amÂ´eliorer le partitionnement avec un cer-
tain pas et ne pas dÂ´etÂ´eriorer la qualitÂ´e de partionnement.

Nous nous sommes Â´egalement focalisÂ´es sur lâ€™ordre de visite des nÅ“uds lors
du processus par propagation de labels. Les expÂ´erimentations ont montrÂ´e que
lâ€™ordre avait une incidence `a la fois sur la stabilisation et sur la qualitÂ´e de par-
titionnement.

Pour rÂ´epondre `a la problÂ´ematique de dÂ´etection de communautÂ´es chevau-
chantes, nous avons voulu amÂ´eliorer notre algorithme basique de dÂ´etection de
cÅ“urs par propagation de labels en utilisant `a la fois lâ€™information topologique
sur les structures communautaires et lâ€™information sur les arË†etes, notamment

5.2. PERSPECTIVES

189

celle concernant la pondÂ´eration du graphe par utilisation de la matrice de
frÂ´equence. Les fonctions dâ€™appartenances fondÂ´ees sur la centralitÂ´e de nÅ“uds et
sur le cÅ“ï¬ƒcient de clustering ont montrÂ´e des rÂ´esultats satisfaisants en mati`ere
de qualitÂ´e. Lâ€™une des forces des mÂ´ethodes proposÂ´ees est que lâ€™algorithme per-
met de rÂ´epliquer certains nÅ“uds dans des communautÂ´es diï¬€Â´erentes autant de
fois que nÂ´ecessaire, câ€™est-`a-dire quâ€™un nÅ“ud peut appartenir `a une ou plusieurs
communautÂ´es suivant la fonction utilisÂ´ee. Mais cela nÂ´ecessite, pour un nÅ“ud
candidat au chevauchement, de tester toutes les combinaisons avec les commu-
nautÂ´es qui lui sont liÂ´ees. Cela a pour consÂ´equence une augmentation du temps
dâ€™exÂ´ecution du programme informatique, notamment lorsquâ€™il y a beaucoup de
communautÂ´es autour dâ€™un nÅ“ud. Ainsi, nous avons pu observer, dans notre
implÂ´ementation, que si un nÅ“ud Â´etait liÂ´e `a beaucoup de communautÂ´es, la taille
du vecteur comprenant toutes les combinaisons pouvait devenir gigantesque et
ralentir lâ€™exÂ´ecution informatique. Nous proposons de ne pas considÂ´erer toutes les
possibilitÂ´es mais dâ€™eï¬€ectuer une procÂ´edure dâ€™Â´echantillonnage. Lâ€™objectif Â´etant, `a
court terme, de pouvoir exploiter cette solution pour de grands graphes. Nous
travaillons Â´egalement sur dâ€™autres mesures sociales en vue de faire une Â´etude
comparative.

Pour rÂ´epondre `a la problÂ´ematique des grands graphes, nous avons dÂ´eveloppÂ´e
une base pour la propagation de labels semi-synchrones `a base de cÅ“urs. Notre
mÂ´ethode est fondÂ´ee sur une coloration de graphe, qui sera utilisÂ´ee pour eï¬€ec-
tuer la propagation de label semi-synchrone pour la dÂ´etection de cÅ“urs. Cette
mÂ´ethode permet lâ€™Â´elaboration dâ€™un dendrogramme. Notre modÂ´elisation Hadoop
pour la dÂ´etection de communautÂ´es a montrÂ´e des rÂ´esultats en termes de qua-
litÂ´e de partitionnement encourageants. Cependant, le temps dâ€™exÂ´ecution reste
trop important. Nos observations ont montrÂ´e que la coloration sur les nÅ“uds du
graphe ne suivait pas une loi uniforme. Un nombre rÂ´eduit de couleurs couvre la
majeure partie du rÂ´eseau alors que la majoritÂ´e des couleurs ne couvre quâ€™une
inï¬me partie du rÂ´eseau. Cela a pour consÂ´equence que notre mÂ´ethode prendra
la majeure partie du temps `a la mise `a jour de labels dâ€™un faible nombre de
nÅ“uds. Pour remÂ´edier `a ce probl`eme, nous avons dÂ´ej`a fusionnÂ´e des couleurs de
telle sorte quâ€™il nâ€™existe pas de connexions entre les nÅ“uds de ces couleurs, ce qui
a pu rÂ´eduire le temps dâ€™exÂ´ecution. Une piste, pour notre mod`ele Hadoop, serait
dâ€™analyser la frÂ´equence de mise `a jour des nÅ“uds des labels et de ne pas eï¬€ec-
tuer de mise `a jour de certains nÅ“uds. Par exemple, un nÅ“ud connectÂ´e `a une
communautÂ´e dont le label ne change plus depuis un certain nombre dâ€™itÂ´erations
pourrait ne plus voir son label modiï¬Â´e. Nous dÂ´eveloppons actuellement une so-
lution in-memory en utilisant Apache Spark.

5.2 Perspectives

Suite `a lâ€™analyse des rÂ´esultats des expÂ´erimentations portant sur la propaga-

tion de labels avec barrages, les questions en suspens portent sur :

190

CHAPITRE 5. CONCLUSION

â€” le nombre de barrages nÂ´ecessaires au PLAB pour obtenir la meilleure

solution.

â€” lâ€™intervalle `a considÂ´erer pour le PBLS pour obtenir des rÂ´esultats satisfai-

sants.

En considÂ´erant des cliques connectÂ´ees, il paraË†Ä±t nÂ´ecessaire de mettre en place
des barrages entre elles. Cependant, mettre davantage de barrages ne semble
pas apporter une amÂ´elioration signiï¬cative dans le partitionnement de graphe,
cela aurait plutË†ot tendance `a dÂ´etÂ´eriorer la qualitÂ´e de partitionnement.

Une des pistes que nous Â´etudions concerne lâ€™information de certaines rÂ´egions
du graphe. Nous pensons interdire la mise en place de barrages dans des zones
denses ayant un fort taux de triangles. Cela pourrait sâ€™eï¬€ectuer en observant les
voisinages des arË†etes et en Â´etudiant la structure topologique des communautÂ´es
itÂ´eration apr`es itÂ´eration en termes de pourcentages de barrages. Nos recherches
portent Â´egalement sur lâ€™ordre de la mise `a jour des labels . En utilisant lâ€™infor-
mation fondÂ´ee sur le nÅ“ud et son horizon (`a quelques arË†etes), nous souhaitons
crÂ´eer un ordre de visite de mise `a jour des labels des nÅ“uds Â´evitant de mauvaises
propagations et permettant une convergence plus rapide de lâ€™algorithme.

Nos mÂ´ethodes de dÂ´etection de communautÂ´es chevauchantes nous incitent
`a chercher `a diminuer le temps dâ€™exÂ´ecution, tout en les appliquant `a de plus
grands graphes grË†ace `a un mod`ele parall`ele et distribuÂ´e. Le nombre important
de mesures sociales nous permettra Â´egalement de faire une Â´etude comparative
portant sur le taux de chevauchement entre communautÂ´es.

Notre mod`ele Hadoop permet de traiter des graphes de plusieurs millions de
nÅ“uds et dâ€™arË†etes. Cependant, la coloration, qui est la base de cet algorithme,
prÂ´esente des inconvÂ´enients surtout lorsquâ€™un tr`es faible nombre de nÅ“uds a la
mË†eme couleur. Cela nÂ´ecessite de faire une mise `a jour du graphe dans son en-
semble, alors quâ€™un tr`es faible nombre de nÅ“uds est concernÂ´e. Une solution
in-memory serait apprÂ´eciable pour faire une Â´etude comparative portant sur les
volumÂ´etries traË†Ä±tÂ´ees et le temps dâ€™exÂ´ecution avec le mod`ele Hadoop.

En observant les communautÂ´es dâ€™Amazon et en allant sur le site de vente
en ligne, nous nous sommes rendu compte dâ€™une grande similaritÂ´e entre les
Â´elÂ´ements des communautÂ´es et les recommandations. Nous pensons que notre
mod`ele pourrait Ë†etre la base pour un syst`eme de recommandation `a grande
Â´echelle. Cela constitue une piste de recherche.

Chapitre 6

Glossaire

Nous proposons un glossaire permettant de dÂ´eï¬nir certaines notions, princi-
palement liÂ´ees au graphe. Dans ce cadre, nous considÂ´erons un graphe G = (V, E)
avec V un ensemble de sommets et E un ensemble dâ€™arË†etes E. |V | dÂ´enote le
nombre de sommets du graphe et |E| le nombre dâ€™arË†etes.

6.1 DÂ´eï¬nitions relatives aux graphes

Benchmark LFR : Le benchmark LFR (Lancichinetti-Fortunato-Radicchi)
est un algorithme de crÂ´eation de graphes alÂ´eatoires dont les caractÂ´eristiques se
veulent aussi proches que des rÂ´eseaux complexes. Les avantages de lâ€™algorithme
sur les autres mÂ´ethodes est quâ€™il tient compte de lâ€™hÂ´etÂ´erogÂ´enÂ´eitÂ´e de la distribu-
tion des degrÂ´es des noeuds et des tailles de communautÂ´es. Lâ€™algorithme demande
un certains nombre de param`etres :

â€” n : le nombre de noeuds
â€” k : le degrÂ´e interne moyen des communautÂ´es
â€” maxk : le degrÂ´e maximum
â€” mu : l param`etre de mixage
â€” t1 : exposant pour la sÂ´equence de degrÂ´e
â€” t2 : exposant pour la distribution des tailles des communautÂ´es
â€” minc : taille minimum des communautÂ´es
â€” maxc : taille maximum des communautÂ´es
â€” on : nombre de noeuds chevauchants
â€” om : nombre de communautÂ´es auxquelles appartiennent les noeuds che-

vauchants

La bordure (ou fronti`ere) dâ€™une communautÂ´e est lâ€™ensemble des nÅ“uds

ayant au moins un lien vers une autre communautÂ´e.

191

192

CHAPITRE 6. GLOSSAIRE

Coloriage : Il sâ€™agit dâ€™attribuer une couleur `a chacun des sommets dâ€™un
graphe de mani`ere que deux sommets reliÂ´es par une arË†ete soient de couleur
diï¬€Â´erente.

Graphe complet : Un graphe complet est un graphe o`u chaque sommet
est reliÂ´e `a tous les autres. On note Kn le graphe complet `a n sommets o`u chaque
sommet est de degrÂ´e n âˆ’ 1.

Graphe nul : Si lâ€™on consid`ere un graphe G, le mod`ele nul (ou graphe nul)
consiste en la crÂ´eation dâ€™un graphe G(cid:48) respectant la distribution des degrÂ´es des
noeuds avec des arË†etes posÂ´ees de mani`ere alÂ´eatoire.

Clique : sous-ensemble de sommets dâ€™un graphe dont le sous-graphe in-
duit est complet, câ€™est-`a-dire que deux sommets quelconques de la clique sont
toujours adjacents. Une K-clique est un sous-ensemble de k sommets tous adja-
cents (sous-graphe complet), et deux k-cliques sont adjacentes si elles partagent
k âˆ’ 1 sommets.

Clique maximum : Une clique maximum dâ€™un graphe est une clique dont
le cardinal est le plus grand (câ€™est-`a-dire quâ€™elle poss`ede le plus grand nombre
de sommets).

Contraction : Une contraction consiste `a supprimer une arË†ete dâ€™un graphe
en fusionnant les deux extrÂ´emitÂ´es. Ainsi, la contraction G/e dâ€™une arË†ete exy `a
un sommet x rend le sommet x adjacent `a tous les voisins prÂ´ecÂ´edents de y. On
retrouve les premiers principes de contraction avec les mÂ´ethodes multi-niveau de
partitionnement de graphe (Karypis et Kumar, 1995) (Karypis et Kumar, 1998a)
(Karypis et Kumar, 1998b) (Hendrickson et Leland, 1995b) (Hendrickson et Le-
land, 1995a) qui seront utilisÂ´ees par la suite pour les mÂ´ethodes agglomÂ´eratives
comme Louvain ou celle de Rotta (Rotta et Noack, 2011) ou de Noack (Noack
et Rotta, 2009).

Dendrogramme : un dendrogramme est une reprÂ´esentation graphique
sous forme dâ€™arbre binaire permettant lâ€™observation dâ€™une hiÂ´erarchie des par-
ties (communautÂ´es) au sein du graphe. On peut ainsi observer pour un noeud
sa communautÂ´e, mais Â´egalement les imbrications entre communautÂ´es jusquâ€™`a la
racine.

Fronti`ere des arË†etes : Les arË†etes menant dâ€™une partie dâ€™un graphe au

reste du graphe.

Fronti`ere intÂ´erieure des sommets

: Les sommets dâ€™une partie dâ€™un

graphe reliÂ´ees au reste du graphe.

Fronti`ere extÂ´erieure des sommets : Les sommets du reste dâ€™un graphe

reliÂ´ees `a une partie du graphe.

6.1. D Â´EFINITIONS RELATIVES AUX GRAPHES

193

Moyenne harmonique : La moyenne harmonique H de nombres rÂ´eels
La moyenne

strictement positifs x1, ..., xn est dÂ´eï¬nie comme Â´etant H =
harmonique est utilisÂ´ee lorsquâ€™on veut dÂ´eterminer un rapport moyen, dans un
domaine o`u il existe des liens de proportionnalitÂ´e inverse.

n

1
x1

+...+ 1
xn

194

CHAPITRE 6. GLOSSAIRE

Bibliographie

BalÂ´azs Adamcsek, Gergely Palla, IllÂ´es J Farkas, Imre DerÂ´enyi et TamÂ´as
Vicsek : Cï¬nder : locating cliques and overlapping modules in biological
networks. Bioinformatics, 22(8):1021â€“1023, 2006.

RÂ´eka Albert, Hawoong Jeong et Albert-LÂ´aszlÂ´o BarabÂ´asi : Internet : Dia-

meter of the world-wide web. Nature, 401(6749):130â€“131, 1999.

LNF Ana et Anil K Jain : Robust data clustering.

In Computer Vision
and Pattern Recognition, 2003. Proceedings. 2003 IEEE Computer Society
Conference on, volume 2, pages IIâ€“128. IEEE, 2003.

George E Andrews : The theory of partitions, volume 2 of encyclopedia of

mathematics and its applications, 1976.

Ching Avery : Giraph : Large-scale graph processing infrastructure on hadoop.

Proceedings of the Hadoop Summit. Santa Clara, 11, 2011.

David A Bader, Shiva Kintali, Kamesh Madduri et Milena Mihail : Ap-
proximating betweenness centrality. In Algorithms and Models for the Web-
Graph, pages 124â€“137. Springer, 2007.

Bahman Bahmani, Ravi Kumar et Sergei Vassilvitskii : Densest subgraph in
streaming and mapreduce. Proceedings of the VLDB Endowment, 5(5):454â€“
465, 2012.

Albert-LÂ´aszlÂ´o BarabÂ´asi et RÂ´eka Albert : Emergence of scaling in random

networks. science, 286(5439):509â€“512, 1999.

Albert-LÂ´aszlÂ´o BarabÂ´asi et Eric Bonabeau : Scale-free networks. Scientiï¬c

American, 288(5):50â€“59, 2003.

Stephen T Barnard : Pmrsb : Parallel multilevel recursive spectral bisec-
tion. In Proceedings of the 1995 ACM/IEEE conference on Supercomputing,
page 27. ACM, 1995.

Stephen T Barnard et Horst D Simon : Fast multilevel implementation of
recursive spectral bisection for partitioning unstructured problems. Concur-
rency : Practice and experience, 6(2):101â€“117, 1994.

195

196

BIBLIOGRAPHIE

ER Barnes et AJ Hoffman : On bounds for eigenvalues of real symmetric

matrices. Linear Algebra and its Applications, 40:217â€“223, 1981.

John Arundel Barnes : Class and committees in a Norwegian island parish.

Plenum New York, 1954.

Vladimir Batagelj et Andrej Mrvar : Pajek datasets, 2006.

Claude Berge : Les nombres fondamentaux de la thÂ´eorie des graphes , volume

361. ThÂ´eorie des Graphes, Â´editions Dunod, 1958.

Marcelo Blatt, Shai Wiseman et Eytan Domany : Superparamagnetic clus-

tering of data. Physical review letters, 76(18):3251, 1996.

Vincent D Blondel, Jean-Loup Guillaume, Renaud Lambiotte et Etienne
Lefebvre : Fast unfolding of communities in large networks. Journal of
statistical mechanics : theory and experiment, 2008(10):P10008, 2008.

Phillip Bonacich : Technique for analyzing overlapping memberships. Socio-

logical methodology, 4:176â€“185, 1972.

Ulrik Brandes : A faster algorithm for betweenness centrality*. Journal of

mathematical sociology, 25(2):163â€“177, 2001.

Ulrik Brandes, Daniel Delling, Marco Gaertler, Robert Gorke, Martin
Hoefer, Zoran Nikoloski et Dorothea Wagner : On modularity clustering.
IEEE Transactions on Knowledge and Data Engineering, 20(2):172â€“188, 2008.

Ronald L Breiger : The duality of persons and groups. Social forces, 53

(2):181â€“190, 1974.

Mingming Chen, Tommy Nguyen et Boleslaw K Szymanski : On measuring
the quality of a network community structure. In Social computing (Social-
Com), 2013 international conference on, pages 122â€“127. IEEE, 2013.

Mingming Chen, Tommy Nguyen et Boleslaw K. Szymanski : A new metric

for quality of network community structure. CoRR, abs/1507.04308, 2015.

Avery Ching : Scaling apache giraph to a trillion edges. Facebook Engineering

blog, page 25, 2013.

Fan R. K. Chung : Spectral Graph Theory (CBMS Regional Conference Series
in Mathematics, No. 92). American Mathematical Society, dÂ´ecembre 1996.
ISBN 0821803158.

Aaron Clauset, Mark EJ Newman et Cristopher Moore : Finding community

structure in very large networks. Physical review E, 70(6):066111, 2004.

Aaron Clauset, Cosma Rohilla Shalizi et Mark EJ Newman : Power-law

distributions in empirical data. SIAM review, 51(4):661â€“703, 2009a.

BIBLIOGRAPHIE

197

Aaron Clauset, Cosma Rohilla Shalizi et Mark EJ Newman : Power-law

distributions in empirical data. SIAM review, 51(4):661â€“703, 2009b.

Linda M Collins et Clyde W Dent : Omega : A general formulation of the
rand index of cluster recovery suitable for non-disjoint solutions. Multivariate
Behavioral Research, 23(2):231â€“242, 1988.

Gennaro Cordasco et Luisa Gargano : Label propagation algorithm : a
semi-synchronous approach. International Journal of Social Network Mining,
1(1):3â€“26, 2012.

Qiguo Dai, Maozu Guo, Yang Liu, Xiaoyan Liu et Ling Chen : Mlpa : De-
tecting overlapping communities by multi-label propagation approach.
In
Evolutionary Computation (CEC), 2013 IEEE Congress on, pages 681â€“688.
IEEE, 2013.

Allison Davis, Burleigh Bradford Gardner et Mary R Gardner : Deep South :
A social anthropological study of caste and class. Univ of South Carolina Press,
2009.

Pasquale De Meo, Emilio Ferrara, Giacomo Fiumara et Alessandro Pro-
vetti : Enhancing community detection using a network weighting strategy.
Information Sciences, 222:648â€“668, 2013.

Jeï¬€rey Dean et Sanjay Ghemawat : Mapreduce : simpliï¬ed data processing

on large clusters. Communications of the ACM, 51(1):107â€“113, 2008.

L. Donetti et M. A. MuËœnoz : Detecting network communities : a new syste-
matic and eï¬ƒcient algorithm. Journal of Statistical Mechanics : Theory and
Experiment, 10:12, octobre 2004.

Jordi Duch et Alex Arenas : Community detection in complex networks using

extremal optimization. Physical review E, 72(2):027104, 2005.

Lei Fang, Qun Yang, Jiawen Wang et Weihua Lei : Signed network label pro-
pagation algorithm with structural balance degree for community detection.
In International Conference on Smart Homes and Health Telematics, pages
427â€“435. Springer, 2016.

Miroslav Fiedler : Algebraic connectivity of graphs. Czechoslovak mathema-

tical journal, 23(2):298â€“305, 1973.

Miroslav Fiedler : A property of eigenvectors of nonnegative symmetric ma-
trices and its application to graph theory. Czechoslovak Mathematical Journal,
25(4):619â€“633, 1975.

Santo Fortunato : Community detection in graphs. Physics Reports, 486

(3):75â€“174, 2010.

Linton C Freeman : Centrality in social networks conceptual clariï¬cation.

Social networks, 1(3):215â€“239, 1978.

198

BIBLIOGRAPHIE

Yaotian Fu et Philip W Anderson : Application of statistical mechanics to
np-complete problems in combinatorial optimisation. Journal of Physics A :
Mathematical and General, 19(9):1605, 1986.

Nishant M Gandhi et Rajiv Misra : Performance comparison of parallel graph
coloring algorithms on bsp model using hadoop. In Computing, Networking
and Communications (ICNC), 2015 International Conference on, pages 110â€“
116. IEEE, 2015.

Robert Geisberger, Peter Sanders et Dominik Schultes : Better approxi-
mation of betweenness centrality. In Proceedings of the Meeting on Algorithm
Engineering & Expermiments, pages 90â€“100. Society for Industrial and Ap-
plied Mathematics, 2008.

David Gfeller, Jean-CÂ´edric Chappelier et Paolo De Los Rios : Finding
instabilities in the community structure of complex networks. Physical Review
E, 72(5):056135, 2005.

M. Girvan et M. E. J. Newman : Community structure in social and biological
networks. Proceedings of the National Academy of Sciences, 99(12):7821â€“7826,
2002a.

Michelle Girvan et Mark EJ Newman : Community structure in social and
biological networks. Proceedings of the national academy of sciences, 99(12):
7821â€“7826, 2002b.

Murray Glanzer et Robert Glaser : Techniques for the study of group struc-
ture and behavior : Ii. empirical studies of the eï¬€ects of structure in small
groups. Psychological Bulletin, 58(1):1, 1961.

Pablo M Gleiser et Leon Danon : Community structure in jazz. Advances in

complex systems, 6(04):565â€“573, 2003.

Gene H Golub : Cf van loan matrix computations. The Johns Hopkins, 1996.

Joseph E Gonzalez, Yucheng Low, Haijie Gu, Danny Bickson et Carlos
Guestrin : Powergraph : Distributed graph-parallel computation on natural
graphs. In OSDI, volume 12, page 2, 2012.

Steve Gregory : An algorithm to ï¬nd overlapping community structure in
networks. In Knowledge discovery in databases : PKDD 2007, pages 91â€“102.
Springer, 2007.

Steve Gregory : Finding overlapping communities in networks by label pro-

pagation. New Journal of Physics, 12(10):103018, 2010.

R. Guimera, M. Sales-Pardo et L.A.N. Amaral : Modularity from ï¬‚uc-
tuations in random graphs and complex networks. Physical Review E, 70
(2):025101, 2004.

BIBLIOGRAPHIE

199

Roger Guimera et Luis A Nunes Amaral : Functional cartography of complex

metabolic networks. Nature, 433(7028):895â€“900, 2005.

Kenneth M Hall : An r-dimensional quadratic placement algorithm. Manage-

ment science, 17(3):219â€“229, 1970.

Bruce Hendrickson et Robert Leland : An improved spectral graph par-
titioning algorithm for mapping parallel computations. SIAM Journal on
Scientiï¬c Computing, 16(2):452â€“469, 1995a.

Bruce Hendrickson et Robert W Leland : A multi-level algorithm for parti-

tioning graphs. SC, 95:28, 1995b.

George C Homans : The human group new york. Harpers, 1950.

Roger A Horn et Charles R Johnson : Matrix analysis cambridge university

press. New York, 1985.

Xuegang Hu, Wei He, Huizong Li et Jianhan Pan : Role-based label propaga-

tion algorithm for community detection. CoRR, abs/1601.06307, 2016.

Lawrence Hubert et Phipps Arabie : Comparing partitions. Journal of clas-

siï¬cation, 2(1):193â€“218, 1985.

Panos Kalnis, Karim Awara, Hani Jamjoom et Zuhair Khayyat : Mizan :
Optimizing graph mining in large parallel systems. Rapport technique, King
Abdullah University of Science and Technology, 2012.

Rushed Kanawati : Licod : Leaders identiï¬cation for community detection in
complex networks. In Privacy, Security, Risk and Trust (PASSAT) and IEEE
Third Inernational Conference on Social Computing (SocialCom), pages 577â€“
582. IEEE, 2011.

U Kang, Brendan Meeder, Evangelos E Papalexakis et Christos Falout-
sos : Heigen : Spectral analysis for billion-scale graphs. IEEE Transactions
on knowledge and data engineering, 26(2):350â€“362, 2014.

U Kang, Charalampos E Tsourakakis et C.Faloutsos : Pegasus : A peta-
scale graph mining system implementation and observations. In Data Mining,
2009. ICDMâ€™09. Ninth IEEE International Conference on, pages 229â€“238.
IEEE, 2009.

Ravi Kannan, Santosh Vempala et Adrian Vetta : On clusterings : Good,

bad and spectral. Journal of the ACM (JACM), 51(3):497â€“515, 2004.

Brian Karrer, Elizaveta Levina et Mark EJ Newman : Robustness of com-

munity structure in networks. Physical Review E, 77(4):046119, 2008.

George Karypis et Vipin Kumar : Multilevel graph partitioning schemes. In

ICPP (3), pages 113â€“122, 1995.

200

BIBLIOGRAPHIE

George Karypis et Vipin Kumar : A fast and high quality multilevel scheme
for partitioning irregular graphs. SIAM Journal on scientiï¬c Computing, 20
(1):359â€“392, 1998a.

George Karypis et Vipin Kumar : Multilevelk-way partitioning scheme for
irregular graphs. Journal of Parallel and Distributed computing, 48(1):96â€“
129, 1998b.

Stephen Kelley : The existence and discovery of overlapping communities in
large-scale networks. Th`ese de doctorat, RENSSELAER POLYTECHNIC
INSTITUTE, 2009.

Anne-Marie Kermarrec, Erwan Le Merrer, Bruno Sericola et Gilles
TrÂ´edan : Second order centrality : Distributed assessment of nodes criti-
city in complex networks. Computer Communications, 34(5):619â€“628, 2011.

Zuhair Khayyat, Karim Awara, Amani Alonazi, Hani Jamjoom, Dan
Williams et Panos Kalnis : Mizan : a system for dynamic load balancing
in large-scale graph processing.
In Proceedings of the 8th ACM European
Conference on Computer Systems, pages 169â€“182. ACM, 2013.

Yehuda Koren, Liran Carmel et David Harel : Ace : A fast multiscale eigen-
vectors computation for drawing huge graphs. In Information Visualization,
2002. INFOVIS 2002. IEEE Symposium on, pages 137â€“144. IEEE, 2002.

Valdis Krebs : Books about us politics. unpublished, http ://www. orgnet. com,

2004.

S Kullback : Statistics and information theory. J. Wiley and Sons, New York,

1959.

Konstantin Kuzmin, Mingming Chen et Boleslaw K Szymanski : Parallelizing
slpa for scalable overlapping community detection. Scientiï¬c Programming,
2015:4, 2015.

Andrea Lancichinetti, Santo Fortunato et JÂ´anos KertÂ´esz : Detecting the
overlapping and hierarchical community structure in complex networks. New
Journal of Physics, 11(3):033015, 2009.

Andrea Lancichinetti, Santo Fortunato et Filippo Radicchi : Benchmark
graphs for testing community detection algorithms. Physical review E, 78
(4):046110, 2008.

Andrea Lancichinetti, Filippo Radicchi, JosÂ´e J Ramasco et Santo Fortu-
nato : Finding statistically signiï¬cant communities in networks. PloS one,
6(4):e18961, 2011.

Cornelius Lanczos : An iteration method for the solution of the eigenvalue
problem of linear diï¬€erential and integral operators. United States Governm.
Press Oï¬ƒce Los Angeles, CA, 1950.

BIBLIOGRAPHIE

201

Conrad Lee, Fergal Reid, Aaron McDaid et Neil Hurley : Detecting highly
overlapping community structure by greedy clique expansion. In SNAKDD
Workshop, page 4533â€“42, 2010.

Ian XY Leung, Pan Hui, Pietro Lio et Jon Crowcroft : Towards real-time
community detection in large networks. Physical Review E, 79(6):066107,
2009.

Wei Liu, Xingpeng Jiang, Matteo Pellegrini et Xiaofan Wang : Discove-
ring communities in complex networks by edge label propagation. Scientiï¬c
reports, 6, 2016.

Hao Lou, Shenghong Li et Yuxin Zhao : Detecting community structure using
label propagation with weighted coherent neighborhood propinquity. Physica
A : Statistical Mechanics and its Applications, 392(14):3095â€“3105, 2013.

LÂ´aszlÂ´o LovÂ´asz : Combinatorial problems and exercises, volume 361. American

Mathematical Soc., 1993.

Yucheng Low, Joseph E. Gonzalez, Aapo Kyrola, Danny Bickson, Carlos
Guestrin et Joseph M. Hellerstein : Graphlab : A new framework for
parallel machine learning. CoRR, abs/1408.2041, 2014.

Robert Harry Lowie : Social organization. 1950.

R Duncan Luce et Albert D Perry : A method of matrix analysis of group

structure. Psychometrika, 14(2):95â€“116, 1949.

David Lusseau, Karsten Schneider, Oliver J Boisseau, Patti Haase, Elisa-
beth Slooten et Steve M Dawson : The bottlenose dolphin community of
doubtful sound features a large proportion of long-lasting associations. Be-
havioral Ecology and Sociobiology, 54(4):396â€“405, 2003.

Grzegorz Malewicz, Matthew H Austern, Aart JC Bik, James C Dehnert,
Ilan Horn, Naty Leiser et Grzegorz Czajkowski : Pregel : a system for
large-scale graph processing. In Proceedings of the 2010 ACM SIGMOD In-
ternational Conference on Management of data, pages 135â€“146. ACM, 2010.

Spiros Mancoridis, Brian S Mitchell, Chris Rorres, Yih-Farn Chen et
Emden R Gansner : Using automatic clustering to produce high-level system
organizations of source code. In IWPC, volume 98, pages 45â€“52, 1998.

Christopher D Manning, Prabhakar Raghavan et Hinrich SchÂ¨utze : Flat

clustering. Introduction to information retrieval, pages 350â€“374, 2008.

Claire P Massen et Jonathan PK Doye : Thermodynamics of community

structure. arXiv preprint cond-mat/0610077, 2006.

Aaron F McDaid, Derek Greene et Neil Hurley : Normalized mutual infor-
mation to evaluate overlapping community ï¬nding algorithms. arXiv preprint
arXiv :1110.2515, 2011.

202

BIBLIOGRAPHIE

Guy Melancon : Just how dense are dense graphs in the real world ? : a me-
thodological note. In Proceedings of the 2006 AVI workshop on BEyond time
and errors : novel evaluation methods for information visualization, pages
1â€“7. ACM, 2006.

Pasquale De Meo, Emilio Ferrara, Giacomo Fiumara et Alessandro Pro-
vetti : Generalized louvain method for community detection in large net-
works.
In Intelligent Systems Design and Applications (ISDA), 2011 11th
International Conference on, pages 88â€“93. IEEE, 2011.

Seunghyeon Moon, Jae-Gil Lee, Minseo Kang et al. : Scalable community de-
tection from networks by computing edge betweenness on mapreduce. In 2014
International Conference on Big Data and Smart Computing (BIGCOMP),
pages 145â€“148. IEEE, 2014.

Jacob L Moreno : Who shall survive, volume 58. JSTOR, 1934.

Jacob Levy Moreno : Sociometry, experimental method and the science of

society. 1951.

George Peter Murdock : Social structure. 1949.

S Nadel : The theory of social structure (cohen and west, london). 1957.

TamÂ´as Nepusz, Andrea PetrÂ´oczi, LÂ´aszlÂ´o NÂ´egyessy et FÂ¨ulÂ¨op BazsÂ´o : Fuzzy
communities and the concept of bridgeness in complex networks. Physical
Review E, 77(1):016107, 2008.

